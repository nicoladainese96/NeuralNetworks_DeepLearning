{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting MNIST characters with Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io # used to load dataset\n",
    "import time # used to evaluate time performances\n",
    "import funcy # used for verbose\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, SubsetRandomSampler\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset\n",
    "mat_dict = scipy.io.loadmat('MNIST.mat')\n",
    "# extract the images and their labels from the dictionary\n",
    "images = mat_dict['input_images']\n",
    "labels = mat_dict['output_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels):\n",
    "    \"\"\"\n",
    "    Encodes a categorical variable with one hot encoding.\n",
    "    \"\"\"\n",
    "    possible_labels = np.arange(10)\n",
    "    n_samples = labels.shape[0]\n",
    "    mask = np.tile(possible_labels, (n_samples,1))\n",
    "    enc_labels = (mask == labels).astype('int')\n",
    "    return enc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_labels = encode_labels(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search with cross validation\n",
    "\n",
    "This is an adaptation of the code of the first assignment used to perform the grid search vith cross validation. The change is due to the fact that in pytorch the loss and the optimizer must be separated from the model class that we want to train for issues in tracking the gradient. \n",
    "\n",
    "I tried to implement a method train for the neural network in Pytorch, but it slowed down the training speed from epoch to epoch, hence I decided to stick with the standar way of training a net and changed instead the grid search procedure. Also I use the accuracy on the validation set instead of the loss to score the various models.\n",
    "\n",
    "I also tried to use different frameworks to perform the grid search with cross validation, namely skorch and tune, but the effort that they required was not worth the (supposed) gain in performance, since Pytorch already parallelizes training on the CPU's cores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_K_folds(x, y, K=5):\n",
    "    \"\"\"\n",
    "    Splits training set x with associated labels y in K (default 5) subsets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy array, training set \n",
    "    y : numpy array, training labels\n",
    "    K : int, number of folds (optional)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x_subsets : list of K numpy arrays\n",
    "        Contains the K training subsets\n",
    "    y_subsets : list of K numpy arrays\n",
    "        Contains the labels of the K subsets\n",
    "    \"\"\"\n",
    "    m = x.shape[0]\n",
    "    permutation = np.random.permutation(m)\n",
    "    x_shuffled = x[permutation]\n",
    "    y_shuffled = y[permutation]\n",
    "    \n",
    "    subset_length = int(m/K)\n",
    "    x_subsets = []\n",
    "    y_subsets = []\n",
    "    for i in range(subset_length-1):\n",
    "        x_subsets.append(x_shuffled[i*subset_length: (i+1)*subset_length])\n",
    "        y_subsets.append(y_shuffled[i*subset_length: (i+1)*subset_length])\n",
    "    \n",
    "    x_subsets.append(x_shuffled[(K-1)*subset_length:])\n",
    "    y_subsets.append(x_shuffled[(K-1)*subset_length:])\n",
    "    \n",
    "    return x_subsets, y_subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_HP(model, params, x_training, y_training, K, verbose):\n",
    "    \"\"\"\n",
    "    Train and evaluates a model given some parameters using a K-fold cross validation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model      : class of the predictor\n",
    "        Must be instantiated as model(**params)\n",
    "        Must have a \"train\" method like:\n",
    "        net.train(x_train, y_train, x_val, y_val, train_log=True, verbose=False)\n",
    "    params     : dictionary {'model_HP':value}\n",
    "        hyper-parameters of the model\n",
    "    x_training : numpy array, training set \n",
    "    y_training : training labels\n",
    "    K          : int, number of folds\n",
    "    \n",
    "    \"\"\"\n",
    "    Kfolds_val_acc = []\n",
    "    epochs_length = []\n",
    "    x_subsets, y_subsets = get_K_folds(x_training, y_training, K)\n",
    "    \n",
    "            \n",
    "    for i in range(K):\n",
    "        print(\"Computing fold %d out of %d...\"%(i+1,K))\n",
    "        \n",
    "        # instantiate new network\n",
    "        #net = model(**params) # CHANGE HERE\n",
    "        \n",
    "        # validation sets for this fold\n",
    "        x_val = x_subsets[i]\n",
    "        y_val = y_subsets[i]\n",
    "        \n",
    "        # training sets\n",
    "        x_train = np.array([])\n",
    "        y_train = np.array([])\n",
    "        for j in range(K):\n",
    "            if j != i:\n",
    "                if len(x_train) == 0:\n",
    "                    x_train = x_subsets[j]\n",
    "                    y_train = y_subsets[j]\n",
    "                else:\n",
    "                    x_train = np.concatenate((x_train, x_subsets[j]), axis=0)\n",
    "                    y_train = np.concatenate((y_train, y_subsets[j]), axis=0)\n",
    "        \n",
    "        \n",
    "        train_loss_log, val_loss_log, val_acc_log = train_torchNN(model, x_train, y_train, x_val, y_val, \n",
    "                                                                train_log=True, verbose=verbose, debug=False, \n",
    "                                                                train_batch_size=128, val_batch_size=128, **params) \n",
    "        # either choose the last element or the smaller (could be a good choice if early stopping is implemented)\n",
    "        Kfolds_val_acc.append(val_acc_log[-1])\n",
    "        epochs_length.append(len(val_acc_log)) #record the real number of training epochs\n",
    "\n",
    "    HP_score = np.array(Kfolds_val_acc).mean()\n",
    "    HP_deviation = np.array(Kfolds_val_acc).std()\n",
    "    mean_epochs = int(np.mean(epochs_length))\n",
    "    return HP_score, HP_deviation, mean_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parameters(params):\n",
    "    print(\"Parameters: \")\n",
    "    print('='*75)\n",
    "    for key in params:\n",
    "        if (key == 'lr') or (key == 'loss') or (key=='act'):\n",
    "            print(key, '\\t \\t', params[key])\n",
    "        else:\n",
    "            print(key, '\\t', params[key])\n",
    "    print('='*75)\n",
    "\n",
    "def print_HP_score(params,score,dev):\n",
    "    print_parameters(params)\n",
    "    print(\"Score: %.4f +/- %.4f\"%(score,dev))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearchCV(model, x_training, y_training, params_comb, K_folds=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    model      : class of the predictor\n",
    "        Must be instantiated as model(**params)\n",
    "        Must have a \"train\" method like:\n",
    "        net.train(x_train, y_train, x_val, y_val, train_log, verbose)\n",
    "    params_comb: list of dictionaries {'model_HP':value}\n",
    "        all combinations of hyper-parameters to be evaluated\n",
    "    x_training : numpy array, training set \n",
    "    y_training : training labels\n",
    "    K_folds    : int, number of folds\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    scoring    : list of all the mean cross-validation losses \n",
    "    deviations : list of all the std deviations of the cross-validation losses \n",
    "    mean_epochs: list of the mean number of epochs of training for each \n",
    "                 configuration of HPs\n",
    "    \"\"\"\n",
    "    import time\n",
    "    scoring = []\n",
    "    deviations = []\n",
    "    mean_epochs = []\n",
    "    combinations = len(params_comb)\n",
    "    init_time = time.time()\n",
    "    for i in range(combinations):\n",
    "        start = time.time()\n",
    "        params = params_comb[i]\n",
    "        HP_score, HP_deviation, epochs = evaluate_HP(model, params, x_training, y_training, K=K_folds, verbose=verbose)\n",
    "        scoring.append(HP_score)\n",
    "        deviations.append(HP_deviation)\n",
    "        mean_epochs.append(epochs)\n",
    "        \n",
    "        print('\\nParameters configuration %d out of %d'%(i+1,len(params_comb)))\n",
    "        print_HP_score(params,HP_score,HP_deviation)\n",
    "        finish = time.time()\n",
    "        print('Time for evaluation: %.1f s'%(finish-start))\n",
    "        time_to_finish = (combinations-i-1)*(finish-init_time)/(i+1)\n",
    "        \n",
    "        if time_to_finish > 3600:\n",
    "            print('Estimated time to finish : %.2f h'%(time_to_finish/3600), '\\n')\n",
    "        elif time_to_finish < 3600 and time_to_finish > 60:\n",
    "            print('Estimated time to finish : %.2f min'%(time_to_finish/60), '\\n')\n",
    "        else:\n",
    "            print('Estimated time to finish : %.2f s'%(time_to_finish), '\\n')\n",
    "    return scoring, deviations, mean_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully-connected neural network in Pytorch\n",
    "\n",
    "The architecture of the network is standard, the only notable upgrades are that I introduced the possibility of getting a custom number of hidden layers and that the output does not have an activation function because this is already done by the CrossEntropyLoss. An identical alternative would have been to use the softmax activation in the last layer and the NLL_loss as a loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, h_sizes, out_size, dropout, n_epochs, act=F.relu):\n",
    "        super(Net, self).__init__()\n",
    "        # Hidden layers\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for k in range(len(h_sizes)-1):\n",
    "            self.hidden.append(nn.Linear(h_sizes[k], h_sizes[k+1]))\n",
    "            self.hidden.append(nn.Dropout(dropout))\n",
    "        # Output layer\n",
    "        self.out_layer = nn.Linear(h_sizes[-1], out_size)\n",
    "        # Activation function of the hidden layers\n",
    "        self.act = act\n",
    "        self.n_epochs = n_epochs\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Feedforward\n",
    "        for layer in self.hidden:\n",
    "            x = self.act(layer(x))\n",
    "        out = self.out_layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My main effort has been directed towards the functions to train and evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_torchNN(model, x_train, y_train, x_val, y_val, train_log=True, verbose=True, debug=True, \n",
    "                  return_model = False, train_batch_size=128, val_batch_size=128, **params):\n",
    "    \"\"\"\n",
    "    Trains a Pytorch model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Pytorch nn.Module class with forward method\n",
    "    x_train: numpy array, training data\n",
    "    y_train: numpy array, training labels, one hot encoded\n",
    "    x_val: numpy array, validation data\n",
    "    y_val: numpy array, validation labels, one hot encoded\n",
    "    train_log: bool, if True returns train loss, val loss and val accuracy for each epoch\n",
    "    verbose: bool, if True prints updates of the training 10 times for each epoch\n",
    "    debug: bool\n",
    "        If True time-profiles the operations of forward, loss, backward prop and optimizer step\n",
    "        Returns an array of containing the time profile for each batch of each epoch\n",
    "    return_model: bool, if True returns the trained instance of the model \n",
    "    train_batch_size: int, number of samples in each training batch\n",
    "    val_batch_size: int, number of samples in each validation batch\n",
    "    **params: dictionary containing all the parameters needed by the model, the optimizer and the loss\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    net (if return_model): trained instance of the model \n",
    "    train_loss_log (if train_log): list, training loss for each epoch\n",
    "    val_loss_log (if train_log): list, validation loss for each epoch\n",
    "    val_acc_log (if train_log): list, validation accuracy for each epoch\n",
    "    epoch_time (if debug): list, time to complete each epoch\n",
    "    epoch_profiler (if debug): numpy array, time profile for each batch of each epoch\n",
    "    \n",
    "    \"\"\"\n",
    "    model_keys = ['n_epochs','out_size', 'h_sizes','dropout','act'] # parameters of the model\n",
    "    optim_keys = ['lr','weight_decay'] # parameters of the optimizer\n",
    "    model_params = {}\n",
    "    optim_params = {}\n",
    "    # reads out the params dictionary and fills the model and optim dictionaries\n",
    "    for k in params.keys():\n",
    "        if k in model_keys:\n",
    "            model_params[k] = params[k]\n",
    "        elif k in optim_keys:\n",
    "            optim_params[k] = params[k]\n",
    "    \n",
    "    # init method\n",
    "    net = model(**model_params)\n",
    "    # init optimizer\n",
    "    optimizer = params['optimizer'](net.parameters(), **optim_params)\n",
    "    # define loss (params['loss'] is usually torch.nn.CrossEntropyLoss())\n",
    "    loss = params['loss']\n",
    "    \n",
    "    # define contextual print functions activated by print flags\n",
    "    verbose_print = print if verbose else lambda *a, **k: None\n",
    "    debug_print  = print if debug else lambda *a, **k: None\n",
    "    verbose_print(\"Verbose: \", verbose)\n",
    "    debug_print(\"Debug: \", debug)\n",
    "    \n",
    "    # convert x and y to tensors\n",
    "    x_train = torch.from_numpy(x_train)\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    x_val1 = torch.from_numpy(x_val)\n",
    "    y_val1 = torch.from_numpy(y_val)\n",
    "    # create training and validation TensorDatasets\n",
    "    train_set = TensorDataset(x_train,y_train)\n",
    "    val_set = TensorDataset(x_val1,y_val1)\n",
    "    # create samplers for batches\n",
    "    train_sampler = SubsetRandomSampler(np.arange(len(x_train)))\n",
    "    val_sampler = SubsetRandomSampler(np.arange(len(x_val)))\n",
    "    # create DataLoaders to load batches\n",
    "    train_loader = DataLoader(train_set, train_batch_size, train_sampler, num_workers = 2)\n",
    "    val_loader = DataLoader(val_set, val_batch_size, val_sampler, num_workers = 2)\n",
    "    \n",
    "    n_batches = len(train_loader)\n",
    "    epoch_time = []\n",
    "    #Time for printing\n",
    "    training_start_time = time.time()\n",
    "    # lists with the history of the training\n",
    "    if (train_log == True):\n",
    "        train_loss_log = []\n",
    "        val_loss_log = []\n",
    "        val_acc_log = []\n",
    "    if debug:\n",
    "        epoch_profiler = []\n",
    "    #Loop for n_epochs\n",
    "    for epoch in range(net.n_epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        print_every = n_batches // 10 # frequency of printing\n",
    "        start_time = time.time()\n",
    "        total_train_loss = 0\n",
    "        batches_done = 0\n",
    "        if debug:\n",
    "            batch_profiler = []\n",
    "        net.train() # activate dropout\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            batches_done += 1\n",
    "            #Get inputs\n",
    "            inputs, labels = data\n",
    "            #Wrap them in a Variable object\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            #Set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            #Forward pass, backward pass, optimize\n",
    "            tb_0 = time.time()\n",
    "            outputs = net.forward(inputs) \n",
    "            tb_1 = time.time()\n",
    "            loss_size = loss(outputs, torch.max(labels, 1)[1])\n",
    "            tb_2 = time.time()\n",
    "            loss_size.backward()\n",
    "            tb_3 = time.time()\n",
    "            optimizer.step()\n",
    "            tb_4 = time.time()\n",
    "            if debug:\n",
    "                batch_profiler.append([tb_1-tb_0,tb_2-tb_0,tb_3-tb_0,tb_4-tb_0])\n",
    "            #Print statistics\n",
    "            running_loss += loss_size.item() \n",
    "            total_train_loss += loss_size.item()\n",
    "            #Print every 10th batch of an epoch\n",
    "            if ((i+1) % (print_every) == 0) or (i == n_batches - 1):\n",
    "                verbose_print('\\r'+\"Epoch {}, {:d}% \\t Train loss: {:.3f} took: {:.2f}s \".format(\n",
    "                        epoch+1, int(100 * (i+1) / n_batches), running_loss / batches_done,\n",
    "                        time.time() - start_time), end=' ')\n",
    "                \n",
    "        epoch_time.append(time.time() - start_time)\n",
    "        if debug:\n",
    "            epoch_profiler.append(batch_profiler)\n",
    "        if (train_log == True):\n",
    "            train_loss_log.append(total_train_loss/len(train_loader))\n",
    "        \n",
    "        \n",
    "        #At the end of the epoch, do a pass on the validation set\n",
    "        total_val_loss = 0\n",
    "        t_val0 = time.time()\n",
    "        with torch.no_grad(): # disable gradient tracking\n",
    "            net.eval() #disable dropout\n",
    "            for inputs, labels in val_loader:\n",
    "                #Forward pass\n",
    "                val_outputs = net.forward(inputs)\n",
    "                val_loss_size = loss(val_outputs, torch.max(labels, 1)[1])\n",
    "                total_val_loss += val_loss_size.item()\n",
    "            if (train_log == True):\n",
    "                val_loss_log.append(total_val_loss/ len(val_loader))\n",
    "            t_val1 = time.time() - t_val0\n",
    "            if debug:\n",
    "                debug_print(\"Val. loss: {:.3f} took: {:.2f}s\".format(total_val_loss / len(val_loader),t_val1), end=' ')\n",
    "            else:\n",
    "                verbose_print(\"Val. loss: {:.3f}\".format(total_val_loss / len(val_loader)), end=' ')\n",
    "        t_val1 = time.time() - t_val0\n",
    "        \n",
    "        # evaluate also accuracy\n",
    "        t_val0 = time.time()\n",
    "        accuracy = eval_accuracy(net,x_val,y_val) # defined as a separate function\n",
    "        if (train_log == True):\n",
    "            val_acc_log.append(accuracy)\n",
    "        t_val1 = time.time() - t_val0\n",
    "        if debug:\n",
    "            debug_print(\" Val. score: {:.3f}% took: {:.2f}s\".format(accuracy,t_val1))\n",
    "        else:\n",
    "            verbose_print(\" Val. score: {:.3f}%\".format(accuracy))\n",
    "\n",
    "    verbose_print(\"Training finished, took {:.3f}s\".format(time.time() - training_start_time))\n",
    "    if train_log:\n",
    "        if debug and return_model:\n",
    "            epoch_profiler = np.array(epoch_profiler)\n",
    "            return net, train_loss_log, val_loss_log, val_acc_log, epoch_time, epoch_profiler # used for debugging\n",
    "        elif debug and not return_model:\n",
    "            return train_loss_log, val_loss_log, val_acc_log, epoch_time, epoch_profiler # used for debugging\n",
    "        elif not debug and return_model:\n",
    "            return net, train_loss_log, val_loss_log, val_acc_log # used for final model\n",
    "        else:\n",
    "            return train_loss_log, val_loss_log, val_acc_log  #used during cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(net, x_test,y_test, return_predictions=False):\n",
    "    # convert x and y to tensors\n",
    "    x_test = torch.from_numpy(x_test)\n",
    "    y_test = torch.from_numpy(y_test)\n",
    "    # create training and validation TensorDatasets\n",
    "    test_set = TensorDataset(x_test,y_test)\n",
    "    # create DataLoaders to load batches\n",
    "    if return_predictions:\n",
    "        test_loader = DataLoader(test_set, batch_size = 1)\n",
    "    else:\n",
    "        test_loader = DataLoader(test_set, batch_size = 16, num_workers = 2)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    if return_predictions:\n",
    "        y_pred = []\n",
    "    with torch.no_grad():\n",
    "        net.eval() #disable dropout\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = net.forward(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            predicted = predicted.numpy()\n",
    "            if return_predictions:\n",
    "                y_pred.append(predicted)\n",
    "            target_labels = np.dot(labels,np.arange(10)) #decode labels\n",
    "            total += len(target_labels)\n",
    "            correct += (predicted == target_labels).sum()\n",
    "    accuracy = 100 * correct / total\n",
    "    if return_predictions:\n",
    "        return accuracy, np.array(y_pred).flatten()\n",
    "    else:\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of parameters dictionary\n",
    "net_dict = {'h_sizes' : [784,400,200],\n",
    "           'out_size' : 10,\n",
    "           'dropout' : 0.2,\n",
    "           'loss' : torch.nn.CrossEntropyLoss(),\n",
    "           'optimizer' : optim.Adamax,\n",
    "           'lr' : 0.01,\n",
    "           'n_epochs' : 10,\n",
    "           'penalty' : 1e-5,\n",
    "            'act': F.leaky_relu}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 54000 # 9/10 for training and validation\n",
    "x_training = images[:training_size]\n",
    "y_training = enc_labels[:training_size]\n",
    "x_test = images[training_size:]\n",
    "y_test = enc_labels[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just needed for single training\n",
    "train_len = int(training_size*4/5)\n",
    "x_train = x_training[:train_len]\n",
    "y_train = y_training[:train_len]\n",
    "x_val = x_training[train_len:]\n",
    "y_val = y_training[train_len:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train a model to make sure that everything works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose:  True\n",
      "Debug:  True\n",
      "Epoch 1, 100% \t Train loss: 0.274 took: 10.82s  Val. loss: 0.162 took: 0.76s  Val. score: 95.019% took: 1.97s\n",
      "Epoch 2, 100% \t Train loss: 0.126 took: 12.97s  Val. loss: 0.104 took: 0.81s  Val. score: 96.907% took: 3.56s\n",
      "Epoch 3, 100% \t Train loss: 0.090 took: 13.76s  Val. loss: 0.091 took: 0.93s  Val. score: 97.435% took: 2.16s\n",
      "Epoch 4, 100% \t Train loss: 0.074 took: 13.59s  Val. loss: 0.085 took: 0.79s  Val. score: 97.315% took: 2.49s\n",
      "Epoch 5, 100% \t Train loss: 0.059 took: 12.84s  Val. loss: 0.089 took: 0.85s  Val. score: 97.472% took: 2.38s\n",
      "Epoch 6, 100% \t Train loss: 0.050 took: 11.10s  Val. loss: 0.088 took: 0.74s  Val. score: 97.565% took: 2.08s\n",
      "Epoch 7, 100% \t Train loss: 0.043 took: 11.79s  Val. loss: 0.092 took: 0.74s  Val. score: 97.657% took: 2.19s\n",
      "Epoch 8, 100% \t Train loss: 0.034 took: 11.76s  Val. loss: 0.089 took: 0.78s  Val. score: 97.694% took: 2.32s\n",
      "Epoch 9, 100% \t Train loss: 0.031 took: 12.75s  Val. loss: 0.081 took: 0.93s  Val. score: 98.000% took: 2.31s\n",
      "Epoch 10, 100% \t Train loss: 0.028 took: 12.97s  Val. loss: 0.084 took: 0.89s  Val. score: 98.000% took: 2.20s\n",
      "Training finished, took 156.412s\n",
      "CPU times: user 4min 3s, sys: 2min 36s, total: 6min 39s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = train_torchNN(Net, x_train, y_train, x_val, y_val, train_log=True, verbose=True, debug=True, \n",
    "                           return_model=True, train_batch_size=128, val_batch_size=128, **net_dict)\n",
    "net, train_loss_log, val_loss_log, val_acc_log, epoch_time, epoch_profiler = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection to see if there are performance issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_time, '-o', label = 'batch size 128')\n",
    "plt.xlabel('Number of epochs', fontsize=16)\n",
    "plt.ylabel('Time for an epoch [s]', fontsize=16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAF4CAYAAAAi4UHLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydeZwU5Z3/P09V9xwwKggaxSOgRuUeRdF4RNQYrw2J0bgeuCKbn3ETdVlj7iWHcaNxXTXZXG4UNSauB24QjauSFUWjIqBEAeUQBhhQuWGuvur5/v6oep5+qrq6u7qnerq6+3n7wpnprq56uruqnu/z+V6MiKDRaDQajaaxMKo9AI1Go9FoNAOPNgA0Go1Go2lAtAGg0Wg0Gk0Dog0AjUaj0WgaEG0AaDQajUbTgGgDQKPRaDSaBiRW7QFUkuHDh9PIkSOrPQyNRqPRaAaMpUuXbieiA4ptV9cGwMiRI7FkyZJqD0Oj0Wg0mgGDMbYhyHbaBaDRaDQaTQOiDQCNRqPRaBoQbQBoNBqNRtOA1HUMgEaj0WiypNNpdHZ2IpFIVHsomhBoaWnBoYceing8XtbrtQGg0Wg0DUJnZyf22WcfjBw5Eoyxag9H0w+ICDt27EBnZydGjRpV1j60C0Cj0WgahEQigWHDhunJvw5gjGHYsGH9UnO0AaDRaDQNhJ7864f+fpfaANBoNBpNZLnnnnvQ29sr/77ggguwe/fuwK+fN28ebr/99koMLYcHH3wQW7ZsCW1/t912G4466igcc8wxeP7550Pbr0AbABqNRqOJLF4D4Nlnn8WQIUMCv37q1Kn4zne+068xZDKZQNuFaQCsXLkSjz76KFasWIHnnnsOX/va12BZVij7FmgDQKPRaDQDxl133YVx48Zh3LhxuOeeewAAHR0dOPbYY3HllVdi9OjRuOSSS9Db24tf/OIX2LJlC84880yceeaZAOwKr9u3b5evmT59Oo4++mhceeWV+Mtf/oJTTz0Vn/rUp/Dmm28CsCfl66+/HgDQ3t4u/7W2tuLll19GT08PZsyYgcmTJ+O4447DU089JV83depUnHXWWTj77LNd78GyLEyfPh3jxo3D+PHjcffdd2POnDlYsmQJrrzySrS3t6Ovrw9Lly7FGWecgUmTJuHcc8/Fhx9+CACYMmUK/vmf/xnt7e0YN26cHKvKU089hcsuuwzNzc0YNWoUjjrqKN/t+oPOAtBoNJoG5MdPr8DKLXtD3eeYEfvih58fm/f5pUuX4oEHHsCiRYtARDjppJNwxhlnYOjQoVi1ahXuv/9+nHrqqZgxYwZ+/etf4+abb8Zdd92FBQsWYPjw4Tn7W7t2LZ544gnMnj0bJ554Ih555BG8+uqrmDdvHn76059i7ty5ru2XLVsGAHj66adxxx134JRTTsEPf/hDnHXWWZg9ezZ2796NyZMn47Of/SwA4K233sI777yD/fffP2c/mzdvxvLlywEAu3fvxpAhQ/DLX/4Sd955J0444QSk02nccMMNeOqpp3DAAQfgsccew/e//33Mnj0bANDb24tly5Zh4cKFmDFjhtyXYPPmzTj55JPl34ceeig2b94c9KsIhFYANBqNZE9yD7b3ba/2MDR1yquvvoqLLroIgwcPRltbG770pS/hlVdeAQAcdthhOPXUUwEA06ZNw6uvvlp0f6NGjcL48eNhGAbGjh2Ls88+G4wxjB8/Hh0dHb6vWbNmDb75zW/i8ccfRzwexwsvvIDbb78d7e3tmDJlChKJBDZu3AgAOOecc3ImfwA44ogjsG7dOtxwww147rnnsO++++Zss2rVKixfvhznnHMO2tvbceutt6Kzs1M+f/nllwMAPvOZz2Dv3r0lxTWEhVYANBqN5I7Fd2Bz92Y8eN6D1R6KpsIUWqlXA29Ee5AI9+bmZvm7YRjyb8MwfP323d3duPTSS/G73/0OBx98MAA7n/7JJ5/EMccc49p20aJFGDx4sO9xhw4dir/97W94/vnn8dvf/haPP/64XNkLiAhjx47F66+/7ruPYu/3kEMOwaZNm+TfnZ2dOOSQQ3z3VS5aAdBoNJK9yb3oSnVVexiaOuX000/H3Llz0dvbi56eHvzpT3/C6aefDgDYuHGjnCwfeeQRnHbaaQCAffbZB11d4ZyTM2bMwDXXXCOPCQDnnnsu/vM//xNEBAB4++23i+5n+/bt4Jzj4osvxq233oq33norZ6zHHHMMtm3bJt9TOp3GihUr5D4ee+wxALYqst9++2G//fZzHWPq1Kl49NFHkUwmsX79eqxZswaTJ0/ux7vPRSsAmsYlkwRWzgPGXwLo3GgAAAcHJ17tYWjqlOOPPx7Tp0+XE9lXvvIVHHfccejo6MAxxxyDX/3qV5gxYwbGjBmDf/qnfwIAXHvttTjvvPMwYsQILFiwoOxjb9iwAXPmzMHq1avlav2+++7DrFmzMHPmTEyYMAGcc4waNQrPPPOM7z7a29ul//+aa64B5/a1cttttwEApk+fjuuuuw6tra14/fXXMWfOHNx4443Ys2cPMpkMZs6cibFjbeWlpaUFxx13HNLpdI56AABjx47FpZdeijFjxiAWi+FXv/oVTNMs+/37wYTVU4+ccMIJtGTJkmoPQxNV3v8z8OgVwNffBA44pvj2DcDX/vI1bOnegrlfnFt8Y03N8d5772H06NHVHkYOHR0d+Lu/+7ucQLh6ZcqUKTJYsL/4faeMsaVEVHTn2gWgaVyslP0zk6zuOCIEOf9pNJr6R7sANI2LkLop3OIatQyBtAtAM+CMHDmyYVb/APDSSy9VewgAtAKgaWSE+4vrCU9Qzy5BjUbjRhsAGo1WACREWgHQaBoFbQBoGhex2tUTnkTHAGg0jYM2ADQNjHABaAVAoBUAjaZx0AaApnGRCoA2AAQE0nEAmkjRqO2Ad+zYgTPPPBNtbW2ymVHYaANA08BoBcCLdgFookajtgNuaWnBT37yE9x5552h7M+PATcAGGPnMcZWMcbWMsZyvhXG2GcYY28xxjKMsUs8z13NGFvj/Lt64EatqUtkGqCWvAWcdCVATWXR7YCDtQMePHgwTjvtNLS0tFTmi8AA1wFgjJkAfgXgHACdABYzxuYR0Upls40ApgO42fPa/QH8EMAJsJduS53X7hqIsWvqEB0EmAORVgAahv/9DvDRu+Hu86DxwPn55XbdDjh4O+CBYKAVgMkA1hLROiJKAXgUwBfUDYiog4jeAeC9K58LYD4R7XQm/fkAzhuIQWvqFe0C8EPHAGgqhW4H3NjtgA8BsEn5uxPASf14bU5vRMbYtQCuBYDDDz+8vFFqGgOtAOSgXQANRIGVejXQ7YAHviFZ3QUBEtF/EdEJRHTCAQccUO3haCKNzgLwooMANZVEtwMO3g54IBhoBWAzgMOUvw91Hgv62ime174Uyqg0jQlpF4AXnQaoqSS6HXDwdsCAHfC4d+9epFIpzJ07Fy+88ALGjBlT9mfgZUDbATPGYgBWAzgb9oS+GMAVRLTCZ9sHATxDRHOcv/cHsBTA8c4mbwGYREQ78x1vINsB//C1H2LyQZNx4REXDsjxNCGw5AHgmZnAJbOBcRdXezSR4Io/X4FNXZvwymWvVHsomgqg2wFHg4ZsB0xEGQDXA3gewHsAHieiFYyxWxhjUwGAMXYiY6wTwJcB3MsYW+G8dieAn8A2GhYDuKXQ5B82H3Z/iM//6fN4ceOLvs8v2LgASz9eOlDD0YSCcAHoFa9AVwLUaBqHAW8HTETPAnjW89gPlN8Xw5b3/V47G4C/VlJhMpRBx94OdKe7fZ/XbVRrEO0CyEHHAGiqgW4HXB3qLgiwUjDYEZr5JnlOXN84aw4dBOiFE9cxABpNg6ANgIAYzP6o8t0ctQJQg2gFwBd9Hms0jYE2AAIiDYA8q3ztO61h9Pcm0S4AjaZx0AZAiRRyAWgDoMbQ3QBz0C4AjaZx0AZAQIoqANoFUHuI70u7ACRaAdBEjUZtBzx//nxMmjQJ48ePx6RJk/Dii/4ZaP1BGwABEUGAeWMASBdQqT10KWAv2pWliRqN2g54+PDhePrpp/Huu+/ioYcewlVXXRXKflW0ARAQUae5YBBgTv8iTaTRvQBy0IasptLodsDB2gEfd9xxGDFiBABg7Nix6OvrQzKZDPW7GPA6ALWKcAHkm+R1DEAtorMAvGgXQOPwszd/hvd3vh/qPo/d/1h8e/K38z6v2wGX1w74ySefxPHHH+9qfhQGWgEISLE6ALqGeg2igwBz0LEsmkqi2wGX3g54xYoV+Pa3v41777236OdRKloBCIhQAPJBRLD0RFJjaAXAC5FWABqFQiv1aqDbAee+387OTlx00UX4/e9/jyOPPNJ3P/1BKwABEV9OwUqAWgGoLcR3qVe8EjH563NZUwl0O+Dg7YB3796NCy+8ELfffrtURsJGGwABCeIC0EGANYYOAsxB3AS1G0BTCdR2wCeddJJsBwxAtgMePXo0du3aldMOWAQBlotoBzx79mwZCLhkyRLMmjUL6XQaEyZMwNixYzFr1qy8+2hvbwcAbN68GVOmTEF7ezumTZuW0w64vb0dlmVhzpw5+Pa3v42JEyeivb0dr732mtyXaAd83XXX4f7778851i9/+UusXbsWt9xyixzv1q1b+/UZeBnQdsADTZjtgHvSPTj5kZNx8wk34+qxV7ueIyJM+P0EnHbIafjNZ38TyvE0A8CrdwN/+RFwxneAM79b7dFEggv+5wJs6tqEt696GzFDewjrDd0OOBo0ZDvgWqaQAqBl0xpFBwHmIM5vfS5rNPWPNvEDUigGQDymZdNaQ7sA8qEDATUDiW4HXB20AhCQQqWAxWM6BqDG0N0Ac9AxABpN46ANgIAYyN8OWN80axTtAshBGLFaAdBo6h9tAATFSdHULoB6QigA+nsTCGNWxwBoNPWPNgACIhWAAi4AfdOsMXQaYA7SnaU/E42m7tEGQEBkDIB2AdQR2gXgRSoA2gWgiQiN2g74zTfflPn/EydOxJ/+9KdQ9quiDYCAyCwAn0A/HQRYo+ggwBy0AqCJGo3aDnjcuHFYsmQJli1bhueeew5f/epXA48jKNoAKAEG5qsA6NzpWkUrAF70OaypNLodcLB2wIMGDUIsZmfqJxKJQL0RSkXXASgBgxkFCwHpVVONoWMActDncuPw0U9/iuR74bYDbh59LA763vfyPq/bAZfWDnjRokWYMWMGNmzYgIcfflgaBGGhFYASYGD+QYA6BqA2Ed+XzgKQ6HNZU0l0O+DS2gGfdNJJWLFiBRYvXozbbrsNiUSi6GdSCloBKAHGCrsA9E2z1tAuAC8yo0UHAdY9hVbq1UC3A87/fkePHo22tjYsX748lP4BAq0AlIDBDB0EWE/oIMAcdDyLppLodsDB2wGvX79eGjEbNmzA+++/j5EjR5b5zv3RCkAJ6CDAekPHAHjRCoCmkqjtgAHIdsAdHR2yHfCMGTMwZsyYnHbAI0aMwIIFC8o+tmgHvHr1arlav++++zBr1izMnDkTEyZMAOcco0aNwjPPPOO7j/b2dun/v+aaa8Ad96G3HXBraytef/11zJkzBzfeeCP27NmDTCaDmTNnYuzYsQCy7YDT6XSOegDYhsHtt9+OeDwOwzDw61//2jcOoj/odsAlMPmPk3Hp0Zfi5hNvdj2+vW87znz8TByx3xF46otPhXY8TYWZ/0Pgr/cAYy8CvvxgtUcTCU555BR0pbsw/5L5OGjwQdUejiZkdDvgaKDbAdcg+VwAOgagVtEuAC/ajaXRNA7aBVAC+VwAunpajSIMNm24SXQWgKYa6HbA1UErACXAWJ40QOcxS68kawtdByAHXQdAo2kctAFQAgysYDdArQDUKNpwk2g1S6NpHLQBUAIGM/xdAHrVVJuQrgPgRXe21GgaB20AlIDBDN+VkQ4CrFV0EKAXrQBoNI2DNgAC0rUzgfMWfR3mBp8uVGIhqVdNtYWOAchBq1maqNGo7YAFGzduRFtbG+68885Q9wtoAyAw3CLs2zscLG3mPuekTukUqhpDZwHkIBUAbcxqIkKjtgMW3HTTTTj//PND3adAGwABEWWa/eYKnTpVq2gXgBddCVBTaXQ74GDtgAFg7ty5GDVqlKweGDa6DkBAmGFbAMR9YgCgYwBqEh0EmIN2ATQOrzy+Gts3dYe6z+GHteH0S4/O+7xuBxy8HXB3dzd+9rOfYf78+RWR/wGtAASmUKemKCoACx9djTfmflDtYUQcHQPgRae0aiqJbgccvB3wj370I/zLv/wL2train4O5aIVgIAwx1Qq5AKIkt/0o3V70DJYf70F0d0A8xKlc1lTGQqt1KuBbgfs/nvRokWYM2cOvvWtb2H37t0wDAMtLS3SnREGWgEIiPxy/LoBRjAIkHMCj85wIop2Aaiok36U1CxN/aDbAQdvB/zKK6+go6MDHR0dmDlzJr73ve+FOvkDWgEITIH5P5IuAOLkG6+gUZAKQHS+t2qinr/aBaCpBLodcPB2wAOBbgcckER3Gvff/Ap2TnoPs/7f113Pvb/zfXz56S+jxWzB4mmLQzlef/njD99Aa1scX/rmpGoPJbrMuxF46yHgwLHA116r9miqToZncNzDxwEAHr3wUYwdXpnIY0310O2Ao4FuB1xrCPdMjSgAtgugfo27cNAuABV11a8VgOrTu2QJ0h9vDbz97975HV7dXDxwTqMRaAMgICIN0O++WG4a4M/f+jluePGG/g7NF7K0C6AoOgjQhY4BiBad19+AXQ//PvD2f3jvD5i/YX4FR1Q5GrEdcBir//6iDYCAdPWlAQCJVO5kIRWAEoMAO/Z0oGNPR7/H5gfn5BuvoFHRCoCKVgCiBU8mwZOp4NsT1y3JNSWhDYCA7E06BkC6gAFQ4qqJE6/YSku7AAIgPh692gXgVgDqOTaoZrAs/6jjfJuTpZUbTUloAyAghiEKAeTmpqor/1JunBwcVoVWn9oFEASdBaCiTh56Iqk+xHlJ5yYnjgwFq1mv0QDaAAgMCxAECJR246y0AqANgCLIZkBaNvWiXQARgHP43nDybV7B+4mmPtEGQEAMUygAuc+pN8tS4gA4VU4B0C6AAOggQBeu81hPJFWFiADObRUgIBmeqcsYgEZtB9zR0YHW1lbZvOi6664LZb8quhBQQMT87+eTK9d3SkQV87WG6QLo6OjAypUrccEFF4Syv+igewGo6Ek/QoiJv4RLuJILimpyzz33YNq0aRg0aBAAux1wKUydOhVTp07t1xgymQxiseLT5YMPPohx48ZhxIgR/Tqe4Mgjj5QNjCqBVgACIkoBk18MgHLjLOUCrLQCENb9fO3atVi8OBoFjkJFdwN0oRWACCEMgBIUgFoJAtTtgIO3A640WgEIiGkw5wbpowCgPAWgUj47Inv1H6a6UJ9R4doFoKLrAESHrPQf7LoT31cpQYALHvwvbN2wrtShFeTATx6BM6dfm/d53Q44eDtgAFi/fj2OO+447Lvvvrj11ltdPQzCQCsAAWHMMQB8FICygwArlAUgpH9uhTNpR7HbYShIBaDO3leZuFxZOgiwulj2fSFoDIDw/fOIZ7TodsDB2wEffPDB2LhxI95++23cdddduOKKK7B3796in0kpaAUgIIwBxDhYgUqA3t+LUSkFQAT/hTVhqwZAkBadtYN2AaiUq2RpwkfG7wT8GsRCopQFRaGVejXQ7YDdfzc3N8v3M2nSJBx55JFYvXp1qBUEtQIQEEMoACisAETBBSBW/mFlAdSvAiD8rNoAAHQlwGIs3dODeVuDR5/3C3FOBlzRi/tI1IMAdTvg4O2At23bBstRgtatW4c1a9bgiCOOKPet+6IVgIAYzFH/a6AOgFg9hLXr+jUAtAKgogsBFeaBzduxeE8Pph44pOLHIufGH9Q9JSb+qH9vuh1w8HbACxcuxA9+8APE43EYhoHf/va3vu6I/qANgIAw2AqA3/VYbvQ0EVXEYpcuAK0AFEGnAWqCYxGV2O2jH8hrrkQFoAbUrJtuugk33XRTzuOxWAx/+MMfch6/4YYbcMMN2aZpwrc/fPhwV+Dcgw8+KH9XmwtNnz4d06dPB5A/RuLee+/NeUx9nUAEEU6cOFGu+lUuvvhiXHzxxfLv9vZ2LFy40PeY06ZNk1kQfnj3VQm0CyAgzLAnet8YgDJXTpVK2xEugLArAdadAaALAbnQWQCF4QD4QF0DUgEItnmG2/7uqLsAagXe1weeTFZ7GBVHKwABMRgD+c3+KF8BEC6AsIPrZBaAVgCKQNmfREq958ZE1wEojH8ScIWOVWIdgFqJAchH1NoBJz/4AADQOm5cRfb/0ksvVWS/paIVgIA4ZYCKxgCUEjwltg37Zhu2AlB/E7+D+r60CuA6D3UQYC6cCANWXbvMGIBaNQA01WHADQDG2HmMsVWMsbWMse/4PN/MGHvMeX4RY2yk83icMfYQY+xdxth7jLHvDuS47SwAgFHuR9YfF0CprwlCNg0wnMm7bhUA9f3oFa+LuvuuQ4AA8AEyjGQgb4kxAFGvA6CJFgNqADDGTAC/AnA+gDEALmeMjfFs9o8AdhHRUQDuBvAz5/EvA2gmovEAJgH4qjAOBgLGAM548WZAJQYBAuFb7erKP4z7eN0aAOqXqVdOuhBQEYgwcAoALy0GQCsAmnIYaAVgMoC1RLSOiFIAHgXwBc82XwDwkPP7HABnM9tBTgAGM8ZiAFoBpACEWxapAIXcw/2pA6D+DAu1AmAYboC6NQC0C8CFq6CVVkRy4KCBUwCs0uoAiOh/bQBoSmGgDYBDAGxS/u50HvPdhogyAPYAGAbbGOgB8CGAjQDuJKKd3gMwxq5ljC1hjC3Ztm1baAOXhYCKKQAlVgJUf4aFGvynDYBCaAVApVxDtlHgNIBVo0ssU11LaYCl0qjtgAHgnXfewac//WmMHTsW48ePRyKRCG3fQG0FAU4GYAEYAWAUgG8wxnLKIhHRfxHRCUR0wgEHHBDawWUWAAGbujZhw94N8rn+dAMs9TVBUCf9sDIBgDqcFHQMgAtdCbAw3Pk3EHS83wXLiAWOAahnF4DXAHj22WcxZEjwYkxTp07Fd76TE25WEn5lhf0I0wDIZDKYNm0afvvb32LFihV46aWXEI/HQ9m3IK8BwBg7q8x//sWTbTYDOEz5+1DnMd9tHLl/PwA7AFwB4DkiShPRVgB/BRBeUeQiGMypAwCGO968A7e8fot8rj/dANWfYaFdAEFRXQDaANB1AApjxwBU/hrYu70Pf5m3A9uHTQgcA1Cpe0klqJV2wA/PnVvVdsAvvPACJkyYgIkTJwIAhg0bBtM0Q/0uCtUB+AuQp/h9LmI7AnAigNwSSTaLAXyKMTYK9kR/GeyJXWUegKsBvA7gEgAvEhExxjYCOAvAw46RcTKA/GWUQoY5WQAgoDfTi75Mn3yu3BunMBzCttrdLoD+769uDQD1w6nDlVOpaAWgMHYMQOXJpJ3J3IgFNkxFG+BS7iW7n/4AqS09pQ+wAE0jBmPI54/M+3yttAM+1alIWM12wKtXrwZjDOeeey62bduGyy67DN/61rdK/EYKU6wQ0PUAVpawrxcKbUBEGcbY9QCeB2ACmE1EKxhjtwBYQkTzANwPe5JfC2AnbCMBsLMHHmCMrYBtbDxARO8EHFsoECMwYuDkbuMbuTRAK1wXQP0aADoIUEXHABRmoLIApGrHjOAxALw2CgGp7YAByHbAU6dOzWkH/Itf/AI333xzwf2JdsAASm4HvGDBAtkOeN68ebjzzjsBAIlEAps++ghAsHbAF154IT73uc/lbKO2AwZs1UB0IAT82wGrro1MJoNXX30VixcvxqBBg3D22Wdj0qRJOWpEfyhmACwlolxtwgcnxa+oWkBEzwJ41vPYD5TfE7BT/ryv6/Z7fGCxhQ5vE59yV06Vku3ICvdGXrcGgCsIMPrSaaXRWQCFGag6APJ6Ays9BqAEQ7bQSr0aRKkdcN/y5Vj8zjsYNGiQ73EHoh3woYceis985jNS+bjgggvw1ltvhWoAFAoCPAxA8b6IDkRkOa8Z0FX5QMKZ3QvAIisUBUBc6DoLoEq4ggCjvXIaENSPQ7sAcuAYmEqA8nbAWOlZABE/j3U74ODtgM8991y8++676O3tRSaTwcsvv4wxY7xlc/pHXgOAiDYTUbqUnTmvCRYuWasQAxHlrbi1/f0Envnl3wJNlpWK3OU6CyAg2gWgUm4wa6PAaWAUAFnJEyywz6EW2wGfdNJJsh0wANkOePTo0di1a1dOO2ARBFguoh3w7NmzZSDgkiVLMGvWLKTTaUyYMAFjx47FrFmzsi/yXAft7e0AgM2bN2PKlClob2/HtGnTctoBt7e3w7IszJkzB9/+9rcxceJEtLe347XXXpP7Eu2Ar7vuOtx///054x06dChuuukmnHjiiWhvb8fxxx+PCy+8sF+fgZdAzYAYY8MBDCKijcpjXwUwDsDzROTfPLnOUIP28smluzcmsWl5HzgnmGZhCatSCgDpLIBg6DRAF7oXQGEIAxQDIM7LEhSAclwA1aIW2gH3LV+Oq774RXxFcQsAA9sOWGwzbdq0gtv0h6B1AGYDkImUjLFZAH4DO4L/KcbY31dgbJGDGGQQYL6bJc84RkK6+IQijAidBVAttAGgorsBFoaT/QlV+joQHz3BCHxe1koQYM1Rd/c8N0ENgBMA/J/y93UAfkpEw2BH5+eac3UIKUGAqqXtSgMUrXgzxU8ccdGG3cBD3V+YWQB1hzcLIJME0uFW2qoldC+AwpDnZ8WOI1wAjAW+9sTET6CaNN6i1g5YUqH6IC+99BJOOGHAytjkJagBsD+AjwGAMTYOwEHI1uufC+CYPK+rM7JBgPkC/0QKnpUJrgCUUj440Ci1CyAY3iDAZ/4FmHNN9cZTZXQMQGHEJ1JpN0D2mg0eA1BuNVJNEer8OggUAwC7Et+hzu9nAdhCRGucv+OorZLCZUMMAGyrXL3IXNJpKQbAQPQC0GmABfAoAHu3AIngNcbrDV0JsDCiCiAPXB+tf8ehMmIA7Nfr7y4swlhARZmgBsBfAPzICQb8BuxVv+BYABt8X1VnEOxCQIUUACrDAAg9BsClAJVeCQYAACAASURBVPR/f3VrAHiDAIk3dDaArgRYGHEpVXxOkNesEbwboHIPsbhll1nT9J86N6aCrty/BbtD320APgDwY+W5KwG8GvK4Igk5dQAIlHfSLksBCNnP5GoGZIV3t6o7A8DbDVAYAQ2KVgAKIy6rSn8yqgIQ1BBzGQDaBRAedXfPcxPIACCij4noHCLah4jOIqLtytOfBfDPlRletLBPBQaLW3lvltIASBc/ccQ+KpoFoF0A+XEFAXJtAOhVf0HE51P5LADFBRA0BkBZRNRCKmApVLUdcImLszC7Af7xj390NS8yDEOmIYZFv333RLSXiFJhDKYWYMRyFACXdFqCAqB7AVQZbzOgRncBaAWgIDRACkBWwQveC6CeFYBqtgMW10Q12gFfeeWVWLZsGZYtW4aHH34Yo0aNkoWIwqJQO+DZTte+QDCb2Yyxw8MZWvQgZrcDLpgF4PxazAAgImk46FLA1YLshitAdvKvs5tnKeheAIXJxgAMUB0AxsqKAYj6d1dL7YAvuvzyqrUDVvnv//5vXHbZZQW3KYdCQYBXwy72sz7gvgznNb8EsLHItjUN5+5ugK786YAKQCWLrpA2AIJBBBgxwEo5k3+DuwDq7fsNGWmwV/o48nsIHgNQThrg//7v/+Ijp+tdWBx00EE4//zz8z5fa+2A3/7b3/DO8uVVaQes8thjj0nDJEwKGQAMwG8YY3sD7qtyeTERQWQBcBSoBOhce8UMgEpKdjoLwOb13d0wAJw0pC3PFooBoF0ALqK+iqwGMgiwwpeB7AXAjJJ7AXh/jxq11g747DPOqFo7YMGiRYswaNAgjBs3ruBnUQ6FDICFQMkJrwsBhNO2KYIQs//HieeV3GwFgAVyAfi9Pgx0MyCbO9Z/CAMMTx53lP8GQgEAsvJ/A098Og2wMNIFUOHPRlUAVBcAT1rY+su3MfTLR6P58H3dYysjCLDQSr0aRLEd8OAqtgMWPProo9JYCJtC3QCnENGZZfxbk2+f9QBzSgHnmwzF/FEsC6CSlbt0JUCbDAesgmMmwHASpoka3gVQblvrRkGcSpW+DFwxAMrBrK4UMtv6kNnam/OaWlEAaq4dcJ4veyDaAQO2Yff4449XxP8PNEgFv7AQzYAssgooAPbPYgpAJW+2YSsAtWoAWCAULIOgKgBk2X83sAug1r7fgWbAYgCUUsCu70TcU3y+ploJAqy5dsAeBrIdMAAsXLgQhx12GI444oh+vfd8BK0EqEE2C0At4Wswwy2d8mAugEoqALoOgI1FVNiBRdztAuDaBSCI8iRSLbIxAAPjAiDmTgMUyp7fdah+XxkeLGWtWkS9HTARIbFiBa764hdxzf7DXNsNdDvgKVOm4I033ii4TX/QCkCpUNYA8MvjD6wAKOuIsCdW0kGAAOx7Z3EXgKoA8IZOA9R1AAojPp3KKwDOT08aIFk87wBqRQGoCVSjq84/S60AlACBwJDbxMeVBiiu0RKCACuqADRwO2ALBJMKSAAEdx2ABs8C0EGAhRHBf5VWALjaDdDXBVBYAYhyDEA+ItsOuELf9UsvvVSR/ZaKVgBKwYkBkAoAz/bgFmQVgMInTiUtdh0DYMPJNgLy45cFUFvvMUx0O+DCiEup0p+MWgqYXOpi/gGokf+1aABEFt0NUCOwTwWWowC4XAAyC6B6MQBhZwHIfdXYpGBRkZs1EWDGnd9FL4DGvXnmq22hsckqAJU9TvY6M1wncKEYAO0CqBB1/lkGVgAYY4cwxu5ijC1hjK1jjI1zHp/JGDupckOMEEopYCDrx3fdLAPGAPj5W/ck94TSyIPzbPBbQysAoOAxANyy/a0N7AJQT2M9ieSS7QVQ4SDAfKWAA2YBRD0IMPK4YgBq655XKoEMAMbYWADvArgKwBYAnwTQ5Dz9STRQN0Cm+JRFRKk7BsB+vqRKgNxC0krivCfPwzPrnun3OLlFMGOGM54GNgCKKgA8NwaggSe+RnQB9C1bhg9nzQr0fmUQ4IAqAKp7MVgMgDbeQiTkVu1RI6gC8B8A3gMwCsCX4E6ueg3AySGPK5owtwEgJnH/GIDgCgCB0JfuQ3e6G1u6+99JirhiAIRws6pVA8CiIgpATh0A7QIQNIoLoPuvf8XuJ+aAksmi28o0wAqPieeLARBxRUUUAN0O2E2/2gGXeM8LsxtgOp3G1VdfjfHjx2P06NGy1kCYBDUATgNwOxF1I/f0+xjAQaGOKqLYGf6KAuATAyDuDvmCAIkIDyx/AFt6sieJRRYyZMt2Pemefo+Tc4IZ1wpA0UJAfkGAdXbzLIVGrANATrlYyhT/3rPdOyvtAnCuNzD33VbEAPhc0/UcBDjg7YDV77eK7YCfeOIJJJNJvPvuu1i6dCnuvffevP0NyiWoAVDobjAcQF8IY4k+zG0ASAWAFMucCrsAdid3466ld2H+hvnyMc659Nv1ZEIwACyCGWPy9/5SqwYAke2vTXPCwp0+pUT9FABQQ2cCCBpFAUA6bf/MpItuKq7oymcBOL/kqwPgM4BacgFEvh3wvHkA7HbAF197bdXaATPG0NPTg0wmg76+PjQ1NWHffffN2a4/BM0CeBPANQCe9nnuUgB/DW1EUYYRQFmbSdYBcK5Ig0z5XD4DIM3tG03KSmW3JUs+HooCoMYAhDiZ1ZoBYJFt4b6wYw/+cXkH3jx5NA5vbVa2IKUXgOL/Jw4w07u7usflAqix77pcKC0UgOIrvKpXApQugMJZAEJNLMbq1T9BV/d7/RhpLvu0jcbRR+cvpVsr7YBPE+2AV67EuytXVqUd8CWXXIKnnnoKBx98MHp7e3H33Xf7dibsD0EVgJ8A+Dxj7AXYgYAE4LOMsYcAXATg30IdVUQp5gJwGQB50gDFSl9M+OL14vG+dP/FFOJcGgA6C4DQ46ycer0BPa5ugEoGQIO6ARqxEiA5CkAQA6A6vQDqSwFQ2wG3tbXJdsAActoBv/rqq0X3J9oBG4ZRcjvgxx9/XLYDvv3229He3o4pU6bIdsDMMHDWySdjqE+THrUd8HPPPee7MlfbAbe3t+PWW29FZ2enfN6vHbDKm2++CdM0sWXLFqxfvx7/8R//gXXr1hX9TEohkAJARC8zxr4I4B4Aoufh7QA6AHyRiBaFOqoI48oCKEMB8DMALLLCdQFwnQUA2AoAQ7YccI43RO0FoBYBivANtJI0YiXAbAxAAANAKgCVHJFyGjL/GIBiCkDQIMBCK/VqEJV2wDydRnLVKixdswaDW1vB+/pgtrW59jMQ7YAfeeQRnHfeeYjH4zjwwANx6qmnYsmSJaE2BgpcB4CI/kxEnwJwNOygwNFEdAQR/W9oo4k6RWIA3AaA/11CGgBW1gAgosq5AOq8F8Bru7qxLeXvv+VE4CB5w87NCPAGAYoVllYAovhdVwKSMQABXADyZ2U/G1cpYDUGICPSjnNfUytBgLXUDpg12ZnuvDe3/fJAtAM+/PDD8eKLLwIAenp68MYbb+DYY4/t/4egUHIpYCJaS0SvEdGqUEdSAxDLowA4J87B25thpdYCKB4DkE8B6E3nnmwlj1PNAqjjboA9loUvLVuL/7e8w/d5DqccsIjk9Y6fvDEADe4C0ApA4W0hroOKDslVCtivG2AxBSDKLoBaaAf8gx/9yH4BY2Cm6TIABrId8Ne//nV0d3dj7NixOPHEE3HNNddgwoQJ/foMvARyATDG7gYwnIiu8nnuYQAfEdE3Qx1ZJGFgis2kVgQ0mYmjN7Ygk3gDZtNReZsBiQCdFM8GAaoxAGEYANwiNLXWfxbA+90JAMD2tP/N2yK7eZO4NeZKt6oBoCoA0b2BVpLGTAMMHgNQiToAfe+8g5axY8HMrHqYTQM03N3oisQAmMx0LSaiStTbAfNUCsnVq3H1lVfiqosuAt+zF0QExtiAtgNua2vDE088kff5MAiqAEwF8EKe554H8MVwhhNxGOVVAExmwuAMAAdY8RiAjJW9SCsRA2AYDMxgdR0DsLzbDpg8dnCL7/MW2ZN/fgUAeVwAjTH5eWnMLADHAMhjRKpIF0BIn02qsxMdl/49ejzBbnL3nhgA4QLwC0KwyELciDtPN+b5WwmMlhYQtwIZiLVI0DTAQwBszPNcp/N83WNfdv6VAE3DhEEAiBBvNsvOAuhN90prs+xxcgIzGOwsovq9ka9wDICDmuO+zxMIoOwNO8cAAAGG0gyo0bMAGtAFAJkGWLwOgLiWwppeueMrtva6/duuQkCuOgD5XRCcOOJGHAkrEekYgHxEth2wUGZCLglca+2AdwE4Ks9zRwHoDmc4EccTAyBvCI78ZpABgNsGQJEgQFWmUysBEgh9mf6lAnKLYJgMBmOhnLdRVwDyiRwWZf/5bpcTA9DYCkAjNgOSQYBWkEqANmEpACKtjyz36lKqdp46AAWzALiFuNPZshYNgEghPl/GsguxOu0JENQA+AuAf2WMfUJ90Pn7ewDm+76q3mAsbxaAwQwwArIGQGEFQI0BULMAAKA30784AM4JhmnUtQvAIsJ7jgGQr94/BznlgPO5ALgtswLOql/cYBvzBtqIvQBKCQIUl1Jon4xQmjzGhzyOtxJgkW6ATaYTtd4gxtuAYIRfUC1KBHUBzAKwGMAaxtgzyMr+fwcgAeBfKzO86JGvDoCtADAQKJABoKYBqpUAATsVcHhrbtWroFADxAB09CXRx/Pk9zuIOgBc/u3jAgCzq/4pn792AUTru64kpcUACMUvpGM7/Qe8x85es4Zrri+UBcCJo8mwDYCoBwHWFI4B0NAKABF1ADgRwFwAZwKY6fz8E4DJRLS+UgOMFAzuLACeVQAYY7ZxQBxNLTFwi3wnX+kCUMp1qjEAQP9rAXCLwEwGo44NgD1pJe/ZZ0kkZFpCduWfWwiIbAXAMAHFIGtUF0AjxgBkFYAAMQDOz9DqAIj7h9cFIEsBuxWAQlkAahDggk0L8JUXvhKp67WmcD43xhgY0wYAANsIIKJ/IKKDiaiJiEYQ0XQi2lDJAUaPrAKwI7ED//bGvyFpJe0EQQLgKAAAYFm5J02a/HsBhGoASAWgfksB9ykXpJ8LQH3baV4gCFAoAC4DoEEVAF0KuCDZXgAhHTvj7wJwdwPMrQPgdx2qMQBvffwWFn24KHBPgKhT1XbAhnO/D3jvC7MbYCqVwjXXXIPx48dj4sSJFQkcLLkQUCNDDDAUF8CbH76JR1c9irW71zoxALbgLA0An0DAYlkAAPodBBi2C0DuN0IGQEJ5X34uAFUVSAkFwLt0IrIDrZjhcQE0xuTnpZHrAJQUBBjWwXk+F4DzS74YAJ9rWnUBiO8xaEngqDPg7YBVHBdAOpUqsqFNmAbA7373OwDAu+++i/nz5+Mb3/hG3joG5RLYAGCMncEY+y1j7FnG2Iuef/8X6qgiChMuAOf6S1pJAPakbisAHgPAJxXQtxcAD1kBUFwAYcz/UVQAEkUUAMtHAcg1FLQLQCVK3+9AETQGwK2OhJUFYLl+yv2rhYBc29t/vfXxW6524oCtIsaMWM5jUaRW2gE/9Mgj+OLFF+P8f/xHfO4LX3C9h4FoB7xy5UqcddZZAIADDzwQQ4YMwZIlS0L9LoJWAvwqgN8A2AlgNYCkd5NQRxVVZG4+A0BSxs/wjBMDAFkHAPAvBuTbCwBUGRcAq98YgITjXjGZvwKgjjUtYwByswB6EMfU8T/HnfxtHCcfj+aNs9KIlSMDaxgFAAHbAaufRlhXgTQAPPEH8tz1xgA495POvZ3YuGU1zvnkOdnxOXUAGJj8HosFA85a0ylTacNiXFsrfvKpQ/M+XxPtgE88Eaf/8Y8AgLfefhuLHnsMnzj6mJz9VLod8MSJEzFv3jxcfvnl2LRpE5YuXYpNmzZh8uTJJX4r+QmaBfANAI8AmEFEwbSQOkS9QRJIpvJlSDEAXC6AgApAyDEAZGVjAOrWAHDe12DT8FcAlN/zxgAQ4WNjEFa0HoEV3R1ZA6BOpNNSEd+vyUwdBOhBvYzCUgCk2yHjjQFwfubEADjtxzl33T8A+x7SzJphMlP6/qOYDaC2AwYg2wFPnTo1px3wL37xC9x8880F9yfaAQMouR3wggULZDvgefPm4c477wQA2Q4YAM455xzsv99+7pLMcLcDvvDCC/G5z30u5zhqO2DAVg1EB0LAvx2w6tqYMWMG3nvvPZxwwgn45Cc/iVNOOQWmUjI6DEqpBPhAI0/+AKQCwIiBWDaQL22lYUDUASDEW0ozADhxV8BOb6YXH/V8hPkb5uOqMTntF4rCueMCMI26NQBEEGCbaRbMAgCAlHPx+rkAks4lkFbfW6Osfj3IttbMaBgFIGg3QFd8RFjHzuMCyKcAqEGA3snd4hYMw4BpmLLMeDEXQKGVejWITDvg3j4k132Atzdvtg0VrxKDgWkHHIvFcPfdd8u/TznlFBx99NEFP49SCRoDsBRAeE2IaxUmfti/5LgAANgKgD2p8AJBgCoWt6RLoMloQm+6F893PI87Ft+BPck9JQ2RiOxKgAZzztv6NACEC8BWAHKf948ByFUAksw21tJuZ2uYQ60ZpAJgmCFWu4k2WQWg8HfuVgBCOrgzqeS4AJQsANehnPuJAearAJjMhMFy05SjRE20A15mtwOWCz7DyPnSB6IdsPiMAGD+/PmIxWIYM2ZMKJ+DIKgCcCOAPzLGVhGRf2ujRkAYAE4mgAwCpAya0CQVgFiTfRH6KgA+qTmcbEnPYAbamtrQk+7Bfs32yeC90P14/40PsWXNbpx11WipGBqmyAIo8T36EEkDwLkgB+VxAai52mJ175cGmGRCAVAfbozVrxfurG0ZmPy93gmaBshdv4cUBJjJ5wIQdQAMjwLgfD+UawCIcuQxlr2lR9EFoLYDBiDbAXd0dMh2wDNmzMCYMWNy2gGPGDECCxYsKPvYoh3w6tWr5Wr9vvvuw6xZszBz5kxMmDABnHOMPPxwzPn3f8++kDHpAmhvb5f+/2uuuUZG5XvbAbe2tuL111/HnDlzcOONN2LPnj3IZDKYOXMmxo4dCyDbDjidTueoBwCwdetWnHvuuTAMA4cccggefvjhst97PoIaAE8D2BfAAsZYL+zeACpERJ8MdWQRJFsG2G0AiMmbOfeFWJP9vF8WgN+ELnoBxFgMg+OD0ZPu8e0ZkI9N7+3Ehnd34KyrRoM7NwlhAIShAAiiZQBwNDGGOGPF6wDIng2ejQj+BkCjpgEqMQAN4wIIGAOgnvuhXQY8XxaA8wvzxABIBcDIdQEIBcDIKgBRrQMQ9XbAVk8vUuvX4eorp2HGPm1IrF4tv5SBbAc8cuRIrFq1Ku/zYRDUAPg/NIwomB/horGb/mQnc1cWAICYnY5bMAZARdQBiBkxNBlNSPO0b6xAPlJ9FtJJ+ybCHe3bMAy7EmAId6toKgAcLSZDjLE8LgAlBiBvECCXLoCUmsjSoC4AgTqJ1DNElPX9F40ByBJaDEDGPwtATPreboCiEqCfC4ATh8EMmMxUNm/s87h8RAyG88PHBVAvBDIAiGh6hcdRE2RrALljANI8basDYgUVcxSAMgyAuBl3GQBBFIB0IgNuEaw0zxoAph0DEGYQYJRIckKzYcDIowCot75MIRcATOc59eHGWP16Eav+hlEA0koqbpE6AC4XQFjXQ75mQGo3QECWGhdBgH4uAKEAuAyAGjJkI9sOGHC5AMKi1toBawBXFgDgKQTEsg6CuHABBAgCjBtxlwEQYzFkeKYkAyCVsC/0dNJyGQCGWb91APosjhbDyFsHQL1JiyBAv3bAKT8FoEFXTmoWQJS+60pBqgFQpBKgej6FrgB4KwGqCoD9gH0d82wQYL4sADUIMIoxADWJYdStWzCoCwAAwBibCOAYAC3e54jo92ENKrLkyQIA4KQB2he0aDEfRAGIGTFZByBmxBAzHAOghFzeVJ/TYjiZkfJtmDEAUTQAEpyjxXBcAD63ZPVtpwooAAmhAGgXgPx+DWY0RBCgGvhXNAZA+T20SoB5YgCypYCdyZzIZXUwGK5CYvaYnCBApRpgvhgAoSho8qCmYcJ2AajGYpTo7z05aCXAIQD+DOBk8ZA4vrJZ3RsATCoA9oUpFAD5nDxxnLzzIAYAi0kFIG7EETNipccAJJxtExbiTlqs7QKoXhYAT1noenET9v3s4WCx8IWmBCe0Goa9GiqWBSDSAH16AUgFgFQDoP4nPz+EAmAyM1LGXqVwRf4XywKoRBqgaBbm7QbIPQoA5yAre34yYjmTe9A0wJaWFuzYsQPDhg2LnBEgzrmojQtGNBUxIsKOHTvQ0pKzHg9MUAXgpwCGAfgMgFcAXARgD4AZAD4N4LKyR1BDZHMAHAWAp1zPyeedaEDfXgCeCzduxmGRhTRPI27EETfi6M30lu0CMGNCATBsBcDHCCmXUi6CVMdedL20CS3HDkXzyP18t/nx2s0Y1dqMfzgkt8RnMRIWR4tpuwD8bsiWjwJQsBCQcuOsV7mvGKoCEEYlQM6T6O3dgLa2cIuXhAWVFANQiUJAGd9jk2cFCiKXKGWA5SgAFlk5QYAZnsHctXNxxqFnYGjLUADAoYceis7OTmzbti2kdxEee/bYNU+8+fADDU8mYe3YAdOyYDQ1wdq1CzyVQjxAx8iBpqWlBYceWn5Bp6AGwLkAfgzgDefvTiJaCuAlxthvAPwzgH8oexQ1AhnuGAB1chaZAYBsIFWyAqC6ANQMg0JYGS4NjXTSQlOL/ZUaJoNhAJl+Llfc6U/B9yVjDwoc//ntezGmraU8A4BzDDINJwvAJwjQJwbArxSwCAJMk3YBqApAGEGAH3/8DN57//v4zOmLEYvt0+/9hY3bBeC+zhIWx8ZECkcPzl1dhVcK2CkElCcNUCgAdrZC9pgsTxaANwhwW982zPrrLHz/pO/jsmPtNVo8HseoUaPCGX/I/OhHP3L9rBbdr7yKTV+/Hp985BEMGj0aH/74x+h67nkc/fprVR1XJQiqzR4MYB0RWQASANSr+X8AXBj2wKKItw6AiqE8xgxnxeljAHgv3JiRawCkeVpuV8wFkE5kbx7ppCV9/tlCQNUxAMTEX2geyRD5BvAFIcEJLYYBg/n59t2+qWwp4PxpgGnlxtmoLgBz+260Jig0BSCT6QJRGpaVCGF04UFE9r+UGgToNgAe+2gnzlmySlacdLkAwhqHLAWcxwWgxACQcqEY5F8HwGCGK4WzN2O30A3iRtSoOK4IZ8FntLSCJ6J1DodFUAPgIwCiS8EG2LK/4KhQRxRhvHUAVAxlBSldAEGyAEw7CyBNacRYDHEjXlIWgPD/AyId0MkVNhwDoJ/38f4aAIUUAIvId/IOgl0HwIDJ/Fse+ykAuUqBkgaoswBw7C2P4dJXeWgxACJ1iiJUkIb39mL1yZ9G98svuwP/PArArnQGSU7ZIlKqCyDsNMBiLgDOZRVAIE8dAM5hGu5KgMmMHaNUC/UA/Or2Vw0hwYiA6tYWUF9fJOMA+ktQF8CrsAMAnwHwMIAfMsZGAsgAuBrAvEoMLnKwnF+Up1QJmcAMFtgFYJEFxpk7C6AcA8CVBmgXAuLlLrHlW+mfC6DQazL9MADsNEC7CJBfMyBXL4B8MQBESDmrrJRqCzeoCyDW1Yf99rULAYXhAiCnGkPYOdT9werqAt+zB+kNGxA74AD5uNcP720hXREFIJMvC8AnDVAZnp8LwC8IMOEoL1GtCKjS3d1d7SFISBgAzmfJWlrtx5NJsH4E3EWRoAbAjwGMcH7/d9gBgX8PYBDsyf+GPK+rK5gnBkDF5NkLj3MLZiygAZDHBSCzAKiwfJfqy948Up46ACyESoCVVAAy5LcqD4ZwAfRxHjgLoGAaoHYBgFkcTRk7pTWUdsDyc4yQQeVMtjyZcq36vTEAQrwT70D9NEIvBew5tqsUMJzrzuUC8KkDIAoBGdnzuC/TZz9XAwpAlAyAbEMV4QKwJ31KJIBGNACI6AMAHzi/pwF8w/nXYDgGQJEYAG7Z0fjcLwvAc+GahgmLLHDiaI215rgAvNG+XtwuAMvdC4BVLwYgGwSYfxvbBVDeuBKco9UwkOLka2P49QLw7QYIUQhIMQBq4IZZESyOpnR4hYCyLoDofJ5idUfJpDsLwDMJe91G7kJAIdUBkM2APCt0v0JAigHAYPgqAN4sAOkCiNDnn4+wuv2FgnOOyLTvVnvS54mEepeoC3QlwBIQLjk/A0B9hDiHGTMCdQOMG3FwzmUaYKmFgHJcADII0HAKWIXntypNAZAvyruJRdQPBcCOAciXBeCqBFggDTClgwAltgJAdgxACJMcIXoGgJhsKZV0ZwFYXgXALf2rn0Z47YDzNQPyBAFyDnLuJQQq2AvA1wVQAxUBhQJgmtWfYuV9TsQAOC4A3tdXrSFVjMCVABljowFcAuAw5FYCJCK6OuB+zgPwcwAmgPuI6HbP882wiwpNArADwN8TUYfz3AQA98LuTMgBnEhEAxaeGdgF4CgAQYIAVck/ZthBgK5eAEX8d8IFwJgnBsCIShZAYRdAOTEAaW5nD7QYzMkCyN1GvaWKid91LOf3pGMDawPAMQDSIcYARFgB4Mmk2+/viQEQtSPEat9lAIQ1FpEG6FEAsteMfZ9JWyn0JuzVPDcJjBg4cVjcgmnYAZuccoMApQsgQp9/PoQCMGjQoCqPBFkLT8YA2NXVqA4zAYJWAvwHALNhXwdbAaQ8mwS6izPGTAC/AnAOgE4Aixlj84hopbLZPwLYRURHMcYuA/AzAH/PGIsB+AOAq4job4yxYQAGOL9FTPy5wolqEnBuwYznUQCKxACUmwUwaN8m2RQIUNMAA761PPTbBVBEASjHAEg4N3G7FwDzjcr2VQVcA/QaAHFlw+jfMMOGiGA4MQChVQKMoAEgYgAomZIuANbamhsDIF0A9t/uSoAhuQCE6pCTBuj8dCTHOe8/gbdXvIt/wRWwTA7DOWczlIGJbM0Gi6eTsgAAIABJREFUEQTIwEAgWalUxwCUiPN5qmmAAMD76s8ACOoCmAXgKQAHENEhRDTK8++IgPuZDGAtEa0johSARwF8wbPNFwA85Pw+B8DZzHbGfA7AO0T0NwAgoh00wHcWxvIrAGoaoO0CCBYEGDfi/r0AAsYApBMWGANa923KbQYUQi+AshUAsW0F6gAIA6DZYIgx/ywAv6G6jQ1hADguAENVAKJ/wwzC5pu+gT1PPxNsY/GZZsKrBJjNAojO5+mKAXDSAI2WltwYAI/vX/X7h+ZUEwpAvjRA5/a8tfdj9CTsCdIyuLzXiHuEWOGLIMC2pjYAQCKTcD0fZYQCwKNQhdMnDRAAKFF/LoCgBsBBAH5NRLv7ebxDAGxS/u50HvPdhuwE4j2wsw6OBkCMsecZY28xxr7ldwDG2LWMsSWMsSVhl7uULgC/GADKDQIMXAiIu3sBZEipBFjEBZDsy6CpNYZ4s+nEAChBgCG7AEp6nVXYBcDJ9hCXowD0OTfOFtNuB+zvAiiiCji/p/wUgDpxAXS//DL63n470LZiAmxKh9gOWCgAEWosRGoMgKMAGK2t+WMAxOsqqADkTQN0FhypTAqmyFYxuLz/iMWBmOANZmBI8xAcNPggAFkDoJZiAEo1AFZsX4E7F98Zao4+5bgA6jcGIKgB8FcAoys5kADEAJwG4Ern50WMsbO9GxHRfxHRCUR0wgFKnm8YFFQAFKOAChgAxRSAuGFPRMJ/V+ziTfdlEG8x0dQSy1EAIpEGmOc1YuVfThBgwtl3q2HARD4XgN8xcxUAEdebVnyn9eICIM5zVrZ5EQZAmApABAsBQcYAZNMAWWtrbgyAp4W0eiWHZs7IUsCeNEAZAuBI/ZmkXPVzphgAziJBdQF8Z/J38PMpPwcA9Fm1FwNQqgFw2Z8vw0MrHwrXyBHGryj85sQl8N7GNQCuB3AtY+xyxtgwxpjh/RdwP5thBxEKDnUe893G8fvvBzsYsBPAQiLaTkS9AJ4FcHzA44aDzALIfbsmVxQA4jBiBqx08SBAsdrKUAYxFpPtPIX1XqyMZyph1/+PN5tIJdyFgEyT+QYilks5LoB8CoBYYZWjACRlDIDtAvCtA+DzmOuj8MYAKG1U60UBsCvIBbsxilVoczq8GIBsFkCEPk8ZA6AoAD4uAHFO+aYBhnRJyZW/1wXgKQSUslLynmMxK68LwGAG9mveDwcOPhBAbaUBplJ2WFm5LoBQ36PzXTPhAhgsDIDe8I4REYJO3J0A3oYdhLcVdvCd+s8bFJiPxQA+xRgbxRhrgt1F0FtFcB7s6oKAnXXwItl3o+cBjGeMDXIMgzMArMQAYigKgJ8bQMCtYGmADAymYRsAaZ5G3IxnDYCAKTypREYaAF4FINZkIpPq34VRqToAlrzBlj4moQCIIEC/ffgd1k8BEC6AVB26AIjzom1u5bbOdjEOGFS+68czAOdndCYgdwyAUAAKxAD47COsOgDSGCnmAkgnYTqTvuWjAIggP1EESNQCEEGAteACEOdbFAwA8sYADB4MoD4NgKBpgL+DXflvLoD3EXzCd0FEGcbY9bAncxPAbCJawRi7BcASIpoH4H4ADzPG1gLYCafVMBHtYozdBduIIADPEtGfyxlH2QifEJhM3xMY3OsCKB4EKAp3yCwARQEI6gJI9WXQMjiuGADZGIB4swFuESyLwzTLK/lQvgtAvsj3ae8KqxQSrhgA+2TgRNJAA/wVAHcMgL0PoQBkjDosBGRZRdvcCtQJsClN4CEI3VGsAyDeJ08lZTMgo6UVmYw7XigjXQC5hkBY7mZpjOQxAKAoAAbsVLQMs2QWgDQAlCBA9WctpQGKib+Ue8ye5B75e6hGjicGwGh1YgB6esI7RkQIagB8AcA3iejn/T0gET0LW75XH/uB8nsCwJfzvPYPsFWIqiALARGT+foCEQPw3lET8Ke+ZvxrvLgBwBiDwQxYZCHN064YAOHXK3ZiZ9IcsSYT8RbTkwZoINbkBA6lOMzWgTUAqEgdAN/c/ID0KWmAMedLsUhW7nTtX6WgC8ClAET/hlkMInJcAAHfi7JdPE0gM4wYgOhlAUAqAClpDBitrTlKScoz8bsrAYaEcM+k3W4+cShRCCidSaKZ7Eh0C7kuAHGvEEWAGGMwmSlVxFpIA1QVACKS8VaFWLdnnfw9XBeAOw2QmSZYS0tdKgBBZ4UeDLDcHkUMOcMwxM246zmnASC2Dz0Qa8m0YwDyGACiWIfo3+3tBaBSLAaAWwQjxhBvNkFkxwSIsWYNgPIvjv73AvB/WqzGywlRyLoAGExpALh35JcFwH1cAFkDoHAMQHf3Kqxb/4vSB1stxERXogsAAGJpHlIvAMcIjJABQGoMQAEXQE4MgPJceFkARRQAYQBYqWzuP7NkPIC3ZbhYPAB2dlEtxQCo0n/Q+8wHuz+Qv/fXyNmxYweef/55u020xwUA2IGAvLf+FICgBsADAK6o5EBqg2wMgFpxy37M/in8dihQCbA5Zst5onSnuID9DIBiCoCVtuMN4s3265K9jqxpMsSbnBtFsooGQCVcAM4F2moa8gT2TvhF6wB4FICMEQMXcR0+N5OtW5/D+vU/B+fJksdbFcRElylsQArUCTCeppC7AUZoAnIFAdqeTKN1UN5eAH6ncXiVAJ00QG8zIPWag2MAOC3IM7Ck2ijuDSnLfh9NZpN8naoAiO36uvZi/bKlIY0+PMTkL8oAB40DCFMBWLNmDV5//XX09PQoLoCsCmEbAPWnAAR1AWwAcDljbD6A5wDs8m5ARLPDHFgUUesAeCdqwykFzIXVGDPA8ygAg+KD0JPuAYPtAhDBOqoLQFBMAbD9+wwxZ7JP9TmypskQa66eAlDMBdCfLACRotXEmMsFoOJnWLjtMQIHQxoGmshCiplIsxiaKe2rAIhUNstKwjCaSx7zQCO/q0zpLoCmNIWbBhihboBitc1TjguAMbCmprwKgF8hoLAUAJEGCMtyyd7u048hnUllJ32WgQl7ohf3BmEANJvZ81LtCigmx+UL5uOVRx7CjQ8/iVjcfZ+pJuJcNU0TlmUFNgA2d2UTyPobA0BSraKstacNAMlvnJ+fBJCTew/bUK17A0AEmRlkAszdtMK0HOtVZETGGSxPN0AiQoYy8kIVpTvFBSwKAakUVQAytgIQU1b7zLA7AaoxAGEQlToA4uYcY4VcAH5DcisAScfYakMaO2EiE8AA4LwPdiuKiCMVgNJdAPE0hVwKOEJZFUoWANJpsHgczDRzPidvDEAlFQAA9vcVs6994mR/dswAMeZyAaSRkUWBRCEgPwVAVSiFPJ5OJkDEwa0M4BgAQf3tlURM+LFYDKlUKrABoC6O+qsAiGNyzpUYALcLgOrQAAjqAhhV5F/QUsA1y4a+JB4Y8QmsOKxJSvfEmtG7z3kgMDDLsd4N1QXgPpFFCqAwAESwjjh5y1EAeIZgxAzEYs5NIWHBMO0xxB0DoK8rhed/txxdO0uvZV2pNMCsAlDykORkbzImA/+8CoB/HQB3FkCK2TfMweTcSIXx5eMCEDK2ZdVGPfBshHlxA8Dq7sm2pgVgpq2Q6wBEJw3NFQOQzoDFYmDxWE4QYLYXgLMyVPcRkgAgFQBkDTDxuRsigJIZtgLgBP6lkZHBfmmeBieOFM8uIATqQkLcdyxxDGWCvfutu3HtC9eG9IbKw+sCCHruqW6q/hoAqgLgGwMweDB4TwMaAIyxOIB2AAYRbcj3r/JDrS4MQMI0kDEBA3bN7VTLOPQMvRJW/DCY3KMAxBiIINPygOxqviVmR/R623eWpQA4NQfMuOMCSFgyWFGoAls3dGHt0q34aN2evPvJR6W6AfbHBZA1AKC4ANz78TusJ9QKScM2ANrgNF4SqyafFSuXCkBtGADIU2TGS9+7y7H6pJOQ3pi9hENLAxQ35SgpAMIASKVA6RRYPA7EYkXrALizAMIKAsyekcIAE9cLk9c9Q0YNAlQUgP9+/79x/pPnSxdiXheAY9By4f5QDIB1u9ehs7szlPdTLuK+EnMUkKAKgDrp9zcI0FWHIG8MQE/O9rVOUQOAiNIAHgcwsuKjiTBiouEGg0kGDCsDctwAxGJZBYBlYwAAuAIBxWQuLlRRB0Aew0cBKGQAEJGjADBpAKSTmawC4MQA9OxxWomWUXWn/GZAzs+8aYDZlVWpPlXxNgq5AIoWAlJcAPs4BoBUAHxWE1kXQG0EAVLALIDMxx8BloX0hx/Jx2IpXrfdAEkxyHlPLxCPg8VidsqkMvEUzgIIaTBq9L8ICBRVaBUFIGV5FADntr1q1yps6dki8/29QYDyvYiKgU5AqPo+ezO9VU8TLDcI0GUAOL8v7FyIVTtXlT0GlwvAawA4CsCO2Q9g9QknIrGq9ONEjaAugHUADqzkQKKONACYLc+Z3VsBxxIHi8F0ggDJyCoAAFxuAKkAmP4KQKlZAGJCN00DMaEA9GVdACIG4KOt213bl0LZLgBxrHwxAMrvpaoAYntDdQF491/MBQBIBWCwVwHwdQGIIMDaUgCK1QEQEyJXOp3FMuGkAUaxEJD63Vo93XYMQMzxhyvGUlpKwvbf6qcRWgwAz3UBCGOYSdWEgXi2BXAKWTVgd8Luzdadshvp5HMBiMmR+7gAetI9VU8TVIMAgRIMAJ6rANzy+i14aMVDvttndu5EatMm3+eKuwCyQYB9y5aB9/Rgw1X/AKu7tlMDgxoAdwD4PmMs3O46NYSpGAAmZzCIQ3x8BFMqANIFYOY3AISlbsBjALDSYgDEvs2YATOWDQI0nKp/IgZgzeb19tis0m9dZa8ExQWVrw6AsowqNQ5AvLSQC8DPALC44tumXBeALAfsGwQo5NPaMACyCkCRNEDnxklKp7Omvgxau4KlDxYcQwQLAamxDrynx44BcOJn1II8Ig1QpJe6ewGEJAEoBofXBZCNAbAL/4o0QFsBcDICHKO0K2U30skXBJhVAISKlf0MetO9VTcA1CBA9e9iqOMWn0V3ulumP3rZdvc96LzhxoJjsBUA58GcOgC98ncA4Hv3wtq5I9BYo0rQLICzAOwPYD1j7A0AH8IbF0N0ddiDixIxkSJu2HUATJAs1AEWA+PCAHB+CgUg7aMAODEAohKgPEapCoAzcxoxJQ0wmcHgZtvFIB4blN7P3r6cwvsK5QUBul/TY1n46Qcf4rPDspH0pWYCiJtyjDGhwQRyAfQkt2LnzoUYNuwM2DEAIgvAiZI28scAEK+xGABxEy0SAyAVgL7s+zrpseU4CQBdYQfJlY1080QoBkCZ/Hh3j6MAONH3iloiYwB8FIBSryLOk1iz5jaMGnUjmpr2z+5HneiEPC/cz3KcBhhl5eg00tIYEAgDoFgaoFQAlIVAb7p2XQCcuAyitrgFThw96R6ZHeHF6uoC37vX9zlXGiDPdQGwQYOcuJG0bCIFuA3KWiTo1X0a7KY/2wAc6fxTqY+IiALEuj8GYE/wJtk3BhIKAIvBsDwugAIKgJoG6I0B8BYYKmQA+CkAPEPSBWDHBRBa004zi364ACzG8E5zGy4PmjaUJw3w7b29uH/zduwbU3yU5boAACUGwHv43H1yYuhLOLnDxBUFwDEAfFwAqxd/hKEHDa5bF4B4r6oLQECZ/hkA2UJAUcoCUGIAurrAmpuz6XfKitwbA+BKAyzxfO3uXo3OzQ9jvyGTcNAnPq+MRVEArAIKAAEmE90Auav1OAB0pXMVAPW+Iib4rALgjgFQFyHVoD9BgE1mE/oyfbDIQm/aXqGLrIjcF1h5rwdXECDlugBM0RCor891ngQttBVVAn3zRDSqyL+6TwMUvmbOfBQAmGBcPO8YAmZuEGDaSTdT0wDzKQAH7zkSU5ffgEwBCzNrAGSDAAFIA4AxBsRJlg7lZUQviQujc+iBeHD/w7GqN+AEmCcLQEirCZ+Aq6Bwsu0rVqgOgM8uOUxYlpPKQ4SUMACYUADcLoCePUnMv38lnv31O0oWQH0FAUrpuc/fAAhC6sMe7PrTmpzvmiIYBKgad+mPP4Y5ZEg2BkBRS8R5KmNZ1V2UeEhhAGUyXe4nXGmAniwA+ZnZBoBBBixwcDvp2LUboQAUiwHIpgEKw4zsIMCIuABKTQO0uCXfc4Zn0J22YyFEVoQX4jzvOa26AOR5rBgAzJH9H3/7IWzepSS9BbxGokp1Tb8aItY6FIDtArBjAAhwKQAiSyBAEKCSBqhKdXEjLnsMHNBzOEZ0HQWk8n9FMggwlg0CBCBjAOxxKL7LfsQApEynS2FAFUGq6J7NhbTap0wWfrtcuLML93Vuy30CtsFgOjdBU9YBCJAFAANWRgTtZGMABjvWW1qsmpwb4upFturTNrQ5qwDUigsgaCEgoQD05b4vSgdb3SRX70LPoo9ACc+xZDvg6LgAVMmW+voQG7Z/VuXIiO56WaeFzAJwxQCUeEznfPIaAC4FwDk2lwaAYzw5MQAMDMQIxHggF4CrDoBwX1luBSBhJcCJV90F0F8FAICU/wHkdQEgk8k7Yfu5ALxpgADwypr52Nn1cfZ1jWIAMMYGMcauZ4w9wRj7P+fn1xhjrZUcYFQwm5yWkMyRngnIfnym/QQgewGQM5cUCgI0mYlBsUHy+bZ4m3QBiIvc4jzbNcyD2LdhGr4KAAC7wbtDv1wAjqES2F+fJwZArPb7rMIKwJMf78J/bvg453ExBvEWpQKQc3gfFwAMWJZjABAh6QT9DXYaOaRZHDBigBMs+P4bHwIA9h3eWoNBgM77L6YA+GQBSAJXERRFhzwKQAQLAXkzPMyh+9uFgAB0L1wIq6tLrv4BpQ6AuosSPZ7cUf4yGY//2eJ2HQIga7CJuUes0pkdAxBHDBYsRwFw4xcE6HIB5CgAjsLlTJhRUwBKMQCE0WORJRWAfC6AoAqAWLUwxoBdHcBz35Utgc1kGsyngFOtEsjBxxg7CMBLAI6G3RfgI9jV/y4GcANjbAoR+d+t6wSD2ZH/nDEYMNDaexA+ETsK3fu7FQBRB0BUBCyUBsgYw5c+9SUcts9haDabMW74OOxM7LSPR8KnnwH+4xjgnB8Dx01zjcnlAoh5DIBtqwEzFpoBwA0ReRxUAfB3AQiPSJ9ykftG7BNJtSD3uezELw0Az3H8VmkuFwBISv6D1SBAswkgjt69KezcYt8guUXZOgC1EgPAS1MAqNfHBRCwlbDsapfjAhBSs/383zbtxqAmE5/6xD6B9hsWVlcXYFkwhwxxxQAAgLn/UMCZeD768S1Irv0Abd/9bva1fkGApSoA3N8FQNwCa262A8syWVkeAAxpNNkugFaz1XEAEBjZ2UOiEl5XqgsxFnO5E30LAXkMAOEzj4oBUKoCwIm7XAA9Kft6zecCgJUJFAPgSgNc+3/AG7+Gcfqp9hgTGTBVRapxA6CUNMChAE53fP6fJqJRsIMDhwD4WaUGGCVsAwAwuYGxK7+LUbva7SeYEgNgiBiA/FkAshAQDLTEWnD6oadj8sGTwVi2zTBzJAQrlQB6twOdS3LGI+ILzJhh+8MdFcAwGfDMTOD574enADgrisD+er/waQRXADJEeY9lKwCOASAe827jObAJDg4DGUUBEJJ/VgGIAUYcIMvVQIlzqjkXQL5Ws/m24wn7ffU1Z9eXwfsIOJ+19/ySsqo9hllPLcedLwx88ZTVJ07GmrPsFibe0six/feXMQAAwOJxl+HJ/VwAJR4/GwPgUQAytgEAZF0A3hgAEQTYYjaDMwIxggHm8vfvTe3NaU/uSgP0lAIWE2xvptd5byEVfiqT/tQB8FUArDwKgJVfAXC7AJQYAMd4Mpxuq7FEGkaGgzmKQKPEAJwP4LtE9Ff1QSJ6DcC/Argw7IFFEZM4yAAO2TkJgFT9QchNAxQKAPepBChjAIzcj9/rAuAp52TetT5nW9Ft0HBW/zHVAEh1A6lu8Jh7IisXyxlryQZAoCBAn+MRkM5zH7CAXBdAnjoA4hNuYhyWVwFwXACDDCfOgcVt1YRzWGk1doKyaYB1qgAIF0CySTEAAsYAQLoA3F+Ytx1wIm0h6dMhM2yIOHbvtg3m9Me2MCkbueQoAMOkCwAAYsOH+boA1LOr1CyAfAYAcQ7W7Mj2llsByKYB2jEALUYLOMhe2ZPbx9+d7nb5/4EiQYDOsYQLQN1my+r3keob2Jr3/XEBCLeHxa3iMQCWBWQyvsaOywWgpgE6173hpFTHkhaYxWG02PfwRlEA2gBsyfNcp/N83WOCwBnDgXvHAgBI3CtZLKsAiEjWAGmAhs/HLyx7psYAAMDOdTnbqmmA6k/DNOy4ASsDUg2AfgQBZg2AgK/L6wJwDABltZjPBRBIAXC+gwc3b8flf/tAbpMtFuSURQYH///svXnUJNldHXh/772IzG+rpav3pqXWhhASAmEL0NiAwDYYD2IdhhlszzEaMDIyYzGA0RgGg+FwwHAGxmbQaBmWozFnZIPdwkYSlrCEaUlo61arW72q96quverbMjMi3vKbP94SLyIjvy+rqqu7StLT0fmqc43MjHjvvnvv7/5IwoRdAtil6N/V8BpGRAbAdX63XAK42hgAaL3n7i4xBUECqEbZObksAxDfK/+tH78DvO2njAgEjOM5qeZyjHPn/gKfuvP7MZk8iu33vLd7rD0PgLrmMOz5zfZ+YwcZgE4Z4AUeT6wgMbrPABiIogzv248CjiZA7wEYizEcOayPNgDuOv53m12Uouy89FAZoEtGw64EAPjF1DQN3vXzP417P/SBC/yElzb6JsClqwA4qwLgrApgQaVOYsMGWLFOEiC7tgIgAoAQq17UBtK45An4QgEADwL4+wvu+3sAHnhmDufKHoIZLvvGXAIAMs0Kbi8TYK8b4FD9bUTuiQFgAdz0VcDWUcB0qS2bqgDyuv/AADgDOAMnWjR8SR6AWId8wRJAjwFIVQD7eADgPQBDk4FlTgmAcYG/a3uKT223OxoHDw4iQCjIf/faztJxxejfVYoMgAKklwC6AMBddSbAjtltrx1VdIYHCaAaZwzAsh6AgAo7JsBP/R6w9aS/PSxm1vEzl6K3x9DaN72ydhfb7/UAQIQ67nkG4BqsvebrUL7gBf5Yne0Az/iRcuPfBTMAIc3T2N3e7S6TAOL5FT0AgREAQTAwphIODgdGBwDmuR1+XwIYCgKyyWgYTIAmYwCchTUazlro6tk9xy+aAXBdBmBfCSCyYgPndZcB4LYCoMcAFJWBsAxa/cICAL8O4H8kog8Q0euJ6NuI6AeJ6E8B/ACAX7t8h3jlDAFuF31kiz1aBiAGAbkBE2CM9d0LABCRN/QEddtBATe8wm8Ntro51i6rAgAyCUBEAKDBtu0AeGlVALEF6ZImwPiwpaoA5p8fv7ahQzbMbf1F+A0m1nUkA8teKxXhfhV2oU2i8BmNiBJAeF1SqQog926w4zYHYJHB6EobAznzQ6PvATh3sF1YeJ8Uwfb1B34sPctyAMIO2DLMJaZRLjNccIEzG+gnPQhx06nf3fU8APKaa1DcfDNe+J4/QTjILgOQooDb51zoJ0hlgAMMQAQAbTOgrgcARPi2T1t8yd2PgME4ODo4xwAAmJcABqKA+ybAmW6Nn5Zt2y1wSeD3TI1LMQEmAMA2mQAXAQBEo+XAed0NAuKWAQi/Q/y6y9p5BmD8BeQBYOb/F8AbALwCwDsA/AmA/wfAKwG8gZn/4LId4RU0JNABAJwxAH0TYIoEzia8oRyAoaGEShKAgwQfebG/41zXB5BXAQCLGIB2wboUCSBKGxfqAeiXgMc+6zkD8Pa/GJA3Yv7AYKIf5iSAiXWdY4thQfEbVvDgS2dBQCbQpIkBEJEBaCUAVYirUwLIAcBeC3lkCoLe/+++8zA+8Y++3j9v2ZSz6AHIV8lm0kYAh5PAOPesMACO/QLgnGnBD7MPO8qvASEgD/qYbCICpAQ72/UA9LysAnOYdt8Rzx095AEoexJAeO3oAai/eornvb7ByW//t3DkcGDsj7egLgDISwCBeQ+AczoBo7jAdjwAzqZzxi0oO75c46JNgAvKAGM08Nz7xNcd+HwdEyC7Nu00vA6xBYoCUlsIx/t6AK6WdsELAQARvZKIxvG/mfltAG4G8HIAXx/+3sLMb7/sR3mFDIF2Z8+kWxNg6gVALQOQzp95AJAnAQ6NQhRJAhAsYK8NAOB8HwC0VQBAbgIM7lVrYHMJ4BKSAPlicwAWSQDZRPzRx+YbakQX/xDgGJIAZs51JAMLhsiSAiMAaNIOnlPzn5WAIgwpL+dkEkAxlqEK4CqTAAZazQ6NvnGvGkvoAyvzr7HHiNQ/5wY/PU0Lf/zu7LPkAYhpjcwGrHXbvGUy8aV3YdGVhw+D8rQ3IQDbZQDadsBBpya66BwA52ZwWXMvthZiFAFAPwnQf3fNa7dBY8CuTWFI49D4EACg7DEAcx6ATAJw7PDxT3wnXvg9d4T36FYBAF6evNoYgNwDkJsAgQVZABFkDSza3STAeQ8ATAVRFJDGQZpMAhgA1ycmJ/D17/p63HXqrqU+x3M59mIA7oLf4YOIHiWir2Rmx8z3M/OHw98rJ+LrWRiCKC3sVk7RBnLJsOAJuHDhpcflVPdAL4ChoYTKAICEWb8BKFbnjIBzJsAhBkDmDMClVAFEBmC5xy9qBpQkgOwirweYifi4IcnBcFYF0LsvubY59grw/63CrlC7KqB8hhYKBRjR+N6IEhDSVwGED6pKGRiAMIlfJVUAvGxYSX+nJCjVxS9fBjhgAmymiSFLFLjjQUnnmR65BMBaQx7yi6abTDwDoBRoNIK65nD3iUqBrUssFdA9nwAPOC82CRDoZQFYCyp7ZYApB8ACcHDXmsSira0WuHH9RgBASW2YGIB5D0BvbplM2vLLqIX3GYDYJXDZBfiZGhfLAPQlgMgAAMMyQBuPvdgEmDwAfQBga9BoBKkdlOUkAQxdIx986oPYqrdw/9n7l/rGon6tAAAgAElEQVQcz+XYCwDMAMSUv9sAjBY/9AtjEFoA4OSk9QCQ8jMFUQoC6jMA1URj6uXIlgGYy/Tyw0sA/mIgFtBEwMFbOx4AZsav2m08cZ2CiBJAaLDjPQAacBpGtBfCpQUBdcsAzx7bxcnHhjtr+SfMu6eBlgGosll0CACkILvBRD+eCwJKrx/buIZKgdg4RaEJt4cFghmaPAAowm+mRen7O2QSQDGKACDuYq8WD8ByYSWd5jiSQCRSH4sL9QB0TIB6CiB6ZKIJjduqlsswHv74R3D/HR9KDICzDeAcxKHQDXM6BVsLktJP5oev6TzfMwBmkAGItyi6eAkA6JYC5ibAyLa0UcAGamUTKBl0zH+PqysSJx8PqX+iRCEKrJe+AGuvMsD+iAFCeRWAY5dJAM8tA7AsfW6cSZ/bONNlAIZ8APFzDUhb/SjgNKskBqABlaVnABzaKoABdu2OY55pme18BnV9aqnP8lyNvZIA7wXw60QU3DH4ISL62wsey8z8i8/soV15Q5KACzXjLCcDHgCRJACDeDH5x993x9M49+51iFcLjNRiEyDQlwAkDAEoVwHd7j41M96PGl9/QzEgAQQGwBrY6AEgfkaigOOC/LE/fhSTrQbf9+a/OvzERQzAwOzZOE/d55JIYgAWhAT1cwD6z4tZAbGJk+Q63O7jgGXIASiIocJn00IFAGA7AKCZmauuHXBHj1+SAXDCB0q13fGW8wAMmwDnGQDtXN+E/4yOu973n6DrCl/7+psBAM743zzq/J4BsH6hLwvIa7oAIDIA+TnXelkvTALY+o//ETRax+pf+bpUBQD0GABjUg5AKwH4u4SzKDd8hgEdI/CtDENTPHb3Gbx8RaIghfViPVHgfQlgEQAg5ZIXaF4CCJuX5wgAXAwDkCSAPgPgGuw0O/iXn/iXePPXvBlrxVrbcXGfKoBuGWAsHaxBZYnCANIiSQD9a6u2NT5+/OMAgC/ZfTeeeuoavPjF/3Spz/NcjL0AwJsA/A580A8D+KE9HssAPu8BAJGAC53jWE46QUC+dKQFAFNbg6g13unaAo4gWKUo4GVMgIIFDACoFcBkACDudAUgZV8CCB4AZ1CvbMOSRbHSPKMMgGm6Tvm55y0KAhpC90SojcO4mG8RPCQBWMZcM6D+8xz7rmnJA8A1QGj7AWQSAAmJwmnPAAjZqQIoRhLVRGdVAFcHANiXAWgmgDMdOtRJ8k1nYqvmZReCWAaYT9zNtO2LkXkALiWMat/DqGuf9x7NbqFsNkkA06mnv6XE4f/++zH6spd2nk9CgK3pnHOtB8APSbRUFPDZt78DxQu+DdO718Hfl0sAngHg4DYXgQFws6mPBI5BQNwCAHlUwMDBilmCHqUo0+4fWCwBKFKp/BgA1MgmCaCTA+BsOmX6WQmXe1yMBMDM80FAzQRKKBhnUNsa95y5B7d/7nZ8x4u+A6++8dXYq0FW1wSIeQBgGqAsUFofrprKN3ss2Z0n70RlKxAIAhrWPbuhShc6FkoAzPyXzPzlAEp4Lu+vASgW/L9c9DqfT0OQbBf9DAB445gHCFECmJoaQoq06Ma/guWeZYDAvAdAA4AadQBAk3bmlJr/zHsANLaPPIg/eNW/AK1U+1YB7DQ7+Nz5z3Vu6wOAOCFas89kngzg3ccMYhDyKXGdp4fHDQGGPAhI9SWABACGqwDafgBeAijJA7eCte8NQLJbBVD2JYCrAwDku5xBAPC21wK/8rwuAyBDe+ooAVxoEFCHAZikxarrAbiMAKCp4axNMg0HxmyOAZAS1/3YP8aBv/W3ui+gJNBjAPo4VhKWYgBcVYFRwFUmgUcgYwDC7xM9ACd/8ZfwyLd/e8cEWK6fAhpCcTLszOW0AwA2yo00l/QlgGgCjBVH6fZR6/bPKXMvAVw9JsAoY0QAEIOArhl7VkdbnTxX8S/vAQD6SYBtFUDmAShLjAOhyuPo3ei+1onJCQDALes3+7Jxt4BFO3EPcOzOfT/n5R7LlAESgP8VwOeY2S76/2U+zitiCCFaWjOTAHwVAANEaaGc2QZCUgYAAs3l1JIAIOj5LLwEoMYdCSBR3RL4/eNn8fp7HpuXAJyBgcVktAmQ3ZcBeOd978Q/+NN/0LmtLwHEhFwfj7v49dJ9CzwAnUFA1WMTEtOwEAD4f4uFEkA3B6BAKOOD9IEs7JsBKQAQAoWzPhdgQALgrBfA1SIBdHMABi7PMw/5+6p2hxLjq5MEcLEeAKv9+Rd/GnahkgKXtQpABwAwxwAc9AyAnUw8WJHD5lsSEmxNLwgoegAyCWCJj8BVBTj/nUQDKdBjAIBUkQAA+oknOzkA5cZJiLMlZFinnazS9fT6l78eb/rqN6W5ZK4MMOQAzHkDxnauFwAQJICL8ADctT3F9tD5dQHjYhiACAD6VQARADS2mQcAaTdvfJe/gWPwOQDDVQAoC6w04XwYR+mmu8DHrJdbgllzYSfMD/w88L7/bfi+Z3EsAwAYPujnVZf5WK74IYFUBgjRmgABv0jkDMDM9AFAxgCo/csAKfw0FCWAYtxlAMJE4ZTAXdtTfGRzt2UAYhCQNTCxFAv7A4DtZju1Fo1jEQPgrNubUdinCqAziDDrMQDxUIcZgHbnr3pfYaRvIwOQqgASAyBgTWQAZGAAJArWMFTMVQEUIwmb5wDY6qqo8e0yAHto+Zmx1AlK9fD+NS6wGVD8rUMgS5QAHJvk/bicAMDUNZxzbRmg7XoAeDptPQADg6ScCwJKHoDwVxItFQXs6to/KSshBTIGIOwcUy+A+H7hxQkOxfop0JkSchZCxUTLALzy2q/Aa25+TVrg+8FA0QMQGQAddit9BiBuQrwEcGEMgGXGd931MN761KUZ3S6GAYiyhiQJRQoTPYFlmwBAbes2ATF+/zH2+uQDwP/5lcCxT6XX60QBd8oAuxLAOHgLXSF9WmDvu4oA4KaV6/zruQXXkJ4Fo+xzO/YFAKHU7ykAa5f/cK7sIbMyQPQZgL4EYOsAALpmQMEyte7cqwxQJgYgSgBdAJCobgU0zmFiHVTsBRB/VWdgUlcxs68EoK2GY5fQdT4MdT0Abj89N9fU8vcYes6ABBCBxpBp0DKnnb3sVVKkTWh4jExVAGEHHyUA9iZAzwBIjJzOGAAHqx2EIEhJYRcXL2TX2dFdsSOfRIcm9MO3AQB481j7FCkgIMCxtfSyKWe2xwCEiS39cuxgwvFEAOCcxiOP/sZci9xLGaZpwNa2gTehKUwEAHYy8ZO7WmB9khLs3KAHoC0DbA2Bew2ezQD2TBg7DSFGACiFAcVFOHoA4kivLYFi9Rxos4CaRLavTe6LTEHc+c9JAGFuiX6jJmSYq3ELAGZmhjW1Ft73wqsAZtahdozHZwuS95YcfRPgMgA7zlGSJKSQaeNycOR/68YNMABRAjgXQO/W0bljWBQFDFuDiwIrEQAoAVJqjiWLjYhuXL0u/Pd8m23/eo1nyp7jsWwU8FsBvImIviC0/kWjDwBSXwDyOQAkRMrM9xKAmJMASox8616Sg82AgAAAEHsCSF9RoBYwAILQsM/Nd4U/OCHijkx3GYB9dl8xPCNeMGcak7r2mXBBnNqJJVbcLfvqjXTfEgwAE80BgL2qADwD4P/dlwB0omz9yR0JmyIwAL4KYBdgBy26HoC+BCALEX5DC2YDKcNkuWQp4NbpKd76v3wImyefHaRvrMO0CRPSflHAsa/E1vF0ky8DvIQcgNSAKEx6ySRrE5CLC9zu7gN4/PHfwvnzH13qPZYZuqnhnG3LAEMVgFgZg0aj4AEwezMAvTLAlAMQ/iqifR0A7By4aTxosD5GWogSSm20ZYA9DwAAoChaCUBZCNUAlYQKX6eTswxU+T9xgZ+XABxeu6ExVv72KnwQOWolAG01VpR3s3eCgJY0AU7D7320ujQA0G8GtAwDEHf1UkhIkpgZ/yWtF94Y2fEARPAegc30vP9bZSWZHRNgVpHEXQYgAQApfNVI7xqJDMD1q0cAALVZcO3bxv//OR57VQHkYwPAiwA8SkTvA3AcXXWXmfmfP9MHd6UNLwH4f5PczWKBld8ikEi0Z2Ua7FqNSe0v0AgERtSGAO2dBNh6ABIDoOcZAKsIdZg0dB8AsINNXcX2lwDiyWucQSlLvO7Oh/DXhcUaAJvMjbG1qNvHBBgBQO89htC9wLwEEE6v4SAghgzH05cAkgcg5gD0kgAdBIydAirkABAAkijdzAMA0ZoApRIgSdkOZQ3WTmBtBaU2Fn/2MLbPVjCNw87ZCoduWN338Zc6fufDj+HffOxJ/PlPfVM3CGhIy480fbUDICTlBbREcSJesh3wXDOgJAGE+9mmxlURCKRgpaHEtosY7Bys9s1s4gLGcYItCojV1ZADsNgDACl9ENBQEmDUqZfwAHAdnWIILIAGkYKUq4nx4AQA2oVbHTqUmAZeCb9ZpXzZmS7gZDUHAOLC3y8DXDdH8V2HNN7TaHwW7feuxi3Vr53GRunPYx8EFMsAlyvDm7pnBgBcTBlgjPoVJCDFPACobb2YAZgEAFC3AGBxGWDOAEishJ/WSvIMQA8AxE3UdePDsADqAQZAHz8OOWsg+OoBAP8s+/frB+5nAJ//AECIpPuTqNsyJ5IAc6gS8CfO6dk5bGmL4zttCAoAFBwSvAJyHRqeAWglAANe6AGwklDHXXoEANReQF0JYB8GwMa0PD85n2wMzhToAIAm8zTsBQA6iDobizwAdc8EuKcHIBj8gD1yAKIHINyeSwDbf/EBnHr4PuhXvAQFGBASpTM+GphCGaBxkMpXWET6X6l1NM2ppY2Aif15FuJvAeDEVo3jm1V88/aOvpbPDDSxLXJ7c6wCiGWAyzAA7DiBvWT87GmbzBkDkEkA/u8zMwmaJqT/Ode+dqBYSSmItTXPALi9PQD9MsA+jmW7i83pk7D2Vkg5nn8RIDVWSkFIzoJIQakD8wCgaLV7bpqWARiH774O84AeBQ9ARAj+b9T458oAwzm7Em5PzbMyCaBxTWIALFuwk+l4lxmTABRONBrGMZQY3tDsNy6JASA/j1ahPDeWRjauSTv/1BegDwAGGICFSYCmAZcFZJQYEwDomQCthhIKh0cbOANADzAAj//A38XBmya4/qufewCwbDMgsc//F0Dqz6+RMwACNisDVEkCiKBgq9mFy3bd8W+BAnj734DsBd/kI68CIBbQHCQAp9PEnrR4QQkM6OgBoHYCayWAJTwAGQMAeG/BLCs39I9pPQ17SQDLmAAlYsezAQZgjyoAx0CUqftzTlpo0M0BKBIAUKhPPI7JJz/jcwAIvTLAngQgKJVxKeknl2VLAZ9tAGCdQ2Nd6Hq3hwRgG09tjg92+9yLkE55IRJAfk7NMQBtDkDyACRgGH6PS/BT7O4+iI997O9A623oJkpTNjUDigwAFaVnACZTXxGxhwdgrgww/I23kKvgnEHTnFl4XBwBQKBAXGAARC2h67D4RDpatlOw07oFUePwvTRBCtQlXO4B6DEAcx4AxNhxGf7bD5WZABvbJABxMd0AowRgGTjeXPzveCkMQJIAguy0VniZLq8CiGAhMQDTTf8i9QIJwM03A4Kp2nwMeOaVlEodBuNoXINCFDgYgIjuyYVsLcyJE9A79oqQAJb1AHxxIJQApQx60w0CYg8AbDhxtpsJHNnUCyAuvgUXwLFPQjWTvZMA0UoAjdMeAACJBWjihCqRJIBG9SQAtAyAW4IBiAYW4wwsMwwDVUS8kQGIC6xdLAH4iyj+R+89sudEXX7IBLhvEmA09+2XA9CrAmCxCicM3HSGhgovIZDwJkDKJADNkEpASAIFRkVGw9SSYUCpSU7vezdmB5+55x+hrk8v9TqDY+sY8J6f8kaid34PcPe7EvgxjjsMwNxCHhZojA+2PD0ADkmAIuxKnd5/guKsOQT3PADxHmab2gC3JsCm83fZsfnv/wOqh3wJ4+7ug9idPIiqOoqnjv0O1m6cdj0ACQAUngGYhmZAF8QA9CQAODAEtNlceIzzDIAGQaK58wFUxx/xt1kHBuPc+NM48qYfxerXfR24rttrasWfr5vjl+HE9a+GMKOeB4DRHJ/gVY+8EMBAM6AAAMahGiBuCqIHgJmhnW4BQN4L4AIBAAAcuwQZ4GIAQN8E2JcAGtskkGBc3wMQFv5qWAIYLAO0NVzZsixW0LAHwGqUssSB0s8Vptc+3O3sAMxwtbuqTIAgP76DiH6diH6XiJ4fbv9GIrr58h3ilTN8MyB/Uf/N6W4nCtgbR1oGYEdP4MilyT9e2EXITJLOLQQAK2qlUwUws7MEAB499xB+6S9/KdH+VlACA03aFbcXkM0ZgH12ookBYJNARb0QAOwhAWQ397MC8h19CwBoLgcgrplPzRq89C/uwX27ee/yrBdArwpgzgPQqwJgKr0fYlbBkPKNgIQMJsAQBey8B0BEACD8xKFUcJPbCZYZCfz1voOdnftx+vR/xubmx5Z6ncHx6AeBj78NOHUf8MifAUc/nhZXbd3eDECk/3sMgJWeAVBFyFfX+5sdOx0AexJAxwPQKwOMDABfIAA48Yu/iK0/+qPwGlFGqHH0+G/hJd/5RACmkQEIpXZFlACmnrFY6AEQQOYBEGjPw/g1SXLeR6K3Fh4j9wCAcxbkAJo4mGYLdtebEc2NwONr/x/4e16Mta/9GsDaNhI4SABnNl6Fo7d8A4QedXIAwMDs7tP46ntvAzHNmQAjuzYK+R0pECtIAHFR7EoAF1YFMM0edyk+gNQAKQDQZaoAcglAkWolgAwA5B6ATnvsWfjt6vY3zCUA7lQBtCZAzpNKJQY9ANppFKJI3qQ+wLXbHnTYiq8eBoCIDgP4CIDbAfwwgP8JwJFw9w8DePNlOborbEiiJAHc6JpOGWDLAIS6WtCgBKA4IHLwQgDwhle+ATeu3OQfxwKVqbwHAMAHn/oQ3vXgu3Au0FdGtKmATTg/hcg8AIiU+PIeAONMAhVJAqCuBGD3kgDyBW+PKOAiNOjZSwJ4ZFZjy1jcvZPFlnLWDXDOBBjeFr1ugJEBoNL/LlWFRigUQDABBgYgSAAumACFEECIfy5LX2NszDZONxq7+wSgtBJAF9xED0HdXAIDEP0gsUNkvZsYAG0ZyEs55wBA+C7Hh7oegJADUKgSlgBbVTj2Ez+J6r77Fh5GB2j0JID2DjeXA9C2yL2wXRDXta+xB9p45oxm9WWA4X6XMQCrq3DT4AFYFAQkFThrBzwSIqX+xdOW4OBA0HoZBiAkKrIGNEPMADdmbL/3PZ4BKOLcME3VAC5S6UECcGYFThQQZgTOGQDHaVErWc0BABG+31JEWdDfLkMUcDSrJQBwETkAOQNwKQAgXh9C+OvtQjwAfRPgWth55x4A40znGuBZKD2tWgAQ3zNWAaQvLGcAMgCw0APgNEpRtgt/LyPPbvl52zUBADzHmSLLMgC/BuBW+DjgI0Bn2/UBAH/jGT6uK3IotLsaAdcJAgK71Acg3tYFAFEC8ADgkHU4UB7A0w9v4j1v+Uxnp3zrgVsxEiEsiCVqUycG4Hx1FgAwCyeeFa0EUMtoAswlgPD+y0gAmQegyRgABuZ6ATjrwDy/wwd6t801A2r/3QKA+TLACAB2wiJ7stad+yIDQESdk1hnDICgrBdAYgAKAC4xAAWxNwGy8QxApwqAOgxAUfj2sdps43+4+xH86mPHsddwCySAuEA1l9IpLJbxnfWUMprdHgOwhASwcqjrAQi9AApRwArAnD6F7T/5E0w+8pGFh5FLAK1zMzIA0QNgsoU/fCexudIeTuidnfuwu5u1sTUGcA7cxNa50WCbpRlCtwxAOJ+TBBA9AHKBBCAEYC204xQi1ZoAowRggwSwBAMQAD47A2gLmgE8Bnb+7M+8MTO2XHB1ypY38Twfhe6VeuwBgB7DqVkmq3BCuwUXCwHAKEkA/nY1srDOJrkvZwBSZskFmgAFgGP1pXsAztfnQUQXBACiCTABADXsAegwANUEeib2MAE6UNycZQyA6zAAHDwA8xJAIYvM29Kb17b9eWObHsB4jsayAOA7AfwMM38Uc6ounoQHB5/3I88BELkHIDIAMjMXkYATNi2GLQPgdaTfPnkaP/aqH8PxRzbx2N1nfLOgbETaWLDw9FYCAN5EVAV602QSQB20/44E0GEA9r6w8hyAOlwQFbf0P5Al7dnuhN49+EwX3qMKQEUamIB6QRLgbjjm4zkAAHd2/nklQFtm5ie9eE+UGxwVYLKAYzRUtCZAp6EpSgA2lQHmHoCyiAzADs40BmeavS/edkLt3m4TA3AJACBqi4kB2MkYANcx581FAWcSQO4BcMJXARSigJU+OAcA7PbisJ4Pfvh9eN/qh/3LPnnUT7SxCiACADh/TMglgLCI7yEBfPwTr8PHPv532s8Rdv7cdBd4ndHxxcasTQKMAECpYAKMHoAFEoBqGYAigMe48MdTWrAFg2CWYQBEdNUboLEQTQEIwDTbPisgHIZzdUoEtAkAhPNVr8AJFTwAmfckA98jV8x5AELxMIqw8ueRJdpO07UecwQMmwvuBRAZgJevr+DfnzyP955e/J3sNeIc8cuf+GU03FywCVAJ5VlSACM1ghJqXgLIroF6U+Fz774R1dH2eDtJgAs8ADYDAFoAKFQr2RgDNiaZANO51wMAbmsrvlx43edWBlgWAKwDOLbgvjHQE2I/T4fMPABENps7FRgMzgAABwYgpVCargRwvbXYEGW6vb875wQApD+5AwA4V/uTtorollpdvgmrolLtBaQvQALITYARVFTc7v4Bv8N2jhMMHJQBOgxA965uFYCBZAMinpMA4uMizX6yyRmA7qKfg4G8F4DMqgBKimbIEhwW9G4OgEYdywDZwmhfBUCCkgQQPQBGb0OH8KW9RvwN+yyJs5EBWOwk33ckBiA0b2p2YWPAi+FOKddcFHAyAR7qKAVOeAaglCWsgC+bA2B3trFoVPwuXP/K/wAA2L3jw5jccYeXGIQa9AA49pPshZQBJsNgXPjj30jxmvb4xofrjAGIHoCiLQM0FqQWSACBATABAOQegPg1Cdh9JYCUAxDKfB1rcKVRrHgAaWnmDWkJADQpETAHAOwE2JZwsoQwY7CsumWA4eBKLufKAEX4bloJoD0Ht2Znk9wXGQAfoRwTHZcEAJUHku94xW14/rjEmx86us8zhkd83zPTM56JuEAToCCRvpdyeg4jUXZzANh0TLF6EvqabGbNkPpJgH0JwNRwqp0HrQySUWAAjv3kT+H4z/xs8gAkBqCXqho9AGyFXxuuEgDwIIBvWXDfNwK455k5nCt7KABWMM684H4vAeSwml0HAIAELFlwoAlaCSCbfHZPptttb3ceF2vJhMpWuI9X8cT4RpxvPIKswgltCWm3ThsFvvWHX4FbX5CdqAA2poyXfbJaWgLQTidZoWKGzQCAcdxhEoaMgJ0Frx8F3CsDFLCQkjsmQGZOE25kAE7U7W7bMnfc/x0GoJ8DkDwA4bWpAIsMAACAECg5MABJAsiqAIIEIEQJKddhzDbMEgDA9gygccQd6jPCACQJYJKc9k2PAZiLAta5B6D97qz0lEkhCpgMALgFDMDxX/gFsD6LYuQfR0KifuRR//rFWrcKII/XzZsrLRGGMpl4kMMLAIDOAMDKkToBrDgJk1IQK2PAWrimTjvzuaFkYAD8zlkQtZJFqgLYXwJwsyp9H0AAIrMG5cb1AAAjKrC1CHsBzwCUXQDApYHTfm/lhILQI0BYsIgLS+u/GLlirgwQ7L+DgqIsCDjt/71Zn2sZgKEywCUWYJx7FNOP/t8owXj+ygjfdOQAti6yKRAnsL8LBwezRA+KvgQQR/HH/wSl1dBOt70AnO2AGmcCM1XlZZV9CWAeAHQZAO54APSxY2iOHU0SQAKfvR1Q9AAAgNWiBfLP0VgWAPw2fBTwzwB4XrjtEBH9IIB/DOD/uhwHd6UNSYRZMcPpl90LQTaxAUwKQN9d7BmAyAC1C3r2mO3jcAsYgLholOzprX9ydh2//IJ/iHONP4HqmOZFbUng1Dq8+K9cD0lZ8xECrt0GysZ2XndoRAbAsm19BehKAIa5c6yDoCKe84r2rAIQcJBwEMJ2GID8JaMH4EQmARjmzombMwBtGSCDqAUHZZBHGKplAESoAkgmQNmpAuhLACQUCnUAxmxDu5Z5WTT6BtB0e5AAmksyAQYAMA0sQt31AOQ7j7kkwAVVAE4AAgKlLOEEwBMPFBYxALsf+nOwayBklHIk3vWBd+OBh08B5WobBZwxAIAHcMuZAP2vvLNzr3+dHgBwiQFoF+OVIxVAXZ8BiiItsDyrFnsApAI7D1YUkV80w33HT54MR+QlgL0ZgJ4HgA141qA85IulnKx6DEAmAQQzHZUaVofduShA1i/UVIQSS27Zt5LnJYBx2MEeGnlXvCDA2VChVJ2f8wAYl0UBL8MA7JzEVI6xGq6NNSlQOR7s3bHfyLsTOnKdNsWLRl8CiKOcnUfBriMBHPnoQ7BnWrbN6fC7NDalq+YmQGaXfruWwq1hMwYgAgCEa4u1BmuNxjXeBBiArVjgAQCCD+BqYACY+W0A/g8AvwAgNox/P4C3AfhNZv43l+fwrqwhg17sp0mTlQFGCaBd3JkCAEgMQJAAXMYS7Dw9lxOQnh+jO533AOyywLZax3ntJ+86XABatM735MrN6C4LoDC+vejQ++Qj9wBEUOFAaFRLLxpGAi1PXyPxS08cT+j5v57bweembbc8kmJOAshrrIXvzQchXMcEmIOEnTAZnWp0Fsvarf/PSwGTSTHcHu8pw4FYKsFhgdCkUg5AyQNVACEIKDIARAqq8Gluhnm4sVE24nfdB0HRA6D1+YtPwutPHE3XA7B3GeACE2CsAhAFjAQw9YuN29kdPASeTgHhIKXxFKxUmBmNzc0pUKxkDEDbDAjwnoioke7lARiPfa+mxv8AACAASURBVCXMdgQAcx6AAAAyD8DoYPt6uQQQI3fdbLbYAyAFYCwadt4DgJYB+NwjnmkRMMEDsAcDkEyAQQLQNdBYjK/1eycrtGcAMgAQJQAzDc8tDZxpAYAI/0b0ATAnqe1LN16C5x2I+7Lw9HDib6gVABwAgJ/ud5utxPYlCaDTDGgJY5qZYSJXOgAAaOOBL2Q45yCEwMRMwGBM+lUkAyPu7ncfBr7iI/9tYrJKXWPkHGpb+5yDmvFV/+r92Lz99vb9TCzPpBQG1G0HjMFugB0GQDKoaCUA1hrc6CQBJA9AjyW0W1nlgRZXBwAAAGZ+M4AXA/gRAD8L4EcBvJSZf+YyHdsVN3wjEAlB0pcDZTtPRwByCQCiBQA7J1OoSocB2DmRgIE13ROlTQ70VQAawEyUqMKJVYeLVGfHkC6+gO4ZvnyvMAyRAMAeDEBWBXD/+c+l2+sOAOAEWh66qcQ7Tp5Lu+4ff+BJ/NpjJ9IWnhS1EsDZR4Bjn5pLApSwEKIrAVi0j4lOYwfgdBNdvdzzAAxJAP4x8b5xYAAMla0EIIqUA1A6DU1yrheAkG0ZIJGEUgfQLOkBWMwAtGVreyXK7TlML2Gs3k2/i7auAwLn2vqmMsCD2KFc1+x6ABCo7EUMgJvNwMKCiOGERn3tWQAMazS4yBkAk+QJADDOtQzAHkmA0eW/s/NZ/99x56+HJQA9kyhWs3IvzgDAKAMAizwAkQEIEoCkLAcg1qqzhdsnCChVAYRFxJkKcMDo+gAAVO0paRkXnbYKwM4qz94UOkgA4aVsoPhV+N0dpwyGf/7qn0td8OKIlREEmyZ5DgvfTrOVPAAdCcDtv0lIw9SYijFWww53LWx+Jkv6B/LBIRV1qqdgYkyb/ZtnRQAwOw4cOHsTCut/38I2KJ1NEkARGdhp+5pJArCUSgH7EsBQGaDNGo9o4mQaBSID0KQgoCQ/9XZALpcAGoHnOgxo2RyAa4lozMyPM/M7mPmXmfmtzPzo5T7AK2lIIr9DJBUkgPY+R9SJigRJOHIemb7nJ+C2vd4rOfvKt5+GMxF1D0sAiiX0xEEzYTfT+eoBpN0yAGFnFG4vDUBufwAQJ4WJnuAtd7+jvT0DADaTAKIHogrHumsdHp3WadEnKdrd74d+Bbj9jXMAQMDNMQD5IdbZ7jnKACbz6AA9CSAzm4nMA7BCId4YI0AwHBGskIEBkCjYoBaFb+fsLKwOZYCCQAEwCCo8ADB+h7KvBOCySSW/PUsSrC+2FLAHAIgtKAALbbtRwPM5ALuALAE1hu1UASAxAFYACLvRIQ8AWwtumvTdTK+5H09/+x9g9foKtm7AZdb8iF1HAvAMQKzhX7wDivft7j7oqdkkAcQywK4JUE8URJG9TwYA4g7bsxaLAIBnALTzJkAipCqAyD5FBkAvwQBQYADYapAFygM3+vuV9qE/kQGwmQdg1kCwBSkLFyQAACAXKH4RfktGYgBYzy+6NjShIW4BQGQAZnongf1UBeBMWsyWKgM0lZcAwnccGYDJMuChNyIDwOF/U70/AIgmQIo7/yCRlLpGaQ1qM4NxBjIcDlft9ZIYAEupFLCTA9ApA2x7AcReKwDQSNcxAS5iAETfA7C9DbHhZRmnr2AJgIgkEf08EZ0HcBLANhH9EREdevYO78oaHgBKrKkDXgvMdp5WUmdiYQhIRSBHwJmHUymYdNnkMzk9lxOQnh/1PVvittu/BZPaYSb2BgAJfUcAEHPwLUA8DDTS+4VoUAA4unsU55uW9q2KVl+0jHkAEI59Zh0em9XtZ1EiTVJoJoCedHbNXgJwgQGwYGb87MNHcef2MAUYKwEcljABhoZBMQlwNdD4GiVYMEzYsZREiQHw35mC7wWQRwHnDMAGqgAAlmUA5iWAdjKazZ5cur1w90Xmn1OGhMI5BmDOAzAByjVAFp2a3tgLIAIACueT3dnB7NOfxs5/+S/tY2ehJj1QwPWa18jlyKKZNCm4CkCnHTDgF9NlugG2j5nBmE24eoEHICzGelL0nh9+N6WSBMBa+4V+aEgFdg61cxgJESSA8HnDX8HaSwBmc2FiXVpssioAWEJ5yEsarjChK2F47U4ZYANyBqRM8gAAGQCQkf1og7hYz88FKRuBbQLLHDwAja1TOXEuASQn/DK7eFN7AIBLBwDM3LJFxKiyrqeLRmQA4i6scCPf+4MtSmY0zQTW2RYA1O1rJg+ARUoD7CQBDpUBmgom22kYijkAAYxqDW4aNLbpVAGIXtW83d5GebMHglc6A/AGAD8H4C4Avw7g3fB5AL/xLBzXFTlEYAD+5vXfNScBWCE6TUYIEmvlKsgJYPNJuGD5TQBAjQHbtE7xBQxAEZBt44BpZvSpB1D6PWcf9saXmIEdbu96AIYnLZMFUngqrp1MkwTADIu2CiCaIGfOJ701zNi1DmfCgkOSvFuZ2SNd04RWvv7lOhKAsZg5xjuOnsF/PjNMOR9PDMBeEkA6VAhqmYIVEU2NI7BkmCDX+DJASgCgEYVvLZu1A0bY5caObvUFAoAhCYDC9/vZ+34cDz70L/Z8ncEx4B4uwqSvrcNDx7f8JCblfFmXngLlOiCKVKUCBAmACIX0OQBx8GyG0//qX+P4//5z7UQ5mcJKmRgAM/ILCgmGmRpwaMoCRBNgJvG41gTIe5gAndNYGXvavKqO71EFEAFAt8kPwwBCgKRMFDuAnlTXDhICMD4EqxRdE2AsMyN4CcC5ZmFXSBfd5VkVAFmgOHQEZBVc6a/RQQ9ApSHYQkgDZ1oQ1QKAlgHYCwA4FxgAmNQIKO58FYCHNx8GMFwFsFQZoKkwFStYDWa31QgAzMUxANF1z+gCgNt/7ZfwmQ+8b+450QRIgVEtzRilLEGABwB6CuNMvHQTeASQznnOGIBuMyDOooAjgrCda6IWznsAeiZA7WIVQDBzUgtEAcBtbaG48Tr/Ga5wD8APA3g7M38zM/80M38fgDcC+HtEVO7xvM/bEXedQq76HzarrXUC4IwBeOnhl+HI2hF/guopHCIACF95uQZYnUkAPZo4AgAXLlAB1BkD0Jj5xedktY0TkxMJtcb43nIJE6DOJuKpmQIdABD1NdthAAKjiJlzqLIJ/tEqll9FJy38jtU20A5YjbXJAQCQYMwa22YP9NiNawpv84tpgHkUMOD/vdJLKrQc09xiFQChJELDIYwlMAAFka8CCAtSQ4U3BwEDDICvAog9vpczATrMil/H9vZn2ttdhfHoJqyu+kYukyztbumRMQC7HOjPAAAeOTXB++89ASYBUgrnmxqf/vSn2+c2u0CxCgg5ZwIUEKkMMB/VQw/Bnj0LffIUzpz9ENx0AqMURGBWTOkXYZIMXVlAtVMEs/XxxPHQHS+VBMissbISAEB9HNz0TIADEkD3+Ta1240UO4CFzYCgpGcA2KEM/pHWeMogZhB7CQBoqzhms6PY2rqrfd/EAISdJgzgAHngAKQbwY1C5n9KAqxaD0CjQS4AgIwBEEkCiGWAnEo9834Mn3riHD70wIkkATCbjAFoY4HPznyiaF4FkEyAS0kANaZyBathobsUD4Bzrk2SIaRQHwA4ev89OP65h+ae0zIA/k/hxiiF/60TAGADFR7W9mfI3te2JsBuMyCeLwMEoLOI9UbYTjOgyAC0OQDt8/JKF7u1BXXkoJchr/AqgBcC+He9294Ff9o+/7Id0RU8ogdEhys3l/ONEEDmARipNUgpIMKC78KCKgINh2INcCYxADabIDkL2lHB/OMIqDMGQA9IAEwjv3gnCSC8lcG+JsAmOxE9A9BOppEBUM4EBqAvATBm2fE8EdF2BACOPdVlNQwzVsJuQQYJgMibAOOOuuotrGtS4nAhcVabrCtbtwpgI7xXXJQt0DEBSlIYS0KDwjMAKmMAMglAk4QNH8z3AsirALwJ0Ibfv+G9dzvOMkRRwZR/is8dux0nJyfD7RWkXMFrvu79OHjwr0KI0Z6vMzgyD8BR9juKCAA2Zw1EiKYmpfBA0+Dd7353+9xMAgADOi5EAgAhlQHmI5ZRnb7/dtx99/+M7e1PwyiVSiTNyJvihGCYmsFZMM3FlAEyWzBbrKx6AFAHBmDnWy2qG3fhphp24he5SHfPSQDIAUB236JeAMJ3A6wdYyy8eJRLAAQPpDks7B/56Dfh6af/EI89/lu497NvSq+TPACRAWALIi9DSDeGGzO4rjIGoEkAwDUGRDWEcB0TIHE4R2SWA5A8AO15+NsffAT3/qffQJxAiC1e9fAB/9ph7hFgbIdy4k4U8AWZAKMHIAKAZ0YCKFSBSld4YvsJfyzGwjTzcldkAJIEYEcoQjlgyYzGVp4BiL9fPQ8AhhiAhd0AAWgZw8QAA5d6RwAtA9DYBqUsO8yWszW4acDGwE0mkOsrkIW74iWAdQB9Lja6gTYuz+FcueP0ieN45C7fvc2ExdERoMIJcMs3Po7i+sfS440LFDJHHTD05Y6Ua7nqGYBUBpibpDKd3I7gCGBB0BkAqHqhG+SmHgDoKRD1bCzvAegzAIyMAShaBsChDS2KEkDlHGbZhf9Y2KFR3KYHCYBtA82cdustA+DbAUfD36w3iYwF4Uih8PRmhZNPe29C3wOwKv2EbfIdG7IuaCQxFsIzACpnAJBMgABQiwI2yDSyoFAFEHMAig4A2JcBcAwKpq0PPfE+/OadvxluryGC+UqK0UV6AFrAdoyvBQCMwq5vpzIJAEApmND+1cbdWQQAogAzxZbzXvcPHgCTuyyzMTvmGwPp6jx0UaTGU7b0UwUJhtHUTcXsBQE5x/uWAbow8Y5HN4GoQFUfh2tm2HmdxeTlU+x8+GlMH+xWUMxLANbrtECi2AEs9gAoCViXJIBuFDDDL6oGjBZA7Ox+Fro5C2NazwxXFZAxDkwWImT1K16DOwC46awrAQSPgm0MlPKAZtgEmDMA8wCgsQ7XuTa0ldngZUfDdB3PawK26wEAkOaiJXbx2gOAtWBoTWWAF2kCjADg2tVrUVCBH3n/j2Cqp3DWwOr5RTKaACMAKO0YBeUAoF5oAoyDLaVQrE4OgOMuAAjAQkewK/18GYOAmBmYYwDaYz7/rj/AI697HeyOXz7l6giy5FAGeBHX/jM49qsCuIWIXhj/D88KzN0e7vu8HrPdXeiwsDXBecoElGGiKq/VEKutM9g4ByUlBAQaFnCBLhARABSrgDODOnEOAKQbJardiBE2wkle2z4AmIDF2DfFiB6AiDXyKoAFi1bjGuji+ZhufCtmegYMMQDWwGXHmiQA6zDLXvfxpisBsANgm1RfvJoYgJgE6AGAXggABI4UCo+d2MFf/rEvPOlXAYyFgCLKAIAHBqkJivAAoOYCLAGdPADe19EyAGpvBqDYgA1yzjIeAJLRsT7DbshwsK6GECHYJQsNuaBhap/lD+BoAACl85PZbmUgmZMEkFrxdgDAemIAIgBw0ndXK0WZftv+qE4+7l+rnnQYABcBgGTvi5Ktb2QvD8Ciz84xSEWMMBrdgKp6GrU+BwjAFRY8M3P+gRwACC67DEDHA7AXA2BRO+c9AIiGRe8AIAaIDUAlXvTCnwBAcK6BNtsdEOfqCvJA65VmWAjl33/kjsBcy3CzWdcEGAGAthAyJDCaeQZAlrGNclvpkUsA2jqUlLnoWYNSMFJoDUzAVkgUjU2ErLNZLwCzf0veyAC4LgDYMha/+fiJFOC1zPDfr3+/1WIVtx24Dcd2j+GxrcdgjYHR8+dIkgDCYRZ2hDIs1CNmNFZ7ABAfNsAAOCvbxlULkwCtZ2sBmPBi1QsdDtV3g4oQBBQBinOwep4BqI8fg37yKbgQAyxWS4jSXRVBQH8I4OHs/w+E22/v3f7w5TrAK2WMV8YQAXVGCcARoYhOaSk6ZYCGGTL893Tt5nS7sPDaoBp7CSB6ALKLOM/XJzuCDauYI4mNYL+oe4ukcLtzEoCNDIDh5AGwAyad7373d+N37/1d1Gv/DSaHfgATM2wCLJyFyyWAcI3kDIAA8Hi4ILoMQKizRxcAeBMgUBmXKhtmPXAzEoQjpcKOBJqw2+mbAEeCoIjaboDo5gAoIbEiBRpWgEQrAQh0JICaii4AyDwAghSU3EiV1fsnAbrEACg2yWjpXAUR2ByRtw7NxuzeM6geOr/4xW0DXPulYFHiHn4hmAnjQIXv1oEBIN+y1Ibz1sRywGbiGSghPQAIP7Wj0A2wZwKMQ918E+rNp8Pb73YBQOHBDQmGdRTN0RAOYGvgmizoKY8CXsgAhHNIFBiPbkJdHYe25wAAXFi/+FH3PMklAMElmF0mAbTs2aIgIFISsBZNkAAk+SoA5zwPQPDXEYNw220/itXVF/hYaLMF59oALJ5VEBstScrkgHANjfk6uEOAqbfAKlxHetcbiIWArTWkDFHGJmMtXAAAo2jUG2YAjGUUlDcNMmmWN3UsZ20ZgFKWUKTmMvh5H3nLmAa1GGE1dOGL1/RHNnfxK4+dwAfPLW4g1R85A1DIAipsPirtX9s02TniLPDeN8Pu+PMQNrKc4wQACgaakAMQGYDcBNh+RpmSAOdzALIkwFDSakIpcf01Dl9SfyJ5ADhnKIwJDEBmOjS+NDr2ARCl9BKAfu4lgGE7rB8/+KwdxVUwxiurKdXJEgMkPQMQF3Apk+YtjYYpBJSS0ACmGy9Ir0OWgLL0TmTT7MsAkCtgM/lyTCMQZn6xzODbCA0MldhtTs95AEaZB8BOpgAOpOcxMx7begxrxRqYvgoggW1tB02AiQEInzkCk8pxMu5dWyps5mWAgN+OmxpGdAFAWwbod4W7Ie//3Hb3Yh0FBmC3CCVukFA9BmBFCBQCnbRAgdYrIElhLAg1K7BEWwUASkmAAKBFCRvlmsIDgCQBhCTAyACYZRiACADIZgCghgwMgFggAWx/8CmItQLjLz08/OKmAq5/GR7+lnfiA7/95zjPP46/bl+Mt4DhpudBYO8BkNKfT6IHAIpVQHQZACvhPQALGICN174W56bv9J+hnsIUrQkwVUoIBhOhOV8BBwG4VTA0Nk5lZVjM++YApChVKjAa34StrTvRuAAARgBrmyKdgagyCThLEJIhXOm7Phb+w+UmwEUMABID4CUAolD26gKY8l98MgEqdRBGb8HobQAM5gZEI7i6htzIGAByOFqdhjp1Fw7SDQCAyp5oGYBmG0QEGo3AIIjIGmWpocT+GowMgLVZGWDOADhGSXnGvQbFGGwbrwUkD0ApSkghUxVAVY5Ral/KKxYlJgKYGgOMgNUgO5VCoCTC4zN/LvdZvL2GB1jB2yOlnyMBTGvPhHQYgK2jwMfeAit/KHxH/ubSjlCGDUbJjIb99SZjVdCQCdBJIACYbhRwzwRYeADQBADgCgLBgVQxBwAK43tp5N4WF0CGPe8BvVACQjGeHH8t7vyjA/jeVy79VT3jYyEAYObffzYP5Eofo5WVxAAYB0AW3gOQSu4UZFjwlDWwXKJQCjMAs9Vb0usIR4Ac+cnXTQZzAPo6fT4ZF1AoZeld1dmvNyaNCQls6wr9HICxocQAmN1ujb1xBpYtNuvNtEvZcQCTCoYniTrsogrrOyD2GYBZxgBcXxY4OvWTQCsBRAbAH3AOAGIZ4EsPP4zzk68FEHIFsrknSgDTghLzITIG4LBSWFMCakrQ4auzzKkMkOAgRYEVIVAhMABymAHQcgwbWjb3mwERSd8LIJoA92EA2HKazAu0AMDaKnkAFjEArF040RYM0wByhEauYoIVaL4FG24FrxH34S0nfhVv42+FIwEUkQGQHgAwA7NzwOo1gCxArusBEBBQQqVzTqyu+hS1osDoy74M7v7wWD2FVgVK6h4jhZCl5twMuA0gVnDUgLOqlY4EsAAAcI8BOFWfRAM/gXoAYMAqS/2zAqooYSsJsWYgrIKDHjQB0iIJIDIA7FDGHABk3gn2prrofSmKA2iasymJ0NoaQozAVQV1zU3tCwuHRkicnJ7EjdLfXrkTrQcggp2yhCMJVYSFJkP+FM/JEG3Hxg2aALVxKEQNB4CgwK6VAJyJzBuSHFWIAoIErLPQ1uFtf/cn8M0feY83txVdU2U+ota/alu5YU0KPBV6GfQrefYazAxHzreilkUK96mbAQYg5JPYGKYVqwDsGEUAACNRoAEHCSB89nrIAyAAHaslchMgd5MAAwPQBAmAlS8HpVBimwMA5TBoAgRaAEAFYVoA58vn4cTJsgs4nuWxdBTwF/ooyhEonNSGGbHd6TjuhiHB4aSRoaWoihKAaulACuABQgFWJ0p+rgogGy47ORRKFKKY05/Xwg5sU9etByDcN85MgGanCwCmxl/A56vzifbfdQKgAgoGxDarAvAhvf0qAO8BiABAYTdSpkkCAGCbZJ6MJsAoAawWW/inr/4tbO94J3ndC88YS8I1SgJE2A67mdwE+K+//Hn41S+91XsA4qSI6AEgCLBfSIRAwzIwANEEKDoMQC1HHQBAHQ9AAcnryQTo0DIOQ8NmDEBJricB+B2pZwAGFkHrOju7+ftrQJWojYOGAmMEBeBWOoUCBqtcw5EAqSIlK1prgWrTywfrN/hzMGcAyCcBEhFc+O3k4cOAEChuvBHqyBG4EPBn9QxGSQjR/fwkvDemOR8WBif9SZ/JOr4bYPRGdCnQpjmDD3/kG7G9fbf/fqjEaHwTmDVmxXH/kokByMKODKCsg6mDzm0VQA4UDKyi4wFYMO1lDMAo5gB0GAD2+R/O7xKVOoimOZNq7iOT46oKYsP7Mxieqaulb7a1Ung5sMKplgGIsbGjEVhIiCLsRjMGQEAAVkEEcGBNVgaY99FwDkWQEJRcheMGLOImw/+mJCU2r/9nsOMv9810ggQwBVCPVrCzdnBxKeCd7wTe/UbsBEBXZgvramgIBFwYAIgMwJpagxAiAYBZiAS2HQAQ/BE2loJGE+DIX8sACjVCA98GuDUBDlQBOAL0rCd9MFISYKwIiB4AZ2AE4CuJGShkMv/FoQyghEoSlz9W/x2ZxAAQPr1eoonVZBfRQOmZGl8EAEsOISVkbMHLDAgJK1oPgIFKZYHSGp8nHnTmymVI3gpAjTwIWMIECHQZAEUSpSxhGKDscethMtnR9TADEI992tKDQFtzu91sJwAwdRIMBUkW0mm4QAUqawCitgogkwByBsAAqEWfAWgSA7CSGAAfBRwX1J1AH84BACFwKFzcm4HTy3MArisLXFsqFLkHIHQMlAhSAymsSIGaJaAAXeRBQDkDMIJFBAA0lwRIzShJAMDeLEBuAhwRZwCgSSbAhQyA4b0BQGQAogSFESQTVhEm/1CuRlKm3grGGGA3dCBcu94zAAzUIeLUhV4A/sP734RWxhDr6yhuugny8GG41bibnMGM53fSJBmsAH0uZNGz9O65HgCIFGn/s+/sPoCqOoqdnfvS97MW8hJ21p70382IfR19xj44I6Csg60CANASTC5VAeQmwIUeAOkZgNo5jKitAvALVAQAPghr9slPolAHUdcn22MIhjiuKoj19fCi/hhrQTDOQJUHIbaBWp5pGYCQp0+jERwpiDLq/NkOnAhwRQIAbN1gEJCxjEL477SgVTin2xyAwADYYh16/DK40YsB+I561lk08doRcnElwON3AA+8B8d2vIw421lPd61lzEq1T+vxfPj23w6rxWpnJ1xFBiCXAGrvLbBmngEow3JWyrEvmzZ1CgLiAQbAWQJM1TE8dpIAo9EwMADWNTASqY0zx+sme21l0ekF4N/HH789H0plC2BaEii80H5t2i/n+CIAuIAxxAAEsA4LlS5oZQ0MM4qwc+4AAEctA+BMVnqzhwSQrXaSC1+mxYQyo1VXwi+5a+pkLLEgrNsVPH/jtckDYHa7OdszkwGCYDCcOQWmAgoMkdXBKttjAKIJ8BO/h6ry1Nz1pT+pdxW1q3SQAEw0ASYGwEsAEQBMm9Amt8eGjQThQHizrQgA0HsQPCtgEwBoqwAEXGAAvAcAAOy6L38qgwTQlgGOYGNqoxIQQnSSAIklnG3d2XtVAuQmwJFgGG4ZANlhAIboSdehzeeGrQE1Cp6IAABAWIX/DlWgqkmplJ3gAUBYsNavSwyAzssAKYKBANLKEYovuQWjl7wE8tBh8Gr8bBVsOQAABHuJJfQRoLCLfcVT78I3CL+r9876sJD1GIC68rt8Y3fC6xXY2Hg5AECP/G1eAnAdBsBZgtQapvbHTVp4ADBgAsSCZkCQAo4Ihr2m7asAPHPC/mAh4D0Ou39xB1RxAMjAauzy6OoaYsXvGjmwR1UsHStLyNOEZrTZNgOioDuPSrCQkGXU7LN5AwTYAiLIHs5kJsCOB8ChCKWCBa34jIEwN7zme/++/0cwyyUjKglYtmjiXCb3AAC2Bppd7IbwCNm0772etcudXSAD4OCwVngGIO6Iq0EJwDMANjIAcY22Y5Thg45CaePUTKH2OAxfBjibAwCpkUhkQYIHwNgGWlEbCBM+r8s2VYWNHoD2mF1I7bTnvIeFFFAVQNRw7RcBwJU/7FaNVYS4TgYgCl8FEE4wA5XaA0trfBvesMusOHMgs/SNWGQRcgDmGYC57PjsV5KQPqsdhDKLeF8NNN/E5AwA8Jqdr8SLbvh+uDUvQ8TwlDiqrDFNZAAMrQBUoCBAhhN5tdaQ7N26EazE46p2T2G245vaXD8KMoLK6q0DAzBvArTwJGmoIQ5IPwKAMixGIyFwINCXWyoamYYBQFyQXbBq/bVDG3gNfQKCSoylQB3Ahl33F7UC9RiAopUAilgFEHwHQoEtw7m2PntZBmBMIW2N2XsAIgCgEsx6znXNZg8JgL2pEqplAJhLCBZYJQ8mJJyXjgqVOpIbY4BJaD60fgMgCpADzq8Dx25dwbGbRy0DEBZJGo3w/N/7PVz/Uz8JefgQ3EoAWKaCXgAAnCDY6AMJqPjI9HG8xn0GI1vBZQxADPyJo6oDADA74fspUBSHHNoRRQAAIABJREFUMB7f2n78Ebz2KjIAYAiy0RkDQGDiFgAIkTTtPgPQNGdw3/0/DacsdGAMvATg2wF7l3orATAEdj/4QRSq24HPudqbyGazxDhEkFJJH7ZFZQl1mqAP1MiiNjwrVI7AJCEiAMhNgERgV4AiANiDAXDhPQsaewAQPAAr69d0Pr8IgD9KABGGWikXSwCmxumJwl1Phm6IGX5bkxcPACxsAgDxHIwegE4OQPIARAnA31zYUcsAhAV7qqcQ/cPI5lJneKEE4BmXMMGO/NxpnIZRlBgAK4EHX/L9mJ5vZdXCemNlDmwjGLCbUQIApiVScuxSwUuXaXwRACw52DHKiNiYwUKBiVC46A1WvjoALQNASoEBNDZ388rMBNiWAebleREMiKDi5wCAWGEsRnAQKLId4mqY06ZWZx4AQhkCRKpxOM6eBJAzABEAOLEOJoVCIDmebz29BWK/+4mti6MEMBPjVLp3XeiZPVGE9x/9gH9d6wA3bwKUsFAwiQGoQn5ADEschdcfC8J6+E62w6Qp59d/KDGfA/C3rzuIN9DbQUKFHIAIAEJ8rujmALynOYCf/kpfAJMAQNjFE/mgGGdbAKD3KJfiLAhoJPwE4ne+rmMCBDCXiMeGF5sAnQHAXgJIk0cJAYG1wABItt4DIFXKs7fWdiUAIYMEAPzWG5+HJ29bSZMvh9+IRiPIAwcgxmPIAwfgQsS/cw3saH76IMlgAszEH4dATMJUsCd28Q1n7+h4AOJrxVFVvrwrAoDdD/w5Hvve/w4HDnxF+92MAWdMpwzQWQHpHEylAA1QA+8ByPpzxLCdvgfgwYd+AceP/yF2Np5AEzwDo5AD4BA1avgoYHiTY/3ww8B2d5F0tvJ6MDNo5M+RBABUYACKEmICuJHrmHjd7EwmAQRQFxiAaOCFbSUAZxipG2AvB2BLh4oBDm70sDlIiZMhMleEv1EC0LkEsKiO39R4anoIp6bhN8s2ITkAqC5gUWNmOJ5nAOpUBpgxZH0PQNyk2xFU9AMEyn5qpskDEIfIyofYYKEE4D0A4cOVXuYwtoFRlLwb26bAsVu+AcefaOdQZX0pY6cKoC8BSMasJHBsFvVFBuDKHyQFinCCGWbYcPHE2yxkSg2T1mIHhB8VJR68pUCddwBk5Xf/Ui1kAKIHQFJYELPUmxuqF+FXP/lGEBRGOQAIj5ka3WEAigBXZ0EjiDuzOLoSgP9MLNdBVKIgoBr5MrTnn96CYAYLoNFtJCYAbMtxcgX/6YP/FoAHAPfOjvoH2KzTHnIToPM71XBF1b22teMwoYyFwHq4azvM4WqAASiyIKDYCwAAmBsI8lUAiQEYh91PqPmNJsA/a8b4rze+AlYAqpAQIi8DLDwDYNtWt3ulAdqsCgAARNZAJjcBAujIABxy3nnRJBpjgFWZJABCCQGZeQBckgA6DMDuSb8FWTnsd7Xsf8eZmXXdyEHP7ZjnBIED9nGuhisHAIBgsCDYKAGEVc5BAcZh1c46EoB/rSw0peoyAObYcVT334+NdS8DxBJ3xzNoymqtLUE6xul7rgH9/ppnUETLAACtDNBnADY3PxluV4kBKFMOgK8CuObIUSjZJAkAAHC2K6c5V6e+86IMMlEAADNJSQIgHXTkvHXx1hPJBChH0ZEeFuhYK555AFxm/OtUAVgGS+9dk1aCMwkggs7YpCiCT0m+DLCJZlGpFjMAtoF2EjbICLle1/EAXICxrc8AOOdQiAJ1kAStafsUJA9ADNAJ77NRX4Pnv+8f4v7pN6Ms/IKtnZ4DACRzAOB8n5aMAfBVAPAegPgdjNbTexpFCbhFE7SpMhNgkADYaXB4IHMwAQYGgKTFpCS4LwKAq2eQynb7zLAhQSveplHChL2WtL5WeAbCqYMyMQCWDMDSmwCFApwe7AbIPQBgMrPTyBzAqh0DpDoegDaK0wMAJxS0kAkA6DBZ21nXDZs33mgZgDWQ8AAgjiObM5+DQIRp0OQiM/HHG4dwsplgRRD0w/4k/8Q1Em/9yu/GY2sida47HdLhVjsmwNYDUNseABAtAODaYdw47JT+oMQAAJDULsgOSK2AnTPeAyAJNaQPdF31k2GMci7DTn4zXNWNJKgykwCY/K7AMpjnPQBDRr7cAwAAEjq1ApaixwDkiXihFwTrBRNDBAByhNo4RIGJILFKLQNg4ZMA49mTJIC161LQiXAEJ1oAIGIDm0wCiMPaSZox3P/P3psH65ad5X2/d6219zec8Y7dt1st3aY1D4AsIcABQ6DC4CF4JLGdiglO7DixXRQmBeWCxLEdO6ZsQ6pIimDsYGIHbAwegjCWYyMwEoMGpJZa6tbU872373DuGb5h772m/LHW2nt/554WaZeRo1Lvf870ne/b41rPep7nfd7Q4s6QAJQiSQ+ZDVMZ9EU0ErPnYyQBnD72ps1BQyVat/UQAlvVawAwNzPgjg1+dG6DywzA2iDPbiNd2JAAxsciRnN8/ChNcx3vG7ouySLBtHTZtyNtaqNbcgC0sYiEJAFIavKq/WYPB+/XxPV647MKA7CuigRQITatIuNYAjh5FpmkMsBeAvClgVg+V75CssEvjCb9TQnAE3XOmQ+BMEoCLPdcLAZP2WQA2iL/TOXFPQCuwQaFL5O9G+6Bf1sJIMbkj+kZgBiZmindqONlbwQ85QHoZfoclPTJ5quo68GYeC8AGH2uj8RukwHoJQA1kgDy+/lg8UYNTZxKdUU7BgCROgTCrY/1/VR88WTdPUwAMHqWNcQMos4KZ/tcbZ9zACAi3yQiT4jIp0Tke874+0RE/kH++6+JyNVTf3+liCxE5Ls+V/sM4G7e6AF7iPQAYJL56pa6T1wzo4lsOVXYzAA41SXnp656CWDoBjhaDeTvDenGsmMnS9bt4hgARMc8P5DrDAC+89J5vu/iOeo8yhRTl283qeZNCSBPRmq79wC87fEf5Q988BeRSJ+DcLjONFwxjKmaA9sw04pqnd7/I/upbO/6TPqOWe/OPgSVV9saj46h9wDcCwCKB0CwjWPeRk6mOWvhDAlgzACEnAOQ9OXQMwCQwdo0D37W8oGffwof5hvv1RnB1BrpcwByyY4PeL/pAVgsnuDdv/gWVqsnN94jeQCGY1JYgi8MwBAElF47YgCKtvtiDIAfGIDOBco0JCMGQBPwIkhVnWIAbsL25WGfxgzAuPriDABg7RB1HaMlTO6NERFNWiGr8nP6/8bsEGMGJqckgNIPwB01NMtNCYAm7f0uj7D7qQeYfjBLCqw3ywC9YDL4k+2tVBqnYoprLftWJACled/7fx/vee9XcXj468Np1R1dBgy/8pOfRDGqAlAxmUnzOYoiaLvZFDXYVYr4BcgMQPEpLOq0IlWZAYAkZfT/e/J87wGQ3gOQ79HMlog3REr/+bMZAAkdsSLlzLuQwol6CSCPHXni6QGAaFx02Lxjaje+eEtg12KjxpdGR073s/D831ICKAzA3KQqgBACUz2l64bFiSs+gAIAQolE3nyv8+ZZ6noou74HAJTbobQfbs8yAZ6SACap4sF5yy999T7NTga1eXwaj6mVg+rkBWJ71LcdPmkT9e8PD5HZDHzH8gtRAhARDfyvwDcDbwT+sIi88dTL/jhwN8b4auAHgL926u9/E/jnv9X7es9mFFWu8/NEQgYA0xKuxgQXBwagbMupwvkBAMSRCTC6oQzQj6sAegYgAwA9PIy+oHjRvQdAomWWg23W3kFwfLKuOFGqZwCKphtOAYAxA9BLABkA1ErYaW5z3/IIIqj8oBw1GQCUu0cmnISQ0vjy+z+zlRkJLT0DsCgDT6bEFIHJC2/BumROsqdoxzJhT7SiazzTLmln6dy8uAnQhcg6ROZaDZGyUvWMQkeNz2bF5sDxq//kM1xrNuO4OkNiAJRkGjefRxcJYZMBWK4+TYyu16/LlpIARyEh0fZU/zgKGOiz74FB+/fx7BrhEQNgfWDSV0SMAEAMBASpq74tdPIA3Ez6P2m1o2K6jo1vCDH0HoChfG6Y5ErbXYCAJUyynDLyuCgFAaHsktIJLB3Ur0i+jOizsc4mTwUDe7J44mlCZjBKFUDM6ZBx0XH5PY9QHZTumM2mByAzAAAy30I6f48EoPKxjJsBvfDCz/YgzOsW22deRJRdphBLl4x0xQQIZwMA1y56R/hpCaBTmxIAQBgDgMW15AHYqALIbv08EUkwxGzy7BkA2fQA1H5NNOC7VNIYo7tHAijdDCU/j1ppQgx0GdwkE+CLy08uKHweb6Kf9GE6Gx6Al2oCjJ6pmfYSwNRMsXYAxb0PoNuUAE4/HxO1oJ4OSaf3eADy6l3t5g6JTXOPCfDsMsBUxvnob9vHz/J9W1pht8N4X3mofJvGxjxfFNCG96jpFHzHopa+vPoLBgAA7wA+FWP8TEwj3k8C33LqNd8C/N38/T8Cvl6yMCkivxd4Enjsc7S//aZm054BcBGcKg1yQEVPy7TvULXBAEwEmwGA1V32ACQJYEN72pAAMpCQ4kwf3aAm0VFR1AYDMMv0eusDBMdhRqcFAJRgF999NgagAIAtkJq6zCvCBgA4aXPwiQz/twiBmVZMbDr2m3mlvjRApu/WecCZiuW/2L/O23gfO51hlc/l6fa6k14CEGzrqVzsa9bPunErJfgIh9nAdK4y/UpTqarPH2ipsRkAkB9efSr83lagtUrBODoMnxgiIYxWxSFibUL4p2WAEDYZAI3rPQBaD82ATv/vRvnfCBh+1y9+F+9+9t30DURyFcCwN5qd3gQY8CQGYEMCWNxMFQDpQ9OXDBDWbt1LAL0HYBSha93AAAQcId8g3g0TodIJAJRMDMnX1qkJISpMdPgAMTq0nm8ce2tv9O/Td9drcl7A4oTYdWg1o6VmJS1ji3fxAMCIAdAQNxiATMuPtOrrN36Gy5e+GWP2MgBIrzce9FP/hhADzi2JKIRUBljOmWqLGJy++G5BWOf8g6o8S9kvE1MQkNR175zfYADaw1QGKCYFAQXNubyfugcAmphZwTLpy0T3DIAPkWlsEwCwCimv0aWKJR+/OiUBSJIAXLnFlcbaBV232W0xfUibPAC6MACTFEvN4AGoRV6SB6DkAFSq6gHARE/oRgCgH7eKCbBUkZyaPEM01PWLA4AiAejcqyG27Qbb0ZcBjqsAlIFqhgsWo0wWEelN3+Mx1XiobJMqwrI/bDyyqOmU6BIAGBiALxwJ4EHg2dHPz+XfnfmamJxCR8AFEdkGvhv4Hz8H+3nPJpPpUPIXIz4P3BKh8paWuqey9eiGWkwV3g0MwGACrF609r+XAAoDYEYMQJVvXFFUDohhgwFogsf5juM8eQ4MQF6tdY7j22ue/uid9PpxGSBDFQBiqEclOQT6NMFFKc/JICNKzSqkFbtxsgGAVlqI+ecmTwY+NPzJ88/wAM+z56DRyQ3gTg0aU12qABS29dQ+9pkIZ5kAjQg2RO5mEHK+MptNZVTxa0zw9aD1poPYpLP9ZHh/pQIl5CG6QBiN3F2MWJt8D6fr+ZMHYDQ44Ppa8SIB6LNMgOPGUBkMxBh511Pv4gMvfGBkAiwAYNjXi5ImThU9XlQCAPlcOWtheStlAEAfzqN6A+nqDAZgAAAp8x6wEMX1QSjO5tdESWWAyMhoVuV/MfioqKPDh0AIFq1zrXxJYfQDAKDIEY0jAjef/DSx6zBmi/+dP8NfvPoqonicywDXCbo8T/N5D+xkVPNfJICox0xT5MqV35/aPKuWpsrXJaQMDB8C3p9sBAGlQ1WIFUQMapGZwW45eACqTQ+AJ1cBTCYDA1CnbAlIngdVTIAqoELFTlmtlqRAPwIAedJXE5Op/oj1gZm0YFKr2ZiBcEkW7OWmsgzOn10kgAJBnTa8cPC3+dCHvp1mafnnP/wRVqU/h+uwUfUSQPBjAJDOw4PT6iX1AvDBE0iTfgEAMzPD2jM8AG26v11wKFGZLR2NnVIzmYw8AKeUjCKH6MwARC99Vj+MJIBxDoAyYKb44NCiURnxhQxAQzfOSoHarglKeoJqPFbJbEbnG5qKl02AL3H7C8APxBgXn+1FIvInROT9IvL+W7du/Tv7cDWd9KESPkRCXnFLEOrQ0jLtzWxmtJJdTgWX3XJOd6mXeDYBhjgMTuNugL0EUDwAo5WOq1PtcVAqrXhSLQtbmbpsQ+B4NKlX4ZQEYB0f+lfP8q4f/SiQamUhP0KqhhiJap4epDwxFGd4YQBWmdIvEkCUmiZK6qDmNdWYATHSt8ssDID1bZ+VvW/TezfMehNl2aYjBqBrHGa0Mn4xCcDFAQCcM3qkNWs++VgijjpqXFmhNaUevd64br4ePktUoJcAfMT/f2UATnkAvn57xYc/nJqYlMH4TAbAjwFA+t5FRyTS+hZ8R4hbnHx8Tuc8YyvaBdL11DHiEKgqfD6PrllAsD0DUIxedf57agOdj7kAgOkIAGQGQB+n/S3FLaVrnbJzRGcAkCfbNp/T5eQWosMpBmBr49itTyvOSl8Yjr+xvLC7xU//1I+ztA262uEOF7hZ1SABn0vlgle9B4C6htJ9sB4xABnMhNE1mUyucO7cV1CZXbxqWM1TEx/jk0QVYsTaBACSB2DEmliHMbvo48yE2PXgATgNAOJYAsjemQlonSarYJfUjzxCEIMoi4QKhbBz8kyfQCpejRiAzHaUNMZrj+GcZUYLVUwmwAIAzGDIjGFwn49NgCEG8m7hlca6m3TdbW4+dcxnPnSLG5/J7I9rNhgA76d9R71vuLjLn33lZd64PXtpEoBPhs1a1xsMgHVjCWDTBBiCRYtOz9h0eFY9E6pqBABOza2Sf6H2sgTghZgBjIgkP0CMMPYAKA3VHBd9Yil6FqgwAAPKMB6qbkUUUEWSkmEn1HRK5zvaL9AcgOeBh0Y/vyL/7szXSILHe8Ad4MuB7xeRp4DvAP68iPzp0x8QY/yRGOPbY4xvv3Tp0r+zHXdxyexymkBc8CMGoACASc8AVKOJpK0VXZ6EreqIvQnQ9IEz8GIMQK4CGN3FLlPHXhQqgGAzA5BXWhHu+FEyVVnZFhOg9TQLi209McYRA5D+v2YForCyxWSUy83IBLh2LZHQSwBITYNiqgQdNbUbVr0rQ18G2BTXa2j68Jf9zDuumOPOiACGJAXYxlON0PxZOQDFBHh3JAEUBmC5aPjEYwn0JACQV6j54fX1earRgzpitVHa93oePhBGwU42RlwGAM3Tt/DLcf1vRCnLihkBxYN16HX0IQfgLAZgdC/YjuXyU9h8DjvfgWtZhy/n6Ndrpgu7wQCoPLirsQRQPABH2aNwIUXAugzkitTiouslAMmAclwGWCQAdSxEE4cVUAYA2m6nzo5RUHsZqBaj6Jt/jItvvJtMgDGZAAcJIEtdobSoHT23K0ubr1XjLKbapqOmVSmiuQCAJAHk586Y3jvAqFKh+BlCLqV79au/h7f9tp9ARGPMDl41LKcJAOgQUTHkMsBFn4dRBv+ohNh1VNUeKs+Nwa16D0DvPcgAIJAlAKWQjJyiBmMyCPJr9v/wH0nUsyQA4L70ed76oR9EZROg8qr3ivSr++zDiD/yjVQ//98xp0WqxABgCwDI5yUIoAil1W2+V4oEYMt9ogw+rPChZXmUw7nW+Xz6bsMDENyU0lHvyqTmzz/yAHOtXlIVgI+eyAAAShWAGwUADVUA2QMQfAIAIVK9wvKxy+8F8QRVYf7Re/iz/zQf+2kPQM8A5F4NXoiZ0TTG5ByAmM0sYwkgMwBKj3wgeewYGTIrD1W3TCW4RYIZzbJqPqN1hQH4wksCfB/wGhF5WERq4D8F/tmp1/wz4I/l7/8g8K9j2r46xng1xngV+EHgr8QYf+hztePOHTG9+t70vfe9BwAfqENHx6SvZ69OadmLDBZcDwCSCTCM1KExCoynTIB+DADyEBSUShNy9BAd26asOAzX3VCfXJ+SAILztEtLjGmCKh6Aov9PM8ESRScAUAxdYWAAWm/x2m1IAC2aOg+OtTslATjHf/P67+W9r/huAKxrUvodiq380jWzvn1x2YoEMFFC13gq/9kZAJ0BwEFhAKqBAbA29iV/LROcikgIfY63e8sfZWJGhrfqFAMQBwYghBEAGDEAJ+97jtX7R9nwPuJV4Dv4YX6Z37G5r6fLAMfsweheuHXwL/m1X/+dLJv0vp3vwLdDKWIbNhiAIuPoGBIDYAyxTPB3n02D/iu/Ir1XHvgmY4qySABntNFNEoBCLUgNUXJ5arO4RHeyg2n3M8UqyHamWEc199WWQ0XfJwH2ACBPai4eI77CqFHC3rrDlf23DjPZw1LTKpUZgJEEUIJxKgPZjCrVMMSVIKCQZZn57FXMZmk9YqpdvKxZbqfPNj4bKWPE++WIASirP0W0llc//N3s/JyABW9XgwfAFMd91udjkgAA1Ehu6lkQv+5ZQBGLBIM2ERNbTCgAQIaSyZ4BKGWWNfVHf5KZdKgq4DvdV98UABAbC1H11yQyAAAXXe8B8Erjw4oQWlbHuT/HKj+ohQEo7+FnRLtZWjxT6iX1AijNgCpVoXXqWjlTM9xoIXGaAfBFAvARvRX5pUf+AVI1eCbIZ27w2ufzIuq0BJBNARsSQH4OtNZDM6DTEkA1w0WPWd7uY9VLD4dxaJLxULdLogJVxsGRCcDXFZ1vaSsGD8Bni/z+Ld4+pwAga/p/GvgXwMeBfxhjfExE/qKI/Mf5ZX+bpPl/CvhO4J5SwX8fm6ganS+4D64PAsI76tjSjBiA+tRK9jhXDFjdAZqoUhJgGA0EZwUBFQ9AyDVvKsSkvxWaNngkOiQ65v3kZbgWBgagLnGiOrX3DdbT5FWq6zyNa9ipdvoKgJ14t//f2cgsJVFSDgDQBUfUYwagwmIweaVS++HBXRoBb/mZ+/6j/nedXxOiAwzb+eZfM+PUs9ozALPsAah+EwmgUqkK4G5G5GMPgLWhb91sqWkX16ii49qrvgczO8AHRTUKXLLjPiza0z8qPuIZAMDYAxCVxS9GGeAhmRaXss2teHFjXyXrJyWO9cU8ALY7IEZP06Uc8da34Fpinval8xsMQAEqhQEIZjgQd3gNHngrTHY4tI7ruZxzMlqiDB6ALHGNqgCsO6Yyu1S7F4lGsjQCy1tXeeYXvhHlJ0PJ2U6mWEfvreuAxIjzKQ3RFA9AKQOMJ2i7hRqd37jueqBpvcNM9+io6URAbUoA1TyXcmqNFAxajT0ARQJI98RTdpsPHqVzYMweTtZ0X5d8CAVM+Bhx/oSQTYC9BKASADi/9ZXUTyrEnsoByOdv7AHo8nGqUQawyabe4NejMaBDQtWzdz0D4KQPlSn3iMoSQIw14jtmND0DEHsGIAOjdQtR4YsTrngAegkgMwBiCHFJjF2v/XeNS6bR4LBREbRGhUDE4Neb6aJT9dIYgNRtMTLREy5cuJAYgG7aM1QA/pQHIJCAS/QB1WVWTQJBasQFpvnlk1Md73sPwIYEkCs3svyQooBHQUCiuWFqXPTo4+d74OtKUuvoea08VO0imUQzaBnbi9bG0wVLVOMqgH9/EsC9hby/xVuM8eeAnzv1u/9+9H0D/KHf5D3+wm/Jzn2WTUmNzg+/C5FQAEDwTLIHoJcATv3vSfm/EuIhNVpXKR0tb/4MCUCXmt8MACY28iu7ht//VXlgIDDpPHUX2DY1EIlScW3Uo7suJVrKoHB4D01G8z/1sZ9mZVdcmF3gcJkerPPc7jWZqdIIMngA8kNtvQcdew+ASI3DorL2v8kAAKcS/jq3opElRD0CAPN7GYCSA6AVtnUbwURnRgELvQfACGxrxSIzAF03AICOmucuXGRPpYm73r2Ot2/uew/AWQzAKAdgLAGEgHWJAYjaEhZjCSBgdfE4bJaMxcMV7I4lgLOrAELWQTuXJqoiARQAoOxpBqDcG5EgCjeKwvWLO/ClXw3A93ziOZ4/WfD9DOcZRn6PzACMJQDnjjDVLtvveCvdnV9HHeUVa9R4HBI1kicbttLk7pX0LnlVewTw+ZhOSwA+HqPsNmp0RHHV4nJFyaq1rNSMjjrpsmMJwAmTc+cAn0KMypg6YgCKB8BnBuB/uTHnefcsv/CO11OZXRxL3H76m/GJPg5Egl8CU4TIJGvw7WxOtHaY8DsIvhkawxQAkF9fqgDStRlGiIEBaGhyqVsUm5gQrxEZAID2EHGpxXAeI6Quq/l0bOf0ISLgO8Xd31jAw4MJkFXDWAKI90gAmWkRQ4hrYvSsjtPxtCvX50/YoHHK9JJLt2o3JpKpks/qAVh/7A4IzN6QvB6FAah1zeXLqUS1Xtd45yjL5w0GQFU4AS0Kbzvq6x+AfRDxBCrEDgAgxbcPz5ZSqaRXjSSA0JX7MbEPMW5WATzZ3OZbqltE4KtH47TLbMzYv2VcpG5PiAq0s1gmG8vs1oDO5/ELsQzw83ZTatK7P513uLyqJwRqulRb3gOAdEEfysuQdZfoW6dLgt40ewDGDMCLSwBhBABu1Ipr86zTBk9tA9M2MjfTJA6I4dpoNVkkAJShCse0ak6bGYD/7QM/zKO3H2Wn3kHneu25dCiXVpvTwgDkYLciAbgYECN9LwCvJnhqVJ7ExgzAyqQqgCvtzf53J90h//RT/xgfGUkA857ZKNumCdAzGT0nL2oCDHDX+qT/n1jcIg1g1obeTNUy4YXZJc6TKiGq+QHehtQXIG/daEQTFVJ+A9kEOPJuJAYgicBR2Xs8ADZ3DGtixR0nLJ5JlPMzz+ZmN7+JCdD3Brk8EGcTYIyZAbCBesQAFAlA5ShgO6LgHQqufhUAN1rL7TxwTUensjAAqphcN6oAjjBmD6UmRFwOSEratJdUp15WWDIbAYC86TwReVco1wIAsgzDCdrNURlgidTQdr2JMRC40cTMAKTJsZcAvDC/+nA6B1oPEQGjuGLJlR/RpGt06FVfMmrMDlEsLvtUiqEwxIgPy5SpQGRCvg5b28TTIdAGAAAgAElEQVSuI+Q+84kBaAjrNTKd9p2Ki2ZfqgCADYbDFBNg6Pi/HvuJvKMdEgwmaCD2923xLkZt+3tE9RJAuk5v0k+m97MKe5zZmMIArBIDEPphf1MCsPlaJQCQFhGrk7Qw6Naud/vboAlajwDAKQlAqyx5nD2xnfzic5z84nP9zz74ZAJUNRcvJqbMrAz+tAQQAtglbF3MDIAiBvqeKUp8Yuc6R+1B+0gdN6e4wlrp3VRNFTw9A9BLADEyTgJ8uj3oOd16FGDl8gKtMABRwAQwy5tEEVSIxAhxJOGuTaArrbBVuXdfBgD/v9+UqnP3OvAx9FnY4jx13GQAyuP9cJ7AV1l7tCojP5nwj995P+89+c/79z8rCrhIAFEriGFDAwdQeGrbUbuWWtcYSR6Aa7HrJ8tBAqioOaKd7NFmQ48JNbfXt5mZGbMqmZ8qFdEu5bHPtEGiEIlIlB4A+BiRDEqmedUf9HYf+FPlFX/ljrME4LiUKWyAm8trhGiJUdjKq91V2O4H+rJtmgBdX8efzs2LBwHddY5zxnDwU09w9O40IHad7z0Alprb6gIX7W2IQjW/i7OBakRXWzOca68WdGUw8oEwBgAh9B6AqCxhWfrcR4hg81uexJrHG82tf/PFXPpLhueezeV6Z5gA2WgMlRmAzOqclgC022QA6AFAYgA2AYCGvVcCsAqBdb7PZnIWA5An4Y0cgGMqs4eomhC7ngpVLk/0UfcAgOk0f+bIAT3J9HkOjtFmswzQcZwkgFj6JFSErsP1XpPUrbFjQiep0dZ6vcvi6Qssr8+58uf+XPogPWIARi1qC5vh83N14oWTHgAkStgWD4UHCeDWLcEt+jLAac5ZWG9tJQagBwBCCA1hvULNZv0zXCj7kKsA0nGNkhuKCTC0HKyK/GZRocoAYCQB5NK/qGzPAKhZnkTyOXtD9VQ6xk6ldreMPACZAfCnPQBZAui9FmIoXX7WuX14AgBFqlE4bQZGbbWZLVKe2xdjAaL1m6WuMfYMQF3XnDt3DllKZgDS5q1Nkz/A1kW8CBohBOkBQGEAyB6gaQf1qNKqvAY2PQAx5w0UEyAh8OjqtXzwV3KEuR0Kz6pRe3Rf2B0fQWt8JVQO1K1PpM8oRM1oMbHSji4vkIo85r+AqgA+bzcRg87mD+ddj94IgWlschVASYhKX3dDQ921rMtgWBgAqbl7t+KOu9q//9kegCwBaIVEf4+hRQXP1/zKP+Gtj/48Uz1NFLZUPB879gsYiaXzl2GxdYujvd2+bNbkqNGpmTLJpTO1gLYJAGgZewDoDVCI6eurZyMDjM8GndqXB/B2kgC8o1XDqufW6gaaSIyqBwBN3N5YLQI8Mp9wvtKcqzS29WyNarrPDAIamQDPVxp/2Pb6ZNv6fsBqqTngAhfaA+i2MfMDvAt92eNO4+jyR934S3+ZIEtsPs7TDEDr1pTZJirXSwCF0SkMwEeaKT99t2JfQXVd8cL1O/m63NsLYEMCyKE/LjMANljwLWXa1zayVX2Sp1RiWDYkAIROnwIA2Suy9oEmjzv7CG84/wYgSwyAyi52tVEGeIypdtFqkvvMZwnAJYO5BEPpPFeicMetXFVOUHP2NANQnosFym4jFAagAmtxpYJFCa2pUha/SOrA6Q3XfvnNtEcTqvksRbjWNcVQMh7/pTcBZgAQYOGT0a8AAMeQBOgbjV2tsUc3CFEnABA2AUBoGp657wE+ot+S2gGv16jZrDdyynbOvoijcysjAFDOAQ6bA2UCLRIqjFcgkUl3zGEFf+eBr8Whk4nxFACIpPN9Ree+Blb1rXILAAjLdfIAFEZFSqy2wQU3SACjGavJzY3adZIAQgQfFUHp1EgL6JpTACBfrxfLAog29CZG2JQAAC5dukQ8SWa8srmuJTYn3OYcbF0muXJSNFNhZpW4JKvmbP77CVz9lju48yM5r5QBjiUAW8K5dN8N8GZ3nueeSq+9ZYcEzGoEaD2lM6NP1TYaag9ksK5DTG09Sjw2sFCWtoQYvcwAfP5sIoLKrjfv/WACDIFaNssA27x6qm3L9vKYRTYnOVUe8AmdFdYhJ1YJZ7YDLjkA0SQAoE7dJzp67r91jQt3b1Lr1O8+YjjA9wCg5AB40bywbznZG/wBJuunMzOjzmakWoF2yQj16CcW7LQpplchQ11rNEiur56Nav5tBgAPHbzAl71wi4k9SBKA8zQjAHBzdR2Vk7JmPoGLNVs42bwdv/HiHh/7qrewpTW28WyNDF1nMgCq5ABkCWDliHnQbVvXA4A7XMJJxYXmDrR7VLMEAColTJWw1Qa6zHAc/9zPIeLwYSQBYHoncDOquAjK4pddSjbL17CswKNUBKTX/25dTzXvPQDwZ5sAy++tG0kAbpAAtAtodYtr2c8Qe+NYxIvqB3Ug5VSYNFGsfKDN99OEyN/7nX+P7/uK7+Pb3/zt8OhPoT+TWznXA9ix9qhnAOKYAegCXsmGBEAGEONGKbr27H3RMefkb6WfT+UAeMkmwCwBlEZCfY6BVixHlRodNTEKvrSXNhVKK/SVB9h62zvSe+xu9a8vbIbPAOA4T0KPHXyG735PyhfrGYAQES9EUYSwTJkdEabZv9DMswSwXvNX/9if4gcvfSc+doTVGpnP+ox6mefzAGcyAEoqFJqg6LPvI6kMUPtUgHPlhffxqxcNP/WKr+Q5HkoMQEk9HAEAO73YAz5v9cAAZOklLltgMAEWBkCJwkePy/eqG3kUXN6nbu145mMf5flVmji91phYGICze3i8mBEwdpudLmOMfQ4AwOU5uJMONaLvnbV89LHH+CG+jVv6CgHBxCJhuP6rxxDaBqeE11iD2Q64KwUJqVEQUJEApK9iKCWIhEhAYXN7xJvdAADGPUj8qAxQqoqgIhMXe3O0yQAADW4rXfNj1dJlxquc/5cBwOfJpvMDFcJQBijeMWEzCKjL+unMd+wsjjjeyu0pswTgYo33kugqwNT6s0oAaI1Ez2K6Oenp6NBB0EGY6AkTpdmbJg1tvy9JTANEVwwn42S6wgDoKROTHogaoWoThTU5eIxXVBBJmfFFAgDVm8RmY5ouO3SvHB/wn3zi46iwTr0AvKNRE0z7aWbHP8/t5TNoIIbULX4rQsP8HgagTPLeB5wNbE8GAPCbBQGdM5qwtoSSQdC4XrO8zhUALq1vw3oXM7+bPAAi7BuTIofzR8W2RZQjFMejDzhRTHLmfjtOUlQOXCR2fgQAiuGqRA+n/7v7wmdhAEaDo3PFeJUAQF8GWEyAzoKA7W3vJtXhx9S2dgwAHLkElQwAMqdjCNS65ltf96287vzr4PYTSEhgLm7lvvYxJgbA7OYJzKNyNz6xISWfRd2XWZGfAdYjAKAt+w+fsK1/Lf9cygAtt37sRwmqRdst3NPJM1OCalzvNVGsqpEBk5qWmn/wO34Xd/YvYqoKURoXPAdf/tsBmP/2r+DwZz/DwU8+PgQBSUeUKYt8nj95/DxH2WVuqdDRYXRLyJ8ZWePTMo5Jvt7rbAL8jbXl8YdfzULvcBhrwnqNms2H1asZygBdKecbAQBRFYoKr6R3ukdJVQDapRJcEUnPUT7mqCxSGIC+CmDK4Su+dnjOO0XIAWTFAxAWC4i6BwB9cmmRAM5gACRXTLQrxy/8w5/h3TcfztdiYABsuwkAZr0EcPbEZm3Xsx1wBgOgU7npJAzgzXUtH/jIEwAcqnM4oQcAdaZ7DJ4QK2Lb8b4vusLrrydZM8wzWNK69ABC7+e/OSH6wQQIEEPAR4XN3ThvdYf9fowrvLyUBV1K3HQ6MnX0kSE6RkL2D/vt9BwdS0s3qi6Af79VAC8DgJewlbHNBdeHOOA9E1q8GBwVKgTa7ACeuIYL4RYnuwkAFAmgcdON960m+kwJoPQCSK1ZHUdb6YZ5YJUHFRU3AECthAuzlPK2n28ukx/mtp+IRtn0uZ59ZmZ83au+CUgMQNU9ybfNfo0/dPF/5qH7P5VSrRjKABGDzgxAPYo9vnz0VP/9WjoMlpUB5yxrNcF0n2b78O8Tok8u/vwAT11kHef3MADF6V9WGDvT6p6/bZzHPgrYsy8KwkCht61DgMo7ruf06QurA8J6l2p+gLOeWgn7laayw/kKbYsoT8iwPrqIF5hmANCMeykUhmdh++vZFdmiAIDsZrbHJxw3qSGOiNkwAbpuGBC6DABcnnh6BqAo/yEZEG0eBCMVh2z3VQCbAGCTAQgI1hjMqbJVXMPqiuN/+lYFr3skfUxYE6PFVHtDH3ntIAqqs3ilNhmA4pFpl8M1M45qPopNzQAgho7VE7+RXmO3sJ9MaeEq37u+GoDAaQbgen2FTz74MM888EXoquZ49xzvkjnvf/8H835E2iePaD9z1JsAPS2dHsoyD23HOpYJtsJgOffad7H+ohVRCcvmgBAVxMjUFwZgRrSWH7cDKH1OncsAYPAA9ACAQQKQqh4qI6RKXgeVcg6gAAAzxNiKJCktH/OYARgkgAkHV35HDzi9Vf09q0yAAPH4CEHjS9hTvieLBFAYgCC6BweiLNvnJnSNo2sajro0kXmt0bFIAB6e+VX4l/8D3PpE79W5fWezPLBsv+Af5V93H+p/jiEzAMcJ+J3LQU01UxBBG8PxcsVTmTVbql0Cw+Lmla7lh9/4J9kmMQCxabi7NRu8D6XRp1ZDY6T5HLU1x3eKMPIAALk3gSqPKre6oQfGmAGIWQ6KopHK4BTMfOzDr3SglwDCTjpvd1nRRpsC1ooH4AslB+DzfTNhYACKCVBFzySv7NfMUNHz0HG6UV+7vMXVB55mOd2m06GXANpTXcSqWp3ZF0CPTIASh4Hzq2+l75dT3QMAo1J2/8AAVPx9fZXtoDms4G985ddwe2uXMOqhXoVBAnjk3OsBeh38weCpdENtLBCRaPokwMprdB6IryzSqn/7zt9CLYbo5VYsW1oRRDh2llZNkJGDVgFEhY2Rug2pCmBkAhRA5Qep5BbsbY0BwNkMQCA58/djOZc5hjjrlBeaBS9IYgAuL24Tlnso0xHiCd96/3m+7YELVE5ojEpBKt6jdGIASqMQJ0IVA4pAmydoiVUPAPzS3isBZLZH8ipvy675+LVcv6wmGyZAO4oWdXlw8hkAHMlFPu4qImlAsfKp9P6Tu9jpbSKGw7iNxKTxtmWVJzEDgAk+RtoM5pp6QnU6gcE2VEQ+/IjC5fuuVDpUZncAAMZC0Kg21epL1PTRa4V+7oZJQATqnVFJ1sgD0K7TvaPsNpKlKckAsY+dVYrVKNego+Z2lSSqZjpDac2vv/kr+LsPvgGfl2EhWvxhgz/phhwAaVmP4oaPnWedd7u1u1RY5pc/geiAN4ooLTEqiMI0X4/VNAGAD4nm9U+la/CcXOpNgEWj91V6PlZhZAKsJxRyT8SgpCYoGQEAlyWAHMKFYm0GBiDoewFAYMrBxS/rPSfhtAkwQDi8w1gCqEoaZZYANg2jGcBpx7n757QrR9e2tEVS1GaQAA7vwr/5m/CeH4Qf+VomTbqvP/6hofKnbDFGTuKau6NE994E+K7vhRDY19lLFGcorTD1hOuHwyS8lDleBBNLOqPnP9i+isYSoqYrAUhZ+iidvkUp9MQjtUFtbaH39tJ5spsMgBdJDEABAO3AAGxEbmStP4hGjKYzaTFTwlONmaeWwBridmIzDljSBY8KA8vyMgPwebKVGy6E2AOAGB21yY5ZZugYeOPt5/m297yTq6vnuGzSQ3C4JYSsGTXdZlKAqfVmDkCI3G+EXfm2dIG0huiYZ9fWn/pky9c8t+K3PfMMADqkrnUTEWb1Hhej8LCa8MVmlyoanpsrDmdb3NneO8UADACg6HXFwVvZGtGeylgiOeY1Dzq1M70E8OrDQz76y9/MbPlLNE3T95RvpWM7P1B3Q6DVEyR2Q+NaiUhQWGBqY84B0H1o1vjGLClk+1sDcHqxHICy7ZcVe57AmnUafN98K5+zaNlfHOOX2Yehb/EH7z/Pf3b5PLWLNEoRmjy5K08IGmtT+ZVTYLzGYGnyirCKF04xAJkeLfeJnAYADb/xbBpYlKo3GIANSvU4D5Sr9Pfr29/KX5A39qavAuIuvP7/4cYbfwwyAyAxrURcPuO1JO8CSrMaDThtPWHoF5g31/Rmp1K7XiKMEwOQ/QfaJmDYtoQScZsBQFznyeGpPZ568kv59KfenvZ3ezg2pWqUmuBDg2tSlYi28wEAlBrwfDM4pXj+odcM54mK21WayNvJDBHhzt5FoghdCVjqLGHpsvE1gaYgLZ06N5xi5zn2QvQPs1o8SIVluvcsQiBoQVeeEDW2mzF9ZxrIm+mM2HUconjd05+hCh3Pq8vE3gMQQcCZI/AV3bgKoBpaAouqEgBUwuzJA9rjnwBJVQDap8oDRFifYgCkeAAmBojEOKXVc7oRAxBL2JSJ4CEc34URA2AzCDTKpG6Aci8AUMqyf99WKmnthnvUK40OHiWe7uA2PPtrcO4q2CXm4GkAlt2mNJDeOGLxrGMHdz4NP/GHiTEHAd18HD7yD9mOSwSPkRmiNLqqOFy13LcFGseyuoCHniHR4sCuUFh80BxsZ2BTzI9ZAkBr9q6ueeSv/wnUbIba20sMgDslAcSYqjas4IA77RGXM1hdjiqRyKA9KoNoRadh4qHLpacTs58kAAO0KV3lgCWr6Df8DS97AD5PNp0fqEkbOLr+RemXYpnmHuZr5qjoiRGmztLKIRdJK5vDrcEEuGo2AUCSADZzAHa0oGQ3hd/oJAH81//iiJ94z5JtD9/5kQX7mV7VebKrleAi/Hyzwx/RlxMNKxUnGWx2pko6dd7GVQBtHlAmTyZtus7tcY1pc994Q+VKP3FNAbDKRy76FTtovPV02WDViWM3r9bKOkCi5VweWDRphWdjyjdYyxQviq08gI2LdwoDsL8zqp9+EQagbPc5OLnvfZzcn/TmwgC86Uail89zgOkifplMTWISa+O6kACA1sQcEKJUmgD+2Q99gOgCTjILEh2HJ5+kri9S+XMDAFjaXsYpmmyRAHQGAJel4wNP383v/+IMABkYxBJZrPc5jKYHAOUaStUQqiW/fvsqd+M2ZBNgl8/JRGJv7hoDgKbebIKUPqSh9EIq6XW2AIARA2B0iqxVtiMqRYxJY610DVnGaBrDs8++hc6myXd82ZQYtJ7j/brvM6BHDEBcpQ715Y791P4DHE+HRi8dNXfqxAC00zRA39nNjEAGKW4xmDRjbuLkaVjLfv/7hfcEhPbON7FuLmBw6MkqyShKUc8afNREr9BP1VQC68kU6xzHSnPu5Jgr6xs8L/cNHgAfQQvOHCE2+WsKAJDK9AelxKSqCgXVUUv0N1IQUDAor9KKUxTrjHgTAOgGAKBTu+rIlJaKd8uXpHRwL70NQZmABAiLpK0XBsDFwjTqbAIcVqW2ZwAse5dmxOjx44ofXaG9p65jSglsDuFL/ygA1UHqObGy965so/VY8bRi8Y//PDzxc9RmQSRQiYYP/BiqO2EmCyqmiFHoesJJZ3mlusmWcqysEER6SVYIYFfoaAlRcSfr7WcxAKKgupTuEb27h3eGmMsbVQFPMVUXeC/cVhWRyBvn96d7ZQQAYqkCEI0oaLUwCZpmkl4zr+9LZlAdUT4neVZwQwJ6nAEzqpT5XG8vA4CXsOmgkRiQEFkv0gAi0TOVRHMmCSA3kwCcOh4AwBxakwajxWIzgPG0CTD4SPHDaSFld0fHXht5zSIHWSDorEMX1rVWii5EJiEg2hBVBRjuZIbCaiEoh8pNb8zIA9DmScG88zG0F8IzORK1apP5CU/dZc1WNKW5UGnBeh+GKlS0OpvWxHEuU67/aJ3bvMaOV7k9/uLT/y0X/R4qaFyMCQAww4qmjkf98ZWtBBed2x25p7kXAIyjfL/YCjdf9/dZXno0fXQGb/P1mi+JH+QhnkZ1YFeZATDpAXXWU9tIow2xbZO2LYEQNNc/cxfXpL7ptasxOBp3wn2XfzcSKmKd9d6xB6B4RXoAkI7lPu344NN3E7iSuo/DhQRChvr57AOxlogmqF0WaA6Bf1V9hMI3irIEZTmy2xzHORIhInQ9A+CTBABnMACnJADXUOV7uExabiwB5NW1MRYVzJB5ns/x3uQ8MVcILJkCkR27z+nt1g/+ECrWeLfEhRyM5LZQGdTEo0WvpwI4ozdqyy0T7tRpJd9M5qx84GgrXc8CAPzJyKQZaoIIPjas1AgAHKay1/a5D+GoqHL1jV4pIoI2gRjTHRdUAqnryZSjPGFurVuuLJ/nmrqy4QEQJTh9iOoSABg8AHqQAFSF0tNkonQRCKCSBKAyhS+iehNgR03UtvfjJADgiDLDeosxFm81IPhMnagqIhH8yXHyAGRQWoJ6hiqAYVwqDICZBGY7FcTNScprgw6eelbRFZH9Tb8PzAydAcDanbqvSCWALt9vyxtP0lbC27/sn/Dgzl3qS6+H5W1ojtniGCNTRCmeuv9VPLN/iVcuH2VrWrNsWhxgShwyDroVig4fFKvs9SjBU7FnAIo7L/99dzflJZxiAMJICrmhEuPzpq1XpH0eU49Syn81olPKX01Fk42Z27OHkvdCg8qIuquE6xJQo/pU32wGKX0ut5cBwEvYVDQoApaAC6VWeQwA5qmBSH591Cec5w4qeprdCX/5Nb8LgJPF5mmvJnqjIUQIsV8Ba8jNXFxf7wpgUOj8UOqQ2ljWInQxpgSrvPpHFIclgc0EkMDEpNHnLAbAeMfD1+asfund6WfTpPInWXPp4lMAOOOJ+UFQeaK7jMIEQ9AlbMdzvk5I/CB3DlPe8ZaDt/LhcINLdp9tt42LUNvIWiZ4UdTZ1DYueSzRxef3BvPkWRJA8QXcX1eo1adx00G7izHJJA7hO8L382f5G+gu4ps8eKncZzwzAK2u6NZrvNaJAQgq9Z9vPE4E4w2GgMNw332/B/EV0Vik1okBOAUApNDmebI8F1ruLDueurNCVI0fMQDOpYgRRxwYG9sR9C6I4gTDNdXwpL7JMlcPiHKJGhaTdNoSBFQAQPQ4Mawfu82iHQbzpq43wk3SZzXUBQBkCeDW7UTrGrOH0vlYjEOiweQVlM9M1O7kPCVs4niyC9qhMwMw3poPPoq0Ed8eE6YZ2NotJK/U46LtMwAAqmD7+xSgYcJBnSbyZjrjyfVwDttca++XgwfhdlT89B/8A1jpWMtO//vl8wkk2oMnsVRUGXSpg0ky/5FxVq6s2DKadT3hMN/Xy+03cf/qGje5j7brUPPsAVAKpw+RbmAAYoyIGXoViBiUnmUAEPo6dQkVKgwMwKqweNQE1VEaVy5/7VdTlYrMqe/+l3zJqz/WH1foxnQ1hOUSQfd5JaclACsDAPCZLZrMA/XMUIBo/3a6QjlLvT2nYwvmF1OXyQuPoA4SoFp3Lac33/nesHpy+zpdpVAqMq8tk/veAusDaE/YlhO0TEErfuG1b+W9j7yZV4Yn2drZY7luCULfHlxJSghUdISg8UqhfRiqH0YMQPqHPB7t7fK+V76FJ1S6PsUE6Eb8480CAHZeBcBqdD+WHIwomiiBTguVTGnmEyqzx2T3VUQPaNB5cdAZ+L+v/hUWe18/nJOXAcDnxyZkACABlzlwiW6TAWBgAKgXaALnOOB42/OO+1Mb1pOTzdnrtAkw+tgHmGkRQvYAoEZdp1DoUemYd45aCV0YAEDMg2CRAFZVaf6xJmjPOX2Bb7z6jbztvrfRhNSoRQXP657d6fUzXbXEENl/6EM8+Pp/AYCrfN8LvlCRl6OiilVGLDDpdriY42DbrJ89dPgwF1/4srRPeoEEzTktTGxkJVOcaKY5anUsARQGYH/3s0sABQC8dXfOYfsrG38LQbG1tYUjRRVXOJQF72qCN4hJcoqznjoPzstf+iGsSQAghvSQu9YlCSAAQVj6HXZ3vyQBAGVR2xVh0eXrGeiK+7+smnOi4FYOw3n/UwdoNdlgALwNdESOdOROBg7iHUEn6nIpNTav/Fd5taq0I+oOhaaNFURSFHC5FaPDR82d//Pj3P3o7f6zmjoxGeOtObrE/cs/BnFgAB5/PLnqq2pvYAC0hWAwWdYoJNbuZJ+Y+dmmnhOqDnH3AgDxIC249oSwFSEolJuhVGaa1kMKYFAmA4DhObnOg/1qbbG1y7/62BP939peAmhSKd3UcMd1eK15t38TL8TBBLjMaXxdrHCihvPRGAKKuzcu0tkZAsRJzZbOACBXJ5g449LqBYJobu7sIIUB0GwwAJBaLm+97YsxJUNBqgQABMSPAICvUD7zXCK9BGCpsdODfuB+7s/8aUQszdSiw5NAyltQMRJRxDazCCESDm7A8Qu929+ekgC8SuXG6XPSWFHNApOZIUZL0AY/20pfTWJ+6llFN3kAXvtNSd+58AjqRjJFrlcj81ze7LolZvSyPLzbl/5q8VTb98P6LjRH7HGcngulWFcT1vWEPRbMz9/PcrnEi0LnCiSFA7tGxw4fFU4JE+fvkQAGWjUzAHt7/MDv/TZ+fPtN6efCAIhmsvcc1dZN7kj659dkAPANzfCcloqXIAYvHmvAyIzmDV/HdPYKZPdKzwBUD7ZU3/Bmnrk04WT6alz9UP8+4WUA8PmxSazQBDoJfcdWwTHTidpPHoBQDLqoSVpVXuQWh3OhesWbEAKLUwDAnFEGuGGGUwrBDTXWKlHk8zEAsJZaSRog/SYAKIrDIgOAqT4hKs+UGX/9a/46D+08RBsiVQwIcOlwMgxEEjHKMdu9PjRDMnZgAPIuXbBTtuwWUoFGcW51hYtVpj7zALu/3u+p+yipmeaTXaCykbWa0FH1UatyigGYzE0qL4oF9d8LAD5wLZURvWlqOIrvQ41WnTEqdnd38Uif065txAdN6OaIXqZa98wAACwfeyeuNqkvSNBE8fg2SQAmRpp2i48fvhkRQbwmKofeqvoqAFGejtKmOU8WmQHQ6wALrj4AACAASURBVBWzSvOx68cpWncMALqUMfZ3Hqn43t0/lc6HcwSdVrtLNenbm5xICTHxBGVRouiCTmEmouhK5Wbs+pXN4Z0h2KSZTvqApB9//ja//Klb3HnuD7Df/m4uunMc5xCUtk1+hZM447uf3WHJVjIBBoPJKz2Xb/yd6R4xr+gjgq0alL8XAOCBtcd1J4Q5KDtFkB4ASOf7yhA72aaKliYON8bTpJr0c4tjmnrGR+4MnSxL8qRfNeidGnNhyvJkwcevXOWH+OP8zCpVvcyiY50BqqXGa6HOk6BqUyvlx3/1bTg3SbR7PWFLK9Z1zWGuhKl9ze46ffadC/uo2ZxHX/gwq7DEyTG62+33y3rL7td+BdN5+gxRFcrMewlAncUAMEgAwVym3X16EMCcBdeyOJekxve+72088c+voiIEJcQmA4AohMUK6Za9B8DHZHhTSmUGoGKWAbjL7aaraaCeG4iW9UOvZnX1Dayuvp6gDeIs9VTT7b4WviV3Zr/wGnRmYpoQoRnuNYBuxNIsVm1/fY0KyPw8xAAn1zgX0/95rWiqKU1V47/hr7K1f5HVaoUXjS4SgHhoTzIDkIKhahcGE+CsyCWFASgSwB6ryYxVyVRYJObCK8OVd/wfXP6Sn2Yd0327Mz3HR558hm/y5dwlaRCSZHBMg9Op6nPdXGM6fRB2HgAPsYLpzPPA73ottk5VWlEPGQe+uZcp+VxtLwOAl7ApDBpPqyJeygTp+lCYNTM0vifq9WTJarHDee5wXCvk3CuZ7kxo12HjfavTHoAQe7nqHV+7i54aiA6VAYCaGSoUuxurxo5J9gAkBkDD1f8QgEW2x69ykt6r68fx2mFGXe2aEKjCwDCoURa+0ZbJ3vW+F0JXWWKmKAoA0McPpc6Bex6DwhO4kAFAUGkA3FvtEnXH7u4LiAQenX6ax9cJAABYmbwoAzCZG0QkRW2y6fgv2wNNAlxfri0L/VF2r39l/7cYFTs7OziRvlFMSlRV+G4LXS8JLuK6oe3wQua4rOeFqECFNDmLYCLgYe1TAxFxmQHYqlIVQIiItrQ9AMiaagYA4fiYRy7N+dTNRa4CGAaB4AId8NxccVOdI1IYgMG53lPCJQWtMACi6YIhRjBm2ieufswdERACkePjk/59mlmN5BXvX3vyBj/2+PU+TfDh9gFur2/jvce5Y5yr+ODRmnceGj7Na1DaIlFjsju8BBjOqjkhXyjTOjwN2m5mX0BmAJYO75bEKajMEhQAgJNeAmiqbaro6EYMwE1S57gLq2OaquYaul8VFgbArxr0/gS9N+FZ1/HeR96czl+s2NGKvdiyzp9n1QSnBVNMWevS0lf1pV1xkgDAytTcmebwLDdlJ+f433pwH6YTnj58iqW5DRLR7QgAhDRhq15/Nyg9xWuF8nGIqg1mKBUTxbpn53dpdp7O30cgEu2a5d51PLt8+pOv4uD6+dSIRmtim+v5Ad8JEgU/ovptjBgxvQdglgG4C+nYqonj47/0s8S4JlaTJIPUU7xO5k/32Idp7y4Gd+eFV/cmzkbV8Pg7N655uxjK/xZxG38pVXVUKsIs399Hz3ORDACU0FQ1URQHb/+v2NraStU41Lk7ok+tl9eHadTJDMB66+q9DEAJAcjSjd7bpa3rPrBIfyLtqxOFnhyj6wVNBkLTSTILhyrnIIjZkACeikucBuU8TfN8AgC7V4hWEgBQgfnJdUydMkhiuccBP0rL/FxvLwOAl7ApqZjGBrW15vDCRwDQuusBgJUaUYGtC9fRusPULccnl9njiEXOIZ/MTzcLzgxAiL10EP3AADzwyjkeQeH71YGaVTlKd9SZKjMANnsATp64y/Ig3bTL/LwXF3TTtQTtqMIAANoQ+mY5MJTQAFTKMtm91q/OuxqkoOogODRHi4d4fv48O9UcnWHQ/eQHOuesf9GDH2Zy6XG+5Evfxfb2Xao84G+vhs8qn7HhAVg6pjkDoOozEu5FAG9vjvn2X/5Zzq+fJErHbPnq0V+F/f39ZCorIMJFAhpv5+h6hXMB1wVmedl8UO3hcyvaEDT1thC6XAYY0j5GgVXnwWmiZADQMwCuZwAChm7yBv71O1I3vmgtrzs34dMFAGz0AghYIoe1EESzYo4Ejx8BgMU4414CIjEBEFHMJ1OI8E2v/T3snuQVdAaLgcDJegjnaeYp1Q+SOXBhHZP6MwBcbR7g1uoWR0dHaN3iXM3dXI2wZCu1Vg0GU7IKCqWsFCGD1b3DIx553qF8Cf2BWGZTL8TjFu/XxGlE5yoTLWl1JB6eedWrWD30GtYmx2mPoqfvkiSR3fWSoBTP6JorJ9ltnVPlQgYAZn/Co1s1ThuuxFSStWs0O7HtGQBHjVNQuU0AEFRKTBQicTZlyyjWVcVBBgATP8E8kSa253/7Prc5IfpIWyVQsMEA5F4Ourj4peJWPMdaT1Eh9iBfsj8HVW1IAP72Tdz8Ft4sKHnDtlnzzguv4EDeTvX/svem0ZZmdZnnb+/9Duc9851iujFHRmTkHEkCmZAMJjIICjZYjbYTZYGtVdqrtVYvy7aWXd2FLbaWUKxaammjiIAFgoIipaiATAE5Z5KRGZkZkTHHvXGnc8890zvv3R/2PufcIOkPfMHlWrm/kNy49wzv++69n/38n//zOJdSYQymWp2WAJCUmQRtJgwAwCNfvIL66qJrA9zGAOhxTPEG93/qI5TZWYzyUEMLHkspkUWOvnzu+jCghWOYMkSWhkQF8PRfs31kG1cn/z0UVYrFOwHwpOGv2M17Dr6LNa/BTmPLB4VSZI5pWc8Kai5mGn+eRnycrZknkVEdki5KFGiXdVAEC9M1rAJGGsRYOCSnIsA4DCc25d447E16qGCE8FJSE1FRISpwwVWhy7gQwcQK20iPvtQUCghKtI4ZfPAzxFf6kIMJDJXGTuhephJaMaFWU0aszL9Nu+R3abwAAL6DIURAlRFUcwbzTwMgtzEAANIvOXzHV1lYuADARmcfTbZIvYC41IRV73mva1asanbMAmhtJiI3U0oybWveUk7NP8au3eNRFjm+EFYkpQtW/vJpOh/+KDBlAHCtY0kSU8icLJGUbiFKtcHbJgYT2yIsK+EQv7ZJlSHSaGI/IBV2E5FG0KVBYQKWq8s0qKGMpBSaOd1AGUPu28kzt/tBqouPT6+VOynsjKdJgWMGQGyjetNRTugAQDCtgjxvjIZDgrJgMLD3JpKHp+8lLQNgL7CrO+aGElsCUP6QpTNdLj65wVzfLgRn6gcpAsVneTN/O/e9BFWJLjSlEijjwj5aAe9+bglyDy1yPtrSfKmibUCIym12PfaUkNS/lw9//w+Ru5a14w3B0laCxr+OATCFIQe2XD/xgAZCX88ADLc9RmNLXoRBScFrb9kDKqIe1JFjCsDd2xLNSG0TAVZCywuUJbHW9IzB9y6iWONItpf1eJ2NjQ08L6XIQ7ZcDXRIjSX2sElrwmqMu76UEpRONNbc2uKepzI8FEXhU8SKIh/rGoB+ZlP0IiZlAjVhAGBt127KWpPheJM2U5DaZQZpNI3EluDW/Ap7HQDIxiWANEU1Q2QjYLniI3XJS/kGAC1P0dApvWAHg5mfYOi3KKUgKHKKpDFxqjSuZi4MiFqNmlKMPI/NqIFXGPwSvIHA0wXru9tcEqdQSDLffhYvbRF59rv94RN/yH988gNcFLv4AD9LhsfPrH8ff+W9BbWNAShdR4XwAtcGaL/zxd6CvW/NSxi3Yf36iXl+J/wpvsBr8U2Olr61vY4qmGTs+meNjNBiYlkOcPnsJlyyxlGF9KhOGABXhlHO7U7aU35l1AFjKKREFgWqHJHrbbNxz4vIbn0HYWGIfQ89nM5tgHRzZfLfQ6qUiyfsNZLwB3Gb9x/4Cb7/zt9jhgHGaJJKE+3KBGtZQbU6/lxz+MUMpRcjvQB6S0gKxwBIEAHS38aqVkF8iwbANFrkfkA8NraaPWh/11NIL0N6KZmJqHpVcCd/7btOJBFM4rC71YA48MkV6JoD8s91Sc5cRuRgQqjuuwe6l5C+Za1KOQUA+gUA8M9jKBlSZUQiK5Su59vzU0KmIo6xUv/gwccoS8VmZw+N0tJZ63kxYQDCyE1MU9L75J8BhouXPkAcX74OACy/5/1kWYovpl0sIvJQQiDIqag6oYwo85xQCjKt0WlJ3hlROveskQMAYySdpDGZyEgTybMrFtFfWV1FlCXB4jynD/QoK63Jd2o2V913M9TLmNgP6Zf2xCO0oI/tzY69mLqpoZBoNEViaBjButMeBDKlvnMq1Bq3e93tTQV7EwZgW5UkHRVUqmPrYXvyFt+GARi55LI4fg6MoBYd5uDJdzNcfSvVahV/bClL1b1HyIGois7ryGDI1z55hlNfukp7qInKhGebByhDxWPcxen6MbzIns7HGgDflBAq/nilwzUzgyHn9/yUv1j00EmJkMWkBACgVYNerUHctifXQ24NGKXqOg2AcSWAnj8FAPJbAMBoWxuEEtNNUShDXkpEZda9qTtpOraoRBNvY3fSKAABsVPyDxV4YhlfXuRIsshavEan08H3E/I8pOsYgBE1/jO/xEeiN04AwKSv3JMsJa6e6sVESYlnFGXpUyQepQMA1AJEBqWOMVWJLNzi7oRXooRBswlCUDrwWmwrU2mhiIqMSj69djtGW3hlQeZOWBl9qHvISLFSq9BO+xziOcAxAGXMRnSUuPF6zs7fSBIIqus5W8+9AjHRq1gtA9hTdU1JYuXRrdaIMvsvedBgtrdJlxlWvCvMjXYjPPssbwcAHzn9ET6x9GU+UbuHL4rX8fVBRM+EbIhZxwDgPvc4S8ACgPH9jl0pJW1eAK154vAxPn3AAt01c5R6MSALaja3o1JBj0sA0pVgSq4rASS5hkIijKQUHtE442J4xLbOioSsPY9236Vh+sg0sUp7XSKL2LFoY1GUIGsdo5IbUl+QJ9e3AmYOoAkDw9pedMWyI74n6DjAdSnaQ8dvY8qEuDYVa66l2YQBqMZzCDyMKGxy5eZFlCgwpsRIgRAB0jOM8aKpApMuALsOZC4SOB13tcxbxrCsjR0UE3JTZabcCX7EH+/+Qf64+gY2mAVZQUqNFvC7P7CLr9z1JjIPiqa75xtQdDchF+gA/PljMLhG6Rwoi215EDp/frvkd2u8AAC+gyGVAwCiQuGyeT0/waNAmHFPqrPLDVK63V0Yo6g6v/hnV75MpWYn355738v8LZ9G6NLaCbeucP7C/8OFcx/DlIZi/hRn7vs5Lv/0F0mzhMUkoDru+Q6nJ5J7d/wgd82/3okAJZkxpF0DBsqu3dxHrl6fur78JC/IRY6nfTaHLvO6uwXG4M80eeJYit45pS2bLYvadeHR0ENSP6KX2NcWWtAX9nczL6NmIqsBEJpkmNMSkvVwHNpxfa1rXOO8IdqY/OzblwDyCXAK9PX/tn0Mh5aVyIsLBPEu/GaTcLCP7tpN1Ot1pKM+hXAnzfqLOV6LCEwdFYwYbDrnP+Do8BJnWwcoQ8mQGgOvighseaaQAk+Dvw34PRfsIBOGDoZOINGjAqnySQkAwMgmRkrWd1kacH9Q8hFqqIvJBAD0ej1LH2PoOwDQp2Fd6bwZRDm+p9PvXd3WmiQ9Q14KROS87l3NXI6p8xmfkb/NCKhiAcDIbaIDT+CZq/jiPLuyHWwM1h0ASMnzClvplAHoMEtHNhF6zAC4EpYo6WsLxlbnC9A5HtIxAB4XHr2b6H5FY9cJRAZaFRYATISC45AgRVaxPzuW2oW/NDbW2Xclk1qRERbT52ouGRIUOSZqYozgZH2FLy09jqx4rFcj5vMNDnDB/q0uqW0Lc3pm4RiDSHLjo5fpPP5GxsujGXvnGxDVKlUlGSmPXlSjmjphrF9nrttlkxmWglXm4z34ysVipzO8ef3V7Mqmm9mGcyI8OXDmTCJCGoNyczUbZ9yrECPE1ApYBKi0SVa9Bqbk0nGb/eGZko7xaBdbFGHLAoAowkxKCQ4QllxXAkizEnKJcKr/yNg50F9tYEqP3IxIdx8kbdjneF+lj8xsqx1hhBb297Nt7pV5XBBmFgBkyTYkD2QDeyipUeHasEGe2+fEk4aNEnYO7WHpfGUPFAlJODV+Wh7GEwDQ6lhBrJEleD5kfdsNMC6LCh/la8qRKwVVzTYGwOWjOEZwDADkwg3ud90l81KizVfxmq/9NNdGkl8+9m/5L5Uf4H38O4SMELKgX5HEoWSzucCgLhmdSKBs8PsvfwdLnVkiPQMBiPZ++17CHqwKFU5SA7cnwX63xwsA4DsYyqsQMSQRkX3wAN9PJyEzYAHAoGcnW3dzDwBtF9X6yHN/QNBYQ/pDwtknaex5DGkKhC6p7T4FwOrVZ9HaULTPof0hZT0jNSWHzw1obDjx1hgAIKh6Lepe22oAXAkg6bgd0iHLMQDIg4pN5isNhUzxtEdnlDEYDEi0RmlNqSrcunnrREADUG+uUeYhRWeOhumTeBFbTswjtaDv2tN2zOxgRrZQLo0+HeU0paR0p3XRt4ueLlzcq7YuW0G1QuQ2wDEAGCvKjDZWBOiAU2C+/UN78dQGnTW7uBhzhaC3iHTOgcPULhwTb3Thg5YI327EytRQQUy5LdnwxuEFnp05SBkKhtQppE/iDFUybfAMdBrTxelssDCpSW+EAjMqns8AODFkZ6fLIiDlIIrKsEKWrvHUv/8V3vve99LJN+gHcpIh3qdpORU1gyqWr7unwMQ9ESwAyEq2MQAaWZYTcZypexSLEcoUBCYlCUOEMNsAAChzBV9exDMe3qah0+kQBJYB6LkUtx4tYlFjIKr8yX3l9luGkeUk8rSbCy7OCjwUly/dxto35wjPdJn5kKL6oruQqQDfKrXHIkBDBWMg9abXDm+spTAWADgwWS0KwmJa0piPbRnIVCLOFDfyG4s/y7tn5xn4gs2oyj61yTyrhHlKeuUC5WAqTjwzb1u9bn3uGaQubGALUxGgwG6qNSWJpWKrWp3oRQqvwfzmJl0zy8BsIIAi2ALtExYNfuTy6/id87/CLSMbrjRwToQnXYtOQgTC4I3b/cYbmeeTBNPrUHg+MqtT+gOMLtnaZTeUY/2ULV0S6owybNi2P0/h73E6mFzZJMgSim0MQFqUUAqEEwRXHQOwfOUCutRo9/+Lqt14b58dEZjb7HWJavSbDrDE01NslpZUckPiC7LserSeOf1JU0dkJmX5nO1eEBK2SsPhTVv7P1c5gChism3ZD6txTLvd5uDBg4Tp9Jrk4xO8KBj7FShypK8pHMDSVZi0TowZAAcmUseMKsc2XNrpDNa8hDDei9Iej/btw32vfpbz4gauiQNIWdKt2+8/qtRQOyXpbYb1q3fz5/e9ic/MH6QhD4AHum4B+UC2JtqN1BNgNPoFAPDPYygVUhUDYhGh3anAD+yG1XS2vAUez515MaNRk/UN1+u5aR+wHi1k/X7CBVujDlrLSBKEKantfBKAvLxKkZYYfwilVXPngOptTRbxMQOg8QhVlYqqT9oAAYZbY59ep8b1pog/E4LM99FkeNpjc5ixvLxM7IdEeUacVdg33Ifa5g4npSbpHMYkIW3RJfZ9BrFF7kIL+rKFT84H3vQBXjZ3N8pItNDEwwEtf/reN6cnOPfUfWQDC4wwkmH9PJ8ftZgt7PUbawCMmxRZ6qyVxxoA8+0ZgNMnl0jSEVLmSLlBONiLrHgIXzLKYur1OqYYt0QpZFmBql0cfd10l2tqG3t8eI716iy9ep0hdqHoegIJ5MJGfY4XpwUDZ8M5OtgFZCMQmDhzIsAA6U7hWlnA0NltlcB0LB0aDBbRJmX1iX9kZuYqcdahH0y/5IA6ifQxsoqXWxFVvK0EkPhTZbXwDEUJIpojIceYAqn1hAHIQ03aUoSkBKQklQgE9Fbs9R96AqWv4gmrS/H7gs3NVZQqyPMKfQeSrrlI5YGI+OLtgJiWABAF2nXJzCwrrjZnUUaytnaI4VKL1tIVe69vugl/xtZEdVTYewIYPM5dPcyoMy15MO7RxlgLWrfQ1/OS0IEXryyo5il+URCHFd7v/W9USLgaVHhndw0tFQe8NYos5I1f/SyvvXyazrjlsByhpcQrDEcvPYfUOZPlcVxuMmMAoDBC0GnVqaalu7cN5rY22WSWhjBIQIdbkLQmpQTPeLxx8xXs9lsMHQC46ER6MRFCGTx30teMDZ5C4mAq1rUAIKIMLADoz84hTcmRYUlv3N8aVNlszfKbr3k7W6VzPDQKtXAcSnWdBiB11L3nRJrjEkApFbba4qyoA3tvQhni5faeKa2tuRiQDacaliwuCB0AGFdnekXJmx8+w1m3We/Vc5Qy58J56xmQSjs39nftenq+ehCRx5NkVYCVOEUIwevf8npSP8WMS5uupi9FgXHAyVMF0tPkw2/DADgjoCSy3zlVNvlibASka+MWTYN0xmZPODOyf+OdRJiSk+Yl5FKwWbPP+ahSJzg6yyl9G93Tlll4ZNbDc6yWrtQZqIhY1lC5nVtJIFA6fyEM6J/LUH5ExIgR0SQucwwA3vrIl/i5zod5Z+//pTfcycMPvpnM0ZYrT98IwMg/wkh8FfaeBKyTVGX2CmK2T3XepbrJJbprMfhDyBqkaZVc2NYk5RZ944+pyTpKKCqqRpmmBO4kOBhEdtFyD3rseYSutSmXkq1WC6FjlFHkX/0HLl+8yCCMaIz6DJA0u1uEbi/UTuATbxxCJiEzYpMk9CfCHGkEfVGnIUbMRrOoXCJR7Fg8RTrzg9TUlGK9oe2xsnYA7VTRRkvi2hIXYsVMPgYAYx+AgjQuJiZA4xJAxWXdDwYDPvjBD3L5S89QrMdsLPcxQlOt9hACwuEiMlQQSEa5ZQD0mB3Uyp42o2MAeE7DoIJtAODo3QBcOXAHsVOl96qKSuRRCBBa84ozj3N8+QIH44wzlZkJAMiUoJ8WqGBISkg0tkR1oHFzwdK2+Zo15AmGdjMtXhJz621fQNUeRRXT/ukBDdacl4IaA4BtDMCF2rnJf0ulyQqNrM7x6eABnlVXkVqjXKTpOj1GpSYkISQljWpoOcPVT9nXLaRgICKUsCezZlxjMLBWznke0nUiwCu5PS0PRAMESE9uYwCKiZGDMaBNyVi2qnwzMX/xd+5k4af+9fSzF+OwHslHv/HDbKzvn5yW9LgPXhrUNgagXhRUXAmgNRqghSQoc87LgK6c4Yfjj/HK9Ss86FoV96lLxHGT/evLzHRWWAvtJjC7+RAAixs5vi4tA3BdCUA4I6AKNVdy2WxUqY8SjCkoVZ25rS5DWacmQ9t2V9nExHYDLkXJQ7WnOB4fYjFoMhLXWyPHVJHKoMZz21HxeAFxOGUpcuVRpC5lUHj0mm3qDNg9gpFSFMpDeVUuLB5mqTXPsrEe9sJI/L13I03luhJAq9TcXJH4ZgwAXJ6FVJhCTICI/RIFmZihdvBBe+2jjlW+A/Ha1PQndwxA6guy3N63Z4YJD/aGnJyzrNvxcpFa3ib37RxIHBBrxIrGSHOxdhiZJ2SOrvfzjLWsoJf1eMNn3sBnFz+L2Ol0HmMK3w8mJYCJ897AiXCrPM8IKNl2kCilnBgBqWDb4cdpH56KExYDxcHFvdzGN/ls/lJ+vvp+Li+48mqlwQNz389vy/+d5ZF9n8fbClHataWM6jxbtXPGy6xhUxIIZJmh/+kkAC8AgO9kSK9CxIhS+CROlBT6KWWpUKXhRx+p8Yb3ngasccvk77SHXxY8uL6I9E8zN3eFNLUP/Pw9n4SfewihSgZLtyP9Pv2NdbQ/oMxDkqRBIRReWeK7SMnSRawqh5qFEJSDfBLlOxhGRDceRCifQkCuFM3UPsg6HrHVahFURpjaBS4Nr/Dc0u+R+QHN9WVa66vc98Uv4rtHI3P53/HGEVQS0pAbJL5H7iamKCV9U6Ph4j11WqJkxpGbvgRAUEwXhrWOphAl2vVFGyMZu/I0Cvf3SKQpkeT0N2Lifk7u9zh/7SnW1s4SkiMNPPXUU1y8eJEn/+5h+t9YYnPDbnDVqn0df7gLESrywFAaTa1WoxyvZUba0+aYxXEtT8of8vpX7+FtRxocvfOHATi3c9pKuDbo4QeSQoIxJbcuned7nn2M3Vt9+l7Asxyf/G4nL/GiLhkhUXo9ZdFrNJD1OsWaZQDCoWUExF2unz4cMdwm1BvQYN2xB942AFA68d8/Lr6dr/Ny+6x5mjw36KjNQI71FAY/S6kYn9Vs0wGAlICMYbXOH9R/iO62kKhPD38ZSRdNwXw+g1L2edO6xlrfxdsG9vmNlYdBkYt84jpoRMnYCjj2Nb0wmQIAT5A46tVfXERta4eSRQWN5lFxiTis0G238UYWGBq3OEtsu6rvFvp6YfC0RpUl7XhAhiAoikkGwn5xgRddPsMeNzf2yNMkcR3jeSTDIT/x+NO89NmEneuWldu35uaWbzd9+33GGgCDqYQTAADQGI0wDFDUaYzGp/Y5hHAAILEb/VY04nT1HIv5Do6YeWL5rQAgQio9YQDGLesWAEzp7tLzyOKMMuijwgb9qEGdPntG9g+26i0CFdKfcSBTuzVCevh7X0Ktei8lng0ZA2Yx7AskyjhxndvwC+WhS4HW2wTORUm32E31wMMA7N35DMzY65VsAwBZXFATwooACwVas+ZKR2ebC2DAR3GifudEST+2Zg5Sn5lByaVoN16WTFi2ma11OkXJ2mjN3RMzYWYeP7+JMaAq1QkAqNbtxp8PXQkg4nkMwGh7roT0JgDAC7cDAAvETmcZtzVrGEr+pfgwbw2fJBMhT+1zepVKlSLYSSZCnjxkvQ2GvuBKaMF9GUY82rjJfsfElnsTX6DKlH9CAuAFAPCdDBlUbRsglpYF8P2YPA9ti8zCHGUw3hi3tXZISRAnLOWLFKVPvdGh01mkHEUE7WV4Zobzf/erbJ23i7gIV9D+kKwIiJO6nbBlQdR0hiV9loX5dwAAIABJREFUezpUYirU04OCwE2IuKxQe9ndIL1Ju1jTqbd1MuTeL3weSkNR2WSms0GwaFF4u7PC0aeftD3unkCXYtKyFW8cxk8jGk7PkDiff2EkfV2hwQA9ysmXBjQWn5h+99hF3hrN5Q0nmIpt3VJ509OF7wBA18xYUaXI6a0nnDl9nu7cYzzwza/wyKM/zc7oIZoZPPOM7SboigFpJ6VwGoJ2yy4AfryACBWp5zaKen0CAEwZorbZswYOpctgRNhNKTcSqt9YQRjDUjT9vW48xBSaUopJzDDAzZft9XuIl05+tr61hYi2KIRPJb2+Y6FfqeAtLFA6R76/kBEqqUHFLrZlEDNwGoyKGdGnwZqyn0PlywhjSJRkFMSUwNXabZzidns/fMhzTVqffm5hoGHqLOgmK6MNYm0mDMCwUqErI65tK3+sit0IYdBqk0bemLBcJq0yMs+vvxhZIyOlGNfMZTGpt6aeZq0R4zlPfaEE3T07OfTpT+HNz6PU1BBFFRErYotT8hILUWyZqmSIQGCUAQKENCitJwxAy7U53nXxGW5evkCm5UQUKIxmt3eFbDjgXd0hd15+mpq4TDKoYjyfFRkyStd4w6MjZgYpLzt3jntO2+fbn2njjVt2xz4AxkAQXAcAjl5ZoxB9wqJB6BiMXLWQgAm3wAGAZ2cLnoosU3M8PkgiWnjbfDxiIoRn8EJ731fVDBkF2ogJAIiSmEL5xMOR1QCg6Qc16qbPrthe8LX2HiqmYDR30L5wbssowa4m+YW/R5qQEkXFrRWBgkDAj3/dslc1J+is7z6GKcWEUgfYs/gM64tL+LM2UdOXGf4Oq0tKtrlL5mlJ01OkviDRVUw2ZNVFAz/XnMVDIRDke2b42Nw7SKiQOwDgjwLaQ82VcBaZZ6SOlp/trrOhmThTApzfukh7ZonKjQ+SaYWs1DDuuajVnRV0aksZOjJTDYB6fipmodQkDfB6BiAl9eBSWXBbvYo2OXvkBu+sPUvFjMhciXMY1um7TIFHb7yZputIerxh70NJyWPt25jLNvByWwKzJQDrXvhPNV4AAN/BUNsAwNABgCBIKMYuZ+02ZegAwDZhEkAQj1jctZMy/1X6vTnWVg9RrLYweUDwD8dJu/vJBra2FtTXKP0hSeExShoYIVGU1BdaGGPortjTbiCni7x59gGC7gUA9NxhwhP3IqPaxAOg7ajbLKigsgTZTWmt38b3fuXv2RRWMNYY9qj80E/y5Xvfi/Q0phB4skEymEdndYK4QhP73rlT54ZG0S99GvRZ/9BT5CsjZG2NNKlhtI8ZWtFaYAr6iUPlIwsAfD8BLdk3W+XQwJZAjg6eQzkA0D2/yqXzdrLsn90NLPM/mD/n5x4dcv68pdE25ZBrS320a8us1WLSNKIsPZCakft5NYyoPOuSBp/5QRaefMfk2k0YgGCIHNjrlH51iXaec20bAIjDKqa0ccClWxilUdTiDlWh2RRzE4fCTpFjqnZxjL5FCLUVBHjz8xRbFvQ0Lj6Mv7otHSxIJvkNe1hyDEATYTSy3KRS5iSeIiWnumVLFT3GoMqQZ+V1p8Y4qlCjybxpsjHYZFTajoyAlNS396QbTMFYz2tA2EKKDcKiYu8TINPahPnZPnx/ltSkE9dBI8rJYpp6mtXmlAGQUiCMpnLcsiXXMQBlRNdZwB70umilUGmMEj5a5AjZQEhcF4BdpJturX7J2WdZ7K6TajMRBbaLLSJviNYFzSur3LfydQSQ9CuIMCITipFXYDBU8zq3X11ndmBPtH4jQkXu9Dg5jhtKz8Pf1oJ627nLZGqAEHVmnaDvOf+ILeF5KSZpc74m+flb9nNqpk1BydxwH0Z4k3ZEgXEMgEE5APDUZso5tcLV1hxxxa4v1WRE4fnkQwHCMOx+k56KaOgBu53a3lu4hRN5k03Xalpq+1xI34eygzCSAo9oLGtQEikEzZptJWwMnLi5uRdTyuv6cQ/d/DjloccmIkKfHJyl8enls/zRH/0RYBmAvYU9oX/g6Ot41UMX+OpX7DweBBVGLtL5L4eXebx+mDMcYyRcGS62DMCqX0VLjxEDvLKgMdhiE0k32Zp8njt3vYg9e55hZl+HXuhZQyA3L51vD0Uh0BnoSEyjqOW3AQBSocZtrNsAwEpb8F/f2MIA97RraJ0jZUAkI44xbWmOVYUVY8HeoFrnxuVVTmwWfHjxJs5yFK1jHmvcxJ290whtWa3EdyUA8wIA+GcxVFAl+hYGIPQT8sIutteU4uqco3PL680doiSBUNKKDvHYY29ia2snWyd3kXxpP8KM1fGWthsDgLjwGKZWPRq2FbW5BiXQWbcLckVNNycunyX40nsA+IdX3sNXzqwjWzMM3Y404/ymUz8k9T3CIiMoZohnQjaw79EYbDF0m7T0DLoQlMPv59o3ftp+rqw6AQCxo4AjqSiMpG5GZJf7hC/ZhV/bYDhsUyRt2t4l+7fasJU7BsNF8Hp+gp838eYE+4fLfND8CLcvn8KjQMqcSx/7NCvdU7zkpZ/ieDLC83I8b5UsX0NrTSBqbIohxSDFSLuBheEWSdwgFhlr//m3GKxY29Rrz/Spb7jQmrhNt2fBVqoNgftcXjCCrYxgfwOTa+ZSw7Vw6ocwqtiUt1JAaQoUkh26waZMOVGz93uvUz1t+hJdtZtJ5VsAwLmig5qfo+zZfz++dAp1efq8aD+h7wuCMqVFlwF11mWLej5EoKmUOamydsuZ6y/fwlHKnkZkFRJ5/fNXo8mCEzsOS/AcAEjcCasrpierkRdSRDsJWEFqjyBwcalZ49sCgDCYpxDF9QyAKwEUSnJ8/c1446VGCptV4YbcxgDIokJXWNC0IJ0mJI6RooKWOUI2Mcr2n3tO0NFywk6ZO8dGYag4Z8K5bBMhwPczeqNNapF9di0ACCmVh3EOilHeRBQSpcc1ZI+JIbWYMgClEByr2Q35R760SZAPSFWffq1FuWs/h/rrfJn7CNr2uffTNs9NlOKHuRBepczss3dj1X72I2FJLkK0ByrSiDwCJFtixFZY41rLrjXVJKbwPJKe3cBWr36Ongipl0N2JAZhDCt7j9Co7WKt7mrPOIGr5yMiwHiUeDgbEnIJ/+VowC+9zdqG11z6Y6oVuhTWmVBrwGDcSTVefhGAZeoiu1l24i2uXr1K3umQdwfsGth7/MjcYc7kJRe2ZQA8uP8GHpxVnNxrQcolDjJwACBKBTMu8nx9ZpGRKmkkCfVhn0IIll378Wff+lm+d/+rabftAWOrFqCi+oSxCGtONJpDmX+rBuD5JYBCKYRjSVU4fT7//ugeCin4dd3g3pkGRmc2wEmEHMcKt5sjdw2YilZ355rffCyhWRR8nB+jm8Wcqezhxf3TtEu7h5StTZZfeZbffsNhnt6WWvndHC8AgO9gqCB6HgPg+wm5a0n5wuVLnDxk0+7kt1Cl86MunaKkcP3LLVljNVpkGEcsGbvJLB7ZQ5E0qNSX0f7Q0e+2baixq0/SeIzM3+JC1y76LWVdwbTR4O0gcDR418t4cP1pntsxZQBmXQRss3WUJPQIXE3uwr59E/Fafdgj7mmUHjLffQxdSvLBPEnHng78skXTeXQPnSNW6OZUDWszqhuSSq3DaNQiH7aYrTjFdwlDpycoHQPg+SnhYB/vT/8be7oZATmq6+FRoChYr0bUWmeoVAb4e2wanfRGeOIiESG7s11kokAXKbmj+qXaIE4axGSMHnqAXmbB0pNfX53Q0AUFp2PN6dHnSQz4LjRofy2GQhPdvgAS5lNJNrYN1SWjMMJoaw1bmpy68WmaiJEZccK3i8DM2hZKG3phSFSzk3o7AxBkGRsCspk6etNucmG6hn8uw2hJWSrwEnqhAr1JnT59GqzLNgvOVCUqc1KlMEYSO7fAMQOAV5LkdUbi+oCRWX8fO3QLKSWjAjydEJqc1NVDt7zpopf4gjRYJDQr5EYTyBK0xM/r3xYABP4cpSgoxtdXZiAMRoMQFerlkQkDIKRku+rpeg1ARD/aVhA1moWiRJqAQubooIFWEk9rfFeCmXVYw8unDErknNVuiu1197yUXrJBu9YDo0i6FQohMa6+XKqYKK9DKZGuTuSFvjXCwSriwQKAIs/ZG/j83j+ucfSaodW7QLdyiWoxy0js5a7lNZbFIo/sdPc2a3Gl6q5LcJC4lGyWdlM+UqvzZ3cc4a2zLoEvDFFVDQ6Q9kRMIT3Wa/YaVZMRufIpXMyvrgv6IqJZDPAN7Op2Obkr4hdfVGPNWVinTqsklIeq+QitKFAELsDpd4+GfOhwyCuXBvxk+gluEbbE1Em6FH4doQwyTwmLDkIaglM/xt4Lb7evWWhEVCBMSVrmlGVJ5x++gK8C6o4OulS3m/yVeY/9eUaY5zyxZx8/9+KItYb9Xhc5yIAadefxcXQ5p1GWnLzzdaR+hfpoSGtg152lxM6pVtgiK7+Jcir91VHE6qmHENKuz37N3bvcoHNBWTEIJ0zd7A153/vex/q2TIxCKoxj5FzkAVfYy9Nzc7zkTMLt6TgTJEdIH6M9bsHW8hc3nq/i24XHbGY40YtZYweff8rqfU70n+b35Q4b1jS3Qu/GDsszFepKPe81vhvjBQDwHQzph8/TAFSCEUVmN8Nhlk0EQ+MlX7oTYWuwyUZWkJYpUioOBtCdaXPj4TY9J2y56/sOkA93UmmdB2HIiwAVWKq0eehJztV+leW7f52+9siNoSrr5DolKQcQ7CMYB1VIiURwtja1jJ1NnE9BdZ4kComcocvGTJ0N5mixhadLhl2NVimeKtGFIM+mpQxPz04YgK3Quep5bpPT9r2TyjpSFYxGLYYmp+ZOcloXeA4oZX17Ajpz6Q5KAS/bcyfNvnPQ2gocACjpzNWpzVgAMZyf6go2Kpc4WuziFmMX0m96zxBHSyhZoLwecdzgy/5TXGtEbPohGHgFEWpsoKxj+hq+LBNyYxilKaIMqFbsvQ321PF3VJnbtofODHuMwohibN5BTk1XaRkFJuPG0l6Hth7QSA2fWvT5lfov2Gckm25qi2vXyIIWWasKyi7O59sB0f2C9QffSZI0wEvZrARUij4NerYEIGbYN/LxjKFSaDLPQxpFHNgP1HMnvQ2vxyPekKtmle1jR3iMUaXHHXfcQWI8oiQlMNkkA74XTDfizBck/i58scZAJERejsrrCE+SK2+SGSHcJuz5M5SioHRF1kLk1jcfgZEBGg811gBIAbrkmc4zkA5QskpCxbZLFhFdhgQujEimCfOveC0YD+0P6e8PyAObXui701ujb/jewWFayZQNqzv/i0PDaadOUg5o1DfxhrsgmyZ2ApQqIcrriFK59j/wKtYrAqD0KmihHADIuPrMJksrihvO/jkL64+z1LACQpF63HR1hDAlX5t1m1vsccWd9IV3lMpgN5vOBc7TA14126Dt6shZJSCIAJeJ0Bcx7WDHJCSnGg8pPZ/cbUZxS5GKkGZhN7Lf+MIT/MLTCSvR1EMicdHNQnjIVgWMoMBDXbLM2JMtybFeyXueKHhT+Tm8lsDXUIjC+t0rTaGhtfkUAGE6gxlH+BYCFRYonZE77cDqQw8TSTEBAPG4xFRXNEYx//M3TvKu+7/BntigtOFYcoFLHKQvalTcSbqSG/7HzhYX9h5jadcJasMBrb7VEi0nKQJBI2iQ6JOUpSIZVomPwuDND7Pj9gfYHR3GdedxS+N7ELlCR2YirLx49RpbW1usbk1Zr0J51C50qZoA6gqRNvkir8XTBfdsPsXnH/skq6urGJ0jpQ/G4wbO8L8Of5t7Np+evI50XSu73T2eTzVdZnjwrH2vG4cXuK0yTw1BEkhW2YHUmt3h8zNivhvjBQDwHYxxFwBYZTaA72UU20wpxqO6ZR9Yz6nv68M+GlhOMmq1KjuHPYyU6CBiaGLuO/V/sutwC6V34s1Y572iCMmdirR68TgL/bdS1FZRYY91d+eyckhcDBA0CRZsW1spJI8fPMHnjxxj08l9Z9ISpQ15pUGvEjC/5Ry/WiEd5pg164Bh1CsZhQY8gy4l9Q2fRbFEuvUhgnInESM8UzJwYse+6gIGsyOhv+NBhvJZAEajFmlWpYZF1abMrZ+4gayosnv3/SxdvZ1cpbz73l/DczVM1QvxKPBNQRKtTWyIy2CK1sPKiEExz4xTOF/x1hkYn6prZTrUOEEpNA+86C5W/S3apkobRcdR1KUZYdAosYt10ecviq9RjmZImhfsPdsRIRcFatffTt5zbtBjFFQo3HVPTcIca9wqbYLY4PGvc5t5jFvVEl6m2QolPef6tZ0B2Lu6TOnV2ZypIhxgG4kMoQVrgxqjosrD1RM8uriDmdEV6vTJRIUVuYv9sc++dI5mUSFXHlL7xI6CSUVEQshAWcB1VW2yf89pXrd3jfu2OjSiw1ysXeXOYzcylDVCUxKQkUmfOV1nOwE5quTcP9yBFGv0REw1yFB5nbWZHrnyUKUVysnCPqfSa6EpKdxyksrYCq40IANK4D/c0eTyzA4GlRpXm03e/pm3s/5bhxDXnuHdvJv38H9QFgF9PeJgaQGiTGP8e1+PKH0bvSqgdAAkdAyb302YNQ32L+6YfP6mw6z7h67d0EsBQ6Wxjt9bJNDXsyOlFxPlDWShUI5FU74CM20DHAP7Is/pLNlrvGvlfgDWGmuMQlebDjJa9NhweOqpIuF+J+7M/Iiz1RGboROblfZvGo6JeOjQvfxW+52UjpHqiZijrbuo1237WDVN0FIyygKe5Fa+csz66DdyO8f2Bfv5vuXrSz+x9MAIhFB47TYmzylRlK62r4WgnRuUsjqLznqGZ6CUBmOU7YU3Jb4rcUXpDLkDAEEZooIMn4zE3ftTyzUqggkA2D50PKCRDtm7NeD37x/ygSeucGtxliUW6Yg20baU1NduJFRHfYxU1EdDds/YVtS1rGSeOrpMSM3fs7m2k353Bubt387c8AxHZ+4EZ1S2GNxMULbQFSYiwLV1exrvbUvhK6RCXdngbek9eF5Glta4xh52m6vc/sr34FfOce3aNcsAiCk79NLqSQ7f/NHJ6xwt7NxYdF7/OxLr3rhUr+Ebzc5sA4I6VQOxr1hnB+0k+bbhZt+N8QIA+A6G8sLrSgDCaNvvmz4/6jRw9STf/W8jdhaX5y8RFgXti7ZG2M0DtoIaZquLMYaD7RZi7HSTVVnxFZ7WrHQOUNu4A4BK+xLNK48CMKpeoB9eIo8VW1+379GPmpzcv5+v7j/CB46ENOIhO+OCw0PNuXadgRewt32M1zQ8TKvKOgvMsc5i8wAGj42ah/GBXLBno8rRagujN/DETuprt09YAGE07Ts+wY1H7+fqLedYOvE7LMf/FwB37PwJsrRKDbtYKq25qjY4XgqE8VBbOceYY6eJmW3sJnCTPxZNfDK07CGDPtXaFujr6bHdKqC78iwV43Ek2cOr8ps4EDzE7fd8GIC5q/u5Iz/IqKboeX1uLvfRr3g85zZiLYb02k9Bc4tvVp4BASubu4jbZ0iqfR4++XmyHRs0pWVmPJMzO0oYhRXO1cZmQiWv9D7GrPcwFROzsb7KL/NujsplOg37eW8yliLcu60N8O5TjwHwvh03YfwquYC/ftlrePe/+nke2TnHL7X+E39SfweHr13le859nDbT9qqdieZdq2+nnisy5eGVwYQBAFsG6Ht9cqnIlWHf4UdYOvwA//cP3MWr3jDHb9y+m/df+zMSEXFTegalC3Lhc/TIEQqlJnHQvfomD3Ql6yKnFJqKnyKyBku1LbSU+C6pTRVr2Ga5BmEKpVtOcpFOGAAhKizNKr64K+DxvUf4qxNv5L+96WfwWOC8+bf83aUeF8RhnhU38Vc7ahhgUc+QFhlRvM7BJ96HX3r0w4iTR24l8QOCUhM6AVc1TfBkQDOsTViGWzdSXrWVcMe6ffb8ICEIYlQwIthapGqmHQ8YyL2hBQDaIwkT+vW6teR1i7yWkkElIsoS8jxnc3lIJdAEzruiqIWsz9sTdbfWo80mXRUgZIWeGjGoRhMG7sHFFTZCgdQFpfN6qLsyzKk9J3jcv5nnzEH7uqK0pSxlS4qvftMP2DlSRnycH+ODJ94CQCvrkmVbNIM5TKk5tLrinlFDogSiqCCEQs3NorOUAg9PTudUw/VvGlkw6BR4pSFTNgFTKk1VJOyYsWXCRjGPk1vg5z6+n3Jzq45wAVPFwk2WAcifDwCCfETHz1BGMZca7jQ+B80ypfB4Vt54XbusThV3PGX9BnrNWXa1LQAYjYa897e7XPiHX8OIPsvnDzEcWP2LGjTwooSzhx7kQc/OvbyUqLKOqRjrrigk6xvWenyQT9nNXCnK1R4VfAIvI06rdJhjXtoDyIGDjxHH8YQBMM458fELt1HbZkX9ynqJ1JqDrm13R2Ln56VGm50mR2IgbCCTIbFnGYC5bGrk9d0ezy/ovTD+f4e1AnZ9ryIiNC45K3k+ABgYj2DlCrVhn+HcAjXnnLeU5uy6cAHxwAPUFneylgX0Aw+Z55g4Rq1osF4ZyKLKNQ92eoJ+v08/PwIH4ZD5NJvFq6kBW3d+nF4a8I3T38cNV+2i+M19NyAM+GXOUjXgdU+eIjIhL+qU/OVejzff8hb+9MDtxErwN3veRSkUd5jHuGnHnayteLzB/xjFbIg3MtRUhJI+EoXvV2ldei1zC6t0mEVR0p69ghCG1uWXU1k+xMqL/5Q8brPVnCXr1icMQFDCgm7xuugTfL55C1/8yDOEcoEZZSn+6IJH7dm3026+lp/K/yvecAf7GhY81VbvZLjrIfzBAnl9jV2yytFHP83poydp7vp5jtU8ygOnMUnIxpn78C7t44BnOKmewS8zElPla/2cPNHIpuBqkJDJBAz0VJ9dus1qZxe79z/O3858gvWTB5ibvUT7VtdZwIA7lld5+MBh3vEyJ/7MqizsOcjnnouQ/TV0ZBehpe46/yb4G5Zafd7GnzF65Bc4Ep/gD91zce83H+aPVv+CL+94Gz/6k99HXqlwrfoapNZoKdmbX+HN+lMUZ/cxU93LTXyNU6Ob+Hp0H0eXr/Gi/Hb+VKf2JK6DiQYALAC4WN3Lh+59Ez/yyOf4Y/kuvsjr8ETBffw9X/NfyUc5zGJ6mTu/8TgXX7uXzAu4+eW3kt//BJEuQAtSp4K+4EJ5ZBCjewtsVuzPGyphgKWwa55CrCvmNht89uUv5yb+hpYf295DDdJUObvbnnCX2gvAPFoqejv/PW/eP4MymgVWaLLF+44fZX7xlXzGa3G1dpQdg1UeS8/y4CtuYhDcQintSbyVZNSLEGE0UTHACxeo+R4BHjEZJ/JdvP4bOYX5EqtYBqBWd54Lvf3UxJOTa+ZlPrk/oFnUMVJz5UBMXL+L456YmGCtNVpkvs+u7hqlZ+hcXKOdnZ68RlkNWN53mjm9k83qVeayG9gIZpAioBf2GVQ8XnK2y4NH2yw1qqSepJ4ljEoLINbXV4BZupHdZB8MbmUfdpPaFDGf3znD0b6m5hwBMxOwzJ4JK9HOtzh9/uPcduydXKx4vPqJR1m7+14qRjBSIWq0kyg6QOXYMcqvPIYRipqcugtWM8O66FGqglKC0lYcqLVCypIFmbN/YT8d8wQqaZC7aktQBPiVFE8OKJwnxb6KZmE4Ii+mLcrjsWNMvIgAU5asbm5yoHgOaUq0UNRdq2CrHLBnpc6LVx7j6y9+DabSpO4PCU2MHhUEuWY5/SzG7GOw3qSUFUz5FKOlt2D2fRpv9ykWNq12qmsKPN1kWIf+cQnSZ23NAvtBlkPozKc8GLSeo81L8byMYebTYY5jWHq/3V5hOPwInj9EF4rOuZdw8Zv/jserT7Ov9tw4aJV3HNvJO6vHqZ15mlQXLMT2Hl2rtDhROE+FsEGwldIPbZ7GLcWqFR38E7AALzAA38EQfohEUzEWBNyApbvDTvd5v7tcmyPsXMO151JPhwit6bRnmX3Ri1j4xV9kMdhiNfFJa3ayfOCvHyV5evpaXtlg2YeD9SpCCC4Mu4RmN5UfqHHtxz9HWluirHWg0mcgExbe8k6k1qzX6rxkpctrnn6YHz4/4PD6Mp5RHB12SJTkN++9hT/f5/N3uzxeO3ySd5nf5S38BWEk8T3Bq8zfUa0OaIQJFc+mDdYqNwMgh4dZcK5q0mgeuP9tdE+9hZ1P/yvE1RfT/ct7WPvmv+A/fvUMWRESMUIYTa8I+ZvsOJW2z1tu/CTtnRGjLMJ3/e7e2mWefPAiqf8xjhZnuEVdIDr6JDKp0Vx+lb3Og/3IPKKsdPjCj7+N336FJjOgZYrcPaA4f4y1U/8CXwiGwZDTjSPc/ehjLKprJIOcotgiijUrErQRtDt3sDtu8Nrsdha6t5JnATvmT7MWJ9SKa5PTd40R33Mt56c+93HeemaZ7z/7NHecbZDd9i85v1FFbHZYGIuT9BqvE3/AD/FnCGD+K5+k3FYCqCYxB1ZP8qpnH6MbVQjSPm/97x/mP/3Jr3H7tfP87NqHuFt8HQV40icg42eu/B4f5H/iwGf+A4+u/wHr6lkyzyfMw0kJAKCr2yxVdlNKxYOHbuLz4g28YmuZj97f4V9/6TRHrv0pgS75yT/9K2747xsc0OuUwuNKc5bStxGyfpmTKrs5PCcWAYMJtxgOWySx/fm8Z79PVRbM+h5Z6XNtZoFzC3t5Kr8HHW0hhMEY67J4dndAK7UAR0vFkQtP0Q9nOLx6lb1bHX5Uf4j/pXwv911eRRrDkYHhe+7/PP0y+v/Ye88oS6/qzvt3nnhzrKpbqSt1zklSK0cUUWIwCCzsIQxgY8IYG0wwxjaMjV/b2AaDbTwzBhsQWQYkrGChiKTOQZ1zVXXFWzenJz/z4Xm6qvUys97FmrXw+0HnS1ffunXvueees/c+/733/8+h5Bo2lC02zs7wked28fafPcoN5ye5+VQfO06+hGvVUCSNqBRBDWsHuqRkKhYdAAAgAElEQVQ8crRF23oB15KIRm0SYQAQrY+QDqWshWMjWRJIFnendDJOFEeFYnc3SN6idsR0Lii27avMU6rWON06TEoKAlcrqqKpEYx8hfFrX8CzDfoqeWpkcN061ZSPLwkKUp242aGmx5iOCLo7Di2rhed7/GjvD19lO/ZG1y7+/GSfzHhC5h1nLSIh/0AjkVlsmwPIWHVm7Bl+XP93fpKX+JWnfsL7/scX0M0OHVmQOPJuxkY/SGT9epzw7EYucTYx26Uq2gjh4YggN++IQIxJklyyUg5HL6OYGQQSVpgC0O0IimLRkZeK4Axhk4rESV6SAsiEHQBrQ/6PutzC80wqCwv0iHk+wR9yg/8U106eJylBLxYpX2XES/PFPW0+9+wp5IhHhiqmpGOu8bGSTaz5HQjPo9nqpvHsPeyalajMD5LLzFPIzWEYccqeheKmkVWYWnuBA2tjVColCr2naNgNon6wF6KZCnO3PY6jVZFUm5YXoymS5FigXutjdnY5Pj+hWt1JZdbilafn6ZRWYMsW1HPIfiAI1xvLMhrT8doOckKip3MxjSTIXywg0hJ0N2tMSkPURYa8v8ASS9kvd7wWAPwCQ5YuCmYEt/m1YRuIXluqAUj7QUR5f+/lZLVeCiMB773kE3CFJ9Mk+vroeu97yMRsmo6Mlg2KfNQvfx5+ulTspnpJZjQYikcZWTbMaTFLTF5Ns3mUZHSOVtdBUG2UsE2rcuAIb3v5Cd5XLHL/K4cZLs9x58RxBDA5sJ/0ij8HoClFefCl3XzjJyd5X+tH3MRTpKgjdINr79vAPfKXKEYGUfQsspARQpCPXwZAR2qxfDpkvHMFlhXDmroc4StUlBSt6q3UJ3ZgCTDbKhI+umdiIXEYDznVS6R9mnuX/R15dYJcsoHveUidNkeLeY7Z58kaDTq54zhamcGDv0339bcG62F0o5hZvEiF2a4OGaOA5UMncwYUiGaCQMFR27SVDv7qJxmRJVJze8B6GKv+Twyfv8Bl+kucixTpSA7bZ0pEULnO3EDpSJ58och9t/2UqCiSIcjnxfw2OSVPvjjNJ88meNfZIqmOwpS+lXa9heQ62F5Qf2HLCvX4EiKkzvsUQ8U42bXRHIeIl2DdzHn+7Lk93HXoOYZrC5h9Mnec3E3KEiiKBfhoIUAXrwlUHKaHkkRO7cVnAVPViJkRTMVFvagk6OeoqUHV9cn8KJLv8gblONbBbzP70k6s+kn+/Vt/z227XkDx4GbjAHG3ydfmayixeMCx79i4IfXxJP0oihkUJTZzuJ0AERgIuS5SskdGlTE9lXZ4k5rw+jEipUA4xxdIYpDpnMzt50zSnRbLKtPc98S3+ODuA9x2bDd3HnyBbd4+0k6Tq84e4W27X+LzBwyuPbiTgedO8fsL5/nLVzz+8XCG9U2IODZpKcG2osr1z+7E8qyADtsRyL6MjoLwITf6M9oOWHWVSLROIl7Ba6TQvQyZsNVQ2Bay5YPwqUkNtJDwyJNlauY8SlhnMJ3pItkxSXbaGLZNR5+nFnI8WFEFXdZRZZW6WSduR+huRamRxbDezuxgYCvy0TrpTot6JM6FmGC4rXDVoVV845tfJ1VdcuYpv8as1kVd1fCExHdGU4w1XW6ecxYDgPl836vsUtap09ZVYhf2s+bYc8SqJdpSBNk26CjghqqESlfX4t8If8nhaGabtjCQJA9XhogscGR5EQHQGMGJVFCMbLjHA0cWsSIoik1dXoKwTWEjhITugRpWWq51AwKkkU6MVU4/VxoD+J5FNJZEiUis5Sjv4cu8xUmyNS4RDTuX0lo3V5VcBm0NJSGRoUJDTzNxj4bblGk/75OWMjiKypMD6/EB6ewAyDZm7gTV+VEWpCaSk0AW8IP0fXwo+6cksnOsWvUySnxisavpomiimQxSsyUvCPpylOl0Epw6eTXTZwOiLy29VPRnSyZ2o5c4TZI0iGpZHNvFqpko/Tm6Lyk3EVPjuL4APclAdXZRlrlHmgOrxX/EeC0A+AWGFFZ2xkK++rUcoVHPsyzzK0BAb9kdEm+MOMPc2v/rjKRWXvxjuioLVKIxYrHAkCYUB9OTcUfHmItmWFse5+zgZUheqE4l5VjQJQZ0jc0rN9CUDAxr6fDPpwJNAUULHMZRf5KYbXBHMsL8zM8AOG0eI5EosXLND4kLk0Fnnqxfov/cv1E1D+OoDWgHTsPRmgwUMpy2skiyS2Lk2sX3yqgBPFm3yxTCgj0rrPDt6QvWxTYaNOLLEAKELOEbMrOzy0lZHWJCCnqyM31QOkXs/MM80PcprrrGxmt3EL5PLBvj3EQc8ZzCmn0GK/bB86Pb6b58FcujnyIzeQuKmUbq38eOru9yfWGOttygkz0BHiR7bsD3fTTRpivVzcnaIU7Hm5w+dgizfR6AZHyOvn6PA/3P8timT9OQg3oGKaUxuyuD3rkPWZRI9LdIX0QA/DYJtQs3NBKpzUFAcuLFZxbXpydVwPNkEskSkmyT+p7MzDdVpA7M2T6K5xOxHRwJ4m4CZNjStRXNkzH6RzmmbaKhZoikcgjhIwkHJ2zlCpl4mRvtpn/eJxnKSztyCkuxKThBnrJMjpa2ZOQ3sR/z6D6O2hNEbRibbOEfP0k7kcaVFKKdDje2f8qjpTrNWAJh22iuhS1H0OQIHjLRaJjnbucRoYbDUCzGqjM/ZIM9QxKfjqxTTwRBzxR9+Fo1aAP0oZoZASFYNe/w5gN7ef2R3awp3Ey8WWTQzbHdSYGj4LgqRalOIkzLSkLGT+WZtjYtFkgViKH4UlCpLTwkScK5KP5Sb6N5OpoET81/A105RcdV6RQjxGJFEokyXjmHEIKMAioOEU9mmZVG9iX2K+dwlOCzSkBjYZJNIQd/LZZgoNwMgppwnImlsRUFM6oQJUrEjTDfnifjpMhaLp6QOHK+gJncDL6LOjNLDpNKLElFl1nVVhmc7uHMqbMUqku38U0EtT3VaJwzqzcxn0jwX0+YSED0YgDQFdiAITtwVkmria3I9FRLXPvSjxC+R0ONIdttSjSpp5bIcwglcL1L6iAUq0lbCvaUKzz6NKhH4mEA4KH1naaTuLAYAPhdITFRSIDW0MqLr2WylFePOR6y77AiHtipZsNjW3uE3tMv4uKiqpFXaQ0IxSWCTSQS2JOMFjhhoafQMxoZKtTVNImRNuVX0ozGN7FBWcvJ3mF+sOYyFrJdKLNJhBvy/8+tpyTqEM7zsLqdE9Janhu8LJyrTpwWwvcIlckxkgGyU+NiAFDCMAJ7feFs0OJtVy9fnLMtm1j1XhI0SYsqnhPlkS8cwDcc6oaL7kHCD4JF6cJRit034S+7kr7mJHLYRVOQL+Cb/zF1AK8FAL/AkC4iAMJE9S2Wc4qZ2ZVE0cCHdCpNr5ch4QeCuD4+KS8Q43CjcXTh0YjELwkAAugs0d/NO2//BG+564/4+2vfTtTJ4DgqRiLkB9BVVuSGifgqj+7OkJHei1HV8PIBL7wsu8iSTRuTnnwXQ+uHkEJCj3qzSSIZ5BNPuh/mjZPP87v8KWahyFz7MKbaoNMK5uipTbyai+l4yFgIZylPmAuj8mLlPAXj1QU+V74uhlr9Bs5EcNB9H9YPpkj4bU6dvJoHL5xhYwPycQ05FSoBKhHE7x6Hmz+J1wwOyM3rUji2w4KVZaDZZLgzy/03BE6nkLkHrdONYgbBivB91gwdIrH9azQKe9DrPaR7evDcWaKGh+5JPLD6AXany1TjMaJ6hHgsjp+0mQsdynbTZF4JbgBKOuSqPxV8J7FukygdNN8k5rXQlBQJPWRMTAUGamHyPLn+oGCjU2tgNQfp6goJYC4IjmoywnepuH5gCBywFYjbcXzJRjZ9Lq93o9TLRIUbwIAhMU5MFJHCYtBOeEwrY91IPqRCtsK2nsKIa2S8ChGvQ9VPM6OkGJgZJ+Ia3MrjtKebOJLK2Ax87Ptl3GKR3Vt/j3Mj9+A3LC63d+H4MCGpKJ6L5jg4soQaogAxPXCKWqQP1QvqHApkeWDPdazedzkxo0U7liDfE/xuTupF14NWOHwoZsNiqKpD0myC67M/XaMitUgjsc4uoLtxXCeIrlJWsP56LIGeSJGvhOI0uMTlDHdb29nkDBOXoJAoLVJAY2ms6KxktHqaUnsau1mm7ag4ZRVVNYhEmziVoFOgK/YF1vpttsjruDq9nnXuAOPyAlV9HlXRWbl6NePtccrSkuMcKDcWVf0kV6MjNJ689VZOLF/F2mNr6TvaFwYASbQQITyEwoyymd7SbuRWi62FvkVu+/6OR0MEF4l4Y6kHYz0BAmgXBni5MMxQaZaNpcA5XIoAKJ7NA/43uc5/elFwJ9c0SDYD1KquxdFsi7qw8S9RliQffE9d+VOLD8lWnY4czNnzJWLT41RjCdywBkKs+wG+XkexUyALvFzgUKNtLdyHlcXX6ngh2ZLTIOK4pP0aV/MCb6u8jFxsUB1/CEmZx8VDUXR8YYMdOmzJRpc0IiHzYUYNvi+hJxEphazZpEqWxuRmtjevJ66kGaSbiVzwvKLrExcZ4gsbUVsFko1V1EQbrAgegmmWofomO7OX0SCBSQTFc9Axfg4BcAgI3fKUMMw4+BIuYJz4FtWjH1z6vGoDq9FLL9MMiiJn9hWZPVVDFoJyI9ib2XBNks0aras+hpUZIy43GCNgPy1oZ/E6ryEA/78fFwOAFcosm2qHUXEozo+goaIISGcyrHb7ecC8FpQqHaeB5sVQFAUnlUMV0NIiKNEALr0YAGTcCg/q+8iJJm+Zc5CqA1hWlHrI5jWoKIiWy6jbg7DazJzvxqqri4pXABotNq5bR3vnU0we3LsoRuQpGol4hY4dIaaP8hPtB4xwDr/QoWkYOGqDougDX2ArNaxymN8XFsJaqhHNKgJX8ShVpxYRAIB1ukI8FkPMPUJu+sXFx7cuy5IRwcYfjMe4Y3UPd2zohUTAdsjYjYt8nV7YsnN+Noy+M5up7fhdAHKNgG5TCuWAu0++iblnf5unD95P7dyN9Cw7gBWfZjD6W+grTV4Y/iqKpGG5BjcN3cT3r/QoLR+gf+NmssOj1A2YD3f9ZR2DhUhgfK2QntP/0R4uHgsB3MpjbDWCauRlkQDNUSNBsNAsFyksX4kkKxjNKk5r9SIxiTInODQi8EKyE9VxSTsyigtpM4laatCuN4jYHnIzUDD0XQffCdZcseuLQikvXhYYuOZwsHZrDgRc7LV4gnZMJ+HXSbl1auQoiRTLps/xlWc+xhb2YSzYeEJmqu8qHCExdfm9uHKaRnIQv1ijVwvQAx+B4jpkW02msxEWIkGwEw0VEqVoDtULboBdbhCYRqa7UKfnacSTLChhUCR3ISs2imyBL5jPREh1bHwbrrRXcYW9goh3sYy8juznUNzYohRwjxfshWxXL5mYRqLl0vF8moqCLgI64ygaApmG4y8iAAAdRyMdoiPlUp2WF4Xykomza6sWf77CvId1jKJIMlucUTRfoaU0iCpJ7rrrLjIiwSH53OLzly00F6nkI1aWtxoP4yoyk/0rkD0ZpaPguz4ZNwnhZ3hxZC2q63DHiRJ9Q31cOTK0+Hr5tk1FClMRdBYLikc4S8SzGc9000IwujDDubASXb8EAeg2K2xRd/Mb/C0L0ggRyyF9CdteI5JEtW1sRaVqeMzWDHzfR14ROLaktlRrJKwGnVA4yvcU1GoRR1Zoh+dTlAawq3HiCxsRqsNcJWDfS88F82qpwQUj6qkYYX3FSX8CxTHJsUCKOrdFPs/KQ59hmXySno98BFfyUWUNX9h4drDnXclAEhIRRQvnGKCOyAq2UyNjpzFElIlz72D0D/8f4moGV40xmQ8uMNVojLiSpnD4nQzt/jhdXgpfgO3pFOnBFBG2hAjLtDNGudmH19HQMfHVIEgyk8HZUkQQ2OcoYRpxVCuJL9mYTQmz5bPmql4e+G9bWT2wHLud5wP+F/mvkX+lXupwsS53odjB1ySyXnDJSDeqtKoVOp0OimpyOTvJuBXy+iSu+I9xxa8FAL/AuJgC+M3oUzzw0j5yj3+G24zLybgRkrJMob+AQCBQkKQZmk4V1VbRwurdpNEGIfjNOmz+2WH+tWs7AImZnbiKTOnGMZzeKPFjD3Ds6A3Mhep/q1UVs2qQ9RMowuP0uQnMuvaquamiyYZl/QjbZu8LLwVsa56Hp+rEE2Vmmr2ko0mqrsDwBFrexPUlJK3NjBcHP4qhlHBLgRERmGAttQopQiBlVGzPoPcSBCBdK4OsYbdlYsbc4uPbh7N0he1imUyGd1wzymfv3wjJ4LCy6o7F57qNBpYsMTUTBAD1tkf6pg8Fv5w9FKx9KAesWBmKlX42s5LzP52hUh4keeIB0p0dHC0fBbeFKmmYVovtPdtJyinMUpXesZWke3qpdSTmhEfM89hkWhTjgYObOBM4+eh8jYgSoBS+C7/KP7PV2Ilr1hlWAmVAJarg+x6depl0T4FELofVqSFb64O/sySkGtRjYG4PpKBV2yHhSShajogXQ7JMdF/H9kykS9qI3HDNFauFFColRrTA4eYnpnnhpuuIjoZMcTGdliaToEHSbXBWHsMTMpl6GasrjuT4+I4EQnB85X3svuzD7FkTtpJFuxEWpLQGMemiKqLHVaeniNs2j68cxSMIAFxHxU7IyCHZUNoIc9aKh3RuHITEqWjgWAw5Qp0UeqSN78NcRiVvmjSEyZhXYJM7zFDRoCjGaSsNFClBdvwOIpPXM+DmyISUxKl8D4PZGFrHxfB8LDWQmb50tFGXEACg4vhoIfHNQtWk5sVRGkvV/BP1TRTtEln184BC06kxZ0yjo7LeWQZAYSRPKpXiNncL8iUc7dm2CWHr3Golzqiocc+PH2Htoe9Q6Qr2aNJOEnWi+E4Q+Lb1KEMLswivyevf9HqWp+KLr3eoc4qF8Hx4irbYXdRFkZzV4kw0WOux8jzH5AuY2IspAFvV6G4tOfCFqsuydI6/vv2DlHI5pgcGiHZ1odomtqrx6OE5PvvoUfbv38+jR4IzatYu0bjoTFGTQhY8ESduhxK47pX8tfkxPt/5KCceupzEwkbsC2c4NXGEPkkQnQmq6VdvfIqhoUNIRouWZDNtTrArMcPW8QO8mW/i1/qQIy5On4GSihO5bAu2Z6Ci48kWthsG1LWXAdDCmE4OZYt92cL3bZLh+teMBA//8csIYGeXiiPJqJZJOZUnpqRpmwLFypAK67FsX2eSIPi6nOA9Zv3lOJKM4ngBH0a4b6xYENw0lSxxr4mGxWpxBbIbwxMORsvGaNlE4ipd+SyfveEz4EvEpT4SWopmySCbCpERy8MBcl4Q6CVbNZrlMoZhoComd/JjPnbhL5EkHyOyRIn9yxyvBQC/wLiIAMhyjEg8iW2YDHp5HKPCm8eWc9MtNyOFhUSKd5qWU0MxlcUAYKS+QE+nyYp4FNmDp5IbAKg22syk85iayst5GduK025nmIpGyJseOSTKcy2UcENXy2Ws/1cAoGl1FhaeAaAyfhpBoEfgayrxeIXp+gBJPQK+wpwtE8uYrO6dQgiwinVwo1hKDa9sIAsXgYcwZaSEihdW/Ub7s6y+8Xqyl1S1t6oVkFWctoyedti+78+5YeUMt68vsCUVGPNM5hLp05Hr4PqPwsY3LT7kNVvMpeP4vs/wpq3Ui0U8LQ65MZgJjKscKrP5+Ii4gj9dxnckZo9cjTW3CaPW4vmp58naMRRJp2M0UWWV65SAO6GwfCXpngJNS2bOdSg4LmO2zWxI1yvmA/U/3XGZmAhuNkY5CPh8V8ItHiMZqi82qON7DXzfI9XVQzybwzbqKO0gQHBqUYxIlKw3jLdjYzB/zyXuwHM3rUFCQrZtVKHTEQa4S1XUTpiaVSQDKUQA4pGQY/z4JNOFPgZGThDzW9QSEh0BCeqsbZ+kKgXPSzcq2EkfyVpyYFp7gk5siNRk4DANPYtvS/iKQ194+4t2YvRX0zz4ykFmUzEOD4yha21MI00jVsJRAgOslgN0admaPJH54JZcjcSJhsWOs/QRi9fpODHKSYke12VeKS3Opd2aoWmfYk4Lb0YzV7Nu9nbutLdiycHeSud7GOmKk3J9DB+c8Frl+j7PNhxS8u/TkSKvQgAavockp5AVmWIdGrZCTDh0GnnsdoYLdopjZgVNehZd+jb7yi+xd+FR9lafYlTrQRcSy9YO4DUsYpbCgBegIKl2E10YuCF8n/cTNOUHg8+ieQgpyIEvay1jlz/OQn1icU4DtRKtSIOcnmXkp59c3AuIyQCeBlBjRHyDmN8iRoeM0cIVAgm4a/wcLWHyjHp0MQAAWDUztfiz3fHY+tGPc7h3FS9eey3PX3ct/SnQbAtL1bB8wcELVc6cOUMltBuNhSU0RHatgL4Z0JQE2XbItz94Jfu0bZzKZfmrd72bF1v7kbQiF7oLDNUrSNVg38iyQy53AdOq08bn2dYTIAR3NyzWi8N408F7WQWQ00leOfR+mtu+jexKILmYBOuqx4PvUrC0bwHcsDajqxW832RGxa0F832mRyHuOKw5c5hSroe4PkqbKEKViPlRptJdtFyFC2EAsIW9yL7NvD6GLStotoyOuUiZjOQhnAjzmkLSLYEvWO6tR/IUfMmmWTVwLA89ruL7Ps6ZKgKIeR9mdOijNCoG2RCtbPs+HdNju3mKKzsvEnUF2cMZ5s89QTK1gISP0U7hezKGscB/xHgtAPgFhgijREWOE0kkMUJrLXI6PffcjaqqKNHgsah3nLZbQ7Yl1NBw9FXmOHTXtXxz80puOm9wQivgIegQ5UI2gHmPJMEQweae0BRWNDx826NZ6uB4YZTompi1kIrXDJzSspUnMeL/RKyng+bbFLYXWbXmZboHLiDLLpONfobzcYQfYc7x6dc8Vq8KWfZKBr6r42SmKGe/z59c/SfB+xgyclrHU8MbYneM173ntxDK0gFtt5ogq9htGT1lk+2co6t9DkWW6KPIA8ubbNu2jQtHD3P8Z8+CFoObPwn6UuWz12wwk0mQznWx8oqr8FyHVqUCvRsxLhzm5R98G8s3QYAcVxnpG8JoBAYw6hgci57FOVnHOFxi2M2jCJV2O7iFjbYCGNHvTZAuBOjDXNNm0HKI+T6lYY3W0e9yoXEES3NppjWU8cDxtkshj7ov44wvpTfGzXH8ENZLdfeQyOZw7QZqS6JTSVFrdHNo21a2li+n2t+HK5lcYwk2lWrUsoEhKkg9CCGYcidwLzmFdkiHqsj2YgogqoXFV4koPpBMFclRohj4JxI0uLJ2BClUyMu1FxB6Hc9aovdNV/ZjWwFrYVmvBILzFzLIkk7WDmDRpNwi7gqunjnF8hmLfWPrOJRczbflN/NMwufQiE7SauPNLBBNqnQPaCQrFxbfY3AhMODjjKGoNmdqV4MQDAifql7G8j0MYTHvzdJjSFScSwh5wvFVcXMwl1w3I/kYWQSG5+NHgwCw40HV9fn3zBkmkuVXIQCG8LH8FJKuUjTj2LaCJGmUTlzB/CtvwBAOthflAgV+1lzJnLlAwy5zurIHIXmskXrID+ax54N5dcnBfhkuzxFTanghX3vKj9J2b0NKL6MUFST9Ej4+o/VREFDQ4kTDnu/ByjyvX3MrsdnDpPf/TzJ2nT6jiBDQDlOAvhYlhkmewAmkQs6Q5TGdoU6Hrc4ok/ICndpSTcL2U2cXf84Uhhlcu4G27WLGQtjeLKM4Np6sIKkqk+UOU1PTeBfRHltFhLS1qWQeEYpHRSIJIo5N1DJxZInVM+N88c8/TW+pyMfvuJLK++7nQt8gvUcPI9WMxTnoegvhOjhCYKYSKI7DmpDpsvfQFL4PTo+PnEtTqb6Ik5lGCsmcPDWYsx6KA106fN/HVYMAoFAxiXdsTgxoJHUJR8ALPQpXtJp0l2fpRGKcyikUdQkppvDoYIQfb7mWv125kTOspNufI06bAnPMK/04koww1EAVk6ULlWylOBuXSNhlaBdQbQnhqSDADNkDI3EVa7xO++HT9KuCnd/VeOk7Eo2SQSpMEaZGUhiOx5WdM7yr8WW6IoNEPSi2P8vgYMAjMVdczvHvfYmotvrnPvsvY7xGBPQLDCEEQmjIchw9nsAM+d/V4W7kVKhwF7OwahBTzrH9pv+CuR/UkOnLrQQ3BWuyzuqyjTEYxYgqxDo2M5nAUY0nFJrCwUNwXhJc0fAw2jZe3aItqciqhlAlqq3g/TqNHEm9TiITQHi51VUk1aPvsgV8r0SPFDCU3X/FTWwfziL5Efa0FK6Iu0yuTWG1VOxzMp3hLUT6H6e08vss1pG3ZeSkhg64U02UfOAQIyuyEFb7dkwDXyg4HRkl5qFEHayzJ6h85zvUfuQRib9M7dxf8HR1mvL8HAXDJnX5FYvrVf7GN5h96CFKiSjbt19BujvIcz/3jX+ifd7DLSeY2vUvKKpKf6wPKa4RTah4bgBlWsUF/sfYc2x21/Lb5x/EcOtIskS7XcNoNbH2nmM+Y3DSOMfGSPA9rHspRSyiwECR/sE1PHjPU7xudx+24nFowGH1QYFxJTRnYuTX1BCShls8xrR6iFR7iMPuKfywaugcM+xqHCLr2siNEvxzH8e2XgbLgiDp2O4TtLvbbJodplSeohNWkq+KrKdhlznnnyEdyyF8H18IzMZFfn0bLwwAVDOAa51sjgh1NC3IrR4LCyozUpW0LdjcOcaR6Equ/JW9YEuY1SXkRbHmmUzsYnyoSaV8Lf/JzOKVNnLd9V/iX554ESKQzp5ElpPoco3X727zyL1Rvpx499IBiMCH9zxO27yMZD6PJBZItupIno8nCfoqbSoZha/H3s4+LuNCb2DUxiIKZ/UKnbbPRGycju7SPR+nZ16FfrC8MpoUGP85NZjzsjUbaesSaSEx7blEEyrQoeP5yIrFY8kIRiWgdAawC1FadZOOlyQut5huZsF3OGfdiDo9xIK9nFSyhdWIMwyPi5AAACAASURBVCVfw5S1kVz3BHr6BBMnV1Gs10nGY1iuhTMfnOs7Zj2OKWfJlg7TrzSZJnBUUW8OOTpI7PrfYTr5t9xbyvCypGF4gqyX4B2bbuTr5gw1M0nS7JDa+UVo5kGJsNYtkbhEqln2JVzJZZvzCqhNhKcQbzShDzYkosiZDMOdKHtVKJ88zh+MraX4Rx8mPbZp8TW2vO5+FpoW1baFG4NELEGz2VzUS7h2wwA7xx2q1QpeWFhMS0H2fVw80uk52qFwkh5PAAZd7RaTms5NRw6jxVL82d9+jt/45J/xOx1BIxKlf+IcNBvET7yB87l9dHWNE7E72JKMFU0yOF/CKQT2ojdVYqapIAouDObw/A5EDTwlREvVNDBJ4s7rsL7oIxCYnoku6bQ8kNTAthl1jf6FOc4PDTLqRjkw36CuCq7pmJyoBJeZ37gyTs7w+MIkfG0AYqbJwa4eoIdt/i5sW6dPnWbaX4cjy+iejkmNQ2Ibn/A+T5eY42r/PNMJmXcVY2y0vkTHMpBCjglfcsBV0GMK5rngEpCUBa7XYeL0LJgqsayGlFBZcUUvxYdPE/N0JN0jn8zR7NkLYgnx830ZX7i4bQPyv/w0wGsIwC84ZFlHVuJEUyksL4SPM0tCDtqaIWS5ihJpk9oQwL9qmLt0a2UWJs5jHC+zph4czmoyS0OPspDIMFBv4EkSz/VGONo/ggWsaLo8uXOSrrZDLa3Rnc3ga1FOW6O4tqBZS+E6lxTrragzdOM0Rj3CC8/cw5HDNzI+83ruuiJoXZOJcNKU2deS8X2bduV6ckaVPft19v9oMxz6EOr52wBwWi2UXAQtE4qX5IOIvuvt63lk20o+9NPvY7gOZ371/fieQIs7qDGX1kt7mP2DT+NZAikSYfZHP2R+ahLHttj/iY9x8oodnLjscsbf/g5mPvNZjngGvhCsvv5mUj1BAHD8Z88yMVVlqpMmEtU5uevFoA4gAr5fwXcXkNUY7UqFoUgfHyj8N/6u+5tE5CCwsD2T57/xVYxqjUNrWhwuHiZz+B8BiFgyXj3JbCfByuxKfCGTbqk0Yw4HRqHrkMRjP0nQngs+r6xEQVVpG6d49MI/cGLyJYSoA4KHph5mwpoD36Q1e5IVtkBXNBCCM8kztJttFBFhpjyOhcN11lquMkYZ0kc4Xd9PlzkGnRhqeBtrl0MZ3IyJEC6+L1E+FIqWRDUyWgAv5ylhSwqq57JJOYhvRnlL+Sl+j8+gyC5KxKbTiuCrKqCAW2e6y+dEz07MWHCz9e98M7Ksk5wLnEI8Ok985csoW15i83V/wB8bf8r7/c/z24c/y+WHv8fNO3eh7d1FtdQi1RXBbM8g+d6iHGrMsXnwqTrX8TJNP0Wu7XHXnhbL0wkaepmDbZ+vdv8rHd1FNmU6oYiNpC+lB+ywQ0MWMsNh6szwfdSw86Ljg5DqHNJ1HNmjZi3QXmbwwoY0huQxYW3HdHbghD3ortSNZa1A8aEv5WP5US60byYq1ViT3gWpDsW0iW+1SLpxLNfCnmshdBnTWeB9Z2r88fVRtudLSwpf7nG6b69ipRXeZb6P5c130W0H+67PyyBJDd5w6lGuPLYHXAepPgMnH4OVt/GPt9zDF264DT0Rkip5QXD3JuvfeAPfQ/VXk2gF67IuEaXvM3/M5/tS1LwE+w68wvuGC+Q8m1RvCrsTrMng6q0cn60TwQHPY3g40A5Qwj3VlU+RD1XykvkAadRsHckVRGkTT5wLtBYAPaxT2NSucevR0/zKww/hbruCokhxq2txuBnYvBFZ4Jt1+sfvoVLuRwjIeaFGhByhZ3YWO7oAnkQ2VsbvRJG6HNo9oVaB5GPFgiA+Fg2uHL7sEjLsUjUD6t+66AStyoBRj7C8UcH04bYhlw9ti6K7PlcZ0FUOUnhrai4+gretlJiKSdxz+Aj/ec9LvMP/Cm90vkWnk6CPKSadKI6skFMzKKGQUYkujrKeLybeTMJyubpeRksnkQwnQAAATwQXn0hcxTofIDJxSVBPH6MY24fruuiuj5KLsHxbDxUPJFcnkjVR3/AvLKx4GN96taP3JAe382p9il/WeC0A+AXH6lV/zODAg2y59a6ALx/QC5cokd2+g97P3o34+HmUoeAg6r5CLpNFUWQOPPETOsfLrOiKEXF9ThdW8+imq1Fcl7ecDgzhVzYM8sLKIHe9ouGR3zeHhKD3in6S0QhuJIre3cORH2/kwrlR7Iv9uBdiyJqHZ0s0j+8gpWSpn43xtjf9BVII/Q2kgv7W71Y01q79C7I99yPjoRTHabUS7HW2M3rqzXSffoBC930kb16GlAxTH7klgpvL0nGullwsReZMbw5rm0982CC/tkl+XZuhmxYYvaPI8B+9Gz75UQAkz2duxzYW3ngv2u23cXTqPM9vWcVEMsJl97yRwsrVpLqWRF3ufO9v8WtjB9i+vouZk8c5a7zCc3u/xStPfA7wWbb+KgDemXwDb3llFYUD55lsBtCaQHDoqccY3rSV3OoxXpl+idj5x0AVzGUN1EiEfQMfZHlmOTuO5FA9iTPDBrtWC1xV5i1PWiRKwWFXtRjawACiGEC07/zL42CXUfQkp07uZHtIkmTOniWxfIxbbruN7tXdHMwf5MY7rmNtLE2kkUP3+lhoCQbMBC9Zz3G6sR/JSxKxu/HageNvl+oY5SG6N1boLZzF8yTckHw9bjdJR6dwHIWYEdyettUOEpdaFOcLpI0ma1iiqDUaHkJkkdFp6gq6kWJFdAWfuG8THeEzF+nF93zUC4FRVxyPxPqn6fSYmFYW12qw9uxZYofq3PjCAbbv/xGu71KvjaPpLYrnjyKkJJlW4BmzUYlUx+c3jHE+eHAXv1a32XK2zXBvH029QsX1kTyXTkg1bBLF830akSUo2Q69rHGqSqwe1it4EM0Ge6/j+czoVVqShK0ErbZ/VjzDX57/MKeHvsuFzCniSRNNjjGVWc5db1pGr3qcsl5kQ7oOSJSqvWyMPcqgUsKQVWbzBsJqknLjPLzvuzT2zaCOJKgbNWJyHF+L0r0sxvLyBu4xL6NqTqL05HniyiOovoIi5mh1BUFav5dFrT7HVSdfZMvBZ0hPHqMp9wACNr+VLk0hqyr0h9z66TCt58QDZ3jwRDfdjSo3yi739mQwInGer7iccLO0ayXK5TI9I2NMHjmI3QguFq2mx3Pf+SbbQ+KqxQAgXMtDc/PcpAW1Gi/OBam3Qr4L2YOYZ5DOzCJCcaBx9QyJRIJ1nbO85+ufAyC/aozfvf79XNB2Ln5P0d+6j7/bcCczaplWKF+8snQWo3qSorrAyLmz2Po8qplDoYrsdyMnXWr6UsrGik8DkMkFFfeeZ6Hlg/lVrXlcpU3jxo8zt/brwZluZ7lMj/CewW7eUoUdczbvOmOR9jUS7SZ/s1DhK7vbfPqQzUdqMr9+zmTT+Qskmwvc4jxNt1HDMiP0MYMbXsqGtAiTIliv2+d38wE+j/B9bpmsQruJnNYRrk/kUgQAcIXJ0+O7+Jr+DIZSw1FbeIpBRzuFbxg80dlL06iR3diFowcFm8LRcfUa1tRl4QqI8DVtnPbSGfhljtdSAL/g6O0NBDhIwC2/835K//0wmTWDr3qOCG8xUkJFqBLbJgfwkssobo8iH3Rx4m32lf6doZ5bOJrLo9sWnzowzeqJOdRNA7iSzIaZCYpCEF+os0wfoeQ12bZC5vEjdZAV8opHTduEEALXiQJNFo7kiLlv4vjjOxnbNsLb3v42FibOLxYhArzvsgf5yLMH6PiC/r434Lmz7AdiXodc7yBv/52rcebaDOZvQIS5f300jT3XQkq8WrLyqt/7fapf+HMO79/NYVZwer6bZWmbUpdLUpjMTCaZ/6vvgqySyOYZWb+Rwy88w/TcNHtVFTcXZ9naddxyxz2s3HE1AIqmEc/m8ByH1de/Dvn0CmRzkp8h8fLhh9l2133YJ2LMnnqFy+++m/MHnuLEvzyMEALbl9m18BiZtM2FdtDnfO1/eiNn5h7i++OP8Y1cnlMrE0wrLneat7PvJz8kNzPJ8uk4yZs20bPsPIpRJn3zauTHn+DmgY2cYoru4VVowxbe/j0w2ssrwwqSOYetxHjfT9/KTNcgcIySKPNIs0ps4lmkNQmWPxrj+K5/plUqoQodNXE34/oEFxae4ZUVPht9QaqQoF1fg3BC4+o5nH70Tro3/ZjC5mlsW8OvBEZzaO0R5GiD+mSStCjCENyk/AhhD7J3xxSrFgKhIcOIE4m0sNsOMj340nEWUjE2no3hlWXOPvERaDQYfybDl3evIhHJA1dR369zdn4j5/Wt6HNVEu0FfK/CxECWev48yxeGiLXA7uxh36M/Bd9HT60l03IBleHeLFBjYs8baRcN0leP8udHj/DGrhRfuu9vePgv9rGmcgW2fQKo42g9vNh02ae3ua7tkJMl7r2tjPd8nOYLU5T3T6AhY/g+Fb1IjCAAqIc3QkcOnNYZ9xVc7Tyd/nUcHPgWP7KrvKWkcsj+FR7Jn6Mw/AVW1Tfi1pcDA3iyw3j3czwVdXkiEQMMrAWDuBdl44FBHNvhyfFv0e/04MuDXHH6TxhSkvyGdh0FP82TjTbWi6/ws/TLnM/u4demDmOnrsWuJjiX/QNGjkqcbXbTpXXwnAZFdYyH1auZ/fw3iWcfI5ZKU5yYgMIQxGwu4c5hYWEABY/fS0polsfL01Vcz0fOFaA9ydnzE6zccQ1Pf/UfSDZkYj3w1E92Y9sVVisdPODMc02EL6FJgWNeMB16sJBcnS2dLCeB6+5ay9deOU/U8Ukmy6hhuumxC0/SPXA9hxuHyfS26arAi9I+lHSMk/PfJTl8Ew1P4+8Pfo6ZayI8n/wJK8VGtgLRmMVzqw/hlV/P+y2LZmwW2cjy99k4nVaDzQWP+cZuJK8XT5rFSgR1PIXkGPVZmJ37Mc7yDs5Ai864TrH7MERqXGw69qw4a/sK/NZYPzPfnmS8bNKnClgV2LcdfgzZtYkrCu8kSutklecbdZyuBJarYBk6XsVhefdJJM/l8gMvkj1zmMJ9t1DTMmw586+MFSb5yviPSR0bZe/U84iGz3quYL1qMQ8sjzSRIjZf+9bz4AdFyePaJAgPfJ92YoKZTg+nvUmM732PlAzZagGp6zCplz7OjPIIpnwlR+f6efPb3szzzz2MJ9mY7f8YHoDXAoD/ixEdy9L/6auRdPl/+3shBMlbhojXLVr75knNrcWPeRQzs/Tu2Mgt5TP0NQuMXDjAVc2tRC9fzQ3nDyNbPlfO1bDGXyT31vfjPuMx0zjI0x//Co7jsO6qG7j73e/juWeewQN0aTdQpL0QYWTdLbzy2C5iqQw9I2P0jIy9ak63Dd/GR/jI4v8HBgpMxIfpocXGa69HCIHaG3/V38Q2dxPb3P1zn0+Lxbj3o59i7uQRJv/uQZ6bHeJ8AyKyg+EpdCdg+ebtTJ46zbrrb2bT626na2wF3cOjvPyDb7NqxzVsvu2uxYDp4th6+91EkylkRYWhq8nv/kdu7u+jZ9VGBgbncTs/ozS6gZ6DH+Pmwmk6xFl+za3864/20nRAv3UA/x+qrBor0Hv6q1x27Nt8vdDFn2Xi4B7mzqE7ue7K/4xtdHjl6SdZduf13PfgB7mmdgbTNcn2dmj+9Gm63/1eJhsHiUa70UYUMj97AU1WuJDtJWJVkOUNzPVeQSHepGpup+7vgbbP+ONPcHagxbXHuogOJ7nl7e/lp1/9nzRL30dty3hCJ+NtAvYxsmaMx6cnyTTHgAWE51JLmaTEGzm+6yXkrIxUtJnZuZXsCpPy6TJz+3KsHSrzqWW/z5rEMfoyv8sfrng9Z/bdj+fV+KeKx3u6BWZjBU5qlG73WRYqeabzHVbIXfQNLeeZkw799gJ+fReJuscNz9S4d9M2arPzZM/upaakcdUIq7b8Kt9M/zWW0uFysRX/6QxGex+RaITblo1z1tnBYGeOAwxzzaYRdj12kMZ0m3hG559eOo+UVulKaNihUl/X1HU4HR2HF2gO2JRKPsPz29gfWyDfzvNvJ37Mv6w4wyen3s22VsCJb3rwoeP/lXu7riF/9hYspUnaEXixGD7g9O9hY/Zq/urGPyKlmdzw1XfyUNdJ8D/Lfz/qQ3cKusdZvpDlVuBYz0t8pVdH+D432HDlbb9N/fQ0EhLXNrZyrLOX2XOHSGZ3oBHnS+c/wXRknnhUxrRNyh2blx95AmdNmezJPI97/TBzlgw+yTUdvntiDark0ZUTaI0W5ybmYGKOddffTLNSxmy3WL1hM/MrbmDVgsTJMz/k8N57sYTNRVB2/1STz33vGXx8JAEfue9ynvjmXp7Yc5ztW7bgA2ZNw3MUTpwLFC0v5tR9UyeixolGg9u0Kym4q++gIwRz5cCdOlZA+4uvIkkuK0aDPLvEWi7os2xIvp6j0eNcKXbyUPPfiPZ7qF6BUSPKlFqj2J5CiaSxfZMtY5vAeg4nC80otDpr8GI/xMxMIE/cyJezU7zZTgJFXKfM5Au9LLtWwowHLXdPn+wwKKBSeQFXThNTUkS3Hg80R50EKE3wJLqIsHKnwf7ZQ/Q0bY4NRegqOygigbv+BmrtCCnfxtckjpRbjADRegVIUCwO40600CNxlnGM33noDxCdQSxvinueeIhOIYJsrQAmGW0KzsQS+BuuZ758BrPdYn36usDmqxrnpDninsbt1hYek3czrgTIoForY2fynA7rky7MBf+qXj87Jj/NI/IZlOYY3WkLYaWQjwcpnOVnH0KPfOznHcgvYbwWAPxfjv+T8784UjcG/cWxrT20DxWJ7+hjWVeQW74C2LdzD09MCrqGChTuXc/X0zfSuVDDb9joKz+ArCg4V5nknY3Y/wydeo03/OYHUDWdO+66C4ATJ3YzMz3LhuvfyOiW7ciqSjKf/9/PV0h86+5vcWQh0DEQQvDgpz7DSD5GT+rnVQ3/v4aQJHrXbKT3bw6hPflvxLwyK8YKOMPXoWr6zz1/++vvB2Bow+b/42vueMObl/4zfBW8/CW29rVg7hGYewR5YDs9jadgpsjW+z8Axx+FY3/HuvQwu0pDpFds463XKKTco3Cixs2OzE+m5pHf+i2ebE9wTf81KJrGbe/9IDf++n9BiwY3pfVdQR8/BVi982Wk2P9q787jo6ruxo9/vrNkJvsOZE8wJIGwJRAW2bUiiwpuP6WLa6t9XKrVtj/UPtY+1rZan9aqrdXaurRatVaFasWVqmgVEUE2iQFkCZBACCEkIcvMef64N2GICQkQMpD5vl+veWXm3DMz55s7yf3OOefeE0FR/RO43XH45u5EwsK4aO45PP+bO4nJySA++Uyoi2XGVVNxOs/B19LMhy88x4cvPENqdQrOFCeX3P0AIkL28GKWv7qQ/dXVfP5xf/JrY2iJKWD8+bNYvv73LFnzOmc7zqJk+kSGlkzC7faw/MOxbCwr47zffR2HfQ70i/f8L7CX+vIEzBOvEXn+fAqmfdtKNkc+zLaKRYyN9rLSNDOoeBIzzGq2f5HN0oYWbr79AVIH5ADw2O/e56WtewnzNZLpqMUVl8V550/FnHsOd7y4kr98bHXPXpmXQ8KBWOqb3Vx10a/ZHfcg/3zOcHb//1CfMJRptb9nUHUMY5MXMDongVe9kHgA9vl8lFbs54krxuBxOXHHOnA4BL/fkBmxg63NYaxuSmXsuGb+vamZQXmnkPx+Dd+N/CG15U0UFHjhk/34MTQauG3SrXy69xPqw+rYWbuH/btPI72gihe8q6mNaOHHE26gf4wX8JLjuIlPti2hMGcPP/3aPG596U3GNjzFiKZVVKU1cce3/4uyJ39PYouP/JhsGPINHh7wNOwHJw5q9pXz2cBcJuTnwOeQXp/CgMYB4K+hLHIBiXlbKdtyCiNLE3H7DUWJO1jsSiKuwk11eSp+HEzI2MY7BT8g4fN3oK6CCu8A3mUsjVE+zpmYSoPTwc9eWccMXGR5XFTXxVLm9NHP7yHG0cgfP9jKkLQsyir3k9svisn5/XktPI5t27ZRue1L4vJHsX1vDVUfJWOkGWdjLD5PDS6Xi3m3nspTT22iqs4aV95TOJyFYV68DgeF2R6kqpbv/PEjmib3Z0+dExIhLPo/7Kzrx7IVl+N0CKv9hpElY8m55Wb+mhnDNS//hr2VI9m4aQd1TT7gZ/zqghEMH1hPZkwmS954mP1ZTu4ruZYbvkzhpRkljJMP8FWl80TTQuZXX0FxwiNUrY2jal08A0buoya6HDfwj0/3cUOx9ae38stzyNw6hZLrUln4j7/xTl0c1415AGdLJCWRLhxNfvp9sY8t+Hmodh8ZTW72llbxe4aQvn4Pw/1OXi+t5MtIP5cawW8PlW0uHUNMRTTh0QOocH+M2zEZExXF8wX/oClyKc7wCC7acC5ZLMZ9IIHS5mj+4BvCjOLTeOWzHdxjz9ur4QA7HdUMah7AO9EH2LfPjdPdaF3zwjGGBDbwpaMS4wjH52ukyTiIcLSwxGyl2e+EsDB2HKgi0R9N89s7wQsLxzspzvzqF6zeoAlALwnLiCYsI/or5UVjRjGseARu98Hu9fD02EPquGI9ROHh7O93nCUOHHgjmZmXEz7NOsVs3p33EmtPputIYWIhhYmFbY/H5Hz19JujMeKMmW333Yepd0QGTYev3QHDL4Iv3gCXF0ZcZG1rXUJz0k3w7r2U1FYTGz2dhLQMZMwc+Jd1NUE59xEy8qZDeDyXtnv51oN/ew77cs0REdYB0z04Hu9g6xvpNQ8+2eFznC43mUOH8+E//kbTzj2MmXthW++G2+ttS2z2VHxM5eZaElKziIqP5uYxN3NjyY14nIcmTMXjxlM8bvwhZbOuv4FHb3oX4/dRMruEMWdPaHuP+LgS4uNKGNZaeQzAJFJbvs2wujoiYg+eFfDD6fmUVdby/PJtrC73ML/YSlTF4WBmUSYV9X6afX6eWbqF125+lv5R0VTua2adJ4vv5C7hty3nsiT8KmYUCE++u5bX8gdZ19kvToIPduOsbeG809KYkmf9Y3M4hKgED00HfJwd+RSu/s282DiLRVUeNjS2cEleEo4tPrZ8Yk2sKo/xMgjr2z/A7PxZnO2YjW+sYeOzORTFeGiKf5Y1e1eQHZPN4ISDK+gNTIrmo41DmZlWwMh+p3B5cSJ1tTOYW+iEfla9fg32mGuKNZvekZEJ66wx86rG7SxvmsPWfYZ0YJNnLz8Jc/JW07fI9htaRl/GO4NLWLHgGcKiYphUsJON4S1srxGojcPtaGFobn+KrriEpQsi2LX5cbxDJxDjdbFpfyOPvf8lxZlxpMWF883xA0l8VfClR1E7M48P315ETXkZ351WwLxpI9lTd3DMfER+DmtXLrfa6IsAl1DXYnA3xdHkH4BQQ2xsLCJCfHw8B7Zbi9a8FxZDcpiLXU0tLGtoYGZaPKfNTcb085IT5aVpXSoO33ZG5p7J0mlf455FnxMfEcb1pw8iwuMiC3jlG/e1tWPl1r2s27GP84vTcdjXCImOz6GuqBRTcS8LrriX9VuiMU0xZOYkklwxkovHTmfDglLqM2Nws4aGGiEmw5qzcGFJHtgH2BETzueqp7dw0QeNPFtewkNfH4mv8jGcTZG4RFia4mHU3haGzcln6YhkVt23jAHVjbw3Jovmz3ZR4zcMHp3ImQUJnDU8hW07RrPu4QfITh1C/thiKjfvo8UMxunYw/YwPzGRwyn3LAF/E7HF6Wx993uky0guPCuLP7+2mldW7eCC0el4MuKIfW0F65zl+AVihkYya+5ZPPCkk5ady4lyReLOy8Ps3IZPGtncFM3WmCJ+cd5wFj39CH5/M3uc/UitLcMXGYPHuHDhxGkctHgiqHMEZzVATQCCTEQOOfgfDbc7Frf7YNLQP+eUY23WicPlgYnft+6Panf4bh06cIfD6f+NF2g7OapgtpUAiAMGnQHh8b3S3JTcfJxuN77mZnJGjuqwTnJWDJWba+mXZSWELocLVzf/FD3hLhJTI6kqr6NgfPFXhk864nS5Dzn4A0wclMTEQUmU5CTw03+u5bzitLZt4wYmMm5gImu21zD7/iW8uKyKpOj93LFwDY0tbk6RXxGeUkDp1hrS41PYH5GJ1231UMyakcML/9lFaZiPW6blHvKeo2ZmE+Z18c/KvxD2wa+J7JfD6gpr7HNCbhKbNh6gcnMtYeEu1q6rJivGxQF7Nn/rgcbpEB6YVwTAo6uspOXM7DMP+T1kJ1pDWFkJVhJ34egMIKPjX86sewFISIwBaqhvqaUxPpZadzQ/297AI+FvUX3GxWxcuIEdnnhS2YMrdxpF8VYCUDDuVNyeOi7esYLnIwZQdSCZjIga3LFW7AOLS9i1eRPTr56H2+PlmaVbmP/CKhav38VZw1I4dUw621/dSmRKMvGnJOHak88r5WWcVZxFmMvBgNiDvXJ5OZmsXbmcyKho/l6dx2zHZ0RIM+H1qYybMIj31n5ObKz1fyAuLg63r6XtuS8W5TJ9WSn1Pj9TkmP5VtrBRaPW7CphZ8UC+idPISnKwz0XdN47BzAiI44RGYd+nrzhadTVlyLiZPvWe4nw15HYfyp5p10PXM8VAKc/BMAj11yOJ6wFsObpzCkayMfLrNcZm1uAyBaeX76N+Ag3Zw5NpbT0XMqWbmRpXQszrxiLN9KN2J+H9NQY6isqYcl2woDscSkUzT34uctITWT2aRcyuGggUTFWz+vKt7ayfc0e5s7I5UenlzDpmYcwGEaNyyNj1CwSUiMREW51+figbDc/P3cYYS4HHzun8Mor1rU0ps45j8gIN1edO47fP7ScpKYIpu/0sZgEytjBjIlDOWvaqUR5XKzPyWHDhg0MLiqhatFqJDKGRrGvu4Cbaf2mkhWTddjf+fGiZwGovikm1brqYM5kiOiZHo7ucIWFkZo3GE9EJKl5gzus03rgT878ao9Qd6TnkhoSwQAAEf9JREFUJxAe7SYmMbzryl0oTI3luavH0y/6q8M/hamxnDGkPw+/u5GfLFjD6Ox4Xv/+FJ6afwnfOz2PJp+fBSvKGZ19MLnK7RfN8pHhxE/szynJUYe83pAJqeSO6seM06cTf9nfuPo06/eTnRhBenwEOSOSiE7wMvva4YjAjugwwoYnkTe2496sYUnDcDvczB44+9Dy9FicDmFwSkzngV++CL63ou2zkdrfGjIro5HZV1xJYmQYNYSzZPw8Th+VS7jbSaU7HYNAzmQSUtM45we3ceqF34CEgUQ17GWs1zqLJytyb9slr5Myspj9vR/itlcWnJBrHXibWvwUZ8XjCHcROS6F8GFWeVFREfPmzSOxgyG8tDQrSSsZPYrLJ+fhySkmJTGTsMZEsgelERUV1fa8hIQEwpsaSXfAL/PSyY3wMiXe+ryVxB46xyc5+UwiInKIjx/b+e+rC1FR+XjC+jO08AEaG3fi9aaRnX1th3W//cCjTJz9q7bHDoeHfskzyRt0O7ERboakxODzG8YNTMThEAoK7iA+8nZ2Ox14Ag7+AP56awal0z5DyRn31WHHkimFbQd/gJwRScSnRDJoVD9iPbEMih+EQxzkJ+STmBbVlkx+a1wWD31zFGEu6zA5fPhwxDjxSjSRkdbvMCk5iYS4ePInDgOfIb3JWnFy+pihRNnLZk+aNIlJkyZxwaShrHdYE8ar7Usve40bV7OLcNex/y0fDTHGdF3rJDV69GizbNmyYDdDBUvrEpueqMPX62G7Nm+ivqaGrOEjO9y+r6qBBfetYPY1w0lIieywzuE0N/lorGsmKv7I52wcqdKKWs68713iwt28cZP1DRFgT10TxXe+AcC/vjeJIakHD7at/1O66p2o2t/I6Lve5OtjMrnr3GGHbNu6bg8JKZFEdvAPPVBDS0OH/zyr65qIjwzr4Bkd21S+Dx5YwZI0L9+6fgzXPr2cVz7bwdPfGcuppyTx1roK8rb+nYwDpXDO/Yc+ubEWPn2Kpsoy3q3I4tTaJ4k47SYYOa/D95p499tsq25g0Y2TKBhwmCSlAxs2bCArKwuXyzq47K9u5D8vlTFlXj51DbV4vV7Cw8NpaWlh3bp1FBYWtp0C/O6eWh4r382jQ7PblljuKX5/C37/AVyuKBoayvF6U5AuFriprl7Klq2PMrTwPpzOg0Nxd768lj8t2cSdcwr51vhsAHzNfupqGolJOnRf1y3dSfULX5By21gaVu8mvDAJZ0z39zvAX9f+ldVVq/nlpF92Wfep+xYRHu7hvKunfWVbw+rdHNiwFzMpgYSEjr90/GLBpzQv/jMDmsMZ7MhhXVwz1f5dXHblpfQfmNvhc46GiHxijBndZT1NAJRSh7NgRTnp8RGMyjp0GGXu794nJymS31zUcaLTHYvXV1KYEnNUE1B7ks9v+NXTKzh7Sg6FGXG8ubaC+9/+gueuHt82vNFTfvzSKl5dtZOlt30Np6NnD8R9wUcbq7jssY95/fuTyUjo+up4xmcQZ+/8Hrub3HamrrGF/3f3SyRvWUqGK55BybHscFXx/R/d3Ol8pKOhCQCaACh1PLX4/IiIHsSOUF1jC3sbmkmLC06378nA7zdt8z76Gp/fYIxh4ZsbaHnvHcq8u7j1x7f06Ht0NwHQSYBKqaPicuoUoqMR6XER6dF/vYfTVw/+gJ0wCwPTYtiMm6aWRnw+H05nz/Y0dYf+BSullFK9LHtANF77evIHDgTnUsCaACillFK9LDbO25YA1Nd/dWns3qAJgFJKKdXLxOUgmiiiHenHfC2Yo6UJgFJKKRUE0Y5oohpPabuAU2/TBEAppZQKAhPmwOXzU1UXnEsBawKglFJKBYHT6yLW4WBnTXAmAeq5KEoppVQQREd7mBznpV+aDgEopZRSIcPhdWIafcF7/6C9s1JKKRXCxKMJgFJKKRVyHB4X/saWriser/fv7TcUkRkisl5EykRkfgfbPSLyrL39IxHJtsvPEJFPRGSV/fO03m67Ukop1VNCqgdARJzA74CZwBBgnogMaVftSqDaGJML/Aa42y7fDZxtjBkGXAr8pXdarZRSSvU88TgxTX6MPziL8vV2D8AYoMwYs9EY0wQ8A8xpV2cO8IR9/3ngdBERY8ynxpjtdvkaIFxEDr9YuFJKKXWCcnisBYBMU3B6AXo7AUgDtgY83maXdVjHGNMC1ACJ7eqcDyw3xjQep3YqpZRSx5XYCYA/SMMAJ911AESkEGtYYHon268CrgLIzMzsxZYppZRS3dfWAxCkBKC3ewDKgYyAx+l2WYd1RMQFxAJV9uN04EXgEmPMho7ewBjziDFmtDFmdHJycg83XymllOoZzngvnrx4xCFBef/eTgA+BgaJSI6IhAEXAwvb1VmINckP4ALgbWOMEZE44BVgvjHm/V5rsVJKKXUceLJiSL5iKK6k8KC8f68mAPaY/nXAa8A64DljzBoR+R8ROceu9icgUUTKgJuA1lMFrwNygdtFZIV969eb7VdKKaX6CjEmOKcf9IbRo0ebZcuWBbsZSimlVK8RkU+MMaO7qqdXAlRKKaVCkCYASimlVAjSBEAppZQKQZoAKKWUUiFIEwCllFIqBGkCoJRSSoUgTQCUUkqpEKQJgFJKKRWCNAFQSimlQpAmAEoppVQI0gRAKaWUCkF9ei0AEdkFbO6hl0sCdvfQa50sQi1mjbdv03j7vlCLubN4s4wxyV09uU8nAD1JRJZ1Z3GFviTUYtZ4+zaNt+8LtZiPNV4dAlBKKaVCkCYASimlVAjSBKD7Hgl2A4Ig1GLWePs2jbfvC7WYjylenQOglFJKhSDtAVBKKaVCkCYA3SAiM0RkvYiUicj8YLfneBCRL0VklYisEJFldlmCiLwhIl/YP+OD3c5jISJ/FpFKEVkdUNZhjGK5397nn4lIcfBafnQ6ifcOESm39/MKEZkVsO0WO971InJmcFp99EQkQ0QWi8haEVkjIjfY5X1yHx8m3j65j0XEKyJLRWSlHe9P7fIcEfnIjutZEQmzyz324zJ7e3Yw23+kDhPv4yKyKWD/jrTLj/zzbIzR22FugBPYAAwEwoCVwJBgt+s4xPklkNSu7B5gvn1/PnB3sNt5jDFOBoqB1V3FCMwCXgUEGAd8FOz291C8dwA/6KDuEPuz7QFy7M+8M9gxHGG8KUCxfT8aKLXj6pP7+DDx9sl9bO+nKPu+G/jI3m/PARfb5X8A/su+fw3wB/v+xcCzwY6hh+J9HLigg/pH/HnWHoCujQHKjDEbjTFNwDPAnCC3qbfMAZ6w7z8BzA1iW46ZMeZdYE+74s5inAM8aSwfAnEiktI7Le0ZncTbmTnAM8aYRmPMJqAM67N/0jDG7DDGLLfv1wLrgDT66D4+TLydOan3sb2f9tsP3fbNAKcBz9vl7fdv635/HjhdRKSXmnvMDhNvZ47486wJQNfSgK0Bj7dx+D+yk5UBXheRT0TkKrusvzFmh31/J9A/OE07rjqLsS/v9+vsLsI/Bwzr9Kl47e7eIqxvTX1+H7eLF/roPhYRp4isACqBN7B6MfYaY1rsKoExtcVrb68BEnu3xcemfbzGmNb9e5e9f38jIh677Ij3ryYAqtVEY0wxMBO4VkQmB240Vh9Tnz5lJBRiBB4CTgFGAjuA/w1uc3qeiEQB/wBuNMbsC9zWF/dxB/H22X1sjPEZY0YC6Vi9FwVBbtJx1T5eERkK3IIVdwmQAPz/o319TQC6Vg5kBDxOt8v6FGNMuf2zEngR64+rorULyf5ZGbwWHjedxdgn97sxpsL+p+IH/sjBLuA+Ea+IuLEOhk8ZY16wi/vsPu4o3r6+jwGMMXuBxcB4rK5ul70pMKa2eO3tsUBVLze1RwTEO8Me+jHGmEbgMY5h/2oC0LWPgUH2TNMwrMkkC4Pcph4lIpEiEt16H5gOrMaK81K72qXAguC08LjqLMaFwCX2zNpxQE1AN/JJq92Y4LlY+xmseC+2Z07nAIOApb3dvmNhj+/+CVhnjPl1wKY+uY87i7ev7mMRSRaROPt+OHAG1ryHxcAFdrX2+7d1v18AvG33AJ0UOon384BkVrDmOwTu3yP7PAd7puPJcMOaXVmKNd50W7DbcxziG4g1O3glsKY1RqzxsreAL4A3gYRgt/UY4/wbVpdoM9b42JWdxYg1k/Z39j5fBYwOdvt7KN6/2PF8Zv/DSAmof5sd73pgZrDbfxTxTsTq3v8MWGHfZvXVfXyYePvkPgaGA5/aca0GbrfLB2IlMmXA3wGPXe61H5fZ2wcGO4Yeivdte/+uBv7KwTMFjvjzrFcCVEoppUKQDgEopZRSIUgTAKWUUioEaQKglFJKhSBNAJRSSqkQpAmAUkopFYI0AVAqCETkMhExATefvYLbcyKSfwyvecVRPvdxEdl2NM890YhItv07/Xaw26LUiczVdRWl1HF0IdY5+k6sy7f+N/CWiBQaY2qO8LUuw/qb/nOPtlAp1SdpAqBUcK0wxpTZ998Xke1Yi5ycirW0pzoBiYgTEHNwERqlTjo6BKDUiaV18Rp3a4GI5IrIX0Rkk4g0iMhGEXkoYJU3ROTfwBRgQsCwwr8DtufYr7FTRBrt1/ht+zcXkSIReU9E6kXkCxH5blcNFpGp9vudIyIPishu+/bX1kuZ2vVau+Yv6+T5UwPjEZElIjJDRFbYcX8qImNFxCUiPxeRHSKyxx6+iOygaWEi8msRqbTjeVmsVfPat/8qEVkpIgfsdv9JRBLa1TEicpeIzBeRTUATMKyr341SJzLtAVAquJz2QiVOrEua/hxrsZp/B9RJxVrm80ag2q53K/AvrMVQAK7BuiyoE7jaLtsH1sEf61Ko9cDtWJfEzcRa8yFQDPA0cB/wP8DlwEMist4Ys7gbsfwWeBn4OpAP3AP4OHg99iOVC/wKuAvYb7/eQvvmwhryGGzXqQR+1O75t2BdHvdyoB/W7/Z1e3ilGUBEfgncDNwP/BBr+dSfAUNF5FRjjC/g9S4DNgI/AOqA7UcZl1InhmBf71hvegvFG9bBxHRwKwdKuniui4PXgS8KKP83sKSD+k9iHUBTD/Oaj9uvNy2gzIO1etojXbRnqv3cJ9qVPwgcgLZLjmfb9S7r5PlT28XSTMD124Fz7Hpvtnv+C8CmgMet77MWcASUT7DLrwyo58O+xnoH9eYGlBmsA354sD87etNbT910CECp4DoXa13vMVgre60F/iUig1sriEiYiNwqIp+LSAPWgfE9e3N3zhiYDrxsjOnqG2u9Cfimb6zlRkuxegu645V2j1dhJRH9u/n89kqNMRsDHn9u/3ytXb3PgXR7dbRAzxtrSVwAjDHvY024bO01OQNrGPQpe1jBZffGfATUApPbvd4iY0zDUcai1AlHhwCUCq7V5uAkQETkdazu/juAi+ziXwDXY3XLf4B1cErH+ubr7cZ7JGId+LpS3UFZYzffA2BPB8/lCJ7fVXuaDlPeOowSOCmvooPXrMDq5gdrWACs1eI6ktju8UmzVLBS3aEJgFInEGNMg4hsxFoKtNXFwJPGmJ+1FohI1BG87G4OHvSC6YD9M6xdefsDbU/pqOehP9a8ALCGN8DqIeko+alq91iXTlV9iiYASp1ARCQC63oAawKKI7C6/QNd3sHTG4HoDspfB84TkRRjTDC/xVZgtXFou/LZx+n9LhCRO1qHAURkAlbPyX/s7W8AfiDTGPPGcWqDUicsTQCUCq6RIpIECJACXAckAA8E1FkEXCoiq7C6q8/Duk5Ae2uBa0TkImADUGuMWQ/8BJgFfCAiP7dfIw2YYYz55vEJ66uMMUZEngWuFJFSYD3WwX/qcXrLaOAlEXkYSMYaSvkCa1IkxpgNInI38KB99cV3sHopMrDmBzxqunf2g1InJU0AlAquvwfc3wWsxjowB050ux4rQbjLfvwvYB7WqX2B7saaFPgoEIV1QJtqjPlSRMZhnd72C3tbObCgZ0PplhuwJt7dYf98Diu+l4/De/0C61TCx4FIYDFwnbFPAQQwxtwqIuuAa+2bwZqD8RZWsqBUn9V6eo5SSimlQoieBqiUUkqFIE0AlFJKqRCkCYBSSikVgjQBUEoppUKQJgBKKaVUCNIEQCmllApBmgAopZRSIUgTAKWUUioEaQKglFJKhaD/Ax+k6gMD8KxyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for j in range(epoch_profiler[0].shape[1]):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    label_dict = {0:'net.forward',1:'loss',2:'loss.backward',3:'optimizer.step'}\n",
    "    for i in range(len(epoch_profiler)):\n",
    "        batch_number = np.arange(len(epoch_profiler[i]))+1\n",
    "        plt.plot(batch_number, epoch_profiler[i][:,j], label = label_dict[j]+' %d'%i)\n",
    "    plt.xlabel('Batch number', fontsize=16)\n",
    "    plt.ylabel('Performance [s]', fontsize=16)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there isn't any particular drift as a function of the epochs, hence everything works properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(len(train_loss_log))+1\n",
    "plt.plot(epochs, train_loss_log, label = 'train')\n",
    "plt.plot(epochs, val_loss_log, label = 'validation')\n",
    "plt.xlabel('Number of epochs', fontsize=16)\n",
    "plt.ylabel('Mean cross entropy loss', fontsize=16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained 98.03%\n"
     ]
    }
   ],
   "source": [
    "accuracy, predictions = eval_accuracy(net, x_test,y_test,return_predictions=True)\n",
    "print(\"Accuracy obtained {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some preliminar trials\n",
    "\n",
    "Adam - Accuracy obtained 97.80% <br>\n",
    "AdamW - Accuracy obtained 97.84% <br>\n",
    "Adagrad - Accuracy obtained 97.65% <br>\n",
    "Adamax - Accuracy obtained 97.69%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search with prior distributions\n",
    "\n",
    "Now we want to explore a method different from the grid search to tune the parameters of the model. The idea is that the more the hyperparameters we have, the less hypothesis we will be able to test given some fixed time/computational resources. \n",
    "\n",
    "Instead of renouncing completely of testing the effect of the various HPs on the performance, we can just renounce to do that in a systematical way and do that with a random search. \n",
    "\n",
    "The problem now is that even a completely random search is inefficient, in the sense that we already know what probably will be bad combinations and we would like to minimize the chances to extract those combinations; moreover some parameters may vary over different orders of magnitude. In that case using a uniform distribution would mean basically never sampling the HPs with lower magnitude, because they span a smaller interval. \n",
    "\n",
    "My idea is to sample from a distribution defined a priori (a.k.a. prior distribution) that encodes the bias (in the sense of hypothetical knowledge) that we have towards the combinations more promising and less promising. \n",
    "\n",
    "For example making some trials I noticed that few hidden layers work at least as well as many hidden layers, hence, since we like simplicity, we would like to use most of the times few layers, but sometimes to try also deeper architectures. In this perspective it is much less biased to choose a decreasing exponential distribution (on integers) for the number of hidden layers than to choose once and for all to keep the number of hidden layers fixed to 2.\n",
    "\n",
    "The following class defines a framework to create a prior distribution for different kinds of variables (integers, continuous, categorical). I do not enter in the details since it is easier to see how it works in practice than to explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class prior_distr():\n",
    "    def __init__(self, discrete, var_type, distribution, **kwargs):\n",
    "        self.discrete = discrete\n",
    "        self.type = var_type\n",
    "        if discrete:\n",
    "            if var_type == 'int':\n",
    "                if distribution == 'exp':\n",
    "                    self.distr = distribution\n",
    "                    self.N_min = kwargs['N_min']\n",
    "                    self.N_max = kwargs['N_max']\n",
    "                    self.alpha = kwargs['alpha']\n",
    "                    self.elements = np.arange(self.N_min,self.N_max+1)\n",
    "                elif distribution == 'uniform':\n",
    "                    self.distr = distribution\n",
    "                    self.N_min = kwargs['N_min']\n",
    "                    self.N_max = kwargs['N_max']\n",
    "                    self.elements = np.arange(self.N_min,self.N_max+1)\n",
    "                    self.probabilities = np.full(len(self.elements), 1/len(self.elements))\n",
    "                elif distribution == 'custom':\n",
    "                    self.distr = distribution\n",
    "                    self.elements = kwargs['elements']\n",
    "                    if (np.abs(kwargs['p'].sum()-1) < 1e-4):\n",
    "                        self.probabilities = kwargs['p']\n",
    "                    else:\n",
    "                        raise Exception ('Total probability must be equal to 1.')\n",
    "                else:\n",
    "                    raise Exception('Variable \\'distribution\\' must be \\'exp\\', \\'uniform\\' or \\'custom\\'.')\n",
    "            elif var_type == 'str':\n",
    "                self.elements = kwargs['elements']\n",
    "                self.distr = distribution\n",
    "                if distribution == 'uniform':\n",
    "                    self.probabilities = np.full(len(self.elements), 1/len(self.elements))\n",
    "                elif distribution == 'custom':\n",
    "                    if (np.abs(kwargs['p'].sum()-1) < 1e-4):\n",
    "                        self.probabilities = kwargs['p']\n",
    "                    else:\n",
    "                        raise Exception ('Total probability must be equal to 1.')\n",
    "                else:\n",
    "                    raise Exception('Variable \\'distribution\\' must be \\'uniform\\' or \\'custom\\'.')\n",
    "            else:\n",
    "                raise Exception('Type must be \\'int\\' or \\'str\\'.')\n",
    "        else:\n",
    "            # continuous case\n",
    "            if var_type == 'float':\n",
    "                if distribution == 'uniform':\n",
    "                    self.distr = distribution\n",
    "                    self.x_min = kwargs['x_min']\n",
    "                    self.x_max = kwargs['x_max']\n",
    "                elif distribution == 'log':\n",
    "                    self.distr = distribution\n",
    "                    self.x_min = kwargs['x_min']\n",
    "                    self.x_max = kwargs['x_max']\n",
    "                else:\n",
    "                    raise Exception('Distribution must be \\'uniform\\' or \\'log\\'.')\n",
    "            else:\n",
    "                raise Exception('Continuous type must be \\'float\\'.')\n",
    "        \n",
    "    def sample(self, n_samples):\n",
    "        if self.discrete == True:\n",
    "            def sample_from_discrete_distr(n_samples, p_cum):\n",
    "                u = np.random.rand(n_samples)\n",
    "                mask = np.tile(p_cum[:,np.newaxis], (1,len(u))) > u\n",
    "                samples = self.elements[np.argmax(mask, axis=0)]\n",
    "                return samples\n",
    "\n",
    "            if (self.type == 'int') and (self.distr == 'exp'): # only case in which self.probabilities is not defined\n",
    "                def exp_distr(n):\n",
    "                    exp_of_Ns = np.exp(-self.alpha*self.elements)\n",
    "                    norm_factor = exp_of_Ns.sum() # 1/(e^alpha - 1)\n",
    "                    p_of_n = np.exp(-self.alpha*n)/norm_factor\n",
    "                    return p_of_n\n",
    "                #Ns = self.elements\n",
    "                self.probabilities = exp_distr(self.elements) # compute prob of each element\n",
    "            p_cum = np.cumsum(self.probabilities)\n",
    "            return sample_from_discrete_distr(n_samples, p_cum)\n",
    "        else:\n",
    "            if self.distr == 'uniform':\n",
    "                samples = np.random.rand(n_samples)*(self.x_max - self.x_min) - self.x_min\n",
    "            else:\n",
    "                u = np.random.rand(n_samples)*(np.log(self.x_max)-np.log(self.x_min)) + np.log(self.x_min)\n",
    "                samples = np.exp(u)\n",
    "            return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior distribution for architecture depth and number of neurons\n",
    "\n",
    "Finally I introduced a function that given the input and output dimensions of the network and the number of hidden layers, it samples the number of neurons of each hidden layer so that on average we have a compression rate C (e.g. the ratio between neurons in one layer and the previous one) fixed to a certain quantity.\n",
    "\n",
    "Going a bit deeper on the argument we have that since the number of neurons depends on the depth of the layer and on the compression rate, if we fix C we can obtain what on average would be the ideal depth of architecture for that compression rate.\n",
    "\n",
    "If we have a constant compression rate, it holds: $$N(n) = N_0 \\cdot C^{-n}$$  \n",
    "where \n",
    "* $N(n)$ is the number of neurons in layer $n$;\n",
    "* $n = 0$ for input layer;\n",
    "* $n_h$ for the number of hidden layers; \n",
    "* $n = n_h + 1$ for the output layer;\n",
    "\n",
    "\n",
    "We can compute the number of hidden layers required for a given C to compress the input layer in the output layer imposing $N(n_h + 1) = N_{OUT}$ and $N(0)= N_{IN}$ and use\n",
    "$N(n_h +1) = N(0)\\cdot C^{-(n_h + 1)} $.\n",
    "\n",
    "We find $\\overline{n_h} = \\frac{1}{logC}log(\\frac{N_{IN}}{N_{OUT}}) - 1 $, that is the average number of hidden layers that we MUST get sampling from a generic distribution if we want to keep the compression rate CONSTANT.\n",
    "\n",
    "In our specific case we choose to sample from an exponential distribution $Ae^{-\\alpha n}$ defined for $n > N_{min}$, (e.g. $N_{min}=2$ if we require at least 2 hidden layers). \n",
    "\n",
    "To find its exponent we must impose $$\\sum_{n=1}^{\\infty}  Ane^{- \\alpha n} = \\frac{e^{\\alpha}}{e^{\\alpha} - 1} = \\overline{n_h}$$ with the normalization factor computed as \n",
    "$$\\sum_{n=1}^{\\infty} Ae^{- \\alpha n} = 1 \\longrightarrow A = \\frac{1}{e^{\\alpha}-1}$$\n",
    "\n",
    "Finally we get $\\alpha = log\\left(\\frac{\\overline{n_h}}{\\overline{n_h} - 1}\\right)$.\n",
    "\n",
    "Concretely what I do for sampling is:\n",
    "* Fix $C$ (e.g. 2);\n",
    "* Compute $\\alpha$;\n",
    "* Sample $n_{layers}$ from $Ae^{-\\alpha n}$;\n",
    "* Recompute the effective $C$ inverting the formula for $\\overline{n_h}$;\n",
    "* Sample for each hidden layer the number of neurons with a binomial with number of trials equal to the number of neurons on the previous layer and with success rate $1/C$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APPENDIX: how to recompute $C$ \n",
    "\n",
    "$$N(n) = N_0 \\cdot C^{-n} = N_0 \\cdot e^{-n logC} = N_0 \\cdot e^{-\\alpha n}$$\n",
    "\n",
    "$$\\frac{N(n_h +1)}{N(0)} = \\frac{N_{OUT}}{N_{IN}} = C^{-(n_h + 1)} $$\n",
    "\n",
    "$$\\frac{N_{IN}}{N_{OUT}} = C^{n_h + 1}$$\n",
    "\n",
    "$$ C = \\left(\\frac{N_{IN}}{N_{OUT}}\\right)^{\\frac{1}{n_{hidden} + 1}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_neurons(n_samples, n_layers):\n",
    "    start = 784\n",
    "    end = 10\n",
    "    N_neurons_samples = []\n",
    "    for i in range(n_samples):\n",
    "        N_neurons = [start]\n",
    "        C = (start/end)**(1/(n_layers[i] + 1))\n",
    "        p = 1./C # probability of not suppressing a neuron = 1/compression\n",
    "        for j in range(n_layers[i]):\n",
    "            n_j = np.random.binomial(N_neurons[-1],p)\n",
    "            N_neurons.append(n_j)\n",
    "        N_neurons_samples.append(N_neurons)\n",
    "    return N_neurons_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 784\n",
    "OUTPUT_DIM = 10\n",
    "C = 3\n",
    "\n",
    "def compute_alpha(in_dim, out_dim, compression):\n",
    "    n_layers = np.log(in_dim/out_dim)/np.log(compression) - 1\n",
    "    alpha = np.log(n_layers/(n_layers-1))\n",
    "    return alpha\n",
    "\n",
    "alpha = compute_alpha(INPUT_DIM, OUTPUT_DIM, C)\n",
    "\n",
    "# already discussed\n",
    "n_layers_P_dict = dict(discrete=True,\n",
    "                       var_type='int',\n",
    "                       distribution='exp',\n",
    "                       N_min = 2,\n",
    "                       N_max = 50,\n",
    "                       alpha=alpha)\n",
    "\n",
    "# spans different magnitude scales, use logaritmic distribution for invariance of scale\n",
    "lr_P_dict = dict(discrete=False,\n",
    "                var_type='float',\n",
    "                distribution='log',\n",
    "                x_min = 1e-3,\n",
    "                x_max = 1e-1)\n",
    "\n",
    "# same thing here\n",
    "penalty_P_dict = dict(discrete=False,\n",
    "                    var_type='float',\n",
    "                    distribution='log',\n",
    "                    x_min = 1e-4,\n",
    "                    x_max = 1e-2)\n",
    "\n",
    "# acts on the number of neurons in a linear way, use uniform distribution\n",
    "dropout_P_dict = dict(discrete=False,\n",
    "                     var_type = 'float',\n",
    "                     distribution='uniform',\n",
    "                     x_min = 0,\n",
    "                     x_max = 0.25)\n",
    "\n",
    "# use custom distribution to encode my personal beliefs on their performances BEFORE testing them in depth\n",
    "optimizer_P_dict = dict(discrete=True,\n",
    "                             var_type = 'str',\n",
    "                             distribution='custom',\n",
    "                             elements=np.array([optim.AdamW, optim.Adam, optim.Adamax, optim.Adagrad]),\n",
    "                             p = np.array([0.2,0.35,0.3,0.15]))\n",
    "\n",
    "# use custom distribution to encode my personal beliefs on their performances BEFORE testing them in depth\n",
    "activation_P_dict = dict(discrete=True,\n",
    "                         var_type = 'str',\n",
    "                         distribution='custom',\n",
    "                         elements=np.array([F.relu,F.leaky_relu]),\n",
    "                         p = np.array([0.65,0.35]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_dict = dict(lr=lr_P_dict, \n",
    "              n_layers=n_layers_P_dict, \n",
    "              penalty=penalty_P_dict, \n",
    "              dropout=dropout_P_dict, \n",
    "              optimizer=optimizer_P_dict,\n",
    "              act=activation_P_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "for key in P_dict.keys():\n",
    "    P = prior_distr(**P_dict[key])\n",
    "    if key == 'n_layers':\n",
    "        n_layers= P.sample(n_samples)\n",
    "        N_neurons_samples = sample_neurons(n_samples, n_layers)\n",
    "        params['h_sizes'] = N_neurons_samples \n",
    "    else:\n",
    "        params[key] = P.sample(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we make a list of dictionary instead of a dictionary of lists and we also add the last constant parameters\n",
    "list_of_dict = []\n",
    "for i in range(n_samples):\n",
    "    d = {'out_size' : 10, 'n_epochs' : 10, 'loss' : torch.nn.CrossEntropyLoss()}\n",
    "    for key in params.keys():\n",
    "        d[key] = params[key][i]\n",
    "    list_of_dict.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual HP search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations:  100\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0063290710465702315\n",
      "h_sizes \t [784, 193, 47]\n",
      "penalty \t 0.00054501486842488\n",
      "dropout \t 0.0600620255163796\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.07876487674635525\n",
      "h_sizes \t [784, 272, 97, 32]\n",
      "penalty \t 0.00010589027861164808\n",
      "dropout \t 0.016448012582696653\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.07280829677046517\n",
      "h_sizes \t [784, 183, 54]\n",
      "penalty \t 0.0023929898527572453\n",
      "dropout \t 0.021751298533804198\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.027121855278143318\n",
      "h_sizes \t [784, 259, 86, 22]\n",
      "penalty \t 0.00022550368094401138\n",
      "dropout \t 0.20849422658404124\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004560551568027305\n",
      "h_sizes \t [784, 258, 92, 29]\n",
      "penalty \t 0.0027556795585062946\n",
      "dropout \t 0.21029238875784556\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0037398524799022105\n",
      "h_sizes \t [784, 307, 130, 60, 26]\n",
      "penalty \t 0.0016077997957414404\n",
      "dropout \t 0.23788002461066338\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0012161665526734605\n",
      "h_sizes \t [784, 430, 215, 119, 55, 27, 16]\n",
      "penalty \t 0.00533975405394582\n",
      "dropout \t 0.050378974425766915\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.013252832186481892\n",
      "h_sizes \t [784, 175, 33]\n",
      "penalty \t 0.0005422381313207656\n",
      "dropout \t 0.13115317768274828\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.013197369641298126\n",
      "h_sizes \t [784, 184, 46]\n",
      "penalty \t 0.00882570540281893\n",
      "dropout \t 0.05629817477165783\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.010401984849280876\n",
      "h_sizes \t [784, 459, 265, 152, 82, 47, 28, 20]\n",
      "penalty \t 0.006529292459372847\n",
      "dropout \t 0.04626426259449612\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0014033260130125094\n",
      "h_sizes \t [784, 286, 113, 42]\n",
      "penalty \t 0.0016954936580884127\n",
      "dropout \t 0.19313974322665312\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.05177376075122143\n",
      "h_sizes \t [784, 405, 205, 113, 66, 36, 19]\n",
      "penalty \t 0.00017096119660620215\n",
      "dropout \t 0.2040835165118251\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003594704024602325\n",
      "h_sizes \t [784, 179, 44]\n",
      "penalty \t 0.0004525864138211596\n",
      "dropout \t 0.231863786929471\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005498858698310429\n",
      "h_sizes \t [784, 270, 91, 32]\n",
      "penalty \t 0.0027221618405975406\n",
      "dropout \t 0.0363923228903284\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.02698379740732466\n",
      "h_sizes \t [784, 178, 46]\n",
      "penalty \t 0.004939537382417476\n",
      "dropout \t 0.021164589819529483\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0015072642652618684\n",
      "h_sizes \t [784, 303, 121, 39]\n",
      "penalty \t 0.0006237138521426357\n",
      "dropout \t 0.11115645654099982\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.014024617714610348\n",
      "h_sizes \t [784, 193, 54]\n",
      "penalty \t 0.00022010120015451793\n",
      "dropout \t 0.2019471603667569\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0032657150226928465\n",
      "h_sizes \t [784, 325, 148, 62, 28]\n",
      "penalty \t 0.006332655921391879\n",
      "dropout \t 0.11990937584513675\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003821408390219275\n",
      "h_sizes \t [784, 259, 88, 27]\n",
      "penalty \t 0.008203127333894325\n",
      "dropout \t 0.11429272682659153\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.007375800323906414\n",
      "h_sizes \t [784, 421, 238, 127, 75, 37, 17]\n",
      "penalty \t 0.0037562322404048622\n",
      "dropout \t 0.18797497722505432\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.03314864166069542\n",
      "h_sizes \t [784, 182, 45]\n",
      "penalty \t 0.00017595780838687398\n",
      "dropout \t 0.10443033798939028\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.024831518494088125\n",
      "h_sizes \t [784, 468, 288, 177, 110, 67, 53, 35, 19]\n",
      "penalty \t 0.00036120597610595965\n",
      "dropout \t 0.20578308659606792\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0037375582245386184\n",
      "h_sizes \t [784, 430, 219, 111, 52, 28, 14]\n",
      "penalty \t 0.002117449362733656\n",
      "dropout \t 0.024118614685061796\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.012272312085380009\n",
      "h_sizes \t [784, 263, 94, 30]\n",
      "penalty \t 0.00043829047995163636\n",
      "dropout \t 0.19739333582312293\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.06723057572401742\n",
      "h_sizes \t [784, 267, 91, 27]\n",
      "penalty \t 0.00393595620696589\n",
      "dropout \t 0.015304053870720952\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.06479253665954669\n",
      "h_sizes \t [784, 339, 138, 61, 25]\n",
      "penalty \t 0.0007461037497009363\n",
      "dropout \t 0.022221661748620586\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0022685081965030263\n",
      "h_sizes \t [784, 175, 44]\n",
      "penalty \t 0.0007358991309055099\n",
      "dropout \t 0.06944058101777792\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.08757971625802691\n",
      "h_sizes \t [784, 337, 133, 63, 27]\n",
      "penalty \t 0.0016404753846861236\n",
      "dropout \t 0.1704594243661044\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005463180649674213\n",
      "h_sizes \t [784, 401, 178, 96, 47, 13]\n",
      "penalty \t 0.00038441639031711674\n",
      "dropout \t 0.19787745502231469\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.010632654292244742\n",
      "h_sizes \t [784, 546, 392, 283, 209, 147, 103, 67, 48, 32, 23, 17]\n",
      "penalty \t 0.0007470420122055038\n",
      "dropout \t 0.04179890660931143\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0069911336794631984\n",
      "h_sizes \t [784, 347, 137, 75, 38]\n",
      "penalty \t 0.0013936926163150459\n",
      "dropout \t 0.15706341389059042\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0021287263431801905\n",
      "h_sizes \t [784, 450, 255, 152, 88, 52, 34, 21]\n",
      "penalty \t 0.0003767441373445643\n",
      "dropout \t 0.08879184491684924\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003741655765113136\n",
      "h_sizes \t [784, 333, 153, 54, 20]\n",
      "penalty \t 0.0016537518033419882\n",
      "dropout \t 0.14829619534702204\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.025457731517690266\n",
      "h_sizes \t [784, 183, 30]\n",
      "penalty \t 0.002755013287716881\n",
      "dropout \t 0.1501461702043529\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0032995417282049846\n",
      "h_sizes \t [784, 197, 39]\n",
      "penalty \t 0.0010151013795989521\n",
      "dropout \t 0.12506344595368327\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004504684081232467\n",
      "h_sizes \t [784, 186, 42]\n",
      "penalty \t 0.0012362445175824873\n",
      "dropout \t 0.007205433363865726\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0013932052244325511\n",
      "h_sizes \t [784, 511, 351, 239, 167, 119, 90, 64, 41, 30, 21]\n",
      "penalty \t 0.0006291177690433944\n",
      "dropout \t 0.09223801249857536\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.029307138561685975\n",
      "h_sizes \t [784, 510, 342, 228, 150, 102, 67, 44, 30, 20, 11]\n",
      "penalty \t 0.0010636771090013963\n",
      "dropout \t 0.024510586706943338\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.07989313039520105\n",
      "h_sizes \t [784, 335, 153, 56, 28]\n",
      "penalty \t 0.0002574505377671439\n",
      "dropout \t 0.041814844211557706\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.04803514391905041\n",
      "h_sizes \t [784, 192, 47]\n",
      "penalty \t 0.0004257497161773112\n",
      "dropout \t 0.1260080804874128\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.011556485370558839\n",
      "h_sizes \t [784, 345, 137, 59, 27]\n",
      "penalty \t 0.0056089614308257995\n",
      "dropout \t 0.055375331457938576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.023619406971909812\n",
      "h_sizes \t [784, 274, 94, 37]\n",
      "penalty \t 0.001479273982522288\n",
      "dropout \t 0.24512489943438218\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.010775198163807087\n",
      "h_sizes \t [784, 304, 139, 57, 24]\n",
      "penalty \t 0.00405721974217973\n",
      "dropout \t 0.00010730503789690982\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.001635176252047257\n",
      "h_sizes \t [784, 193, 47]\n",
      "penalty \t 0.00019633309036954866\n",
      "dropout \t 0.0015152021977760666\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.051568221454798176\n",
      "h_sizes \t [784, 433, 214, 117, 57, 33, 18]\n",
      "penalty \t 0.0011448632640503613\n",
      "dropout \t 0.0027434773820436686\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.019924549276729427\n",
      "h_sizes \t [784, 195, 39]\n",
      "penalty \t 0.0005329682713549593\n",
      "dropout \t 0.035150887278989545\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.05215110649264988\n",
      "h_sizes \t [784, 187, 39]\n",
      "penalty \t 0.000823299943953609\n",
      "dropout \t 0.24151906255207303\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002738006756293353\n",
      "h_sizes \t [784, 359, 173, 81, 40, 12]\n",
      "penalty \t 0.00012562630368413155\n",
      "dropout \t 0.11993636262909585\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.028660208258474564\n",
      "h_sizes \t [784, 260, 90, 22]\n",
      "penalty \t 0.00034786273066751943\n",
      "dropout \t 0.06280119239803944\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0012868819504405363\n",
      "h_sizes \t [784, 196, 45]\n",
      "penalty \t 0.007622722881057016\n",
      "dropout \t 0.15528939591430263\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.08293585215254763\n",
      "h_sizes \t [784, 243, 77, 24]\n",
      "penalty \t 0.0067654299237902464\n",
      "dropout \t 0.1704427090684666\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.02408867561976459\n",
      "h_sizes \t [784, 536, 361, 245, 163, 109, 72, 48, 30, 16, 6]\n",
      "penalty \t 0.0002385632785467408\n",
      "dropout \t 0.03274539494544193\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.018530861530015867\n",
      "h_sizes \t [784, 184, 42]\n",
      "penalty \t 0.0002273396633902985\n",
      "dropout \t 0.045489897069608515\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00832535814576171\n",
      "h_sizes \t [784, 277, 102, 42]\n",
      "penalty \t 0.008361853977780893\n",
      "dropout \t 0.18445865828079366\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.02198551312074487\n",
      "h_sizes \t [784, 326, 143, 56, 24]\n",
      "penalty \t 0.0008554686653340579\n",
      "dropout \t 0.14885943020590423\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0021422450455047086\n",
      "h_sizes \t [784, 186, 35]\n",
      "penalty \t 0.0008060169352221008\n",
      "dropout \t 0.1824585453898257\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0027916068503331527\n",
      "h_sizes \t [784, 198, 44]\n",
      "penalty \t 0.0007188550564236634\n",
      "dropout \t 0.08257223213831072\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0011689952044494595\n",
      "h_sizes \t [784, 193, 50]\n",
      "penalty \t 0.000132336553776008\n",
      "dropout \t 0.07809963019141042\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.02732593305277972\n",
      "h_sizes \t [784, 278, 100, 39]\n",
      "penalty \t 0.0014455825401777954\n",
      "dropout \t 0.03538387763815615\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.024705431497769364\n",
      "h_sizes \t [784, 513, 332, 192, 109, 76, 51, 33, 17, 12]\n",
      "penalty \t 0.0077311463166655735\n",
      "dropout \t 0.14665653202738396\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.05109488264187131\n",
      "h_sizes \t [784, 342, 145, 61, 25]\n",
      "penalty \t 0.0002808154016195489\n",
      "dropout \t 0.16838520513594574\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.029287638420366868\n",
      "h_sizes \t [784, 376, 178, 75, 43, 25]\n",
      "penalty \t 0.00043440603957187017\n",
      "dropout \t 0.04314147063796506\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0012985192830829973\n",
      "h_sizes \t [784, 286, 92, 31]\n",
      "penalty \t 0.0013038960917419018\n",
      "dropout \t 0.20171874231851802\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.021018873037980793\n",
      "h_sizes \t [784, 271, 93, 34]\n",
      "penalty \t 0.001095996666790129\n",
      "dropout \t 0.2278369253463069\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.007911234094433662\n",
      "h_sizes \t [784, 414, 221, 111, 52, 30, 14]\n",
      "penalty \t 0.002987934642494971\n",
      "dropout \t 0.23892697450806277\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008356840227188436\n",
      "h_sizes \t [784, 203, 47]\n",
      "penalty \t 0.003585294788687961\n",
      "dropout \t 0.24830568165062988\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.03224408973474611\n",
      "h_sizes \t [784, 175, 49]\n",
      "penalty \t 0.0004022943536542634\n",
      "dropout \t 0.22347396781393866\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00296977292858642\n",
      "h_sizes \t [784, 245, 97, 41]\n",
      "penalty \t 0.00015330974177846243\n",
      "dropout \t 0.02261601854249423\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.010097895651643055\n",
      "h_sizes \t [784, 189, 46]\n",
      "penalty \t 0.00023720847203241894\n",
      "dropout \t 0.24448304630005188\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.06094350943284017\n",
      "h_sizes \t [784, 458, 295, 195, 116, 72, 50, 35, 20]\n",
      "penalty \t 0.0044331221754760645\n",
      "dropout \t 0.10719572320826204\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.04678695060081313\n",
      "h_sizes \t [784, 484, 313, 195, 123, 80, 53, 32, 18]\n",
      "penalty \t 0.0003255073284435559\n",
      "dropout \t 0.2368514146190828\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0023764453665107046\n",
      "h_sizes \t [784, 278, 91, 31]\n",
      "penalty \t 0.000981127168384203\n",
      "dropout \t 0.13886607330466164\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.020774002849792864\n",
      "h_sizes \t [784, 302, 134, 47, 17]\n",
      "penalty \t 0.0003726170595747665\n",
      "dropout \t 0.07358155810835007\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004129343894066938\n",
      "h_sizes \t [784, 177, 43]\n",
      "penalty \t 0.005218274945274288\n",
      "dropout \t 0.2207080198359869\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.07853705839303185\n",
      "h_sizes \t [784, 504, 312, 208, 133, 93, 59, 42, 26, 17]\n",
      "penalty \t 0.00047760923871105357\n",
      "dropout \t 0.016873261959553826\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004401044327699978\n",
      "h_sizes \t [784, 267, 92, 22]\n",
      "penalty \t 0.00041651596897831345\n",
      "dropout \t 0.12530264604839508\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.038045634720108634\n",
      "h_sizes \t [784, 277, 94, 35]\n",
      "penalty \t 0.00017712273430963007\n",
      "dropout \t 0.03844956767307764\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0017561803613412098\n",
      "h_sizes \t [784, 352, 139, 52, 19]\n",
      "penalty \t 0.00039666081878683983\n",
      "dropout \t 0.10031320460877713\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0050774238043958956\n",
      "h_sizes \t [784, 497, 333, 223, 142, 98, 56, 39, 24, 19]\n",
      "penalty \t 0.007591300999242725\n",
      "dropout \t 0.10661305367710183\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0052709222854375555\n",
      "h_sizes \t [784, 539, 361, 237, 164, 108, 69, 48, 38, 25, 18]\n",
      "penalty \t 0.0016777975017644954\n",
      "dropout \t 0.02461036415449397\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.06627875953395775\n",
      "h_sizes \t [784, 567, 414, 313, 211, 152, 110, 80, 63, 41, 26, 20, 15]\n",
      "penalty \t 0.008042615459276023\n",
      "dropout \t 0.07655014584025518\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0012714733011444605\n",
      "h_sizes \t [784, 244, 73, 26]\n",
      "penalty \t 0.001713893298855269\n",
      "dropout \t 0.016934535845452653\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.01440920056199898\n",
      "h_sizes \t [784, 394, 212, 116, 71, 34, 17]\n",
      "penalty \t 0.0001137037998456522\n",
      "dropout \t 0.03412852826201293\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.007102334544449898\n",
      "h_sizes \t [784, 260, 85, 24]\n",
      "penalty \t 0.008502319368887819\n",
      "dropout \t 0.12822088041935495\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0011391398286245316\n",
      "h_sizes \t [784, 199, 51]\n",
      "penalty \t 0.00010261473403120613\n",
      "dropout \t 0.2490087834704026\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.046946892916355225\n",
      "h_sizes \t [784, 271, 91, 24]\n",
      "penalty \t 0.00014291155046154566\n",
      "dropout \t 0.21687360000070438\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.028228750676287287\n",
      "h_sizes \t [784, 265, 86, 28]\n",
      "penalty \t 0.0070729965375289595\n",
      "dropout \t 0.1800033267365161\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0017339394488245722\n",
      "h_sizes \t [784, 258, 102, 33]\n",
      "penalty \t 0.00020289231593628796\n",
      "dropout \t 0.06498763109567998\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.07002218093578078\n",
      "h_sizes \t [784, 265, 88, 32]\n",
      "penalty \t 0.00020719139943243555\n",
      "dropout \t 0.17312047679031223\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.05280599623611874\n",
      "h_sizes \t [784, 334, 141, 45, 16]\n",
      "penalty \t 0.0066175357066091895\n",
      "dropout \t 0.17253799926580854\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0038624315184015295\n",
      "h_sizes \t [784, 380, 184, 88, 40, 20]\n",
      "penalty \t 0.00012956057793722043\n",
      "dropout \t 1.054559712440617e-05\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.007003761640517866\n",
      "h_sizes \t [784, 182, 46]\n",
      "penalty \t 0.00039049826545493004\n",
      "dropout \t 0.18885246027478317\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.09925811684379246\n",
      "h_sizes \t [784, 172, 41]\n",
      "penalty \t 0.004059969509368143\n",
      "dropout \t 0.10349644510407358\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002927020939018547\n",
      "h_sizes \t [784, 334, 143, 54, 17]\n",
      "penalty \t 0.0025034804225486647\n",
      "dropout \t 0.07907552243823002\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.05715485829844656\n",
      "h_sizes \t [784, 191, 50]\n",
      "penalty \t 0.003621845053393744\n",
      "dropout \t 0.026030328043574524\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.06751393376714074\n",
      "h_sizes \t [784, 536, 364, 250, 176, 122, 95, 70, 50, 39, 27, 17]\n",
      "penalty \t 0.0001651487072777321\n",
      "dropout \t 0.2396328141209408\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.018052581152210583\n",
      "h_sizes \t [784, 274, 101, 33]\n",
      "penalty \t 0.0005598991518943194\n",
      "dropout \t 0.1875503947468227\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0019497130420817875\n",
      "h_sizes \t [784, 456, 248, 143, 86, 50, 29, 21]\n",
      "penalty \t 0.0004311325884649133\n",
      "dropout \t 0.006901273702664523\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.017747928705121752\n",
      "h_sizes \t [784, 323, 126, 59, 30]\n",
      "penalty \t 0.002256007969370328\n",
      "dropout \t 0.1867472496037631\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004708918432683523\n",
      "h_sizes \t [784, 189, 49]\n",
      "penalty \t 0.0031423858284781903\n",
      "dropout \t 0.062829110179135\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of combinations: \", len(list_of_dict))\n",
    "\n",
    "flag = True #set to True to see all combinations\n",
    "if flag == True:\n",
    "    for params in list_of_dict:\n",
    "        print()\n",
    "        print_parameters(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.490 took: 3.53s  Val. loss: 0.293  Val. score: 91.738%\n",
      "Epoch 2, 100% \t Train loss: 0.273 took: 3.86s  Val. loss: 0.239  Val. score: 92.974%\n",
      "Epoch 3, 100% \t Train loss: 0.231 took: 3.61s  Val. loss: 0.213  Val. score: 93.790%\n",
      "Epoch 4, 100% \t Train loss: 0.206 took: 3.38s  Val. loss: 0.196  Val. score: 94.360%\n",
      "Epoch 5, 100% \t Train loss: 0.189 took: 3.54s  Val. loss: 0.186  Val. score: 94.606%\n",
      "Epoch 6, 100% \t Train loss: 0.177 took: 3.45s  Val. loss: 0.182  Val. score: 94.648%\n",
      "Epoch 7, 100% \t Train loss: 0.166 took: 3.37s  Val. loss: 0.171  Val. score: 95.086%\n",
      "Epoch 8, 100% \t Train loss: 0.156 took: 3.55s  Val. loss: 0.162  Val. score: 95.164%\n",
      "Epoch 9, 100% \t Train loss: 0.150 took: 3.30s  Val. loss: 0.156  Val. score: 95.320%\n",
      "Epoch 10, 100% \t Train loss: 0.141 took: 3.64s  Val. loss: 0.153  Val. score: 95.458%\n",
      "Training finished, took 67.391s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.474 took: 3.56s  Val. loss: 0.280  Val. score: 91.900%\n",
      "Epoch 2, 100% \t Train loss: 0.272 took: 3.41s  Val. loss: 0.236  Val. score: 92.998%\n",
      "Epoch 3, 100% \t Train loss: 0.231 took: 3.59s  Val. loss: 0.213  Val. score: 93.640%\n",
      "Epoch 4, 100% \t Train loss: 0.207 took: 3.59s  Val. loss: 0.193  Val. score: 94.402%\n",
      "Epoch 5, 100% \t Train loss: 0.190 took: 3.62s  Val. loss: 0.184  Val. score: 94.732%\n",
      "Epoch 6, 100% \t Train loss: 0.178 took: 3.62s  Val. loss: 0.171  Val. score: 95.020%\n",
      "Epoch 7, 100% \t Train loss: 0.164 took: 3.64s  Val. loss: 0.166  Val. score: 95.188%\n",
      "Epoch 8, 100% \t Train loss: 0.153 took: 3.62s  Val. loss: 0.157  Val. score: 95.380%\n",
      "Epoch 9, 100% \t Train loss: 0.149 took: 3.45s  Val. loss: 0.154  Val. score: 95.518%\n",
      "Epoch 10, 100% \t Train loss: 0.140 took: 3.62s  Val. loss: 0.149  Val. score: 95.620%\n",
      "Training finished, took 66.718s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.486 took: 3.47s  Val. loss: 0.292  Val. score: 92.008%\n",
      "Epoch 2, 100% \t Train loss: 0.280 took: 3.33s  Val. loss: 0.241  Val. score: 93.184%\n",
      "Epoch 3, 100% \t Train loss: 0.237 took: 3.59s  Val. loss: 0.214  Val. score: 93.916%\n",
      "Epoch 4, 100% \t Train loss: 0.210 took: 3.60s  Val. loss: 0.195  Val. score: 94.426%\n",
      "Epoch 5, 100% \t Train loss: 0.191 took: 3.33s  Val. loss: 0.185  Val. score: 94.594%\n",
      "Epoch 6, 100% \t Train loss: 0.179 took: 3.56s  Val. loss: 0.175  Val. score: 94.864%\n",
      "Epoch 7, 100% \t Train loss: 0.168 took: 3.41s  Val. loss: 0.167  Val. score: 95.116%\n",
      "Epoch 8, 100% \t Train loss: 0.158 took: 3.59s  Val. loss: 0.160  Val. score: 95.254%\n",
      "Epoch 9, 100% \t Train loss: 0.150 took: 3.65s  Val. loss: 0.156  Val. score: 95.428%\n",
      "Epoch 10, 100% \t Train loss: 0.143 took: 3.53s  Val. loss: 0.151  Val. score: 95.548%\n",
      "Training finished, took 66.187s\n",
      "\n",
      "Parameters configuration 1 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0063290710465702315\n",
      "h_sizes \t [784, 193, 47]\n",
      "penalty \t 0.00054501486842488\n",
      "dropout \t 0.0600620255163796\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 95.5418 +/- 0.0663\n",
      "Time for evaluation: 201.4 s\n",
      "Estimated time to finish : 5.54 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.399 took: 4.80s  Val. loss: 0.900  Val. score: 69.033%\n",
      "Epoch 2, 100% \t Train loss: 0.995 took: 4.71s  Val. loss: 0.920  Val. score: 68.697%\n",
      "Epoch 3, 100% \t Train loss: 1.007 took: 6.15s  Val. loss: 0.849  Val. score: 71.583%\n",
      "Epoch 4, 100% \t Train loss: 0.981 took: 7.91s  Val. loss: 0.926  Val. score: 69.627%\n",
      "Epoch 5, 100% \t Train loss: 0.984 took: 7.52s  Val. loss: 0.978  Val. score: 64.623%\n",
      "Epoch 6, 100% \t Train loss: 1.018 took: 7.50s  Val. loss: 1.055  Val. score: 66.393%\n",
      "Epoch 7, 100% \t Train loss: 1.158 took: 7.59s  Val. loss: 1.088  Val. score: 59.474%\n",
      "Epoch 8, 100% \t Train loss: 1.104 took: 7.11s  Val. loss: 1.028  Val. score: 63.549%\n",
      "Epoch 9, 100% \t Train loss: 1.060 took: 7.11s  Val. loss: 1.028  Val. score: 58.700%\n",
      "Epoch 10, 100% \t Train loss: 1.203 took: 7.21s  Val. loss: 0.974  Val. score: 65.313%\n",
      "Training finished, took 103.498s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.019 took: 4.63s  Val. loss: 1.718  Val. score: 28.831%\n",
      "Epoch 2, 100% \t Train loss: 1.606 took: 4.84s  Val. loss: 1.583  Val. score: 35.167%\n",
      "Epoch 3, 100% \t Train loss: 1.587 took: 5.79s  Val. loss: 1.544  Val. score: 33.607%\n",
      "Epoch 4, 100% \t Train loss: 1.585 took: 7.61s  Val. loss: 1.536  Val. score: 36.019%\n",
      "Epoch 5, 100% \t Train loss: 1.553 took: 7.47s  Val. loss: 1.561  Val. score: 32.383%\n",
      "Epoch 6, 100% \t Train loss: 1.574 took: 7.64s  Val. loss: 1.502  Val. score: 33.949%\n",
      "Epoch 7, 100% \t Train loss: 1.582 took: 7.20s  Val. loss: 1.617  Val. score: 34.441%\n",
      "Epoch 8, 100% \t Train loss: 1.600 took: 7.64s  Val. loss: 1.551  Val. score: 34.369%\n",
      "Epoch 9, 100% \t Train loss: 1.555 took: 7.45s  Val. loss: 1.482  Val. score: 37.381%\n",
      "Epoch 10, 100% \t Train loss: 1.535 took: 7.12s  Val. loss: 1.588  Val. score: 31.009%\n",
      "Training finished, took 102.150s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.503 took: 4.63s  Val. loss: 2.308  Val. score: 11.280%\n",
      "Epoch 2, 100% \t Train loss: 2.309 took: 5.11s  Val. loss: 2.303  Val. score: 11.280%\n",
      "Epoch 3, 100% \t Train loss: 2.306 took: 5.76s  Val. loss: 2.306  Val. score: 9.708%\n",
      "Epoch 4, 100% \t Train loss: 2.306 took: 8.04s  Val. loss: 2.305  Val. score: 9.708%\n",
      "Epoch 5, 100% \t Train loss: 2.306 took: 7.54s  Val. loss: 2.305  Val. score: 11.280%\n",
      "Epoch 6, 100% \t Train loss: 2.305 took: 7.57s  Val. loss: 2.306  Val. score: 10.434%\n",
      "Epoch 7, 100% \t Train loss: 2.306 took: 7.31s  Val. loss: 2.304  Val. score: 10.098%\n",
      "Epoch 8, 100% \t Train loss: 2.305 took: 7.59s  Val. loss: 2.307  Val. score: 9.708%\n",
      "Epoch 9, 100% \t Train loss: 2.305 took: 7.11s  Val. loss: 2.305  Val. score: 9.774%\n",
      "Epoch 10, 100% \t Train loss: 2.306 took: 7.56s  Val. loss: 2.305  Val. score: 11.280%\n",
      "Training finished, took 103.077s\n",
      "\n",
      "Parameters configuration 2 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.07876487674635525\n",
      "h_sizes \t [784, 272, 97, 32]\n",
      "penalty \t 0.00010589027861164808\n",
      "dropout \t 0.016448012582696653\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 35.8674 +/- 22.3244\n",
      "Time for evaluation: 309.8 s\n",
      "Estimated time to finish : 6.96 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.533 took: 3.46s  Val. loss: 0.229  Val. score: 92.890%\n",
      "Epoch 2, 100% \t Train loss: 0.174 took: 3.35s  Val. loss: 0.158  Val. score: 95.296%\n",
      "Epoch 3, 100% \t Train loss: 0.133 took: 3.41s  Val. loss: 0.149  Val. score: 95.650%\n",
      "Epoch 4, 100% \t Train loss: 0.110 took: 3.39s  Val. loss: 0.133  Val. score: 96.064%\n",
      "Epoch 5, 100% \t Train loss: 0.095 took: 3.34s  Val. loss: 0.137  Val. score: 95.836%\n",
      "Epoch 6, 100% \t Train loss: 0.083 took: 3.41s  Val. loss: 0.130  Val. score: 96.088%\n",
      "Epoch 7, 100% \t Train loss: 0.075 took: 3.40s  Val. loss: 0.123  Val. score: 96.442%\n",
      "Epoch 8, 100% \t Train loss: 0.067 took: 3.33s  Val. loss: 0.131  Val. score: 96.220%\n",
      "Epoch 9, 100% \t Train loss: 0.061 took: 3.42s  Val. loss: 0.125  Val. score: 96.358%\n",
      "Epoch 10, 100% \t Train loss: 0.055 took: 3.54s  Val. loss: 0.116  Val. score: 96.688%\n",
      "Training finished, took 64.342s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.529 took: 3.12s  Val. loss: 0.204  Val. score: 94.042%\n",
      "Epoch 2, 100% \t Train loss: 0.170 took: 3.30s  Val. loss: 0.150  Val. score: 95.560%\n",
      "Epoch 3, 100% \t Train loss: 0.126 took: 3.43s  Val. loss: 0.127  Val. score: 96.184%\n",
      "Epoch 4, 100% \t Train loss: 0.097 took: 3.30s  Val. loss: 0.119  Val. score: 96.478%\n",
      "Epoch 5, 100% \t Train loss: 0.079 took: 3.47s  Val. loss: 0.112  Val. score: 96.652%\n",
      "Epoch 6, 100% \t Train loss: 0.065 took: 3.41s  Val. loss: 0.120  Val. score: 96.568%\n",
      "Epoch 7, 100% \t Train loss: 0.057 took: 3.16s  Val. loss: 0.124  Val. score: 96.544%\n",
      "Epoch 8, 100% \t Train loss: 0.047 took: 3.11s  Val. loss: 0.113  Val. score: 96.856%\n",
      "Epoch 9, 100% \t Train loss: 0.040 took: 3.13s  Val. loss: 0.114  Val. score: 96.910%\n",
      "Epoch 10, 100% \t Train loss: 0.035 took: 3.45s  Val. loss: 0.108  Val. score: 97.180%\n",
      "Training finished, took 63.071s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.499 took: 3.34s  Val. loss: 0.246  Val. score: 92.122%\n",
      "Epoch 2, 100% \t Train loss: 0.161 took: 3.39s  Val. loss: 0.144  Val. score: 95.620%\n",
      "Epoch 3, 100% \t Train loss: 0.117 took: 3.45s  Val. loss: 0.131  Val. score: 96.076%\n",
      "Epoch 4, 100% \t Train loss: 0.090 took: 3.42s  Val. loss: 0.124  Val. score: 96.244%\n",
      "Epoch 5, 100% \t Train loss: 0.072 took: 3.27s  Val. loss: 0.117  Val. score: 96.466%\n",
      "Epoch 6, 100% \t Train loss: 0.059 took: 3.23s  Val. loss: 0.120  Val. score: 96.556%\n",
      "Epoch 7, 100% \t Train loss: 0.051 took: 3.10s  Val. loss: 0.111  Val. score: 96.736%\n",
      "Epoch 8, 100% \t Train loss: 0.042 took: 3.17s  Val. loss: 0.120  Val. score: 96.586%\n",
      "Epoch 9, 100% \t Train loss: 0.037 took: 3.27s  Val. loss: 0.111  Val. score: 96.874%\n",
      "Epoch 10, 100% \t Train loss: 0.033 took: 3.32s  Val. loss: 0.110  Val. score: 96.946%\n",
      "Training finished, took 63.259s\n",
      "\n",
      "Parameters configuration 3 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.07280829677046517\n",
      "h_sizes \t [784, 183, 54]\n",
      "penalty \t 0.0023929898527572453\n",
      "dropout \t 0.021751298533804198\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.9379 +/- 0.2009\n",
      "Time for evaluation: 191.8 s\n",
      "Estimated time to finish : 6.31 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.620 took: 5.41s  Val. loss: 0.248  Val. score: 93.082%\n",
      "Epoch 2, 100% \t Train loss: 0.294 took: 5.59s  Val. loss: 0.191  Val. score: 94.828%\n",
      "Epoch 3, 100% \t Train loss: 0.235 took: 5.60s  Val. loss: 0.171  Val. score: 95.434%\n",
      "Epoch 4, 100% \t Train loss: 0.213 took: 7.26s  Val. loss: 0.168  Val. score: 95.584%\n",
      "Epoch 5, 100% \t Train loss: 0.194 took: 6.74s  Val. loss: 0.169  Val. score: 95.602%\n",
      "Epoch 6, 100% \t Train loss: 0.174 took: 7.06s  Val. loss: 0.150  Val. score: 96.172%\n",
      "Epoch 7, 100% \t Train loss: 0.162 took: 7.12s  Val. loss: 0.161  Val. score: 96.148%\n",
      "Epoch 8, 100% \t Train loss: 0.152 took: 6.87s  Val. loss: 0.150  Val. score: 96.184%\n",
      "Epoch 9, 100% \t Train loss: 0.145 took: 7.26s  Val. loss: 0.149  Val. score: 96.238%\n",
      "Epoch 10, 100% \t Train loss: 0.132 took: 7.38s  Val. loss: 0.152  Val. score: 96.388%\n",
      "Training finished, took 100.894s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.574 took: 5.71s  Val. loss: 0.234  Val. score: 93.178%\n",
      "Epoch 2, 100% \t Train loss: 0.271 took: 5.45s  Val. loss: 0.191  Val. score: 94.498%\n",
      "Epoch 3, 100% \t Train loss: 0.227 took: 6.14s  Val. loss: 0.158  Val. score: 95.530%\n",
      "Epoch 4, 100% \t Train loss: 0.188 took: 6.82s  Val. loss: 0.155  Val. score: 95.926%\n",
      "Epoch 5, 100% \t Train loss: 0.172 took: 6.64s  Val. loss: 0.144  Val. score: 95.938%\n",
      "Epoch 6, 100% \t Train loss: 0.150 took: 6.96s  Val. loss: 0.140  Val. score: 96.514%\n",
      "Epoch 7, 100% \t Train loss: 0.136 took: 7.04s  Val. loss: 0.129  Val. score: 96.514%\n",
      "Epoch 8, 100% \t Train loss: 0.128 took: 7.06s  Val. loss: 0.131  Val. score: 96.688%\n",
      "Epoch 9, 100% \t Train loss: 0.118 took: 6.75s  Val. loss: 0.137  Val. score: 96.634%\n",
      "Epoch 10, 100% \t Train loss: 0.112 took: 6.95s  Val. loss: 0.124  Val. score: 96.898%\n",
      "Training finished, took 100.311s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.539 took: 5.21s  Val. loss: 0.188  Val. score: 94.792%\n",
      "Epoch 2, 100% \t Train loss: 0.253 took: 5.08s  Val. loss: 0.152  Val. score: 95.842%\n",
      "Epoch 3, 100% \t Train loss: 0.206 took: 6.09s  Val. loss: 0.130  Val. score: 96.466%\n",
      "Epoch 4, 100% \t Train loss: 0.176 took: 6.27s  Val. loss: 0.135  Val. score: 96.130%\n",
      "Epoch 5, 100% \t Train loss: 0.154 took: 6.31s  Val. loss: 0.111  Val. score: 96.952%\n",
      "Epoch 6, 100% \t Train loss: 0.137 took: 6.36s  Val. loss: 0.115  Val. score: 96.862%\n",
      "Epoch 7, 100% \t Train loss: 0.124 took: 6.26s  Val. loss: 0.130  Val. score: 96.754%\n",
      "Epoch 8, 100% \t Train loss: 0.115 took: 6.06s  Val. loss: 0.104  Val. score: 97.282%\n",
      "Epoch 9, 100% \t Train loss: 0.100 took: 6.53s  Val. loss: 0.130  Val. score: 96.982%\n",
      "Epoch 10, 100% \t Train loss: 0.097 took: 6.68s  Val. loss: 0.112  Val. score: 97.306%\n",
      "Training finished, took 95.829s\n",
      "\n",
      "Parameters configuration 4 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.027121855278143318\n",
      "h_sizes \t [784, 259, 86, 22]\n",
      "penalty \t 0.00022550368094401138\n",
      "dropout \t 0.20849422658404124\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.8639 +/- 0.3756\n",
      "Time for evaluation: 298.1 s\n",
      "Estimated time to finish : 6.67 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.487 took: 4.99s  Val. loss: 0.180  Val. score: 94.810%\n",
      "Epoch 2, 100% \t Train loss: 0.213 took: 5.19s  Val. loss: 0.153  Val. score: 95.860%\n",
      "Epoch 3, 100% \t Train loss: 0.173 took: 5.12s  Val. loss: 0.137  Val. score: 96.106%\n",
      "Epoch 4, 100% \t Train loss: 0.144 took: 5.70s  Val. loss: 0.135  Val. score: 96.640%\n",
      "Epoch 5, 100% \t Train loss: 0.130 took: 5.19s  Val. loss: 0.125  Val. score: 96.574%\n",
      "Epoch 6, 100% \t Train loss: 0.119 took: 5.16s  Val. loss: 0.114  Val. score: 96.928%\n",
      "Epoch 7, 100% \t Train loss: 0.103 took: 5.44s  Val. loss: 0.115  Val. score: 97.132%\n",
      "Epoch 8, 100% \t Train loss: 0.095 took: 5.59s  Val. loss: 0.124  Val. score: 97.114%\n",
      "Epoch 9, 100% \t Train loss: 0.097 took: 5.31s  Val. loss: 0.115  Val. score: 97.168%\n",
      "Epoch 10, 100% \t Train loss: 0.090 took: 5.24s  Val. loss: 0.121  Val. score: 96.970%\n",
      "Training finished, took 88.010s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.479 took: 5.35s  Val. loss: 0.185  Val. score: 94.600%\n",
      "Epoch 2, 100% \t Train loss: 0.214 took: 5.02s  Val. loss: 0.136  Val. score: 95.980%\n",
      "Epoch 3, 100% \t Train loss: 0.169 took: 4.95s  Val. loss: 0.119  Val. score: 96.640%\n",
      "Epoch 4, 100% \t Train loss: 0.142 took: 5.20s  Val. loss: 0.114  Val. score: 96.790%\n",
      "Epoch 5, 100% \t Train loss: 0.128 took: 5.20s  Val. loss: 0.128  Val. score: 96.244%\n",
      "Epoch 6, 100% \t Train loss: 0.110 took: 5.53s  Val. loss: 0.116  Val. score: 96.916%\n",
      "Epoch 7, 100% \t Train loss: 0.099 took: 5.23s  Val. loss: 0.106  Val. score: 97.306%\n",
      "Epoch 8, 100% \t Train loss: 0.104 took: 5.57s  Val. loss: 0.100  Val. score: 97.270%\n",
      "Epoch 9, 100% \t Train loss: 0.087 took: 5.61s  Val. loss: 0.104  Val. score: 97.360%\n",
      "Epoch 10, 100% \t Train loss: 0.086 took: 5.29s  Val. loss: 0.101  Val. score: 97.516%\n",
      "Training finished, took 88.328s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.467 took: 4.84s  Val. loss: 0.226  Val. score: 93.184%\n",
      "Epoch 2, 100% \t Train loss: 0.210 took: 5.18s  Val. loss: 0.166  Val. score: 95.182%\n",
      "Epoch 3, 100% \t Train loss: 0.171 took: 5.13s  Val. loss: 0.141  Val. score: 95.956%\n",
      "Epoch 4, 100% \t Train loss: 0.142 took: 5.27s  Val. loss: 0.145  Val. score: 96.010%\n",
      "Epoch 5, 100% \t Train loss: 0.126 took: 5.24s  Val. loss: 0.126  Val. score: 96.424%\n",
      "Epoch 6, 100% \t Train loss: 0.114 took: 5.76s  Val. loss: 0.112  Val. score: 96.904%\n",
      "Epoch 7, 100% \t Train loss: 0.108 took: 5.30s  Val. loss: 0.125  Val. score: 96.742%\n",
      "Epoch 8, 100% \t Train loss: 0.096 took: 5.30s  Val. loss: 0.125  Val. score: 97.042%\n",
      "Epoch 9, 100% \t Train loss: 0.093 took: 5.29s  Val. loss: 0.110  Val. score: 97.084%\n",
      "Epoch 10, 100% \t Train loss: 0.085 took: 5.44s  Val. loss: 0.127  Val. score: 96.970%\n",
      "Training finished, took 88.002s\n",
      "\n",
      "Parameters configuration 5 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004560551568027305\n",
      "h_sizes \t [784, 258, 92, 29]\n",
      "penalty \t 0.0027556795585062946\n",
      "dropout \t 0.21029238875784556\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.1519 +/- 0.2574\n",
      "Time for evaluation: 265.4 s\n",
      "Estimated time to finish : 6.68 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.831 took: 7.11s  Val. loss: 0.287  Val. score: 91.900%\n",
      "Epoch 2, 100% \t Train loss: 0.335 took: 6.83s  Val. loss: 0.200  Val. score: 94.222%\n",
      "Epoch 3, 100% \t Train loss: 0.247 took: 6.61s  Val. loss: 0.167  Val. score: 95.260%\n",
      "Epoch 4, 100% \t Train loss: 0.200 took: 6.62s  Val. loss: 0.146  Val. score: 95.956%\n",
      "Epoch 5, 100% \t Train loss: 0.172 took: 6.35s  Val. loss: 0.135  Val. score: 96.388%\n",
      "Epoch 6, 100% \t Train loss: 0.148 took: 6.84s  Val. loss: 0.119  Val. score: 96.898%\n",
      "Epoch 7, 100% \t Train loss: 0.132 took: 7.00s  Val. loss: 0.116  Val. score: 97.012%\n",
      "Epoch 8, 100% \t Train loss: 0.118 took: 7.21s  Val. loss: 0.112  Val. score: 97.162%\n",
      "Epoch 9, 100% \t Train loss: 0.105 took: 6.93s  Val. loss: 0.111  Val. score: 97.264%\n",
      "Epoch 10, 100% \t Train loss: 0.098 took: 6.80s  Val. loss: 0.106  Val. score: 97.402%\n",
      "Training finished, took 107.391s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.776 took: 6.68s  Val. loss: 0.289  Val. score: 91.726%\n",
      "Epoch 2, 100% \t Train loss: 0.338 took: 6.87s  Val. loss: 0.203  Val. score: 94.210%\n",
      "Epoch 3, 100% \t Train loss: 0.246 took: 6.72s  Val. loss: 0.163  Val. score: 95.482%\n",
      "Epoch 4, 100% \t Train loss: 0.198 took: 7.04s  Val. loss: 0.151  Val. score: 95.938%\n",
      "Epoch 5, 100% \t Train loss: 0.171 took: 6.34s  Val. loss: 0.136  Val. score: 96.460%\n",
      "Epoch 6, 100% \t Train loss: 0.145 took: 6.95s  Val. loss: 0.135  Val. score: 96.664%\n",
      "Epoch 7, 100% \t Train loss: 0.128 took: 7.20s  Val. loss: 0.126  Val. score: 96.904%\n",
      "Epoch 8, 100% \t Train loss: 0.118 took: 6.98s  Val. loss: 0.124  Val. score: 97.054%\n",
      "Epoch 9, 100% \t Train loss: 0.104 took: 6.32s  Val. loss: 0.120  Val. score: 96.988%\n",
      "Epoch 10, 100% \t Train loss: 0.092 took: 6.75s  Val. loss: 0.118  Val. score: 97.090%\n",
      "Training finished, took 106.449s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.822 took: 7.09s  Val. loss: 0.279  Val. score: 92.068%\n",
      "Epoch 2, 100% \t Train loss: 0.338 took: 6.61s  Val. loss: 0.207  Val. score: 94.084%\n",
      "Epoch 3, 100% \t Train loss: 0.247 took: 7.10s  Val. loss: 0.170  Val. score: 95.104%\n",
      "Epoch 4, 100% \t Train loss: 0.197 took: 6.94s  Val. loss: 0.148  Val. score: 95.944%\n",
      "Epoch 5, 100% \t Train loss: 0.170 took: 6.98s  Val. loss: 0.138  Val. score: 96.178%\n",
      "Epoch 6, 100% \t Train loss: 0.141 took: 7.03s  Val. loss: 0.127  Val. score: 96.664%\n",
      "Epoch 7, 100% \t Train loss: 0.130 took: 6.76s  Val. loss: 0.121  Val. score: 96.712%\n",
      "Epoch 8, 100% \t Train loss: 0.113 took: 6.34s  Val. loss: 0.116  Val. score: 97.012%\n",
      "Epoch 9, 100% \t Train loss: 0.105 took: 6.31s  Val. loss: 0.124  Val. score: 96.940%\n",
      "Epoch 10, 100% \t Train loss: 0.091 took: 6.47s  Val. loss: 0.116  Val. score: 97.228%\n",
      "Training finished, took 106.368s\n",
      "\n",
      "Parameters configuration 6 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0037398524799022105\n",
      "h_sizes \t [784, 307, 130, 60, 26]\n",
      "penalty \t 0.0016077997957414404\n",
      "dropout \t 0.23788002461066338\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.2399 +/- 0.1277\n",
      "Time for evaluation: 321.3 s\n",
      "Estimated time to finish : 6.91 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.196 took: 10.39s  Val. loss: 0.588  Val. score: 82.203%\n",
      "Epoch 2, 100% \t Train loss: 0.557 took: 9.77s  Val. loss: 0.359  Val. score: 89.974%\n",
      "Epoch 3, 100% \t Train loss: 0.367 took: 10.10s  Val. loss: 0.273  Val. score: 92.614%\n",
      "Epoch 4, 100% \t Train loss: 0.287 took: 11.22s  Val. loss: 0.238  Val. score: 93.448%\n",
      "Epoch 5, 100% \t Train loss: 0.225 took: 11.02s  Val. loss: 0.198  Val. score: 94.660%\n",
      "Epoch 6, 100% \t Train loss: 0.187 took: 11.14s  Val. loss: 0.179  Val. score: 95.272%\n",
      "Epoch 7, 100% \t Train loss: 0.159 took: 10.38s  Val. loss: 0.161  Val. score: 95.656%\n",
      "Epoch 8, 100% \t Train loss: 0.137 took: 10.52s  Val. loss: 0.158  Val. score: 95.830%\n",
      "Epoch 9, 100% \t Train loss: 0.121 took: 10.29s  Val. loss: 0.162  Val. score: 95.890%\n",
      "Epoch 10, 100% \t Train loss: 0.106 took: 10.39s  Val. loss: 0.149  Val. score: 96.280%\n",
      "Training finished, took 157.061s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.374 took: 10.30s  Val. loss: 0.665  Val. score: 80.937%\n",
      "Epoch 2, 100% \t Train loss: 0.636 took: 9.91s  Val. loss: 0.392  Val. score: 89.236%\n",
      "Epoch 3, 100% \t Train loss: 0.408 took: 10.80s  Val. loss: 0.266  Val. score: 92.800%\n",
      "Epoch 4, 100% \t Train loss: 0.300 took: 11.30s  Val. loss: 0.220  Val. score: 93.964%\n",
      "Epoch 5, 100% \t Train loss: 0.234 took: 11.36s  Val. loss: 0.184  Val. score: 94.954%\n",
      "Epoch 6, 100% \t Train loss: 0.193 took: 10.80s  Val. loss: 0.169  Val. score: 95.296%\n",
      "Epoch 7, 100% \t Train loss: 0.162 took: 10.99s  Val. loss: 0.150  Val. score: 96.076%\n",
      "Epoch 8, 100% \t Train loss: 0.137 took: 10.43s  Val. loss: 0.144  Val. score: 96.142%\n",
      "Epoch 9, 100% \t Train loss: 0.120 took: 10.30s  Val. loss: 0.135  Val. score: 96.442%\n",
      "Epoch 10, 100% \t Train loss: 0.102 took: 10.40s  Val. loss: 0.134  Val. score: 96.574%\n",
      "Training finished, took 159.029s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.314 took: 10.60s  Val. loss: 0.592  Val. score: 83.379%\n",
      "Epoch 2, 100% \t Train loss: 0.584 took: 10.72s  Val. loss: 0.371  Val. score: 89.578%\n",
      "Epoch 3, 100% \t Train loss: 0.397 took: 10.03s  Val. loss: 0.298  Val. score: 91.558%\n",
      "Epoch 4, 100% \t Train loss: 0.297 took: 10.67s  Val. loss: 0.224  Val. score: 93.604%\n",
      "Epoch 5, 100% \t Train loss: 0.240 took: 10.46s  Val. loss: 0.194  Val. score: 94.528%\n",
      "Epoch 6, 100% \t Train loss: 0.199 took: 10.26s  Val. loss: 0.182  Val. score: 94.840%\n",
      "Epoch 7, 100% \t Train loss: 0.171 took: 11.43s  Val. loss: 0.159  Val. score: 95.656%\n",
      "Epoch 8, 100% \t Train loss: 0.148 took: 10.91s  Val. loss: 0.152  Val. score: 95.914%\n",
      "Epoch 9, 100% \t Train loss: 0.129 took: 10.47s  Val. loss: 0.143  Val. score: 96.070%\n",
      "Epoch 10, 100% \t Train loss: 0.113 took: 11.12s  Val. loss: 0.139  Val. score: 96.292%\n",
      "Training finished, took 158.738s\n",
      "\n",
      "Parameters configuration 7 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0012161665526734605\n",
      "h_sizes \t [784, 430, 215, 119, 55, 27, 16]\n",
      "penalty \t 0.00533975405394582\n",
      "dropout \t 0.050378974425766915\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.3819 +/- 0.1359\n",
      "Time for evaluation: 475.9 s\n",
      "Estimated time to finish : 7.62 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.379 took: 3.33s  Val. loss: 0.183  Val. score: 94.768%\n",
      "Epoch 2, 100% \t Train loss: 0.216 took: 3.66s  Val. loss: 0.158  Val. score: 95.716%\n",
      "Epoch 3, 100% \t Train loss: 0.184 took: 3.56s  Val. loss: 0.145  Val. score: 95.992%\n",
      "Epoch 4, 100% \t Train loss: 0.165 took: 4.01s  Val. loss: 0.156  Val. score: 95.884%\n",
      "Epoch 5, 100% \t Train loss: 0.150 took: 3.94s  Val. loss: 0.141  Val. score: 95.962%\n",
      "Epoch 6, 100% \t Train loss: 0.137 took: 4.16s  Val. loss: 0.158  Val. score: 96.286%\n",
      "Epoch 7, 100% \t Train loss: 0.138 took: 4.11s  Val. loss: 0.136  Val. score: 96.598%\n",
      "Epoch 8, 100% \t Train loss: 0.128 took: 4.10s  Val. loss: 0.148  Val. score: 96.778%\n",
      "Epoch 9, 100% \t Train loss: 0.128 took: 4.10s  Val. loss: 0.165  Val. score: 96.160%\n",
      "Epoch 10, 100% \t Train loss: 0.142 took: 3.93s  Val. loss: 0.157  Val. score: 96.592%\n",
      "Training finished, took 68.291s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.366 took: 3.41s  Val. loss: 0.192  Val. score: 94.204%\n",
      "Epoch 2, 100% \t Train loss: 0.201 took: 3.58s  Val. loss: 0.184  Val. score: 94.930%\n",
      "Epoch 3, 100% \t Train loss: 0.175 took: 3.67s  Val. loss: 0.165  Val. score: 95.338%\n",
      "Epoch 4, 100% \t Train loss: 0.163 took: 3.95s  Val. loss: 0.178  Val. score: 95.548%\n",
      "Epoch 5, 100% \t Train loss: 0.139 took: 4.14s  Val. loss: 0.150  Val. score: 96.064%\n",
      "Epoch 6, 100% \t Train loss: 0.125 took: 4.09s  Val. loss: 0.174  Val. score: 95.422%\n",
      "Epoch 7, 100% \t Train loss: 0.147 took: 4.05s  Val. loss: 0.171  Val. score: 95.680%\n",
      "Epoch 8, 100% \t Train loss: 0.129 took: 4.09s  Val. loss: 0.171  Val. score: 95.920%\n",
      "Epoch 9, 100% \t Train loss: 0.132 took: 4.15s  Val. loss: 0.169  Val. score: 96.214%\n",
      "Epoch 10, 100% \t Train loss: 0.119 took: 3.80s  Val. loss: 0.179  Val. score: 96.040%\n",
      "Training finished, took 68.295s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.371 took: 3.50s  Val. loss: 0.183  Val. score: 94.228%\n",
      "Epoch 2, 100% \t Train loss: 0.211 took: 3.64s  Val. loss: 0.153  Val. score: 95.734%\n",
      "Epoch 3, 100% \t Train loss: 0.179 took: 3.73s  Val. loss: 0.168  Val. score: 95.368%\n",
      "Epoch 4, 100% \t Train loss: 0.164 took: 3.78s  Val. loss: 0.145  Val. score: 96.034%\n",
      "Epoch 5, 100% \t Train loss: 0.149 took: 4.05s  Val. loss: 0.169  Val. score: 95.740%\n",
      "Epoch 6, 100% \t Train loss: 0.145 took: 3.90s  Val. loss: 0.143  Val. score: 96.142%\n",
      "Epoch 7, 100% \t Train loss: 0.124 took: 4.05s  Val. loss: 0.169  Val. score: 96.064%\n",
      "Epoch 8, 100% \t Train loss: 0.120 took: 4.08s  Val. loss: 0.169  Val. score: 95.920%\n",
      "Epoch 9, 100% \t Train loss: 0.125 took: 3.79s  Val. loss: 0.165  Val. score: 96.124%\n",
      "Epoch 10, 100% \t Train loss: 0.134 took: 4.19s  Val. loss: 0.180  Val. score: 96.058%\n",
      "Training finished, took 68.138s\n",
      "\n",
      "Parameters configuration 8 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.013252832186481892\n",
      "h_sizes \t [784, 175, 33]\n",
      "penalty \t 0.0005422381313207656\n",
      "dropout \t 0.13115317768274828\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.2298 +/- 0.2561\n",
      "Time for evaluation: 205.8 s\n",
      "Estimated time to finish : 7.25 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.411 took: 3.15s  Val. loss: 0.214  Val. score: 93.784%\n",
      "Epoch 2, 100% \t Train loss: 0.206 took: 3.55s  Val. loss: 0.184  Val. score: 94.480%\n",
      "Epoch 3, 100% \t Train loss: 0.167 took: 3.55s  Val. loss: 0.150  Val. score: 95.596%\n",
      "Epoch 4, 100% \t Train loss: 0.143 took: 3.36s  Val. loss: 0.131  Val. score: 95.962%\n",
      "Epoch 5, 100% \t Train loss: 0.127 took: 3.12s  Val. loss: 0.124  Val. score: 96.058%\n",
      "Epoch 6, 100% \t Train loss: 0.114 took: 3.40s  Val. loss: 0.112  Val. score: 96.430%\n",
      "Epoch 7, 100% \t Train loss: 0.106 took: 3.49s  Val. loss: 0.109  Val. score: 96.616%\n",
      "Epoch 8, 100% \t Train loss: 0.095 took: 3.13s  Val. loss: 0.109  Val. score: 96.646%\n",
      "Epoch 9, 100% \t Train loss: 0.089 took: 3.48s  Val. loss: 0.106  Val. score: 96.718%\n",
      "Epoch 10, 100% \t Train loss: 0.083 took: 3.47s  Val. loss: 0.100  Val. score: 96.886%\n",
      "Training finished, took 64.156s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.399 took: 3.53s  Val. loss: 0.256  Val. score: 91.882%\n",
      "Epoch 2, 100% \t Train loss: 0.202 took: 3.20s  Val. loss: 0.170  Val. score: 94.822%\n",
      "Epoch 3, 100% \t Train loss: 0.161 took: 3.29s  Val. loss: 0.161  Val. score: 94.948%\n",
      "Epoch 4, 100% \t Train loss: 0.135 took: 3.18s  Val. loss: 0.133  Val. score: 95.878%\n",
      "Epoch 5, 100% \t Train loss: 0.119 took: 3.54s  Val. loss: 0.124  Val. score: 96.160%\n",
      "Epoch 6, 100% \t Train loss: 0.107 took: 3.50s  Val. loss: 0.118  Val. score: 96.298%\n",
      "Epoch 7, 100% \t Train loss: 0.098 took: 3.47s  Val. loss: 0.109  Val. score: 96.574%\n",
      "Epoch 8, 100% \t Train loss: 0.088 took: 3.27s  Val. loss: 0.106  Val. score: 96.772%\n",
      "Epoch 9, 100% \t Train loss: 0.082 took: 3.49s  Val. loss: 0.102  Val. score: 96.850%\n",
      "Epoch 10, 100% \t Train loss: 0.075 took: 3.24s  Val. loss: 0.100  Val. score: 96.958%\n",
      "Training finished, took 64.283s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.408 took: 3.33s  Val. loss: 0.239  Val. score: 93.184%\n",
      "Epoch 2, 100% \t Train loss: 0.195 took: 3.47s  Val. loss: 0.186  Val. score: 94.678%\n",
      "Epoch 3, 100% \t Train loss: 0.152 took: 3.46s  Val. loss: 0.164  Val. score: 95.062%\n",
      "Epoch 4, 100% \t Train loss: 0.131 took: 3.31s  Val. loss: 0.151  Val. score: 95.644%\n",
      "Epoch 5, 100% \t Train loss: 0.116 took: 3.42s  Val. loss: 0.138  Val. score: 95.962%\n",
      "Epoch 6, 100% \t Train loss: 0.103 took: 3.37s  Val. loss: 0.132  Val. score: 96.148%\n",
      "Epoch 7, 100% \t Train loss: 0.093 took: 3.14s  Val. loss: 0.126  Val. score: 96.352%\n",
      "Epoch 8, 100% \t Train loss: 0.085 took: 3.14s  Val. loss: 0.121  Val. score: 96.460%\n",
      "Epoch 9, 100% \t Train loss: 0.080 took: 3.31s  Val. loss: 0.118  Val. score: 96.568%\n",
      "Epoch 10, 100% \t Train loss: 0.072 took: 3.44s  Val. loss: 0.113  Val. score: 96.724%\n",
      "Training finished, took 63.857s\n",
      "\n",
      "Parameters configuration 9 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.013197369641298126\n",
      "h_sizes \t [784, 184, 46]\n",
      "penalty \t 0.00882570540281893\n",
      "dropout \t 0.05629817477165783\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.8559 +/- 0.0979\n",
      "Time for evaluation: 193.4 s\n",
      "Estimated time to finish : 6.92 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.162 took: 10.45s  Val. loss: 0.461  Val. score: 89.476%\n",
      "Epoch 2, 100% \t Train loss: 0.401 took: 9.70s  Val. loss: 0.299  Val. score: 93.238%\n",
      "Epoch 3, 100% \t Train loss: 0.282 took: 12.31s  Val. loss: 0.259  Val. score: 94.282%\n",
      "Epoch 4, 100% \t Train loss: 0.243 took: 15.06s  Val. loss: 0.240  Val. score: 94.678%\n",
      "Epoch 5, 100% \t Train loss: 0.233 took: 14.21s  Val. loss: 0.230  Val. score: 94.942%\n",
      "Epoch 6, 100% \t Train loss: 0.210 took: 14.85s  Val. loss: 0.237  Val. score: 95.368%\n",
      "Epoch 7, 100% \t Train loss: 0.203 took: 14.38s  Val. loss: 0.211  Val. score: 95.356%\n",
      "Epoch 8, 100% \t Train loss: 0.205 took: 14.62s  Val. loss: 0.207  Val. score: 95.320%\n",
      "Epoch 9, 100% \t Train loss: 0.189 took: 15.21s  Val. loss: 0.239  Val. score: 95.272%\n",
      "Epoch 10, 100% \t Train loss: 0.208 took: 15.22s  Val. loss: 0.238  Val. score: 95.260%\n",
      "Training finished, took 190.263s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.830 took: 9.96s  Val. loss: 0.373  Val. score: 90.376%\n",
      "Epoch 2, 100% \t Train loss: 0.334 took: 9.67s  Val. loss: 0.230  Val. score: 94.528%\n",
      "Epoch 3, 100% \t Train loss: 0.257 took: 11.31s  Val. loss: 0.246  Val. score: 93.832%\n",
      "Epoch 4, 100% \t Train loss: 0.240 took: 13.55s  Val. loss: 0.261  Val. score: 93.928%\n",
      "Epoch 5, 100% \t Train loss: 0.214 took: 13.52s  Val. loss: 0.244  Val. score: 95.242%\n",
      "Epoch 6, 100% \t Train loss: 0.207 took: 14.23s  Val. loss: 0.301  Val. score: 94.222%\n",
      "Epoch 7, 100% \t Train loss: 0.213 took: 14.93s  Val. loss: 0.273  Val. score: 95.110%\n",
      "Epoch 8, 100% \t Train loss: 0.228 took: 14.19s  Val. loss: 0.199  Val. score: 95.428%\n",
      "Epoch 9, 100% \t Train loss: 0.279 took: 14.88s  Val. loss: 0.266  Val. score: 94.582%\n",
      "Epoch 10, 100% \t Train loss: 0.269 took: 14.82s  Val. loss: 0.245  Val. score: 94.324%\n",
      "Training finished, took 185.624s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.035 took: 10.82s  Val. loss: 0.396  Val. score: 89.620%\n",
      "Epoch 2, 100% \t Train loss: 0.382 took: 10.82s  Val. loss: 0.297  Val. score: 92.248%\n",
      "Epoch 3, 100% \t Train loss: 0.294 took: 12.41s  Val. loss: 0.211  Val. score: 94.912%\n",
      "Epoch 4, 100% \t Train loss: 0.258 took: 13.83s  Val. loss: 0.222  Val. score: 94.672%\n",
      "Epoch 5, 100% \t Train loss: 0.219 took: 14.55s  Val. loss: 0.210  Val. score: 95.308%\n",
      "Epoch 6, 100% \t Train loss: 0.209 took: 14.77s  Val. loss: 0.220  Val. score: 95.290%\n",
      "Epoch 7, 100% \t Train loss: 0.189 took: 14.81s  Val. loss: 0.203  Val. score: 95.500%\n",
      "Epoch 8, 100% \t Train loss: 0.206 took: 14.74s  Val. loss: 0.219  Val. score: 95.188%\n",
      "Epoch 9, 100% \t Train loss: 0.198 took: 14.17s  Val. loss: 0.238  Val. score: 94.576%\n",
      "Epoch 10, 100% \t Train loss: 0.222 took: 15.20s  Val. loss: 0.216  Val. score: 95.062%\n",
      "Training finished, took 190.613s\n",
      "\n",
      "Parameters configuration 10 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.010401984849280876\n",
      "h_sizes \t [784, 459, 265, 152, 82, 47, 28, 20]\n",
      "penalty \t 0.006529292459372847\n",
      "dropout \t 0.04626426259449612\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 94.8818 +/- 0.4028\n",
      "Time for evaluation: 567.6 s\n",
      "Estimated time to finish : 7.58 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.568 took: 5.50s  Val. loss: 0.222  Val. score: 93.442%\n",
      "Epoch 2, 100% \t Train loss: 0.219 took: 5.23s  Val. loss: 0.151  Val. score: 95.428%\n",
      "Epoch 3, 100% \t Train loss: 0.159 took: 5.60s  Val. loss: 0.122  Val. score: 96.178%\n",
      "Epoch 4, 100% \t Train loss: 0.125 took: 5.99s  Val. loss: 0.105  Val. score: 96.892%\n",
      "Epoch 5, 100% \t Train loss: 0.103 took: 6.00s  Val. loss: 0.115  Val. score: 96.682%\n",
      "Epoch 6, 100% \t Train loss: 0.084 took: 5.76s  Val. loss: 0.104  Val. score: 97.102%\n",
      "Epoch 7, 100% \t Train loss: 0.074 took: 5.90s  Val. loss: 0.094  Val. score: 97.408%\n",
      "Epoch 8, 100% \t Train loss: 0.065 took: 5.69s  Val. loss: 0.096  Val. score: 97.384%\n",
      "Epoch 9, 100% \t Train loss: 0.056 took: 5.92s  Val. loss: 0.107  Val. score: 97.114%\n",
      "Epoch 10, 100% \t Train loss: 0.053 took: 6.02s  Val. loss: 0.099  Val. score: 97.438%\n",
      "Training finished, took 94.853s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.590 took: 5.48s  Val. loss: 0.205  Val. score: 93.976%\n",
      "Epoch 2, 100% \t Train loss: 0.219 took: 5.46s  Val. loss: 0.144  Val. score: 95.710%\n",
      "Epoch 3, 100% \t Train loss: 0.156 took: 5.23s  Val. loss: 0.133  Val. score: 96.130%\n",
      "Epoch 4, 100% \t Train loss: 0.121 took: 5.60s  Val. loss: 0.113  Val. score: 96.484%\n",
      "Epoch 5, 100% \t Train loss: 0.101 took: 5.60s  Val. loss: 0.105  Val. score: 96.928%\n",
      "Epoch 6, 100% \t Train loss: 0.088 took: 5.33s  Val. loss: 0.120  Val. score: 96.688%\n",
      "Epoch 7, 100% \t Train loss: 0.076 took: 5.40s  Val. loss: 0.102  Val. score: 97.144%\n",
      "Epoch 8, 100% \t Train loss: 0.064 took: 5.56s  Val. loss: 0.096  Val. score: 97.354%\n",
      "Epoch 9, 100% \t Train loss: 0.058 took: 5.53s  Val. loss: 0.106  Val. score: 97.252%\n",
      "Epoch 10, 100% \t Train loss: 0.053 took: 5.53s  Val. loss: 0.101  Val. score: 97.366%\n",
      "Training finished, took 91.967s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.569 took: 5.01s  Val. loss: 0.226  Val. score: 93.370%\n",
      "Epoch 2, 100% \t Train loss: 0.217 took: 5.30s  Val. loss: 0.150  Val. score: 95.506%\n",
      "Epoch 3, 100% \t Train loss: 0.156 took: 5.66s  Val. loss: 0.135  Val. score: 95.986%\n",
      "Epoch 4, 100% \t Train loss: 0.122 took: 5.92s  Val. loss: 0.121  Val. score: 96.460%\n",
      "Epoch 5, 100% \t Train loss: 0.100 took: 5.55s  Val. loss: 0.109  Val. score: 96.760%\n",
      "Epoch 6, 100% \t Train loss: 0.087 took: 5.69s  Val. loss: 0.111  Val. score: 96.916%\n",
      "Epoch 7, 100% \t Train loss: 0.075 took: 5.39s  Val. loss: 0.105  Val. score: 97.132%\n",
      "Epoch 8, 100% \t Train loss: 0.068 took: 5.78s  Val. loss: 0.105  Val. score: 97.162%\n",
      "Epoch 9, 100% \t Train loss: 0.058 took: 5.91s  Val. loss: 0.098  Val. score: 97.336%\n",
      "Epoch 10, 100% \t Train loss: 0.052 took: 6.05s  Val. loss: 0.096  Val. score: 97.432%\n",
      "Training finished, took 93.498s\n",
      "\n",
      "Parameters configuration 11 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0014033260130125094\n",
      "h_sizes \t [784, 286, 113, 42]\n",
      "penalty \t 0.0016954936580884127\n",
      "dropout \t 0.19313974322665312\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.4119 +/- 0.0326\n",
      "Time for evaluation: 281.4 s\n",
      "Estimated time to finish : 7.44 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.361 took: 7.69s  Val. loss: 2.303  Val. score: 10.008%\n",
      "Epoch 2, 100% \t Train loss: 2.304 took: 8.00s  Val. loss: 2.306  Val. score: 9.972%\n",
      "Epoch 3, 100% \t Train loss: 2.304 took: 9.56s  Val. loss: 2.304  Val. score: 10.212%\n",
      "Epoch 4, 100% \t Train loss: 2.304 took: 13.08s  Val. loss: 2.303  Val. score: 10.212%\n",
      "Epoch 5, 100% \t Train loss: 2.304 took: 12.16s  Val. loss: 2.303  Val. score: 9.972%\n",
      "Epoch 6, 100% \t Train loss: 2.304 took: 12.18s  Val. loss: 2.304  Val. score: 11.286%\n",
      "Epoch 7, 100% \t Train loss: 2.305 took: 12.25s  Val. loss: 2.305  Val. score: 11.286%\n",
      "Epoch 8, 100% \t Train loss: 2.304 took: 12.16s  Val. loss: 2.302  Val. score: 11.286%\n",
      "Epoch 9, 100% \t Train loss: 2.304 took: 13.00s  Val. loss: 2.304  Val. score: 10.008%\n",
      "Epoch 10, 100% \t Train loss: 2.304 took: 12.18s  Val. loss: 2.306  Val. score: 10.212%\n",
      "Training finished, took 160.719s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.124 took: 8.33s  Val. loss: 1.873  Val. score: 29.527%\n",
      "Epoch 2, 100% \t Train loss: 2.078 took: 7.72s  Val. loss: 1.912  Val. score: 24.133%\n",
      "Epoch 3, 100% \t Train loss: 2.184 took: 9.02s  Val. loss: 2.305  Val. score: 11.058%\n",
      "Epoch 4, 100% \t Train loss: 2.305 took: 12.46s  Val. loss: 2.305  Val. score: 11.058%\n",
      "Epoch 5, 100% \t Train loss: 2.304 took: 12.80s  Val. loss: 2.304  Val. score: 11.058%\n",
      "Epoch 6, 100% \t Train loss: 2.304 took: 12.71s  Val. loss: 2.304  Val. score: 9.804%\n",
      "Epoch 7, 100% \t Train loss: 2.304 took: 13.04s  Val. loss: 2.306  Val. score: 11.058%\n",
      "Epoch 8, 100% \t Train loss: 2.304 took: 12.88s  Val. loss: 2.304  Val. score: 10.134%\n",
      "Epoch 9, 100% \t Train loss: 2.304 took: 13.00s  Val. loss: 2.305  Val. score: 10.134%\n",
      "Epoch 10, 100% \t Train loss: 2.305 took: 12.57s  Val. loss: 2.303  Val. score: 11.058%\n",
      "Training finished, took 162.135s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.316 took: 8.35s  Val. loss: 2.304  Val. score: 11.412%\n",
      "Epoch 2, 100% \t Train loss: 2.306 took: 8.38s  Val. loss: 2.304  Val. score: 10.476%\n",
      "Epoch 3, 100% \t Train loss: 2.304 took: 9.24s  Val. loss: 2.304  Val. score: 11.412%\n",
      "Epoch 4, 100% \t Train loss: 2.304 took: 12.91s  Val. loss: 2.303  Val. score: 10.284%\n",
      "Epoch 5, 100% \t Train loss: 2.304 took: 12.12s  Val. loss: 2.306  Val. score: 9.144%\n",
      "Epoch 6, 100% \t Train loss: 2.305 took: 12.15s  Val. loss: 2.302  Val. score: 11.412%\n",
      "Epoch 7, 100% \t Train loss: 2.304 took: 12.63s  Val. loss: 2.307  Val. score: 9.144%\n",
      "Epoch 8, 100% \t Train loss: 2.305 took: 12.13s  Val. loss: 2.302  Val. score: 11.412%\n",
      "Epoch 9, 100% \t Train loss: 2.304 took: 12.09s  Val. loss: 2.303  Val. score: 11.412%\n",
      "Epoch 10, 100% \t Train loss: 2.304 took: 14.02s  Val. loss: 2.306  Val. score: 11.412%\n",
      "Training finished, took 163.582s\n",
      "\n",
      "Parameters configuration 12 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.05177376075122143\n",
      "h_sizes \t [784, 405, 205, 113, 66, 36, 19]\n",
      "penalty \t 0.00017096119660620215\n",
      "dropout \t 0.2040835165118251\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 10.8944 +/- 0.5035\n",
      "Time for evaluation: 487.5 s\n",
      "Estimated time to finish : 7.74 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.455 took: 3.48s  Val. loss: 0.188  Val. score: 94.270%\n",
      "Epoch 2, 100% \t Train loss: 0.209 took: 3.71s  Val. loss: 0.145  Val. score: 95.710%\n",
      "Epoch 3, 100% \t Train loss: 0.163 took: 3.70s  Val. loss: 0.125  Val. score: 96.136%\n",
      "Epoch 4, 100% \t Train loss: 0.134 took: 3.62s  Val. loss: 0.126  Val. score: 96.238%\n",
      "Epoch 5, 100% \t Train loss: 0.114 took: 4.07s  Val. loss: 0.109  Val. score: 96.796%\n",
      "Epoch 6, 100% \t Train loss: 0.104 took: 3.95s  Val. loss: 0.105  Val. score: 96.928%\n",
      "Epoch 7, 100% \t Train loss: 0.096 took: 3.82s  Val. loss: 0.101  Val. score: 97.072%\n",
      "Epoch 8, 100% \t Train loss: 0.092 took: 3.92s  Val. loss: 0.104  Val. score: 97.066%\n",
      "Epoch 9, 100% \t Train loss: 0.085 took: 4.04s  Val. loss: 0.102  Val. score: 97.186%\n",
      "Epoch 10, 100% \t Train loss: 0.079 took: 4.08s  Val. loss: 0.099  Val. score: 97.270%\n",
      "Training finished, took 68.397s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.453 took: 3.81s  Val. loss: 0.185  Val. score: 94.456%\n",
      "Epoch 2, 100% \t Train loss: 0.206 took: 3.78s  Val. loss: 0.135  Val. score: 95.914%\n",
      "Epoch 3, 100% \t Train loss: 0.157 took: 3.85s  Val. loss: 0.132  Val. score: 96.070%\n",
      "Epoch 4, 100% \t Train loss: 0.131 took: 4.00s  Val. loss: 0.115  Val. score: 96.682%\n",
      "Epoch 5, 100% \t Train loss: 0.113 took: 4.09s  Val. loss: 0.109  Val. score: 96.898%\n",
      "Epoch 6, 100% \t Train loss: 0.105 took: 3.68s  Val. loss: 0.111  Val. score: 96.886%\n",
      "Epoch 7, 100% \t Train loss: 0.094 took: 3.99s  Val. loss: 0.122  Val. score: 96.658%\n",
      "Epoch 8, 100% \t Train loss: 0.089 took: 4.02s  Val. loss: 0.104  Val. score: 97.192%\n",
      "Epoch 9, 100% \t Train loss: 0.083 took: 3.99s  Val. loss: 0.103  Val. score: 97.342%\n",
      "Epoch 10, 100% \t Train loss: 0.077 took: 4.04s  Val. loss: 0.114  Val. score: 97.114%\n",
      "Training finished, took 69.298s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.464 took: 3.78s  Val. loss: 0.208  Val. score: 93.454%\n",
      "Epoch 2, 100% \t Train loss: 0.205 took: 3.72s  Val. loss: 0.146  Val. score: 95.638%\n",
      "Epoch 3, 100% \t Train loss: 0.160 took: 3.79s  Val. loss: 0.127  Val. score: 96.100%\n",
      "Epoch 4, 100% \t Train loss: 0.132 took: 4.07s  Val. loss: 0.127  Val. score: 96.250%\n",
      "Epoch 5, 100% \t Train loss: 0.116 took: 4.02s  Val. loss: 0.115  Val. score: 96.838%\n",
      "Epoch 6, 100% \t Train loss: 0.100 took: 4.03s  Val. loss: 0.110  Val. score: 96.958%\n",
      "Epoch 7, 100% \t Train loss: 0.096 took: 4.04s  Val. loss: 0.108  Val. score: 96.952%\n",
      "Epoch 8, 100% \t Train loss: 0.087 took: 4.10s  Val. loss: 0.112  Val. score: 97.126%\n",
      "Epoch 9, 100% \t Train loss: 0.081 took: 3.92s  Val. loss: 0.112  Val. score: 96.988%\n",
      "Epoch 10, 100% \t Train loss: 0.076 took: 3.98s  Val. loss: 0.116  Val. score: 97.024%\n",
      "Training finished, took 69.485s\n",
      "\n",
      "Parameters configuration 13 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003594704024602325\n",
      "h_sizes \t [784, 179, 44]\n",
      "penalty \t 0.0004525864138211596\n",
      "dropout \t 0.231863786929471\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.1359 +/- 0.1016\n",
      "Time for evaluation: 208.3 s\n",
      "Estimated time to finish : 7.45 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.359 took: 4.64s  Val. loss: 0.161  Val. score: 95.326%\n",
      "Epoch 2, 100% \t Train loss: 0.144 took: 5.17s  Val. loss: 0.143  Val. score: 95.722%\n",
      "Epoch 3, 100% \t Train loss: 0.105 took: 4.85s  Val. loss: 0.105  Val. score: 96.862%\n",
      "Epoch 4, 100% \t Train loss: 0.080 took: 5.27s  Val. loss: 0.122  Val. score: 96.460%\n",
      "Epoch 5, 100% \t Train loss: 0.076 took: 5.26s  Val. loss: 0.110  Val. score: 96.934%\n",
      "Epoch 6, 100% \t Train loss: 0.063 took: 5.25s  Val. loss: 0.134  Val. score: 96.646%\n",
      "Epoch 7, 100% \t Train loss: 0.058 took: 5.28s  Val. loss: 0.115  Val. score: 96.928%\n",
      "Epoch 8, 100% \t Train loss: 0.048 took: 5.66s  Val. loss: 0.130  Val. score: 97.138%\n",
      "Epoch 9, 100% \t Train loss: 0.044 took: 5.63s  Val. loss: 0.111  Val. score: 97.318%\n",
      "Epoch 10, 100% \t Train loss: 0.046 took: 5.81s  Val. loss: 0.111  Val. score: 97.102%\n",
      "Training finished, took 88.425s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.383 took: 4.70s  Val. loss: 0.160  Val. score: 95.254%\n",
      "Epoch 2, 100% \t Train loss: 0.153 took: 5.07s  Val. loss: 0.132  Val. score: 96.112%\n",
      "Epoch 3, 100% \t Train loss: 0.110 took: 5.44s  Val. loss: 0.159  Val. score: 95.584%\n",
      "Epoch 4, 100% \t Train loss: 0.086 took: 5.63s  Val. loss: 0.131  Val. score: 96.352%\n",
      "Epoch 5, 100% \t Train loss: 0.073 took: 5.44s  Val. loss: 0.137  Val. score: 96.706%\n",
      "Epoch 6, 100% \t Train loss: 0.065 took: 5.31s  Val. loss: 0.112  Val. score: 96.898%\n",
      "Epoch 7, 100% \t Train loss: 0.065 took: 5.53s  Val. loss: 0.114  Val. score: 97.072%\n",
      "Epoch 8, 100% \t Train loss: 0.046 took: 5.61s  Val. loss: 0.117  Val. score: 97.120%\n",
      "Epoch 9, 100% \t Train loss: 0.043 took: 5.78s  Val. loss: 0.112  Val. score: 97.330%\n",
      "Epoch 10, 100% \t Train loss: 0.045 took: 5.64s  Val. loss: 0.135  Val. score: 97.192%\n",
      "Training finished, took 89.822s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.377 took: 4.82s  Val. loss: 0.183  Val. score: 94.540%\n",
      "Epoch 2, 100% \t Train loss: 0.147 took: 4.92s  Val. loss: 0.135  Val. score: 95.962%\n",
      "Epoch 3, 100% \t Train loss: 0.106 took: 4.90s  Val. loss: 0.126  Val. score: 96.496%\n",
      "Epoch 4, 100% \t Train loss: 0.087 took: 5.40s  Val. loss: 0.128  Val. score: 96.418%\n",
      "Epoch 5, 100% \t Train loss: 0.071 took: 5.45s  Val. loss: 0.114  Val. score: 97.060%\n",
      "Epoch 6, 100% \t Train loss: 0.061 took: 5.68s  Val. loss: 0.141  Val. score: 96.334%\n",
      "Epoch 7, 100% \t Train loss: 0.060 took: 5.71s  Val. loss: 0.133  Val. score: 96.670%\n",
      "Epoch 8, 100% \t Train loss: 0.054 took: 5.52s  Val. loss: 0.112  Val. score: 97.084%\n",
      "Epoch 9, 100% \t Train loss: 0.045 took: 5.56s  Val. loss: 0.112  Val. score: 97.204%\n",
      "Epoch 10, 100% \t Train loss: 0.041 took: 5.69s  Val. loss: 0.131  Val. score: 97.000%\n",
      "Training finished, took 88.973s\n",
      "\n",
      "Parameters configuration 14 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005498858698310429\n",
      "h_sizes \t [784, 270, 91, 32]\n",
      "penalty \t 0.0027221618405975406\n",
      "dropout \t 0.0363923228903284\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.0979 +/- 0.0784\n",
      "Time for evaluation: 268.3 s\n",
      "Estimated time to finish : 7.30 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.397 took: 3.71s  Val. loss: 0.242  Val. score: 92.848%\n",
      "Epoch 2, 100% \t Train loss: 0.226 took: 3.76s  Val. loss: 0.260  Val. score: 92.950%\n",
      "Epoch 3, 100% \t Train loss: 0.199 took: 3.78s  Val. loss: 0.199  Val. score: 94.570%\n",
      "Epoch 4, 100% \t Train loss: 0.195 took: 3.81s  Val. loss: 0.214  Val. score: 94.036%\n",
      "Epoch 5, 100% \t Train loss: 0.177 took: 3.85s  Val. loss: 0.228  Val. score: 94.936%\n",
      "Epoch 6, 100% \t Train loss: 0.183 took: 3.82s  Val. loss: 0.213  Val. score: 94.834%\n",
      "Epoch 7, 100% \t Train loss: 0.169 took: 3.65s  Val. loss: 0.286  Val. score: 93.334%\n",
      "Epoch 8, 100% \t Train loss: 0.174 took: 3.69s  Val. loss: 0.202  Val. score: 95.176%\n",
      "Epoch 9, 100% \t Train loss: 0.185 took: 3.50s  Val. loss: 0.232  Val. score: 94.786%\n",
      "Epoch 10, 100% \t Train loss: 0.155 took: 3.94s  Val. loss: 0.201  Val. score: 95.440%\n",
      "Training finished, took 66.390s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.372 took: 3.48s  Val. loss: 0.230  Val. score: 93.646%\n",
      "Epoch 2, 100% \t Train loss: 0.232 took: 3.52s  Val. loss: 0.202  Val. score: 94.534%\n",
      "Epoch 3, 100% \t Train loss: 0.200 took: 3.54s  Val. loss: 0.226  Val. score: 94.390%\n",
      "Epoch 4, 100% \t Train loss: 0.187 took: 3.81s  Val. loss: 0.270  Val. score: 92.422%\n",
      "Epoch 5, 100% \t Train loss: 0.184 took: 3.38s  Val. loss: 0.209  Val. score: 94.840%\n",
      "Epoch 6, 100% \t Train loss: 0.184 took: 3.86s  Val. loss: 0.224  Val. score: 94.414%\n",
      "Epoch 7, 100% \t Train loss: 0.181 took: 3.60s  Val. loss: 0.215  Val. score: 94.948%\n",
      "Epoch 8, 100% \t Train loss: 0.164 took: 3.79s  Val. loss: 0.218  Val. score: 95.092%\n",
      "Epoch 9, 100% \t Train loss: 0.184 took: 3.86s  Val. loss: 0.213  Val. score: 94.732%\n",
      "Epoch 10, 100% \t Train loss: 0.182 took: 4.20s  Val. loss: 0.232  Val. score: 94.474%\n",
      "Training finished, took 66.237s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.395 took: 3.83s  Val. loss: 0.231  Val. score: 93.436%\n",
      "Epoch 2, 100% \t Train loss: 0.221 took: 3.79s  Val. loss: 0.216  Val. score: 94.264%\n",
      "Epoch 3, 100% \t Train loss: 0.199 took: 3.75s  Val. loss: 0.206  Val. score: 94.516%\n",
      "Epoch 4, 100% \t Train loss: 0.180 took: 3.64s  Val. loss: 0.231  Val. score: 94.084%\n",
      "Epoch 5, 100% \t Train loss: 0.182 took: 3.89s  Val. loss: 0.230  Val. score: 94.126%\n",
      "Epoch 6, 100% \t Train loss: 0.167 took: 3.61s  Val. loss: 0.206  Val. score: 95.230%\n",
      "Epoch 7, 100% \t Train loss: 0.171 took: 3.83s  Val. loss: 0.209  Val. score: 94.648%\n",
      "Epoch 8, 100% \t Train loss: 0.169 took: 3.43s  Val. loss: 0.238  Val. score: 94.684%\n",
      "Epoch 9, 100% \t Train loss: 0.153 took: 3.83s  Val. loss: 0.205  Val. score: 95.098%\n",
      "Epoch 10, 100% \t Train loss: 0.154 took: 3.96s  Val. loss: 0.200  Val. score: 95.200%\n",
      "Training finished, took 66.641s\n",
      "\n",
      "Parameters configuration 15 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.02698379740732466\n",
      "h_sizes \t [784, 178, 46]\n",
      "penalty \t 0.004939537382417476\n",
      "dropout \t 0.021164589819529483\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 95.0378 +/- 0.4107\n",
      "Time for evaluation: 200.3 s\n",
      "Estimated time to finish : 7.05 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.543 took: 5.88s  Val. loss: 0.223  Val. score: 93.424%\n",
      "Epoch 2, 100% \t Train loss: 0.207 took: 5.64s  Val. loss: 0.156  Val. score: 95.404%\n",
      "Epoch 3, 100% \t Train loss: 0.143 took: 5.62s  Val. loss: 0.116  Val. score: 96.400%\n",
      "Epoch 4, 100% \t Train loss: 0.103 took: 6.34s  Val. loss: 0.118  Val. score: 96.412%\n",
      "Epoch 5, 100% \t Train loss: 0.086 took: 5.79s  Val. loss: 0.103  Val. score: 96.958%\n",
      "Epoch 6, 100% \t Train loss: 0.071 took: 6.14s  Val. loss: 0.100  Val. score: 97.198%\n",
      "Epoch 7, 100% \t Train loss: 0.057 took: 6.50s  Val. loss: 0.115  Val. score: 96.946%\n",
      "Epoch 8, 100% \t Train loss: 0.052 took: 5.76s  Val. loss: 0.094  Val. score: 97.552%\n",
      "Epoch 9, 100% \t Train loss: 0.043 took: 6.33s  Val. loss: 0.123  Val. score: 96.844%\n",
      "Epoch 10, 100% \t Train loss: 0.039 took: 6.42s  Val. loss: 0.100  Val. score: 97.366%\n",
      "Training finished, took 98.388s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.517 took: 5.37s  Val. loss: 0.227  Val. score: 93.400%\n",
      "Epoch 2, 100% \t Train loss: 0.198 took: 5.41s  Val. loss: 0.152  Val. score: 95.470%\n",
      "Epoch 3, 100% \t Train loss: 0.135 took: 5.72s  Val. loss: 0.117  Val. score: 96.412%\n",
      "Epoch 4, 100% \t Train loss: 0.098 took: 5.87s  Val. loss: 0.107  Val. score: 96.940%\n",
      "Epoch 5, 100% \t Train loss: 0.078 took: 6.50s  Val. loss: 0.113  Val. score: 96.634%\n",
      "Epoch 6, 100% \t Train loss: 0.065 took: 6.26s  Val. loss: 0.097  Val. score: 97.240%\n",
      "Epoch 7, 100% \t Train loss: 0.053 took: 6.28s  Val. loss: 0.092  Val. score: 97.402%\n",
      "Epoch 8, 100% \t Train loss: 0.046 took: 5.91s  Val. loss: 0.098  Val. score: 97.330%\n",
      "Epoch 9, 100% \t Train loss: 0.043 took: 6.45s  Val. loss: 0.093  Val. score: 97.534%\n",
      "Epoch 10, 100% \t Train loss: 0.039 took: 6.10s  Val. loss: 0.107  Val. score: 97.300%\n",
      "Training finished, took 98.067s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.533 took: 5.38s  Val. loss: 0.213  Val. score: 93.550%\n",
      "Epoch 2, 100% \t Train loss: 0.200 took: 5.77s  Val. loss: 0.144  Val. score: 95.740%\n",
      "Epoch 3, 100% \t Train loss: 0.138 took: 6.12s  Val. loss: 0.117  Val. score: 96.394%\n",
      "Epoch 4, 100% \t Train loss: 0.105 took: 6.25s  Val. loss: 0.106  Val. score: 96.688%\n",
      "Epoch 5, 100% \t Train loss: 0.083 took: 6.22s  Val. loss: 0.098  Val. score: 97.150%\n",
      "Epoch 6, 100% \t Train loss: 0.068 took: 5.97s  Val. loss: 0.095  Val. score: 97.216%\n",
      "Epoch 7, 100% \t Train loss: 0.059 took: 6.21s  Val. loss: 0.094  Val. score: 97.306%\n",
      "Epoch 8, 100% \t Train loss: 0.051 took: 6.32s  Val. loss: 0.106  Val. score: 97.144%\n",
      "Epoch 9, 100% \t Train loss: 0.043 took: 6.24s  Val. loss: 0.098  Val. score: 97.360%\n",
      "Epoch 10, 100% \t Train loss: 0.040 took: 5.92s  Val. loss: 0.099  Val. score: 97.414%\n",
      "Training finished, took 98.548s\n",
      "\n",
      "Parameters configuration 16 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0015072642652618684\n",
      "h_sizes \t [784, 303, 121, 39]\n",
      "penalty \t 0.0006237138521426357\n",
      "dropout \t 0.11115645654099982\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.3599 +/- 0.0467\n",
      "Time for evaluation: 296.1 s\n",
      "Estimated time to finish : 6.96 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.391 took: 3.97s  Val. loss: 0.183  Val. score: 94.786%\n",
      "Epoch 2, 100% \t Train loss: 0.248 took: 3.67s  Val. loss: 0.186  Val. score: 94.636%\n",
      "Epoch 3, 100% \t Train loss: 0.216 took: 3.92s  Val. loss: 0.167  Val. score: 95.650%\n",
      "Epoch 4, 100% \t Train loss: 0.198 took: 4.01s  Val. loss: 0.154  Val. score: 95.752%\n",
      "Epoch 5, 100% \t Train loss: 0.200 took: 3.58s  Val. loss: 0.160  Val. score: 95.620%\n",
      "Epoch 6, 100% \t Train loss: 0.183 took: 3.90s  Val. loss: 0.169  Val. score: 95.632%\n",
      "Epoch 7, 100% \t Train loss: 0.182 took: 3.95s  Val. loss: 0.155  Val. score: 95.818%\n",
      "Epoch 8, 100% \t Train loss: 0.166 took: 3.70s  Val. loss: 0.152  Val. score: 95.950%\n",
      "Epoch 9, 100% \t Train loss: 0.170 took: 3.66s  Val. loss: 0.169  Val. score: 95.980%\n",
      "Epoch 10, 100% \t Train loss: 0.166 took: 3.66s  Val. loss: 0.165  Val. score: 96.178%\n",
      "Training finished, took 67.951s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.388 took: 3.62s  Val. loss: 0.192  Val. score: 94.318%\n",
      "Epoch 2, 100% \t Train loss: 0.240 took: 3.85s  Val. loss: 0.187  Val. score: 94.582%\n",
      "Epoch 3, 100% \t Train loss: 0.228 took: 3.85s  Val. loss: 0.185  Val. score: 95.026%\n",
      "Epoch 4, 100% \t Train loss: 0.197 took: 3.84s  Val. loss: 0.184  Val. score: 94.978%\n",
      "Epoch 5, 100% \t Train loss: 0.198 took: 3.77s  Val. loss: 0.174  Val. score: 95.626%\n",
      "Epoch 6, 100% \t Train loss: 0.187 took: 3.63s  Val. loss: 0.174  Val. score: 95.536%\n",
      "Epoch 7, 100% \t Train loss: 0.180 took: 3.79s  Val. loss: 0.175  Val. score: 95.518%\n",
      "Epoch 8, 100% \t Train loss: 0.169 took: 4.01s  Val. loss: 0.163  Val. score: 95.872%\n",
      "Epoch 9, 100% \t Train loss: 0.166 took: 3.83s  Val. loss: 0.170  Val. score: 95.536%\n",
      "Epoch 10, 100% \t Train loss: 0.169 took: 3.83s  Val. loss: 0.182  Val. score: 95.380%\n",
      "Training finished, took 68.425s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.392 took: 3.95s  Val. loss: 0.187  Val. score: 94.750%\n",
      "Epoch 2, 100% \t Train loss: 0.249 took: 3.81s  Val. loss: 0.168  Val. score: 95.302%\n",
      "Epoch 3, 100% \t Train loss: 0.220 took: 4.00s  Val. loss: 0.182  Val. score: 94.846%\n",
      "Epoch 4, 100% \t Train loss: 0.198 took: 3.87s  Val. loss: 0.158  Val. score: 95.866%\n",
      "Epoch 5, 100% \t Train loss: 0.185 took: 3.92s  Val. loss: 0.158  Val. score: 95.728%\n",
      "Epoch 6, 100% \t Train loss: 0.176 took: 4.02s  Val. loss: 0.162  Val. score: 95.794%\n",
      "Epoch 7, 100% \t Train loss: 0.176 took: 4.02s  Val. loss: 0.184  Val. score: 95.410%\n",
      "Epoch 8, 100% \t Train loss: 0.175 took: 4.06s  Val. loss: 0.170  Val. score: 95.716%\n",
      "Epoch 9, 100% \t Train loss: 0.168 took: 4.06s  Val. loss: 0.187  Val. score: 95.752%\n",
      "Epoch 10, 100% \t Train loss: 0.179 took: 3.83s  Val. loss: 0.170  Val. score: 95.638%\n",
      "Training finished, took 69.353s\n",
      "\n",
      "Parameters configuration 17 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.014024617714610348\n",
      "h_sizes \t [784, 193, 54]\n",
      "penalty \t 0.00022010120015451793\n",
      "dropout \t 0.2019471603667569\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 95.7318 +/- 0.3325\n",
      "Time for evaluation: 206.8 s\n",
      "Estimated time to finish : 6.75 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.690 took: 7.64s  Val. loss: 0.249  Val. score: 92.800%\n",
      "Epoch 2, 100% \t Train loss: 0.241 took: 6.92s  Val. loss: 0.179  Val. score: 94.780%\n",
      "Epoch 3, 100% \t Train loss: 0.168 took: 6.94s  Val. loss: 0.141  Val. score: 96.010%\n",
      "Epoch 4, 100% \t Train loss: 0.130 took: 7.32s  Val. loss: 0.129  Val. score: 96.304%\n",
      "Epoch 5, 100% \t Train loss: 0.107 took: 6.78s  Val. loss: 0.120  Val. score: 96.538%\n",
      "Epoch 6, 100% \t Train loss: 0.084 took: 7.20s  Val. loss: 0.113  Val. score: 97.042%\n",
      "Epoch 7, 100% \t Train loss: 0.072 took: 7.36s  Val. loss: 0.118  Val. score: 96.976%\n",
      "Epoch 8, 100% \t Train loss: 0.061 took: 7.44s  Val. loss: 0.118  Val. score: 97.174%\n",
      "Epoch 9, 100% \t Train loss: 0.051 took: 6.84s  Val. loss: 0.105  Val. score: 97.318%\n",
      "Epoch 10, 100% \t Train loss: 0.043 took: 7.36s  Val. loss: 0.118  Val. score: 97.216%\n",
      "Training finished, took 111.778s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.709 took: 7.44s  Val. loss: 0.281  Val. score: 91.990%\n",
      "Epoch 2, 100% \t Train loss: 0.266 took: 7.60s  Val. loss: 0.182  Val. score: 94.606%\n",
      "Epoch 3, 100% \t Train loss: 0.190 took: 7.00s  Val. loss: 0.137  Val. score: 95.932%\n",
      "Epoch 4, 100% \t Train loss: 0.142 took: 7.22s  Val. loss: 0.118  Val. score: 96.490%\n",
      "Epoch 5, 100% \t Train loss: 0.121 took: 7.33s  Val. loss: 0.111  Val. score: 96.802%\n",
      "Epoch 6, 100% \t Train loss: 0.097 took: 7.50s  Val. loss: 0.093  Val. score: 97.480%\n",
      "Epoch 7, 100% \t Train loss: 0.084 took: 7.09s  Val. loss: 0.090  Val. score: 97.480%\n",
      "Epoch 8, 100% \t Train loss: 0.071 took: 7.10s  Val. loss: 0.093  Val. score: 97.534%\n",
      "Epoch 9, 100% \t Train loss: 0.060 took: 6.75s  Val. loss: 0.092  Val. score: 97.510%\n",
      "Epoch 10, 100% \t Train loss: 0.051 took: 6.82s  Val. loss: 0.087  Val. score: 97.690%\n",
      "Training finished, took 112.152s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.686 took: 6.77s  Val. loss: 0.276  Val. score: 91.912%\n",
      "Epoch 2, 100% \t Train loss: 0.268 took: 7.42s  Val. loss: 0.178  Val. score: 94.888%\n",
      "Epoch 3, 100% \t Train loss: 0.186 took: 7.51s  Val. loss: 0.155  Val. score: 95.392%\n",
      "Epoch 4, 100% \t Train loss: 0.145 took: 7.41s  Val. loss: 0.128  Val. score: 96.232%\n",
      "Epoch 5, 100% \t Train loss: 0.117 took: 7.42s  Val. loss: 0.117  Val. score: 96.586%\n",
      "Epoch 6, 100% \t Train loss: 0.099 took: 7.27s  Val. loss: 0.116  Val. score: 96.550%\n",
      "Epoch 7, 100% \t Train loss: 0.082 took: 7.30s  Val. loss: 0.106  Val. score: 96.970%\n",
      "Epoch 8, 100% \t Train loss: 0.070 took: 7.19s  Val. loss: 0.105  Val. score: 97.000%\n",
      "Epoch 9, 100% \t Train loss: 0.061 took: 7.51s  Val. loss: 0.104  Val. score: 97.186%\n",
      "Epoch 10, 100% \t Train loss: 0.055 took: 7.52s  Val. loss: 0.101  Val. score: 97.240%\n",
      "Training finished, took 113.412s\n",
      "\n",
      "Parameters configuration 18 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0032657150226928465\n",
      "h_sizes \t [784, 325, 148, 62, 28]\n",
      "penalty \t 0.006332655921391879\n",
      "dropout \t 0.11990937584513675\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.3819 +/- 0.2180\n",
      "Time for evaluation: 338.5 s\n",
      "Estimated time to finish : 6.73 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.606 took: 5.54s  Val. loss: 0.257  Val. score: 92.146%\n",
      "Epoch 2, 100% \t Train loss: 0.249 took: 5.69s  Val. loss: 0.176  Val. score: 94.816%\n",
      "Epoch 3, 100% \t Train loss: 0.174 took: 5.90s  Val. loss: 0.145  Val. score: 95.560%\n",
      "Epoch 4, 100% \t Train loss: 0.138 took: 6.08s  Val. loss: 0.135  Val. score: 95.962%\n",
      "Epoch 5, 100% \t Train loss: 0.109 took: 6.16s  Val. loss: 0.125  Val. score: 96.448%\n",
      "Epoch 6, 100% \t Train loss: 0.089 took: 6.06s  Val. loss: 0.109  Val. score: 96.880%\n",
      "Epoch 7, 100% \t Train loss: 0.079 took: 5.59s  Val. loss: 0.103  Val. score: 96.976%\n",
      "Epoch 8, 100% \t Train loss: 0.067 took: 5.54s  Val. loss: 0.106  Val. score: 97.042%\n",
      "Epoch 9, 100% \t Train loss: 0.058 took: 5.63s  Val. loss: 0.099  Val. score: 97.342%\n",
      "Epoch 10, 100% \t Train loss: 0.050 took: 6.02s  Val. loss: 0.099  Val. score: 97.486%\n",
      "Training finished, took 93.541s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.630 took: 5.57s  Val. loss: 0.259  Val. score: 92.074%\n",
      "Epoch 2, 100% \t Train loss: 0.264 took: 5.74s  Val. loss: 0.180  Val. score: 94.402%\n",
      "Epoch 3, 100% \t Train loss: 0.188 took: 5.69s  Val. loss: 0.138  Val. score: 95.638%\n",
      "Epoch 4, 100% \t Train loss: 0.147 took: 5.67s  Val. loss: 0.120  Val. score: 96.304%\n",
      "Epoch 5, 100% \t Train loss: 0.121 took: 5.68s  Val. loss: 0.111  Val. score: 96.454%\n",
      "Epoch 6, 100% \t Train loss: 0.100 took: 6.16s  Val. loss: 0.103  Val. score: 96.784%\n",
      "Epoch 7, 100% \t Train loss: 0.086 took: 6.13s  Val. loss: 0.103  Val. score: 96.838%\n",
      "Epoch 8, 100% \t Train loss: 0.073 took: 5.99s  Val. loss: 0.093  Val. score: 97.270%\n",
      "Epoch 9, 100% \t Train loss: 0.066 took: 5.88s  Val. loss: 0.096  Val. score: 97.168%\n",
      "Epoch 10, 100% \t Train loss: 0.052 took: 6.17s  Val. loss: 0.095  Val. score: 97.294%\n",
      "Training finished, took 93.934s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.629 took: 5.29s  Val. loss: 0.258  Val. score: 92.320%\n",
      "Epoch 2, 100% \t Train loss: 0.252 took: 5.57s  Val. loss: 0.170  Val. score: 94.918%\n",
      "Epoch 3, 100% \t Train loss: 0.182 took: 5.64s  Val. loss: 0.151  Val. score: 95.578%\n",
      "Epoch 4, 100% \t Train loss: 0.141 took: 5.67s  Val. loss: 0.124  Val. score: 96.196%\n",
      "Epoch 5, 100% \t Train loss: 0.114 took: 6.20s  Val. loss: 0.112  Val. score: 96.760%\n",
      "Epoch 6, 100% \t Train loss: 0.099 took: 5.96s  Val. loss: 0.107  Val. score: 96.946%\n",
      "Epoch 7, 100% \t Train loss: 0.083 took: 5.71s  Val. loss: 0.107  Val. score: 96.826%\n",
      "Epoch 8, 100% \t Train loss: 0.074 took: 6.05s  Val. loss: 0.098  Val. score: 97.186%\n",
      "Epoch 9, 100% \t Train loss: 0.062 took: 5.83s  Val. loss: 0.096  Val. score: 97.414%\n",
      "Epoch 10, 100% \t Train loss: 0.054 took: 6.32s  Val. loss: 0.102  Val. score: 97.252%\n",
      "Training finished, took 93.717s\n",
      "\n",
      "Parameters configuration 19 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003821408390219275\n",
      "h_sizes \t [784, 259, 88, 27]\n",
      "penalty \t 0.008203127333894325\n",
      "dropout \t 0.11429272682659153\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.3439 +/- 0.1019\n",
      "Time for evaluation: 282.3 s\n",
      "Estimated time to finish : 6.63 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.079 took: 8.56s  Val. loss: 0.507  Val. score: 86.529%\n",
      "Epoch 2, 100% \t Train loss: 0.477 took: 9.60s  Val. loss: 0.292  Val. score: 93.244%\n",
      "Epoch 3, 100% \t Train loss: 0.357 took: 9.31s  Val. loss: 0.234  Val. score: 94.534%\n",
      "Epoch 4, 100% \t Train loss: 0.298 took: 11.12s  Val. loss: 0.260  Val. score: 94.432%\n",
      "Epoch 5, 100% \t Train loss: 0.267 took: 10.97s  Val. loss: 0.207  Val. score: 95.146%\n",
      "Epoch 6, 100% \t Train loss: 0.264 took: 10.82s  Val. loss: 0.233  Val. score: 95.206%\n",
      "Epoch 7, 100% \t Train loss: 0.255 took: 11.88s  Val. loss: 0.213  Val. score: 95.680%\n",
      "Epoch 8, 100% \t Train loss: 0.229 took: 12.09s  Val. loss: 0.209  Val. score: 95.836%\n",
      "Epoch 9, 100% \t Train loss: 0.237 took: 11.55s  Val. loss: 0.270  Val. score: 95.662%\n",
      "Epoch 10, 100% \t Train loss: 0.246 took: 12.25s  Val. loss: 0.190  Val. score: 96.028%\n",
      "Training finished, took 157.447s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.904 took: 9.20s  Val. loss: 0.341  Val. score: 91.102%\n",
      "Epoch 2, 100% \t Train loss: 0.434 took: 9.67s  Val. loss: 0.281  Val. score: 93.334%\n",
      "Epoch 3, 100% \t Train loss: 0.331 took: 9.84s  Val. loss: 0.222  Val. score: 94.810%\n",
      "Epoch 4, 100% \t Train loss: 0.303 took: 10.24s  Val. loss: 0.225  Val. score: 94.654%\n",
      "Epoch 5, 100% \t Train loss: 0.299 took: 9.90s  Val. loss: 0.210  Val. score: 95.278%\n",
      "Epoch 6, 100% \t Train loss: 0.269 took: 9.25s  Val. loss: 0.178  Val. score: 95.926%\n",
      "Epoch 7, 100% \t Train loss: 0.262 took: 9.85s  Val. loss: 0.181  Val. score: 95.812%\n",
      "Epoch 8, 100% \t Train loss: 0.237 took: 10.10s  Val. loss: 0.162  Val. score: 96.286%\n",
      "Epoch 9, 100% \t Train loss: 0.214 took: 10.49s  Val. loss: 0.177  Val. score: 96.028%\n",
      "Epoch 10, 100% \t Train loss: 0.235 took: 11.00s  Val. loss: 0.216  Val. score: 96.010%\n",
      "Training finished, took 149.772s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.949 took: 8.60s  Val. loss: 0.441  Val. score: 86.277%\n",
      "Epoch 2, 100% \t Train loss: 0.440 took: 8.74s  Val. loss: 0.235  Val. score: 94.732%\n",
      "Epoch 3, 100% \t Train loss: 0.345 took: 9.93s  Val. loss: 0.217  Val. score: 94.840%\n",
      "Epoch 4, 100% \t Train loss: 0.282 took: 10.16s  Val. loss: 0.210  Val. score: 95.410%\n",
      "Epoch 5, 100% \t Train loss: 0.265 took: 10.41s  Val. loss: 0.214  Val. score: 95.116%\n",
      "Epoch 6, 100% \t Train loss: 0.286 took: 10.21s  Val. loss: 0.192  Val. score: 95.902%\n",
      "Epoch 7, 100% \t Train loss: 0.259 took: 10.11s  Val. loss: 0.179  Val. score: 96.238%\n",
      "Epoch 8, 100% \t Train loss: 0.237 took: 11.69s  Val. loss: 0.215  Val. score: 95.668%\n",
      "Epoch 9, 100% \t Train loss: 0.257 took: 12.72s  Val. loss: 0.221  Val. score: 95.110%\n",
      "Epoch 10, 100% \t Train loss: 0.233 took: 11.77s  Val. loss: 0.203  Val. score: 95.986%\n",
      "Training finished, took 154.004s\n",
      "\n",
      "Parameters configuration 20 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.007375800323906414\n",
      "h_sizes \t [784, 421, 238, 127, 75, 37, 17]\n",
      "penalty \t 0.0037562322404048622\n",
      "dropout \t 0.18797497722505432\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 96.0078 +/- 0.0172\n",
      "Time for evaluation: 462.3 s\n",
      "Estimated time to finish : 6.74 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.379 took: 4.01s  Val. loss: 0.181  Val. score: 94.624%\n",
      "Epoch 2, 100% \t Train loss: 0.182 took: 4.19s  Val. loss: 0.162  Val. score: 94.990%\n",
      "Epoch 3, 100% \t Train loss: 0.143 took: 4.41s  Val. loss: 0.147  Val. score: 95.830%\n",
      "Epoch 4, 100% \t Train loss: 0.121 took: 4.88s  Val. loss: 0.135  Val. score: 96.160%\n",
      "Epoch 5, 100% \t Train loss: 0.109 took: 4.95s  Val. loss: 0.122  Val. score: 96.382%\n",
      "Epoch 6, 100% \t Train loss: 0.097 took: 4.97s  Val. loss: 0.115  Val. score: 96.520%\n",
      "Epoch 7, 100% \t Train loss: 0.085 took: 5.47s  Val. loss: 0.127  Val. score: 96.682%\n",
      "Epoch 8, 100% \t Train loss: 0.075 took: 4.95s  Val. loss: 0.132  Val. score: 96.634%\n",
      "Epoch 9, 100% \t Train loss: 0.073 took: 4.94s  Val. loss: 0.125  Val. score: 96.844%\n",
      "Epoch 10, 100% \t Train loss: 0.069 took: 4.85s  Val. loss: 0.119  Val. score: 96.856%\n",
      "Training finished, took 77.398s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.388 took: 3.97s  Val. loss: 0.155  Val. score: 95.452%\n",
      "Epoch 2, 100% \t Train loss: 0.183 took: 4.02s  Val. loss: 0.158  Val. score: 95.518%\n",
      "Epoch 3, 100% \t Train loss: 0.146 took: 4.43s  Val. loss: 0.145  Val. score: 96.028%\n",
      "Epoch 4, 100% \t Train loss: 0.119 took: 5.06s  Val. loss: 0.118  Val. score: 96.532%\n",
      "Epoch 5, 100% \t Train loss: 0.108 took: 4.85s  Val. loss: 0.120  Val. score: 96.802%\n",
      "Epoch 6, 100% \t Train loss: 0.098 took: 5.02s  Val. loss: 0.141  Val. score: 96.412%\n",
      "Epoch 7, 100% \t Train loss: 0.092 took: 4.61s  Val. loss: 0.124  Val. score: 96.616%\n",
      "Epoch 8, 100% \t Train loss: 0.076 took: 4.56s  Val. loss: 0.115  Val. score: 96.802%\n",
      "Epoch 9, 100% \t Train loss: 0.071 took: 4.77s  Val. loss: 0.115  Val. score: 96.892%\n",
      "Epoch 10, 100% \t Train loss: 0.072 took: 4.94s  Val. loss: 0.114  Val. score: 96.988%\n",
      "Training finished, took 75.868s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.399 took: 4.21s  Val. loss: 0.180  Val. score: 94.468%\n",
      "Epoch 2, 100% \t Train loss: 0.194 took: 4.19s  Val. loss: 0.152  Val. score: 95.560%\n",
      "Epoch 3, 100% \t Train loss: 0.148 took: 4.41s  Val. loss: 0.142  Val. score: 96.028%\n",
      "Epoch 4, 100% \t Train loss: 0.127 took: 4.63s  Val. loss: 0.131  Val. score: 96.274%\n",
      "Epoch 5, 100% \t Train loss: 0.112 took: 4.62s  Val. loss: 0.137  Val. score: 96.280%\n",
      "Epoch 6, 100% \t Train loss: 0.095 took: 4.52s  Val. loss: 0.120  Val. score: 96.742%\n",
      "Epoch 7, 100% \t Train loss: 0.089 took: 4.55s  Val. loss: 0.130  Val. score: 96.598%\n",
      "Epoch 8, 100% \t Train loss: 0.080 took: 5.05s  Val. loss: 0.122  Val. score: 96.616%\n",
      "Epoch 9, 100% \t Train loss: 0.075 took: 4.54s  Val. loss: 0.128  Val. score: 96.754%\n",
      "Epoch 10, 100% \t Train loss: 0.066 took: 5.06s  Val. loss: 0.140  Val. score: 96.700%\n",
      "Training finished, took 75.639s\n",
      "\n",
      "Parameters configuration 21 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.03314864166069542\n",
      "h_sizes \t [784, 182, 45]\n",
      "penalty \t 0.00017595780838687398\n",
      "dropout \t 0.10443033798939028\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.8479 +/- 0.1177\n",
      "Time for evaluation: 230.0 s\n",
      "Estimated time to finish : 6.58 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.573 took: 12.79s  Val. loss: 1.008  Val. score: 68.865%\n",
      "Epoch 2, 100% \t Train loss: 1.025 took: 13.02s  Val. loss: 0.753  Val. score: 76.371%\n",
      "Epoch 3, 100% \t Train loss: 0.811 took: 15.43s  Val. loss: 0.510  Val. score: 83.655%\n",
      "Epoch 4, 100% \t Train loss: 0.612 took: 18.44s  Val. loss: 0.380  Val. score: 90.562%\n",
      "Epoch 5, 100% \t Train loss: 0.512 took: 18.00s  Val. loss: 0.310  Val. score: 92.848%\n",
      "Epoch 6, 100% \t Train loss: 0.448 took: 17.37s  Val. loss: 0.272  Val. score: 93.730%\n",
      "Epoch 7, 100% \t Train loss: 0.408 took: 16.89s  Val. loss: 0.267  Val. score: 93.820%\n",
      "Epoch 8, 100% \t Train loss: 0.380 took: 16.70s  Val. loss: 0.252  Val. score: 94.540%\n",
      "Epoch 9, 100% \t Train loss: 0.357 took: 16.86s  Val. loss: 0.244  Val. score: 94.378%\n",
      "Epoch 10, 100% \t Train loss: 0.344 took: 16.89s  Val. loss: 0.245  Val. score: 94.672%\n",
      "Training finished, took 221.775s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.494 took: 12.71s  Val. loss: 0.838  Val. score: 69.981%\n",
      "Epoch 2, 100% \t Train loss: 0.845 took: 13.79s  Val. loss: 0.524  Val. score: 87.664%\n",
      "Epoch 3, 100% \t Train loss: 0.654 took: 14.18s  Val. loss: 0.410  Val. score: 90.598%\n",
      "Epoch 4, 100% \t Train loss: 0.521 took: 17.03s  Val. loss: 0.297  Val. score: 93.406%\n",
      "Epoch 5, 100% \t Train loss: 0.428 took: 17.06s  Val. loss: 0.270  Val. score: 93.526%\n",
      "Epoch 6, 100% \t Train loss: 0.383 took: 16.85s  Val. loss: 0.257  Val. score: 93.910%\n",
      "Epoch 7, 100% \t Train loss: 0.346 took: 16.80s  Val. loss: 0.237  Val. score: 94.420%\n",
      "Epoch 8, 100% \t Train loss: 0.314 took: 17.00s  Val. loss: 0.231  Val. score: 94.912%\n",
      "Epoch 9, 100% \t Train loss: 0.308 took: 17.75s  Val. loss: 0.206  Val. score: 95.242%\n",
      "Epoch 10, 100% \t Train loss: 0.282 took: 17.04s  Val. loss: 0.207  Val. score: 95.704%\n",
      "Training finished, took 218.717s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.439 took: 12.39s  Val. loss: 0.913  Val. score: 64.725%\n",
      "Epoch 2, 100% \t Train loss: 0.889 took: 12.73s  Val. loss: 0.638  Val. score: 80.133%\n",
      "Epoch 3, 100% \t Train loss: 0.670 took: 16.30s  Val. loss: 0.529  Val. score: 87.550%\n",
      "Epoch 4, 100% \t Train loss: 0.548 took: 18.56s  Val. loss: 0.425  Val. score: 90.736%\n",
      "Epoch 5, 100% \t Train loss: 0.469 took: 17.18s  Val. loss: 0.303  Val. score: 93.436%\n",
      "Epoch 6, 100% \t Train loss: 0.396 took: 18.12s  Val. loss: 0.274  Val. score: 94.072%\n",
      "Epoch 7, 100% \t Train loss: 0.352 took: 18.29s  Val. loss: 0.243  Val. score: 94.528%\n",
      "Epoch 8, 100% \t Train loss: 0.322 took: 17.61s  Val. loss: 0.221  Val. score: 94.996%\n",
      "Epoch 9, 100% \t Train loss: 0.299 took: 17.32s  Val. loss: 0.225  Val. score: 95.164%\n",
      "Epoch 10, 100% \t Train loss: 0.291 took: 18.03s  Val. loss: 0.205  Val. score: 95.320%\n",
      "Training finished, took 225.214s\n",
      "\n",
      "Parameters configuration 22 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.024831518494088125\n",
      "h_sizes \t [784, 468, 288, 177, 110, 67, 53, 35, 19]\n",
      "penalty \t 0.00036120597610595965\n",
      "dropout \t 0.20578308659606792\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 95.2318 +/- 0.4259\n",
      "Time for evaluation: 666.8 s\n",
      "Estimated time to finish : 6.85 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.796 took: 10.96s  Val. loss: 0.266  Val. score: 92.650%\n",
      "Epoch 2, 100% \t Train loss: 0.253 took: 9.82s  Val. loss: 0.174  Val. score: 95.224%\n",
      "Epoch 3, 100% \t Train loss: 0.167 took: 10.75s  Val. loss: 0.145  Val. score: 95.902%\n",
      "Epoch 4, 100% \t Train loss: 0.120 took: 10.74s  Val. loss: 0.134  Val. score: 96.346%\n",
      "Epoch 5, 100% \t Train loss: 0.094 took: 9.65s  Val. loss: 0.121  Val. score: 96.736%\n",
      "Epoch 6, 100% \t Train loss: 0.076 took: 9.85s  Val. loss: 0.123  Val. score: 96.538%\n",
      "Epoch 7, 100% \t Train loss: 0.059 took: 9.65s  Val. loss: 0.117  Val. score: 97.084%\n",
      "Epoch 8, 100% \t Train loss: 0.050 took: 10.33s  Val. loss: 0.126  Val. score: 96.982%\n",
      "Epoch 9, 100% \t Train loss: 0.040 took: 10.66s  Val. loss: 0.121  Val. score: 97.306%\n",
      "Epoch 10, 100% \t Train loss: 0.031 took: 10.73s  Val. loss: 0.143  Val. score: 96.760%\n",
      "Training finished, took 153.881s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.823 took: 10.83s  Val. loss: 0.341  Val. score: 90.154%\n",
      "Epoch 2, 100% \t Train loss: 0.268 took: 9.79s  Val. loss: 0.208  Val. score: 94.306%\n",
      "Epoch 3, 100% \t Train loss: 0.175 took: 10.45s  Val. loss: 0.167  Val. score: 95.578%\n",
      "Epoch 4, 100% \t Train loss: 0.128 took: 9.75s  Val. loss: 0.139  Val. score: 96.280%\n",
      "Epoch 5, 100% \t Train loss: 0.096 took: 10.09s  Val. loss: 0.148  Val. score: 96.130%\n",
      "Epoch 6, 100% \t Train loss: 0.074 took: 9.62s  Val. loss: 0.127  Val. score: 96.766%\n",
      "Epoch 7, 100% \t Train loss: 0.059 took: 9.58s  Val. loss: 0.130  Val. score: 96.964%\n",
      "Epoch 8, 100% \t Train loss: 0.045 took: 9.61s  Val. loss: 0.124  Val. score: 97.210%\n",
      "Epoch 9, 100% \t Train loss: 0.043 took: 10.64s  Val. loss: 0.148  Val. score: 96.712%\n",
      "Epoch 10, 100% \t Train loss: 0.033 took: 10.21s  Val. loss: 0.142  Val. score: 97.096%\n",
      "Training finished, took 151.235s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.969 took: 10.46s  Val. loss: 0.342  Val. score: 90.454%\n",
      "Epoch 2, 100% \t Train loss: 0.280 took: 9.66s  Val. loss: 0.226  Val. score: 93.700%\n",
      "Epoch 3, 100% \t Train loss: 0.185 took: 9.66s  Val. loss: 0.181  Val. score: 95.194%\n",
      "Epoch 4, 100% \t Train loss: 0.143 took: 9.64s  Val. loss: 0.146  Val. score: 96.142%\n",
      "Epoch 5, 100% \t Train loss: 0.110 took: 9.62s  Val. loss: 0.142  Val. score: 96.208%\n",
      "Epoch 6, 100% \t Train loss: 0.089 took: 9.71s  Val. loss: 0.150  Val. score: 96.166%\n",
      "Epoch 7, 100% \t Train loss: 0.071 took: 9.67s  Val. loss: 0.132  Val. score: 96.808%\n",
      "Epoch 8, 100% \t Train loss: 0.059 took: 9.62s  Val. loss: 0.125  Val. score: 97.078%\n",
      "Epoch 9, 100% \t Train loss: 0.048 took: 9.62s  Val. loss: 0.140  Val. score: 96.664%\n",
      "Epoch 10, 100% \t Train loss: 0.043 took: 10.26s  Val. loss: 0.132  Val. score: 97.060%\n",
      "Training finished, took 147.834s\n",
      "\n",
      "Parameters configuration 23 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0037375582245386184\n",
      "h_sizes \t [784, 430, 219, 111, 52, 28, 14]\n",
      "penalty \t 0.002117449362733656\n",
      "dropout \t 0.024118614685061796\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 96.9719 +/- 0.1506\n",
      "Time for evaluation: 454.0 s\n",
      "Estimated time to finish : 6.89 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.454 took: 5.22s  Val. loss: 0.179  Val. score: 94.804%\n",
      "Epoch 2, 100% \t Train loss: 0.192 took: 5.21s  Val. loss: 0.146  Val. score: 95.884%\n",
      "Epoch 3, 100% \t Train loss: 0.149 took: 5.86s  Val. loss: 0.136  Val. score: 96.190%\n",
      "Epoch 4, 100% \t Train loss: 0.123 took: 5.65s  Val. loss: 0.125  Val. score: 96.442%\n",
      "Epoch 5, 100% \t Train loss: 0.105 took: 5.21s  Val. loss: 0.111  Val. score: 97.030%\n",
      "Epoch 6, 100% \t Train loss: 0.091 took: 5.53s  Val. loss: 0.113  Val. score: 96.898%\n",
      "Epoch 7, 100% \t Train loss: 0.079 took: 5.58s  Val. loss: 0.103  Val. score: 97.324%\n",
      "Epoch 8, 100% \t Train loss: 0.069 took: 5.78s  Val. loss: 0.111  Val. score: 97.156%\n",
      "Epoch 9, 100% \t Train loss: 0.063 took: 5.19s  Val. loss: 0.109  Val. score: 97.210%\n",
      "Epoch 10, 100% \t Train loss: 0.055 took: 5.23s  Val. loss: 0.113  Val. score: 97.168%\n",
      "Training finished, took 89.137s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.468 took: 5.61s  Val. loss: 0.194  Val. score: 94.222%\n",
      "Epoch 2, 100% \t Train loss: 0.205 took: 5.36s  Val. loss: 0.136  Val. score: 96.016%\n",
      "Epoch 3, 100% \t Train loss: 0.157 took: 5.27s  Val. loss: 0.117  Val. score: 96.646%\n",
      "Epoch 4, 100% \t Train loss: 0.133 took: 5.23s  Val. loss: 0.116  Val. score: 96.850%\n",
      "Epoch 5, 100% \t Train loss: 0.109 took: 5.21s  Val. loss: 0.115  Val. score: 96.868%\n",
      "Epoch 6, 100% \t Train loss: 0.095 took: 5.67s  Val. loss: 0.101  Val. score: 97.282%\n",
      "Epoch 7, 100% \t Train loss: 0.080 took: 5.62s  Val. loss: 0.109  Val. score: 97.252%\n",
      "Epoch 8, 100% \t Train loss: 0.072 took: 5.70s  Val. loss: 0.104  Val. score: 97.408%\n",
      "Epoch 9, 100% \t Train loss: 0.065 took: 5.66s  Val. loss: 0.099  Val. score: 97.474%\n",
      "Epoch 10, 100% \t Train loss: 0.059 took: 5.65s  Val. loss: 0.100  Val. score: 97.714%\n",
      "Training finished, took 89.847s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.462 took: 5.87s  Val. loss: 0.182  Val. score: 94.642%\n",
      "Epoch 2, 100% \t Train loss: 0.212 took: 5.34s  Val. loss: 0.143  Val. score: 95.704%\n",
      "Epoch 3, 100% \t Train loss: 0.161 took: 5.21s  Val. loss: 0.124  Val. score: 96.436%\n",
      "Epoch 4, 100% \t Train loss: 0.127 took: 5.29s  Val. loss: 0.116  Val. score: 96.790%\n",
      "Epoch 5, 100% \t Train loss: 0.113 took: 5.22s  Val. loss: 0.112  Val. score: 96.922%\n",
      "Epoch 6, 100% \t Train loss: 0.091 took: 5.22s  Val. loss: 0.109  Val. score: 97.168%\n",
      "Epoch 7, 100% \t Train loss: 0.081 took: 5.19s  Val. loss: 0.112  Val. score: 97.222%\n",
      "Epoch 8, 100% \t Train loss: 0.070 took: 5.47s  Val. loss: 0.105  Val. score: 97.264%\n",
      "Epoch 9, 100% \t Train loss: 0.061 took: 5.34s  Val. loss: 0.113  Val. score: 97.294%\n",
      "Epoch 10, 100% \t Train loss: 0.057 took: 5.39s  Val. loss: 0.097  Val. score: 97.588%\n",
      "Training finished, took 88.376s\n",
      "\n",
      "Parameters configuration 24 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.012272312085380009\n",
      "h_sizes \t [784, 263, 94, 30]\n",
      "penalty \t 0.00043829047995163636\n",
      "dropout \t 0.19739333582312293\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.4899 +/- 0.2334\n",
      "Time for evaluation: 268.4 s\n",
      "Estimated time to finish : 6.76 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.664 took: 5.16s  Val. loss: 0.257  Val. score: 92.608%\n",
      "Epoch 2, 100% \t Train loss: 0.256 took: 5.16s  Val. loss: 0.227  Val. score: 93.670%\n",
      "Epoch 3, 100% \t Train loss: 0.207 took: 5.40s  Val. loss: 0.200  Val. score: 94.330%\n",
      "Epoch 4, 100% \t Train loss: 0.184 took: 5.51s  Val. loss: 0.205  Val. score: 94.636%\n",
      "Epoch 5, 100% \t Train loss: 0.169 took: 5.40s  Val. loss: 0.202  Val. score: 94.528%\n",
      "Epoch 6, 100% \t Train loss: 0.151 took: 5.66s  Val. loss: 0.179  Val. score: 95.314%\n",
      "Epoch 7, 100% \t Train loss: 0.144 took: 5.26s  Val. loss: 0.177  Val. score: 95.266%\n",
      "Epoch 8, 100% \t Train loss: 0.134 took: 5.47s  Val. loss: 0.188  Val. score: 95.404%\n",
      "Epoch 9, 100% \t Train loss: 0.128 took: 5.46s  Val. loss: 0.177  Val. score: 95.470%\n",
      "Epoch 10, 100% \t Train loss: 0.122 took: 5.56s  Val. loss: 0.202  Val. score: 94.978%\n",
      "Training finished, took 88.498s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.592 took: 5.37s  Val. loss: 0.279  Val. score: 92.188%\n",
      "Epoch 2, 100% \t Train loss: 0.261 took: 5.16s  Val. loss: 0.232  Val. score: 93.358%\n",
      "Epoch 3, 100% \t Train loss: 0.215 took: 5.64s  Val. loss: 0.217  Val. score: 94.342%\n",
      "Epoch 4, 100% \t Train loss: 0.196 took: 5.58s  Val. loss: 0.226  Val. score: 93.412%\n",
      "Epoch 5, 100% \t Train loss: 0.184 took: 5.73s  Val. loss: 0.196  Val. score: 94.432%\n",
      "Epoch 6, 100% \t Train loss: 0.170 took: 5.60s  Val. loss: 0.206  Val. score: 94.546%\n",
      "Epoch 7, 100% \t Train loss: 0.159 took: 5.28s  Val. loss: 0.214  Val. score: 94.762%\n",
      "Epoch 8, 100% \t Train loss: 0.152 took: 5.37s  Val. loss: 0.215  Val. score: 94.288%\n",
      "Epoch 9, 100% \t Train loss: 0.147 took: 5.15s  Val. loss: 0.189  Val. score: 95.182%\n",
      "Epoch 10, 100% \t Train loss: 0.133 took: 5.56s  Val. loss: 0.185  Val. score: 95.032%\n",
      "Training finished, took 89.166s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.663 took: 5.74s  Val. loss: 0.298  Val. score: 91.738%\n",
      "Epoch 2, 100% \t Train loss: 0.255 took: 5.63s  Val. loss: 0.225  Val. score: 93.802%\n",
      "Epoch 3, 100% \t Train loss: 0.202 took: 5.53s  Val. loss: 0.210  Val. score: 94.126%\n",
      "Epoch 4, 100% \t Train loss: 0.174 took: 5.18s  Val. loss: 0.203  Val. score: 94.888%\n",
      "Epoch 5, 100% \t Train loss: 0.162 took: 5.14s  Val. loss: 0.197  Val. score: 94.852%\n",
      "Epoch 6, 100% \t Train loss: 0.152 took: 5.37s  Val. loss: 0.179  Val. score: 95.284%\n",
      "Epoch 7, 100% \t Train loss: 0.139 took: 5.60s  Val. loss: 0.200  Val. score: 95.158%\n",
      "Epoch 8, 100% \t Train loss: 0.122 took: 5.79s  Val. loss: 0.191  Val. score: 95.572%\n",
      "Epoch 9, 100% \t Train loss: 0.119 took: 5.28s  Val. loss: 0.159  Val. score: 95.704%\n",
      "Epoch 10, 100% \t Train loss: 0.113 took: 5.40s  Val. loss: 0.180  Val. score: 95.464%\n",
      "Training finished, took 89.111s\n",
      "\n",
      "Parameters configuration 25 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.06723057572401742\n",
      "h_sizes \t [784, 267, 91, 27]\n",
      "penalty \t 0.00393595620696589\n",
      "dropout \t 0.015304053870720952\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 95.1578 +/- 0.2175\n",
      "Time for evaluation: 267.9 s\n",
      "Estimated time to finish : 6.62 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.361 took: 6.17s  Val. loss: 2.303  Val. score: 9.378%\n",
      "Epoch 2, 100% \t Train loss: 2.305 took: 5.74s  Val. loss: 2.307  Val. score: 10.350%\n",
      "Epoch 3, 100% \t Train loss: 2.305 took: 6.68s  Val. loss: 2.308  Val. score: 10.140%\n",
      "Epoch 4, 100% \t Train loss: 2.305 took: 9.74s  Val. loss: 2.303  Val. score: 11.358%\n",
      "Epoch 5, 100% \t Train loss: 2.305 took: 8.85s  Val. loss: 2.305  Val. score: 11.358%\n",
      "Epoch 6, 100% \t Train loss: 2.306 took: 8.84s  Val. loss: 2.304  Val. score: 9.666%\n",
      "Epoch 7, 100% \t Train loss: 2.305 took: 8.85s  Val. loss: 2.304  Val. score: 10.140%\n",
      "Epoch 8, 100% \t Train loss: 2.306 took: 9.29s  Val. loss: 2.307  Val. score: 9.666%\n",
      "Epoch 9, 100% \t Train loss: 2.305 took: 9.43s  Val. loss: 2.307  Val. score: 10.350%\n",
      "Epoch 10, 100% \t Train loss: 2.305 took: 8.84s  Val. loss: 2.302  Val. score: 11.358%\n",
      "Training finished, took 123.102s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.250 took: 5.70s  Val. loss: 0.839  Val. score: 78.039%\n",
      "Epoch 2, 100% \t Train loss: 0.923 took: 6.18s  Val. loss: 0.880  Val. score: 75.975%\n",
      "Epoch 3, 100% \t Train loss: 0.996 took: 6.78s  Val. loss: 0.858  Val. score: 75.993%\n",
      "Epoch 4, 100% \t Train loss: 1.757 took: 8.98s  Val. loss: 1.773  Val. score: 27.211%\n",
      "Epoch 5, 100% \t Train loss: 2.178 took: 8.74s  Val. loss: 2.305  Val. score: 11.286%\n",
      "Epoch 6, 100% \t Train loss: 2.305 took: 9.27s  Val. loss: 2.304  Val. score: 11.286%\n",
      "Epoch 7, 100% \t Train loss: 2.304 took: 9.31s  Val. loss: 2.305  Val. score: 10.224%\n",
      "Epoch 8, 100% \t Train loss: 2.304 took: 9.41s  Val. loss: 2.302  Val. score: 10.464%\n",
      "Epoch 9, 100% \t Train loss: 2.303 took: 8.89s  Val. loss: 2.303  Val. score: 10.194%\n",
      "Epoch 10, 100% \t Train loss: 2.303 took: 9.51s  Val. loss: 2.305  Val. score: 9.642%\n",
      "Training finished, took 122.919s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.150 took: 5.75s  Val. loss: 0.726  Val. score: 76.707%\n",
      "Epoch 2, 100% \t Train loss: 0.891 took: 5.66s  Val. loss: 0.856  Val. score: 70.371%\n",
      "Epoch 3, 100% \t Train loss: 0.892 took: 6.72s  Val. loss: 0.771  Val. score: 77.409%\n",
      "Epoch 4, 100% \t Train loss: 0.933 took: 9.22s  Val. loss: 0.993  Val. score: 70.089%\n",
      "Epoch 5, 100% \t Train loss: 1.102 took: 8.82s  Val. loss: 0.952  Val. score: 65.337%\n",
      "Epoch 6, 100% \t Train loss: 1.446 took: 8.91s  Val. loss: 1.338  Val. score: 49.508%\n",
      "Epoch 7, 100% \t Train loss: 1.563 took: 9.18s  Val. loss: 1.290  Val. score: 50.798%\n",
      "Epoch 8, 100% \t Train loss: 1.365 took: 8.81s  Val. loss: 1.274  Val. score: 52.634%\n",
      "Epoch 9, 100% \t Train loss: 1.411 took: 8.76s  Val. loss: 1.311  Val. score: 51.350%\n",
      "Epoch 10, 100% \t Train loss: 1.424 took: 9.20s  Val. loss: 1.352  Val. score: 52.880%\n",
      "Training finished, took 120.816s\n",
      "\n",
      "Parameters configuration 26 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.06479253665954669\n",
      "h_sizes \t [784, 339, 138, 61, 25]\n",
      "penalty \t 0.0007461037497009363\n",
      "dropout \t 0.022221661748620586\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 24.6270 +/- 19.9903\n",
      "Time for evaluation: 367.9 s\n",
      "Estimated time to finish : 6.58 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.441 took: 3.62s  Val. loss: 0.211  Val. score: 93.712%\n",
      "Epoch 2, 100% \t Train loss: 0.176 took: 3.67s  Val. loss: 0.145  Val. score: 95.488%\n",
      "Epoch 3, 100% \t Train loss: 0.121 took: 3.43s  Val. loss: 0.120  Val. score: 96.292%\n",
      "Epoch 4, 100% \t Train loss: 0.094 took: 3.74s  Val. loss: 0.127  Val. score: 96.148%\n",
      "Epoch 5, 100% \t Train loss: 0.074 took: 3.54s  Val. loss: 0.127  Val. score: 96.412%\n",
      "Epoch 6, 100% \t Train loss: 0.062 took: 3.75s  Val. loss: 0.108  Val. score: 96.844%\n",
      "Epoch 7, 100% \t Train loss: 0.053 took: 3.36s  Val. loss: 0.107  Val. score: 96.886%\n",
      "Epoch 8, 100% \t Train loss: 0.047 took: 3.39s  Val. loss: 0.112  Val. score: 96.706%\n",
      "Epoch 9, 100% \t Train loss: 0.040 took: 3.57s  Val. loss: 0.107  Val. score: 97.126%\n",
      "Epoch 10, 100% \t Train loss: 0.035 took: 3.48s  Val. loss: 0.117  Val. score: 96.946%\n",
      "Training finished, took 65.042s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.442 took: 3.62s  Val. loss: 0.190  Val. score: 94.312%\n",
      "Epoch 2, 100% \t Train loss: 0.182 took: 3.49s  Val. loss: 0.141  Val. score: 95.734%\n",
      "Epoch 3, 100% \t Train loss: 0.128 took: 3.82s  Val. loss: 0.121  Val. score: 96.448%\n",
      "Epoch 4, 100% \t Train loss: 0.097 took: 3.84s  Val. loss: 0.116  Val. score: 96.586%\n",
      "Epoch 5, 100% \t Train loss: 0.079 took: 3.86s  Val. loss: 0.103  Val. score: 96.934%\n",
      "Epoch 6, 100% \t Train loss: 0.062 took: 3.39s  Val. loss: 0.100  Val. score: 97.132%\n",
      "Epoch 7, 100% \t Train loss: 0.052 took: 3.55s  Val. loss: 0.104  Val. score: 96.964%\n",
      "Epoch 8, 100% \t Train loss: 0.045 took: 3.56s  Val. loss: 0.094  Val. score: 97.372%\n",
      "Epoch 9, 100% \t Train loss: 0.040 took: 3.69s  Val. loss: 0.096  Val. score: 97.420%\n",
      "Epoch 10, 100% \t Train loss: 0.036 took: 3.79s  Val. loss: 0.100  Val. score: 97.414%\n",
      "Training finished, took 65.808s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.443 took: 3.78s  Val. loss: 0.217  Val. score: 93.220%\n",
      "Epoch 2, 100% \t Train loss: 0.185 took: 3.94s  Val. loss: 0.142  Val. score: 95.536%\n",
      "Epoch 3, 100% \t Train loss: 0.128 took: 3.55s  Val. loss: 0.124  Val. score: 96.136%\n",
      "Epoch 4, 100% \t Train loss: 0.096 took: 3.81s  Val. loss: 0.102  Val. score: 96.796%\n",
      "Epoch 5, 100% \t Train loss: 0.077 took: 3.81s  Val. loss: 0.106  Val. score: 96.844%\n",
      "Epoch 6, 100% \t Train loss: 0.062 took: 3.48s  Val. loss: 0.095  Val. score: 97.138%\n",
      "Epoch 7, 100% \t Train loss: 0.053 took: 3.97s  Val. loss: 0.104  Val. score: 97.102%\n",
      "Epoch 8, 100% \t Train loss: 0.043 took: 3.85s  Val. loss: 0.095  Val. score: 97.348%\n",
      "Epoch 9, 100% \t Train loss: 0.043 took: 3.82s  Val. loss: 0.101  Val. score: 97.186%\n",
      "Epoch 10, 100% \t Train loss: 0.033 took: 3.80s  Val. loss: 0.100  Val. score: 97.240%\n",
      "Training finished, took 67.325s\n",
      "\n",
      "Parameters configuration 27 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0022685081965030263\n",
      "h_sizes \t [784, 175, 44]\n",
      "penalty \t 0.0007358991309055099\n",
      "dropout \t 0.06944058101777792\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.1999 +/- 0.1932\n",
      "Time for evaluation: 199.3 s\n",
      "Estimated time to finish : 6.40 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.623 took: 7.25s  Val. loss: 1.554  Val. score: 36.529%\n",
      "Epoch 2, 100% \t Train loss: 1.459 took: 6.69s  Val. loss: 1.022  Val. score: 68.091%\n",
      "Epoch 3, 100% \t Train loss: 1.108 took: 6.75s  Val. loss: 0.800  Val. score: 77.451%\n",
      "Epoch 4, 100% \t Train loss: 1.129 took: 6.82s  Val. loss: 0.729  Val. score: 77.655%\n",
      "Epoch 5, 100% \t Train loss: 0.953 took: 7.13s  Val. loss: 0.634  Val. score: 82.485%\n",
      "Epoch 6, 100% \t Train loss: 0.766 took: 7.44s  Val. loss: 0.622  Val. score: 83.217%\n",
      "Epoch 7, 100% \t Train loss: 0.694 took: 7.50s  Val. loss: 0.532  Val. score: 86.355%\n",
      "Epoch 8, 100% \t Train loss: 0.676 took: 6.79s  Val. loss: 0.507  Val. score: 87.526%\n",
      "Epoch 9, 100% \t Train loss: 0.642 took: 7.04s  Val. loss: 0.497  Val. score: 88.552%\n",
      "Epoch 10, 100% \t Train loss: 0.582 took: 6.73s  Val. loss: 0.432  Val. score: 89.824%\n",
      "Training finished, took 109.415s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.560 took: 7.25s  Val. loss: 0.570  Val. score: 83.145%\n",
      "Epoch 2, 100% \t Train loss: 0.664 took: 7.41s  Val. loss: 0.367  Val. score: 90.388%\n",
      "Epoch 3, 100% \t Train loss: 0.525 took: 6.99s  Val. loss: 0.339  Val. score: 91.492%\n",
      "Epoch 4, 100% \t Train loss: 0.461 took: 7.55s  Val. loss: 0.291  Val. score: 92.236%\n",
      "Epoch 5, 100% \t Train loss: 0.409 took: 6.68s  Val. loss: 0.282  Val. score: 93.094%\n",
      "Epoch 6, 100% \t Train loss: 0.393 took: 7.47s  Val. loss: 0.296  Val. score: 93.340%\n",
      "Epoch 7, 100% \t Train loss: 0.380 took: 7.60s  Val. loss: 0.272  Val. score: 93.184%\n",
      "Epoch 8, 100% \t Train loss: 0.351 took: 7.46s  Val. loss: 0.253  Val. score: 93.634%\n",
      "Epoch 9, 100% \t Train loss: 0.336 took: 7.44s  Val. loss: 0.237  Val. score: 94.168%\n",
      "Epoch 10, 100% \t Train loss: 0.323 took: 7.05s  Val. loss: 0.250  Val. score: 93.994%\n",
      "Training finished, took 112.251s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.957 took: 6.66s  Val. loss: 0.714  Val. score: 75.543%\n",
      "Epoch 2, 100% \t Train loss: 0.763 took: 7.26s  Val. loss: 0.473  Val. score: 85.563%\n",
      "Epoch 3, 100% \t Train loss: 0.603 took: 6.88s  Val. loss: 0.392  Val. score: 89.308%\n",
      "Epoch 4, 100% \t Train loss: 0.487 took: 6.72s  Val. loss: 0.302  Val. score: 91.954%\n",
      "Epoch 5, 100% \t Train loss: 0.417 took: 6.76s  Val. loss: 0.282  Val. score: 92.650%\n",
      "Epoch 6, 100% \t Train loss: 0.394 took: 6.91s  Val. loss: 0.267  Val. score: 93.292%\n",
      "Epoch 7, 100% \t Train loss: 0.349 took: 7.49s  Val. loss: 0.255  Val. score: 93.910%\n",
      "Epoch 8, 100% \t Train loss: 0.326 took: 7.72s  Val. loss: 0.290  Val. score: 93.664%\n",
      "Epoch 9, 100% \t Train loss: 0.323 took: 7.34s  Val. loss: 0.252  Val. score: 94.096%\n",
      "Epoch 10, 100% \t Train loss: 0.305 took: 8.40s  Val. loss: 0.231  Val. score: 94.468%\n",
      "Training finished, took 111.650s\n",
      "\n",
      "Parameters configuration 28 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.08757971625802691\n",
      "h_sizes \t [784, 337, 133, 63, 27]\n",
      "penalty \t 0.0016404753846861236\n",
      "dropout \t 0.1704594243661044\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 92.7617 +/- 2.0866\n",
      "Time for evaluation: 334.4 s\n",
      "Estimated time to finish : 6.32 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.975 took: 9.34s  Val. loss: 0.312  Val. score: 91.924%\n",
      "Epoch 2, 100% \t Train loss: 0.388 took: 9.13s  Val. loss: 0.213  Val. score: 94.612%\n",
      "Epoch 3, 100% \t Train loss: 0.282 took: 8.41s  Val. loss: 0.171  Val. score: 95.746%\n",
      "Epoch 4, 100% \t Train loss: 0.238 took: 8.76s  Val. loss: 0.157  Val. score: 96.370%\n",
      "Epoch 5, 100% \t Train loss: 0.205 took: 9.48s  Val. loss: 0.136  Val. score: 96.814%\n",
      "Epoch 6, 100% \t Train loss: 0.173 took: 8.37s  Val. loss: 0.144  Val. score: 96.934%\n",
      "Epoch 7, 100% \t Train loss: 0.152 took: 8.60s  Val. loss: 0.129  Val. score: 97.204%\n",
      "Epoch 8, 100% \t Train loss: 0.139 took: 9.34s  Val. loss: 0.129  Val. score: 97.282%\n",
      "Epoch 9, 100% \t Train loss: 0.131 took: 8.51s  Val. loss: 0.131  Val. score: 97.330%\n",
      "Epoch 10, 100% \t Train loss: 0.113 took: 8.50s  Val. loss: 0.147  Val. score: 97.090%\n",
      "Training finished, took 133.987s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.849 took: 8.65s  Val. loss: 0.297  Val. score: 92.074%\n",
      "Epoch 2, 100% \t Train loss: 0.389 took: 8.78s  Val. loss: 0.204  Val. score: 94.840%\n",
      "Epoch 3, 100% \t Train loss: 0.289 took: 9.01s  Val. loss: 0.181  Val. score: 95.374%\n",
      "Epoch 4, 100% \t Train loss: 0.244 took: 9.58s  Val. loss: 0.158  Val. score: 96.268%\n",
      "Epoch 5, 100% \t Train loss: 0.208 took: 9.10s  Val. loss: 0.166  Val. score: 96.142%\n",
      "Epoch 6, 100% \t Train loss: 0.183 took: 8.63s  Val. loss: 0.146  Val. score: 96.568%\n",
      "Epoch 7, 100% \t Train loss: 0.157 took: 8.64s  Val. loss: 0.153  Val. score: 96.730%\n",
      "Epoch 8, 100% \t Train loss: 0.136 took: 8.39s  Val. loss: 0.148  Val. score: 96.862%\n",
      "Epoch 9, 100% \t Train loss: 0.126 took: 9.17s  Val. loss: 0.144  Val. score: 97.066%\n",
      "Epoch 10, 100% \t Train loss: 0.116 took: 8.37s  Val. loss: 0.150  Val. score: 97.036%\n",
      "Training finished, took 134.221s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.927 took: 8.45s  Val. loss: 0.332  Val. score: 91.732%\n",
      "Epoch 2, 100% \t Train loss: 0.389 took: 8.40s  Val. loss: 0.207  Val. score: 94.744%\n",
      "Epoch 3, 100% \t Train loss: 0.280 took: 9.52s  Val. loss: 0.158  Val. score: 95.914%\n",
      "Epoch 4, 100% \t Train loss: 0.223 took: 9.68s  Val. loss: 0.154  Val. score: 96.298%\n",
      "Epoch 5, 100% \t Train loss: 0.195 took: 9.58s  Val. loss: 0.153  Val. score: 96.196%\n",
      "Epoch 6, 100% \t Train loss: 0.164 took: 8.73s  Val. loss: 0.138  Val. score: 96.916%\n",
      "Epoch 7, 100% \t Train loss: 0.153 took: 8.39s  Val. loss: 0.138  Val. score: 97.042%\n",
      "Epoch 8, 100% \t Train loss: 0.140 took: 8.37s  Val. loss: 0.129  Val. score: 97.126%\n",
      "Epoch 9, 100% \t Train loss: 0.124 took: 9.11s  Val. loss: 0.147  Val. score: 97.024%\n",
      "Epoch 10, 100% \t Train loss: 0.121 took: 9.04s  Val. loss: 0.134  Val. score: 97.144%\n",
      "Training finished, took 135.115s\n",
      "\n",
      "Parameters configuration 29 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005463180649674213\n",
      "h_sizes \t [784, 401, 178, 96, 47, 13]\n",
      "penalty \t 0.00038441639031711674\n",
      "dropout \t 0.19787745502231469\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.0899 +/- 0.0441\n",
      "Time for evaluation: 404.4 s\n",
      "Estimated time to finish : 6.29 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.652 took: 19.93s  Val. loss: 1.315  Val. score: 52.568%\n",
      "Epoch 2, 100% \t Train loss: 1.161 took: 19.81s  Val. loss: 0.955  Val. score: 68.883%\n",
      "Epoch 3, 100% \t Train loss: 0.809 took: 22.73s  Val. loss: 0.771  Val. score: 85.545%\n",
      "Epoch 4, 100% \t Train loss: 0.607 took: 24.63s  Val. loss: 0.523  Val. score: 90.838%\n",
      "Epoch 5, 100% \t Train loss: 0.379 took: 24.68s  Val. loss: 0.326  Val. score: 92.356%\n",
      "Epoch 6, 100% \t Train loss: 0.260 took: 24.59s  Val. loss: 0.264  Val. score: 94.852%\n",
      "Epoch 7, 100% \t Train loss: 0.208 took: 23.93s  Val. loss: 0.285  Val. score: 95.566%\n",
      "Epoch 8, 100% \t Train loss: 0.176 took: 24.56s  Val. loss: 0.259  Val. score: 95.818%\n",
      "Epoch 9, 100% \t Train loss: 0.142 took: 25.13s  Val. loss: 0.247  Val. score: 95.908%\n",
      "Epoch 10, 100% \t Train loss: 0.122 took: 27.51s  Val. loss: 0.276  Val. score: 96.370%\n",
      "Training finished, took 313.600s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.485 took: 17.84s  Val. loss: 1.030  Val. score: 57.938%\n",
      "Epoch 2, 100% \t Train loss: 0.866 took: 18.47s  Val. loss: 0.614  Val. score: 82.269%\n",
      "Epoch 3, 100% \t Train loss: 0.487 took: 21.27s  Val. loss: 0.394  Val. score: 89.752%\n",
      "Epoch 4, 100% \t Train loss: 0.328 took: 24.31s  Val. loss: 0.328  Val. score: 93.436%\n",
      "Epoch 5, 100% \t Train loss: 0.254 took: 23.80s  Val. loss: 0.283  Val. score: 94.378%\n",
      "Epoch 6, 100% \t Train loss: 0.216 took: 24.46s  Val. loss: 0.255  Val. score: 94.816%\n",
      "Epoch 7, 100% \t Train loss: 0.184 took: 23.56s  Val. loss: 0.255  Val. score: 95.440%\n",
      "Epoch 8, 100% \t Train loss: 0.160 took: 25.22s  Val. loss: 0.277  Val. score: 95.716%\n",
      "Epoch 9, 100% \t Train loss: 0.140 took: 25.12s  Val. loss: 0.339  Val. score: 95.932%\n",
      "Epoch 10, 100% \t Train loss: 0.127 took: 24.73s  Val. loss: 0.263  Val. score: 95.224%\n",
      "Training finished, took 305.114s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.497 took: 19.79s  Val. loss: 1.128  Val. score: 61.934%\n",
      "Epoch 2, 100% \t Train loss: 0.896 took: 19.15s  Val. loss: 0.816  Val. score: 70.185%\n",
      "Epoch 3, 100% \t Train loss: 0.674 took: 22.21s  Val. loss: 0.586  Val. score: 78.045%\n",
      "Epoch 4, 100% \t Train loss: 0.448 took: 24.79s  Val. loss: 0.415  Val. score: 89.002%\n",
      "Epoch 5, 100% \t Train loss: 0.334 took: 23.33s  Val. loss: 0.370  Val. score: 94.066%\n",
      "Epoch 6, 100% \t Train loss: 0.230 took: 26.31s  Val. loss: 0.306  Val. score: 94.708%\n",
      "Epoch 7, 100% \t Train loss: 0.188 took: 28.07s  Val. loss: 0.274  Val. score: 95.176%\n",
      "Epoch 8, 100% \t Train loss: 0.145 took: 28.61s  Val. loss: 0.270  Val. score: 95.554%\n",
      "Epoch 9, 100% \t Train loss: 0.132 took: 27.43s  Val. loss: 0.358  Val. score: 95.674%\n",
      "Epoch 10, 100% \t Train loss: 0.129 took: 28.86s  Val. loss: 0.276  Val. score: 95.542%\n",
      "Training finished, took 325.793s\n",
      "\n",
      "Parameters configuration 30 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.010632654292244742\n",
      "h_sizes \t [784, 546, 392, 283, 209, 147, 103, 67, 48, 32, 23, 17]\n",
      "penalty \t 0.0007470420122055038\n",
      "dropout \t 0.04179890660931143\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 95.7118 +/- 0.4831\n",
      "Time for evaluation: 945.6 s\n",
      "Estimated time to finish : 6.61 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.471 took: 6.44s  Val. loss: 0.231  Val. score: 93.934%\n",
      "Epoch 2, 100% \t Train loss: 0.216 took: 6.36s  Val. loss: 0.162  Val. score: 95.746%\n",
      "Epoch 3, 100% \t Train loss: 0.185 took: 6.38s  Val. loss: 0.166  Val. score: 95.674%\n",
      "Epoch 4, 100% \t Train loss: 0.157 took: 7.11s  Val. loss: 0.154  Val. score: 96.502%\n",
      "Epoch 5, 100% \t Train loss: 0.144 took: 7.17s  Val. loss: 0.160  Val. score: 96.214%\n",
      "Epoch 6, 100% \t Train loss: 0.132 took: 7.83s  Val. loss: 0.156  Val. score: 96.490%\n",
      "Epoch 7, 100% \t Train loss: 0.131 took: 7.19s  Val. loss: 0.148  Val. score: 96.880%\n",
      "Epoch 8, 100% \t Train loss: 0.117 took: 7.36s  Val. loss: 0.172  Val. score: 96.430%\n",
      "Epoch 9, 100% \t Train loss: 0.124 took: 7.82s  Val. loss: 0.147  Val. score: 96.844%\n",
      "Epoch 10, 100% \t Train loss: 0.118 took: 8.23s  Val. loss: 0.188  Val. score: 96.070%\n",
      "Training finished, took 113.513s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.514 took: 6.65s  Val. loss: 0.224  Val. score: 93.616%\n",
      "Epoch 2, 100% \t Train loss: 0.228 took: 6.65s  Val. loss: 0.161  Val. score: 95.440%\n",
      "Epoch 3, 100% \t Train loss: 0.182 took: 6.47s  Val. loss: 0.143  Val. score: 96.100%\n",
      "Epoch 4, 100% \t Train loss: 0.162 took: 7.24s  Val. loss: 0.173  Val. score: 95.662%\n",
      "Epoch 5, 100% \t Train loss: 0.152 took: 7.23s  Val. loss: 0.135  Val. score: 96.184%\n",
      "Epoch 6, 100% \t Train loss: 0.134 took: 7.79s  Val. loss: 0.129  Val. score: 96.622%\n",
      "Epoch 7, 100% \t Train loss: 0.135 took: 7.66s  Val. loss: 0.134  Val. score: 96.838%\n",
      "Epoch 8, 100% \t Train loss: 0.137 took: 7.88s  Val. loss: 0.132  Val. score: 96.700%\n",
      "Epoch 9, 100% \t Train loss: 0.112 took: 7.93s  Val. loss: 0.128  Val. score: 97.066%\n",
      "Epoch 10, 100% \t Train loss: 0.124 took: 7.74s  Val. loss: 0.121  Val. score: 96.964%\n",
      "Training finished, took 114.557s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.471 took: 6.68s  Val. loss: 0.209  Val. score: 94.168%\n",
      "Epoch 2, 100% \t Train loss: 0.217 took: 6.14s  Val. loss: 0.177  Val. score: 95.260%\n",
      "Epoch 3, 100% \t Train loss: 0.174 took: 7.14s  Val. loss: 0.147  Val. score: 96.136%\n",
      "Epoch 4, 100% \t Train loss: 0.162 took: 7.42s  Val. loss: 0.145  Val. score: 96.274%\n",
      "Epoch 5, 100% \t Train loss: 0.150 took: 7.09s  Val. loss: 0.149  Val. score: 96.046%\n",
      "Epoch 6, 100% \t Train loss: 0.142 took: 7.17s  Val. loss: 0.161  Val. score: 96.520%\n",
      "Epoch 7, 100% \t Train loss: 0.128 took: 7.87s  Val. loss: 0.160  Val. score: 96.766%\n",
      "Epoch 8, 100% \t Train loss: 0.125 took: 7.77s  Val. loss: 0.142  Val. score: 97.012%\n",
      "Epoch 9, 100% \t Train loss: 0.107 took: 7.76s  Val. loss: 0.157  Val. score: 96.862%\n",
      "Epoch 10, 100% \t Train loss: 0.113 took: 7.55s  Val. loss: 0.145  Val. score: 96.892%\n",
      "Training finished, took 114.253s\n",
      "\n",
      "Parameters configuration 31 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0069911336794631984\n",
      "h_sizes \t [784, 347, 137, 75, 38]\n",
      "penalty \t 0.0013936926163150459\n",
      "dropout \t 0.15706341389059042\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.6419 +/- 0.4055\n",
      "Time for evaluation: 343.4 s\n",
      "Estimated time to finish : 6.52 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.773 took: 10.71s  Val. loss: 0.301  Val. score: 92.122%\n",
      "Epoch 2, 100% \t Train loss: 0.274 took: 10.41s  Val. loss: 0.195  Val. score: 94.996%\n",
      "Epoch 3, 100% \t Train loss: 0.204 took: 10.75s  Val. loss: 0.175  Val. score: 95.662%\n",
      "Epoch 4, 100% \t Train loss: 0.160 took: 10.59s  Val. loss: 0.167  Val. score: 96.160%\n",
      "Epoch 5, 100% \t Train loss: 0.137 took: 10.80s  Val. loss: 0.147  Val. score: 96.430%\n",
      "Epoch 6, 100% \t Train loss: 0.117 took: 10.82s  Val. loss: 0.162  Val. score: 96.454%\n",
      "Epoch 7, 100% \t Train loss: 0.103 took: 10.76s  Val. loss: 0.181  Val. score: 96.508%\n",
      "Epoch 8, 100% \t Train loss: 0.086 took: 10.81s  Val. loss: 0.128  Val. score: 97.246%\n",
      "Epoch 9, 100% \t Train loss: 0.077 took: 11.68s  Val. loss: 0.162  Val. score: 96.712%\n",
      "Epoch 10, 100% \t Train loss: 0.072 took: 11.39s  Val. loss: 0.136  Val. score: 97.036%\n",
      "Training finished, took 164.728s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.871 took: 9.68s  Val. loss: 0.325  Val. score: 91.006%\n",
      "Epoch 2, 100% \t Train loss: 0.289 took: 9.58s  Val. loss: 0.203  Val. score: 94.888%\n",
      "Epoch 3, 100% \t Train loss: 0.209 took: 10.01s  Val. loss: 0.172  Val. score: 95.878%\n",
      "Epoch 4, 100% \t Train loss: 0.166 took: 10.72s  Val. loss: 0.168  Val. score: 96.016%\n",
      "Epoch 5, 100% \t Train loss: 0.145 took: 11.69s  Val. loss: 0.170  Val. score: 95.806%\n",
      "Epoch 6, 100% \t Train loss: 0.124 took: 12.11s  Val. loss: 0.166  Val. score: 96.208%\n",
      "Epoch 7, 100% \t Train loss: 0.101 took: 11.97s  Val. loss: 0.184  Val. score: 95.530%\n",
      "Epoch 8, 100% \t Train loss: 0.093 took: 11.80s  Val. loss: 0.153  Val. score: 96.442%\n",
      "Epoch 9, 100% \t Train loss: 0.091 took: 11.83s  Val. loss: 0.133  Val. score: 97.156%\n",
      "Epoch 10, 100% \t Train loss: 0.071 took: 11.06s  Val. loss: 0.156  Val. score: 96.586%\n",
      "Training finished, took 166.315s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.820 took: 10.28s  Val. loss: 0.308  Val. score: 92.140%\n",
      "Epoch 2, 100% \t Train loss: 0.273 took: 9.57s  Val. loss: 0.248  Val. score: 93.412%\n",
      "Epoch 3, 100% \t Train loss: 0.205 took: 10.96s  Val. loss: 0.176  Val. score: 95.698%\n",
      "Epoch 4, 100% \t Train loss: 0.160 took: 10.69s  Val. loss: 0.206  Val. score: 94.990%\n",
      "Epoch 5, 100% \t Train loss: 0.136 took: 11.90s  Val. loss: 0.151  Val. score: 96.514%\n",
      "Epoch 6, 100% \t Train loss: 0.112 took: 11.99s  Val. loss: 0.164  Val. score: 96.430%\n",
      "Epoch 7, 100% \t Train loss: 0.097 took: 12.17s  Val. loss: 0.139  Val. score: 96.742%\n",
      "Epoch 8, 100% \t Train loss: 0.100 took: 12.08s  Val. loss: 0.187  Val. score: 95.842%\n",
      "Epoch 9, 100% \t Train loss: 0.083 took: 10.92s  Val. loss: 0.150  Val. score: 96.850%\n",
      "Epoch 10, 100% \t Train loss: 0.071 took: 11.13s  Val. loss: 0.130  Val. score: 97.294%\n",
      "Training finished, took 167.414s\n",
      "\n",
      "Parameters configuration 32 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0021287263431801905\n",
      "h_sizes \t [784, 450, 255, 152, 88, 52, 34, 21]\n",
      "penalty \t 0.0003767441373445643\n",
      "dropout \t 0.08879184491684924\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.9719 +/- 0.2926\n",
      "Time for evaluation: 499.5 s\n",
      "Estimated time to finish : 6.52 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.548 took: 6.04s  Val. loss: 0.228  Val. score: 93.394%\n",
      "Epoch 2, 100% \t Train loss: 0.215 took: 6.42s  Val. loss: 0.204  Val. score: 94.654%\n",
      "Epoch 3, 100% \t Train loss: 0.165 took: 6.22s  Val. loss: 0.140  Val. score: 96.292%\n",
      "Epoch 4, 100% \t Train loss: 0.136 took: 5.89s  Val. loss: 0.130  Val. score: 96.496%\n",
      "Epoch 5, 100% \t Train loss: 0.112 took: 5.81s  Val. loss: 0.136  Val. score: 96.514%\n",
      "Epoch 6, 100% \t Train loss: 0.111 took: 6.43s  Val. loss: 0.116  Val. score: 97.150%\n",
      "Epoch 7, 100% \t Train loss: 0.093 took: 6.42s  Val. loss: 0.112  Val. score: 97.366%\n",
      "Epoch 8, 100% \t Train loss: 0.084 took: 6.53s  Val. loss: 0.125  Val. score: 96.994%\n",
      "Epoch 9, 100% \t Train loss: 0.078 took: 6.21s  Val. loss: 0.116  Val. score: 97.186%\n",
      "Epoch 10, 100% \t Train loss: 0.074 took: 6.29s  Val. loss: 0.110  Val. score: 97.492%\n",
      "Training finished, took 102.239s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.546 took: 6.50s  Val. loss: 0.199  Val. score: 94.402%\n",
      "Epoch 2, 100% \t Train loss: 0.219 took: 5.81s  Val. loss: 0.162  Val. score: 95.542%\n",
      "Epoch 3, 100% \t Train loss: 0.163 took: 6.49s  Val. loss: 0.142  Val. score: 96.028%\n",
      "Epoch 4, 100% \t Train loss: 0.137 took: 6.45s  Val. loss: 0.131  Val. score: 96.376%\n",
      "Epoch 5, 100% \t Train loss: 0.111 took: 6.26s  Val. loss: 0.129  Val. score: 96.580%\n",
      "Epoch 6, 100% \t Train loss: 0.102 took: 6.45s  Val. loss: 0.126  Val. score: 96.778%\n",
      "Epoch 7, 100% \t Train loss: 0.100 took: 6.53s  Val. loss: 0.116  Val. score: 96.994%\n",
      "Epoch 8, 100% \t Train loss: 0.081 took: 6.38s  Val. loss: 0.116  Val. score: 97.120%\n",
      "Epoch 9, 100% \t Train loss: 0.080 took: 6.38s  Val. loss: 0.140  Val. score: 96.946%\n",
      "Epoch 10, 100% \t Train loss: 0.072 took: 6.42s  Val. loss: 0.125  Val. score: 97.084%\n",
      "Training finished, took 103.680s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.607 took: 6.33s  Val. loss: 0.199  Val. score: 94.402%\n",
      "Epoch 2, 100% \t Train loss: 0.222 took: 6.30s  Val. loss: 0.163  Val. score: 95.584%\n",
      "Epoch 3, 100% \t Train loss: 0.170 took: 5.78s  Val. loss: 0.133  Val. score: 96.466%\n",
      "Epoch 4, 100% \t Train loss: 0.140 took: 5.83s  Val. loss: 0.129  Val. score: 96.736%\n",
      "Epoch 5, 100% \t Train loss: 0.113 took: 6.34s  Val. loss: 0.153  Val. score: 96.358%\n",
      "Epoch 6, 100% \t Train loss: 0.102 took: 5.87s  Val. loss: 0.127  Val. score: 96.982%\n",
      "Epoch 7, 100% \t Train loss: 0.090 took: 5.79s  Val. loss: 0.139  Val. score: 96.898%\n",
      "Epoch 8, 100% \t Train loss: 0.084 took: 6.18s  Val. loss: 0.130  Val. score: 97.060%\n",
      "Epoch 9, 100% \t Train loss: 0.080 took: 6.25s  Val. loss: 0.136  Val. score: 97.036%\n",
      "Epoch 10, 100% \t Train loss: 0.073 took: 6.59s  Val. loss: 0.128  Val. score: 97.228%\n",
      "Training finished, took 101.318s\n",
      "\n",
      "Parameters configuration 33 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003741655765113136\n",
      "h_sizes \t [784, 333, 153, 54, 20]\n",
      "penalty \t 0.0016537518033419882\n",
      "dropout \t 0.14829619534702204\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.2679 +/- 0.1690\n",
      "Time for evaluation: 308.3 s\n",
      "Estimated time to finish : 6.40 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.482 took: 3.71s  Val. loss: 0.285  Val. score: 92.170%\n",
      "Epoch 2, 100% \t Train loss: 0.312 took: 3.56s  Val. loss: 0.230  Val. score: 93.922%\n",
      "Epoch 3, 100% \t Train loss: 0.284 took: 3.62s  Val. loss: 0.228  Val. score: 93.826%\n",
      "Epoch 4, 100% \t Train loss: 0.283 took: 4.29s  Val. loss: 0.235  Val. score: 94.270%\n",
      "Epoch 5, 100% \t Train loss: 0.282 took: 4.24s  Val. loss: 0.249  Val. score: 93.172%\n",
      "Epoch 6, 100% \t Train loss: 0.258 took: 4.28s  Val. loss: 0.220  Val. score: 94.570%\n",
      "Epoch 7, 100% \t Train loss: 0.264 took: 4.30s  Val. loss: 0.237  Val. score: 93.940%\n",
      "Epoch 8, 100% \t Train loss: 0.244 took: 4.32s  Val. loss: 0.225  Val. score: 94.798%\n",
      "Epoch 9, 100% \t Train loss: 0.248 took: 4.44s  Val. loss: 0.233  Val. score: 94.822%\n",
      "Epoch 10, 100% \t Train loss: 0.235 took: 4.66s  Val. loss: 0.247  Val. score: 94.756%\n",
      "Training finished, took 70.806s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.640 took: 3.71s  Val. loss: 0.269  Val. score: 92.656%\n",
      "Epoch 2, 100% \t Train loss: 0.368 took: 3.72s  Val. loss: 0.227  Val. score: 94.000%\n",
      "Epoch 3, 100% \t Train loss: 0.321 took: 3.92s  Val. loss: 0.206  Val. score: 94.516%\n",
      "Epoch 4, 100% \t Train loss: 0.289 took: 4.73s  Val. loss: 0.224  Val. score: 94.276%\n",
      "Epoch 5, 100% \t Train loss: 0.298 took: 4.70s  Val. loss: 0.212  Val. score: 94.906%\n",
      "Epoch 6, 100% \t Train loss: 0.288 took: 4.76s  Val. loss: 0.222  Val. score: 94.480%\n",
      "Epoch 7, 100% \t Train loss: 0.272 took: 4.67s  Val. loss: 0.250  Val. score: 94.234%\n",
      "Epoch 8, 100% \t Train loss: 0.261 took: 4.70s  Val. loss: 0.196  Val. score: 95.140%\n",
      "Epoch 9, 100% \t Train loss: 0.250 took: 4.68s  Val. loss: 0.242  Val. score: 94.414%\n",
      "Epoch 10, 100% \t Train loss: 0.249 took: 4.41s  Val. loss: 0.230  Val. score: 94.720%\n",
      "Training finished, took 73.418s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.511 took: 3.47s  Val. loss: 0.296  Val. score: 92.248%\n",
      "Epoch 2, 100% \t Train loss: 0.325 took: 3.61s  Val. loss: 0.244  Val. score: 93.790%\n",
      "Epoch 3, 100% \t Train loss: 0.294 took: 3.80s  Val. loss: 0.230  Val. score: 93.730%\n",
      "Epoch 4, 100% \t Train loss: 0.291 took: 4.34s  Val. loss: 0.234  Val. score: 94.264%\n",
      "Epoch 5, 100% \t Train loss: 0.264 took: 4.64s  Val. loss: 0.226  Val. score: 93.946%\n",
      "Epoch 6, 100% \t Train loss: 0.264 took: 4.40s  Val. loss: 0.249  Val. score: 94.000%\n",
      "Epoch 7, 100% \t Train loss: 0.252 took: 4.77s  Val. loss: 0.245  Val. score: 94.462%\n",
      "Epoch 8, 100% \t Train loss: 0.242 took: 4.72s  Val. loss: 0.246  Val. score: 94.570%\n",
      "Epoch 9, 100% \t Train loss: 0.257 took: 4.38s  Val. loss: 0.251  Val. score: 94.066%\n",
      "Epoch 10, 100% \t Train loss: 0.245 took: 4.58s  Val. loss: 0.245  Val. score: 94.528%\n",
      "Training finished, took 72.159s\n",
      "\n",
      "Parameters configuration 34 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.025457731517690266\n",
      "h_sizes \t [784, 183, 30]\n",
      "penalty \t 0.002755013287716881\n",
      "dropout \t 0.1501461702043529\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 94.6678 +/- 0.1001\n",
      "Time for evaluation: 217.5 s\n",
      "Estimated time to finish : 6.24 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.544 took: 4.39s  Val. loss: 0.269  Val. score: 92.134%\n",
      "Epoch 2, 100% \t Train loss: 0.252 took: 4.26s  Val. loss: 0.190  Val. score: 94.432%\n",
      "Epoch 3, 100% \t Train loss: 0.188 took: 4.28s  Val. loss: 0.157  Val. score: 95.308%\n",
      "Epoch 4, 100% \t Train loss: 0.148 took: 4.41s  Val. loss: 0.134  Val. score: 96.034%\n",
      "Epoch 5, 100% \t Train loss: 0.125 took: 4.29s  Val. loss: 0.123  Val. score: 96.334%\n",
      "Epoch 6, 100% \t Train loss: 0.107 took: 4.44s  Val. loss: 0.115  Val. score: 96.610%\n",
      "Epoch 7, 100% \t Train loss: 0.095 took: 4.37s  Val. loss: 0.110  Val. score: 96.778%\n",
      "Epoch 8, 100% \t Train loss: 0.082 took: 4.01s  Val. loss: 0.099  Val. score: 97.012%\n",
      "Epoch 9, 100% \t Train loss: 0.073 took: 4.48s  Val. loss: 0.105  Val. score: 96.844%\n",
      "Epoch 10, 100% \t Train loss: 0.066 took: 4.45s  Val. loss: 0.098  Val. score: 97.180%\n",
      "Training finished, took 73.509s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.559 took: 4.42s  Val. loss: 0.268  Val. score: 92.344%\n",
      "Epoch 2, 100% \t Train loss: 0.266 took: 4.27s  Val. loss: 0.197  Val. score: 94.228%\n",
      "Epoch 3, 100% \t Train loss: 0.204 took: 4.01s  Val. loss: 0.156  Val. score: 95.230%\n",
      "Epoch 4, 100% \t Train loss: 0.165 took: 4.46s  Val. loss: 0.142  Val. score: 95.740%\n",
      "Epoch 5, 100% \t Train loss: 0.136 took: 4.48s  Val. loss: 0.119  Val. score: 96.316%\n",
      "Epoch 6, 100% \t Train loss: 0.114 took: 4.36s  Val. loss: 0.109  Val. score: 96.682%\n",
      "Epoch 7, 100% \t Train loss: 0.100 took: 4.01s  Val. loss: 0.101  Val. score: 96.844%\n",
      "Epoch 8, 100% \t Train loss: 0.085 took: 4.45s  Val. loss: 0.096  Val. score: 97.000%\n",
      "Epoch 9, 100% \t Train loss: 0.074 took: 4.44s  Val. loss: 0.094  Val. score: 97.108%\n",
      "Epoch 10, 100% \t Train loss: 0.067 took: 4.39s  Val. loss: 0.094  Val. score: 97.024%\n",
      "Training finished, took 73.658s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.546 took: 4.37s  Val. loss: 0.268  Val. score: 92.062%\n",
      "Epoch 2, 100% \t Train loss: 0.254 took: 4.46s  Val. loss: 0.188  Val. score: 94.270%\n",
      "Epoch 3, 100% \t Train loss: 0.188 took: 4.39s  Val. loss: 0.152  Val. score: 95.374%\n",
      "Epoch 4, 100% \t Train loss: 0.152 took: 4.46s  Val. loss: 0.132  Val. score: 95.974%\n",
      "Epoch 5, 100% \t Train loss: 0.124 took: 4.13s  Val. loss: 0.120  Val. score: 96.454%\n",
      "Epoch 6, 100% \t Train loss: 0.108 took: 4.02s  Val. loss: 0.108  Val. score: 96.622%\n",
      "Epoch 7, 100% \t Train loss: 0.092 took: 3.98s  Val. loss: 0.104  Val. score: 96.862%\n",
      "Epoch 8, 100% \t Train loss: 0.082 took: 4.19s  Val. loss: 0.096  Val. score: 97.072%\n",
      "Epoch 9, 100% \t Train loss: 0.070 took: 4.34s  Val. loss: 0.095  Val. score: 97.054%\n",
      "Epoch 10, 100% \t Train loss: 0.064 took: 3.98s  Val. loss: 0.093  Val. score: 97.210%\n",
      "Training finished, took 72.561s\n",
      "\n",
      "Parameters configuration 35 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0032995417282049846\n",
      "h_sizes \t [784, 197, 39]\n",
      "penalty \t 0.0010151013795989521\n",
      "dropout \t 0.12506344595368327\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.1379 +/- 0.0815\n",
      "Time for evaluation: 220.8 s\n",
      "Estimated time to finish : 6.08 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.345 took: 3.92s  Val. loss: 0.178  Val. score: 94.744%\n",
      "Epoch 2, 100% \t Train loss: 0.139 took: 3.87s  Val. loss: 0.132  Val. score: 95.770%\n",
      "Epoch 3, 100% \t Train loss: 0.091 took: 3.91s  Val. loss: 0.129  Val. score: 96.010%\n",
      "Epoch 4, 100% \t Train loss: 0.070 took: 3.53s  Val. loss: 0.108  Val. score: 96.772%\n",
      "Epoch 5, 100% \t Train loss: 0.054 took: 3.90s  Val. loss: 0.103  Val. score: 96.940%\n",
      "Epoch 6, 100% \t Train loss: 0.041 took: 3.88s  Val. loss: 0.114  Val. score: 96.904%\n",
      "Epoch 7, 100% \t Train loss: 0.039 took: 3.78s  Val. loss: 0.119  Val. score: 97.012%\n",
      "Epoch 8, 100% \t Train loss: 0.032 took: 3.85s  Val. loss: 0.123  Val. score: 96.586%\n",
      "Epoch 9, 100% \t Train loss: 0.032 took: 3.66s  Val. loss: 0.125  Val. score: 96.886%\n",
      "Epoch 10, 100% \t Train loss: 0.029 took: 3.51s  Val. loss: 0.126  Val. score: 97.036%\n",
      "Training finished, took 67.441s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.358 took: 3.77s  Val. loss: 0.182  Val. score: 94.462%\n",
      "Epoch 2, 100% \t Train loss: 0.146 took: 3.63s  Val. loss: 0.145  Val. score: 95.554%\n",
      "Epoch 3, 100% \t Train loss: 0.100 took: 3.63s  Val. loss: 0.102  Val. score: 96.928%\n",
      "Epoch 4, 100% \t Train loss: 0.076 took: 3.86s  Val. loss: 0.110  Val. score: 96.844%\n",
      "Epoch 5, 100% \t Train loss: 0.060 took: 3.89s  Val. loss: 0.114  Val. score: 96.832%\n",
      "Epoch 6, 100% \t Train loss: 0.049 took: 3.87s  Val. loss: 0.115  Val. score: 96.874%\n",
      "Epoch 7, 100% \t Train loss: 0.042 took: 3.91s  Val. loss: 0.130  Val. score: 96.640%\n",
      "Epoch 8, 100% \t Train loss: 0.036 took: 3.87s  Val. loss: 0.121  Val. score: 97.054%\n",
      "Epoch 9, 100% \t Train loss: 0.032 took: 3.82s  Val. loss: 0.127  Val. score: 96.922%\n",
      "Epoch 10, 100% \t Train loss: 0.027 took: 3.70s  Val. loss: 0.121  Val. score: 97.150%\n",
      "Training finished, took 67.603s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.346 took: 3.78s  Val. loss: 0.178  Val. score: 94.756%\n",
      "Epoch 2, 100% \t Train loss: 0.138 took: 3.77s  Val. loss: 0.152  Val. score: 95.308%\n",
      "Epoch 3, 100% \t Train loss: 0.092 took: 3.87s  Val. loss: 0.130  Val. score: 96.136%\n",
      "Epoch 4, 100% \t Train loss: 0.069 took: 3.89s  Val. loss: 0.124  Val. score: 96.460%\n",
      "Epoch 5, 100% \t Train loss: 0.056 took: 3.69s  Val. loss: 0.130  Val. score: 96.388%\n",
      "Epoch 6, 100% \t Train loss: 0.047 took: 3.92s  Val. loss: 0.129  Val. score: 96.436%\n",
      "Epoch 7, 100% \t Train loss: 0.040 took: 3.90s  Val. loss: 0.149  Val. score: 96.190%\n",
      "Epoch 8, 100% \t Train loss: 0.034 took: 3.88s  Val. loss: 0.144  Val. score: 96.724%\n",
      "Epoch 9, 100% \t Train loss: 0.036 took: 3.87s  Val. loss: 0.130  Val. score: 96.832%\n",
      "Epoch 10, 100% \t Train loss: 0.027 took: 3.85s  Val. loss: 0.127  Val. score: 97.078%\n",
      "Training finished, took 68.305s\n",
      "\n",
      "Parameters configuration 36 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004504684081232467\n",
      "h_sizes \t [784, 186, 42]\n",
      "penalty \t 0.0012362445175824873\n",
      "dropout \t 0.007205433363865726\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.0879 +/- 0.0471\n",
      "Time for evaluation: 204.4 s\n",
      "Estimated time to finish : 5.92 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.868 took: 12.97s  Val. loss: 1.471  Val. score: 42.632%\n",
      "Epoch 2, 100% \t Train loss: 1.506 took: 11.77s  Val. loss: 1.218  Val. score: 51.158%\n",
      "Epoch 3, 100% \t Train loss: 1.317 took: 12.83s  Val. loss: 1.048  Val. score: 56.198%\n",
      "Epoch 4, 100% \t Train loss: 1.188 took: 12.97s  Val. loss: 0.957  Val. score: 60.626%\n",
      "Epoch 5, 100% \t Train loss: 1.104 took: 12.50s  Val. loss: 0.889  Val. score: 62.775%\n",
      "Epoch 6, 100% \t Train loss: 1.043 took: 12.16s  Val. loss: 0.840  Val. score: 64.713%\n",
      "Epoch 7, 100% \t Train loss: 1.001 took: 11.81s  Val. loss: 0.802  Val. score: 66.825%\n",
      "Epoch 8, 100% \t Train loss: 0.959 took: 12.87s  Val. loss: 0.773  Val. score: 67.929%\n",
      "Epoch 9, 100% \t Train loss: 0.923 took: 12.81s  Val. loss: 0.747  Val. score: 70.419%\n",
      "Epoch 10, 100% \t Train loss: 0.885 took: 13.30s  Val. loss: 0.726  Val. score: 71.391%\n",
      "Training finished, took 193.952s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.608 took: 13.22s  Val. loss: 1.154  Val. score: 50.288%\n",
      "Epoch 2, 100% \t Train loss: 1.253 took: 13.23s  Val. loss: 0.957  Val. score: 58.034%\n",
      "Epoch 3, 100% \t Train loss: 1.099 took: 13.34s  Val. loss: 0.829  Val. score: 70.365%\n",
      "Epoch 4, 100% \t Train loss: 0.961 took: 13.08s  Val. loss: 0.697  Val. score: 78.573%\n",
      "Epoch 5, 100% \t Train loss: 0.851 took: 13.09s  Val. loss: 0.591  Val. score: 83.895%\n",
      "Epoch 6, 100% \t Train loss: 0.765 took: 13.14s  Val. loss: 0.509  Val. score: 86.325%\n",
      "Epoch 7, 100% \t Train loss: 0.688 took: 12.02s  Val. loss: 0.449  Val. score: 88.708%\n",
      "Epoch 8, 100% \t Train loss: 0.643 took: 11.95s  Val. loss: 0.412  Val. score: 89.440%\n",
      "Epoch 9, 100% \t Train loss: 0.597 took: 13.28s  Val. loss: 0.382  Val. score: 90.436%\n",
      "Epoch 10, 100% \t Train loss: 0.563 took: 12.48s  Val. loss: 0.355  Val. score: 91.222%\n",
      "Training finished, took 196.707s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.878 took: 13.12s  Val. loss: 1.688  Val. score: 29.965%\n",
      "Epoch 2, 100% \t Train loss: 1.641 took: 13.51s  Val. loss: 1.415  Val. score: 31.453%\n",
      "Epoch 3, 100% \t Train loss: 1.442 took: 13.43s  Val. loss: 1.259  Val. score: 45.464%\n",
      "Epoch 4, 100% \t Train loss: 1.292 took: 11.84s  Val. loss: 1.032  Val. score: 54.776%\n",
      "Epoch 5, 100% \t Train loss: 1.152 took: 11.79s  Val. loss: 0.916  Val. score: 60.260%\n",
      "Epoch 6, 100% \t Train loss: 1.046 took: 11.79s  Val. loss: 0.839  Val. score: 63.675%\n",
      "Epoch 7, 100% \t Train loss: 0.965 took: 13.68s  Val. loss: 0.770  Val. score: 72.339%\n",
      "Epoch 8, 100% \t Train loss: 0.905 took: 13.34s  Val. loss: 0.694  Val. score: 76.371%\n",
      "Epoch 9, 100% \t Train loss: 0.839 took: 12.39s  Val. loss: 0.634  Val. score: 77.547%\n",
      "Epoch 10, 100% \t Train loss: 0.771 took: 12.42s  Val. loss: 0.570  Val. score: 80.229%\n",
      "Training finished, took 194.720s\n",
      "\n",
      "Parameters configuration 37 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0013932052244325511\n",
      "h_sizes \t [784, 511, 351, 239, 167, 119, 90, 64, 41, 30, 21]\n",
      "penalty \t 0.0006291177690433944\n",
      "dropout \t 0.09223801249857536\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 80.9472 +/- 8.1118\n",
      "Time for evaluation: 586.5 s\n",
      "Estimated time to finish : 5.95 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.541 took: 11.19s  Val. loss: 1.001  Val. score: 68.913%\n",
      "Epoch 2, 100% \t Train loss: 0.934 took: 12.29s  Val. loss: 0.852  Val. score: 74.469%\n",
      "Epoch 3, 100% \t Train loss: 0.725 took: 12.28s  Val. loss: 0.660  Val. score: 83.421%\n",
      "Epoch 4, 100% \t Train loss: 0.500 took: 12.24s  Val. loss: 0.425  Val. score: 92.188%\n",
      "Epoch 5, 100% \t Train loss: 0.302 took: 12.36s  Val. loss: 0.360  Val. score: 92.122%\n",
      "Epoch 6, 100% \t Train loss: 0.220 took: 12.48s  Val. loss: 0.267  Val. score: 94.732%\n",
      "Epoch 7, 100% \t Train loss: 0.156 took: 12.70s  Val. loss: 0.310  Val. score: 95.602%\n",
      "Epoch 8, 100% \t Train loss: 0.126 took: 11.81s  Val. loss: 0.288  Val. score: 95.884%\n",
      "Epoch 9, 100% \t Train loss: 0.106 took: 11.32s  Val. loss: 0.301  Val. score: 95.626%\n",
      "Epoch 10, 100% \t Train loss: 0.094 took: 11.39s  Val. loss: 0.285  Val. score: 96.148%\n",
      "Training finished, took 187.128s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.979 took: 12.32s  Val. loss: 1.725  Val. score: 29.611%\n",
      "Epoch 2, 100% \t Train loss: 1.550 took: 12.43s  Val. loss: 1.235  Val. score: 52.142%\n",
      "Epoch 3, 100% \t Train loss: 0.897 took: 11.74s  Val. loss: 0.622  Val. score: 83.361%\n",
      "Epoch 4, 100% \t Train loss: 0.478 took: 12.44s  Val. loss: 0.438  Val. score: 87.213%\n",
      "Epoch 5, 100% \t Train loss: 0.318 took: 11.26s  Val. loss: 0.287  Val. score: 93.964%\n",
      "Epoch 6, 100% \t Train loss: 0.240 took: 11.30s  Val. loss: 0.303  Val. score: 93.154%\n",
      "Epoch 7, 100% \t Train loss: 0.198 took: 11.53s  Val. loss: 0.276  Val. score: 94.762%\n",
      "Epoch 8, 100% \t Train loss: 0.174 took: 12.44s  Val. loss: 0.265  Val. score: 95.344%\n",
      "Epoch 9, 100% \t Train loss: 0.154 took: 12.14s  Val. loss: 0.260  Val. score: 95.578%\n",
      "Epoch 10, 100% \t Train loss: 0.136 took: 12.16s  Val. loss: 0.246  Val. score: 95.848%\n",
      "Training finished, took 188.028s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.741 took: 12.27s  Val. loss: 1.044  Val. score: 59.996%\n",
      "Epoch 2, 100% \t Train loss: 0.856 took: 12.39s  Val. loss: 0.649  Val. score: 73.257%\n",
      "Epoch 3, 100% \t Train loss: 0.523 took: 12.40s  Val. loss: 0.373  Val. score: 91.048%\n",
      "Epoch 4, 100% \t Train loss: 0.310 took: 11.77s  Val. loss: 0.280  Val. score: 93.640%\n",
      "Epoch 5, 100% \t Train loss: 0.233 took: 12.32s  Val. loss: 0.215  Val. score: 95.122%\n",
      "Epoch 6, 100% \t Train loss: 0.192 took: 12.59s  Val. loss: 0.207  Val. score: 95.548%\n",
      "Epoch 7, 100% \t Train loss: 0.161 took: 12.54s  Val. loss: 0.193  Val. score: 95.992%\n",
      "Epoch 8, 100% \t Train loss: 0.140 took: 11.25s  Val. loss: 0.176  Val. score: 96.130%\n",
      "Epoch 9, 100% \t Train loss: 0.122 took: 11.26s  Val. loss: 0.174  Val. score: 96.322%\n",
      "Epoch 10, 100% \t Train loss: 0.108 took: 11.27s  Val. loss: 0.180  Val. score: 96.340%\n",
      "Training finished, took 187.381s\n",
      "\n",
      "Parameters configuration 38 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.029307138561685975\n",
      "h_sizes \t [784, 510, 342, 228, 150, 102, 67, 44, 30, 20, 11]\n",
      "penalty \t 0.0010636771090013963\n",
      "dropout \t 0.024510586706943338\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.1118 +/- 0.2025\n",
      "Time for evaluation: 563.6 s\n",
      "Estimated time to finish : 5.96 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.116 took: 7.28s  Val. loss: 0.334  Val. score: 91.054%\n",
      "Epoch 2, 100% \t Train loss: 0.393 took: 7.23s  Val. loss: 0.289  Val. score: 92.494%\n",
      "Epoch 3, 100% \t Train loss: 0.320 took: 7.67s  Val. loss: 0.258  Val. score: 93.358%\n",
      "Epoch 4, 100% \t Train loss: 0.273 took: 10.25s  Val. loss: 0.217  Val. score: 94.030%\n",
      "Epoch 5, 100% \t Train loss: 0.251 took: 9.51s  Val. loss: 0.212  Val. score: 94.372%\n",
      "Epoch 6, 100% \t Train loss: 0.246 took: 9.74s  Val. loss: 0.239  Val. score: 94.030%\n",
      "Epoch 7, 100% \t Train loss: 0.229 took: 9.96s  Val. loss: 0.221  Val. score: 94.378%\n",
      "Epoch 8, 100% \t Train loss: 0.212 took: 9.50s  Val. loss: 0.215  Val. score: 94.822%\n",
      "Epoch 9, 100% \t Train loss: 0.207 took: 9.50s  Val. loss: 0.213  Val. score: 95.128%\n",
      "Epoch 10, 100% \t Train loss: 0.197 took: 9.50s  Val. loss: 0.209  Val. score: 94.786%\n",
      "Training finished, took 130.313s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.643 took: 6.69s  Val. loss: 1.930  Val. score: 22.087%\n",
      "Epoch 2, 100% \t Train loss: 1.463 took: 6.72s  Val. loss: 0.846  Val. score: 70.935%\n",
      "Epoch 3, 100% \t Train loss: 0.593 took: 7.43s  Val. loss: 0.328  Val. score: 91.432%\n",
      "Epoch 4, 100% \t Train loss: 0.358 took: 10.42s  Val. loss: 0.265  Val. score: 93.166%\n",
      "Epoch 5, 100% \t Train loss: 0.299 took: 9.98s  Val. loss: 0.264  Val. score: 93.364%\n",
      "Epoch 6, 100% \t Train loss: 0.268 took: 9.74s  Val. loss: 0.242  Val. score: 93.520%\n",
      "Epoch 7, 100% \t Train loss: 0.252 took: 10.09s  Val. loss: 0.250  Val. score: 93.832%\n",
      "Epoch 8, 100% \t Train loss: 0.228 took: 9.65s  Val. loss: 0.238  Val. score: 93.976%\n",
      "Epoch 9, 100% \t Train loss: 0.219 took: 9.72s  Val. loss: 0.216  Val. score: 94.702%\n",
      "Epoch 10, 100% \t Train loss: 0.212 took: 9.83s  Val. loss: 0.215  Val. score: 94.690%\n",
      "Training finished, took 130.243s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.108 took: 7.10s  Val. loss: 0.347  Val. score: 90.850%\n",
      "Epoch 2, 100% \t Train loss: 0.404 took: 7.04s  Val. loss: 0.295  Val. score: 92.020%\n",
      "Epoch 3, 100% \t Train loss: 0.327 took: 7.92s  Val. loss: 0.280  Val. score: 92.476%\n",
      "Epoch 4, 100% \t Train loss: 0.292 took: 10.54s  Val. loss: 0.253  Val. score: 93.346%\n",
      "Epoch 5, 100% \t Train loss: 0.283 took: 10.07s  Val. loss: 0.250  Val. score: 93.208%\n",
      "Epoch 6, 100% \t Train loss: 0.261 took: 10.25s  Val. loss: 0.265  Val. score: 93.244%\n",
      "Epoch 7, 100% \t Train loss: 0.248 took: 9.90s  Val. loss: 0.235  Val. score: 93.916%\n",
      "Epoch 8, 100% \t Train loss: 0.243 took: 10.07s  Val. loss: 0.248  Val. score: 94.054%\n",
      "Epoch 9, 100% \t Train loss: 0.224 took: 10.13s  Val. loss: 0.252  Val. score: 93.970%\n",
      "Epoch 10, 100% \t Train loss: 0.223 took: 10.09s  Val. loss: 0.216  Val. score: 94.426%\n",
      "Training finished, took 132.958s\n",
      "\n",
      "Parameters configuration 39 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.07989313039520105\n",
      "h_sizes \t [784, 335, 153, 56, 28]\n",
      "penalty \t 0.0002574505377671439\n",
      "dropout \t 0.041814844211557706\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 94.6338 +/- 0.1522\n",
      "Time for evaluation: 394.6 s\n",
      "Estimated time to finish : 5.88 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.592 took: 4.27s  Val. loss: 0.239  Val. score: 92.770%\n",
      "Epoch 2, 100% \t Train loss: 0.258 took: 4.25s  Val. loss: 0.174  Val. score: 94.870%\n",
      "Epoch 3, 100% \t Train loss: 0.200 took: 4.60s  Val. loss: 0.151  Val. score: 95.536%\n",
      "Epoch 4, 100% \t Train loss: 0.174 took: 5.45s  Val. loss: 0.146  Val. score: 95.812%\n",
      "Epoch 5, 100% \t Train loss: 0.156 took: 5.33s  Val. loss: 0.155  Val. score: 95.554%\n",
      "Epoch 6, 100% \t Train loss: 0.145 took: 5.25s  Val. loss: 0.146  Val. score: 95.938%\n",
      "Epoch 7, 100% \t Train loss: 0.134 took: 5.33s  Val. loss: 0.138  Val. score: 96.322%\n",
      "Epoch 8, 100% \t Train loss: 0.132 took: 5.30s  Val. loss: 0.143  Val. score: 96.028%\n",
      "Epoch 9, 100% \t Train loss: 0.117 took: 5.27s  Val. loss: 0.135  Val. score: 96.250%\n",
      "Epoch 10, 100% \t Train loss: 0.107 took: 4.97s  Val. loss: 0.138  Val. score: 96.376%\n",
      "Training finished, took 80.415s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.529 took: 4.32s  Val. loss: 0.193  Val. score: 94.252%\n",
      "Epoch 2, 100% \t Train loss: 0.249 took: 4.30s  Val. loss: 0.170  Val. score: 95.248%\n",
      "Epoch 3, 100% \t Train loss: 0.209 took: 4.56s  Val. loss: 0.153  Val. score: 95.572%\n",
      "Epoch 4, 100% \t Train loss: 0.183 took: 5.51s  Val. loss: 0.149  Val. score: 95.620%\n",
      "Epoch 5, 100% \t Train loss: 0.167 took: 5.00s  Val. loss: 0.144  Val. score: 95.914%\n",
      "Epoch 6, 100% \t Train loss: 0.151 took: 5.04s  Val. loss: 0.144  Val. score: 95.944%\n",
      "Epoch 7, 100% \t Train loss: 0.144 took: 5.01s  Val. loss: 0.151  Val. score: 96.016%\n",
      "Epoch 8, 100% \t Train loss: 0.142 took: 5.46s  Val. loss: 0.146  Val. score: 96.142%\n",
      "Epoch 9, 100% \t Train loss: 0.137 took: 5.02s  Val. loss: 0.144  Val. score: 96.214%\n",
      "Epoch 10, 100% \t Train loss: 0.126 took: 5.38s  Val. loss: 0.152  Val. score: 96.148%\n",
      "Training finished, took 79.634s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.541 took: 4.29s  Val. loss: 0.243  Val. score: 92.944%\n",
      "Epoch 2, 100% \t Train loss: 0.250 took: 4.32s  Val. loss: 0.185  Val. score: 94.612%\n",
      "Epoch 3, 100% \t Train loss: 0.218 took: 4.54s  Val. loss: 0.174  Val. score: 94.972%\n",
      "Epoch 4, 100% \t Train loss: 0.195 took: 5.12s  Val. loss: 0.185  Val. score: 94.780%\n",
      "Epoch 5, 100% \t Train loss: 0.172 took: 5.38s  Val. loss: 0.153  Val. score: 95.770%\n",
      "Epoch 6, 100% \t Train loss: 0.153 took: 5.08s  Val. loss: 0.159  Val. score: 95.824%\n",
      "Epoch 7, 100% \t Train loss: 0.152 took: 5.43s  Val. loss: 0.150  Val. score: 95.704%\n",
      "Epoch 8, 100% \t Train loss: 0.135 took: 5.34s  Val. loss: 0.143  Val. score: 96.142%\n",
      "Epoch 9, 100% \t Train loss: 0.131 took: 5.38s  Val. loss: 0.154  Val. score: 96.304%\n",
      "Epoch 10, 100% \t Train loss: 0.123 took: 5.16s  Val. loss: 0.150  Val. score: 96.118%\n",
      "Training finished, took 80.156s\n",
      "\n",
      "Parameters configuration 40 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.04803514391905041\n",
      "h_sizes \t [784, 192, 47]\n",
      "penalty \t 0.0004257497161773112\n",
      "dropout \t 0.1260080804874128\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.2138 +/- 0.1152\n",
      "Time for evaluation: 241.3 s\n",
      "Estimated time to finish : 5.74 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.488 took: 6.97s  Val. loss: 0.207  Val. score: 93.988%\n",
      "Epoch 2, 100% \t Train loss: 0.176 took: 7.64s  Val. loss: 0.171  Val. score: 95.074%\n",
      "Epoch 3, 100% \t Train loss: 0.125 took: 8.08s  Val. loss: 0.117  Val. score: 96.778%\n",
      "Epoch 4, 100% \t Train loss: 0.093 took: 7.99s  Val. loss: 0.110  Val. score: 97.042%\n",
      "Epoch 5, 100% \t Train loss: 0.073 took: 8.73s  Val. loss: 0.111  Val. score: 97.090%\n",
      "Epoch 6, 100% \t Train loss: 0.060 took: 8.17s  Val. loss: 0.105  Val. score: 97.348%\n",
      "Epoch 7, 100% \t Train loss: 0.048 took: 8.42s  Val. loss: 0.112  Val. score: 97.186%\n",
      "Epoch 8, 100% \t Train loss: 0.043 took: 8.44s  Val. loss: 0.113  Val. score: 97.204%\n",
      "Epoch 9, 100% \t Train loss: 0.031 took: 8.30s  Val. loss: 0.110  Val. score: 97.486%\n",
      "Epoch 10, 100% \t Train loss: 0.028 took: 7.95s  Val. loss: 0.122  Val. score: 97.438%\n",
      "Training finished, took 122.118s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.478 took: 7.67s  Val. loss: 0.200  Val. score: 94.024%\n",
      "Epoch 2, 100% \t Train loss: 0.170 took: 7.84s  Val. loss: 0.148  Val. score: 95.560%\n",
      "Epoch 3, 100% \t Train loss: 0.122 took: 7.33s  Val. loss: 0.128  Val. score: 96.160%\n",
      "Epoch 4, 100% \t Train loss: 0.093 took: 8.01s  Val. loss: 0.120  Val. score: 96.682%\n",
      "Epoch 5, 100% \t Train loss: 0.074 took: 7.96s  Val. loss: 0.114  Val. score: 96.922%\n",
      "Epoch 6, 100% \t Train loss: 0.062 took: 8.81s  Val. loss: 0.108  Val. score: 97.198%\n",
      "Epoch 7, 100% \t Train loss: 0.051 took: 8.89s  Val. loss: 0.115  Val. score: 97.198%\n",
      "Epoch 8, 100% \t Train loss: 0.044 took: 8.29s  Val. loss: 0.104  Val. score: 97.366%\n",
      "Epoch 9, 100% \t Train loss: 0.035 took: 8.55s  Val. loss: 0.124  Val. score: 97.348%\n",
      "Epoch 10, 100% \t Train loss: 0.030 took: 8.84s  Val. loss: 0.118  Val. score: 97.300%\n",
      "Training finished, took 123.757s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.462 took: 7.41s  Val. loss: 0.183  Val. score: 94.672%\n",
      "Epoch 2, 100% \t Train loss: 0.166 took: 6.97s  Val. loss: 0.134  Val. score: 96.262%\n",
      "Epoch 3, 100% \t Train loss: 0.119 took: 7.96s  Val. loss: 0.116  Val. score: 96.664%\n",
      "Epoch 4, 100% \t Train loss: 0.090 took: 8.70s  Val. loss: 0.101  Val. score: 97.204%\n",
      "Epoch 5, 100% \t Train loss: 0.072 took: 8.40s  Val. loss: 0.104  Val. score: 97.126%\n",
      "Epoch 6, 100% \t Train loss: 0.058 took: 7.92s  Val. loss: 0.112  Val. score: 97.162%\n",
      "Epoch 7, 100% \t Train loss: 0.050 took: 7.92s  Val. loss: 0.113  Val. score: 97.240%\n",
      "Epoch 8, 100% \t Train loss: 0.041 took: 7.94s  Val. loss: 0.113  Val. score: 97.606%\n",
      "Epoch 9, 100% \t Train loss: 0.034 took: 8.38s  Val. loss: 0.101  Val. score: 97.486%\n",
      "Epoch 10, 100% \t Train loss: 0.027 took: 7.93s  Val. loss: 0.108  Val. score: 97.630%\n",
      "Training finished, took 121.025s\n",
      "\n",
      "Parameters configuration 41 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.011556485370558839\n",
      "h_sizes \t [784, 345, 137, 59, 27]\n",
      "penalty \t 0.0056089614308257995\n",
      "dropout \t 0.055375331457938576\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.4559 +/- 0.1353\n",
      "Time for evaluation: 368.0 s\n",
      "Estimated time to finish : 5.66 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.507 took: 4.31s  Val. loss: 0.193  Val. score: 94.216%\n",
      "Epoch 2, 100% \t Train loss: 0.222 took: 4.09s  Val. loss: 0.145  Val. score: 95.812%\n",
      "Epoch 3, 100% \t Train loss: 0.178 took: 4.15s  Val. loss: 0.125  Val. score: 96.280%\n",
      "Epoch 4, 100% \t Train loss: 0.146 took: 4.55s  Val. loss: 0.117  Val. score: 96.610%\n",
      "Epoch 5, 100% \t Train loss: 0.132 took: 4.49s  Val. loss: 0.116  Val. score: 96.730%\n",
      "Epoch 6, 100% \t Train loss: 0.117 took: 4.43s  Val. loss: 0.104  Val. score: 97.018%\n",
      "Epoch 7, 100% \t Train loss: 0.103 took: 4.53s  Val. loss: 0.098  Val. score: 97.204%\n",
      "Epoch 8, 100% \t Train loss: 0.093 took: 4.07s  Val. loss: 0.101  Val. score: 97.234%\n",
      "Epoch 9, 100% \t Train loss: 0.086 took: 4.09s  Val. loss: 0.102  Val. score: 97.138%\n",
      "Epoch 10, 100% \t Train loss: 0.079 took: 4.13s  Val. loss: 0.097  Val. score: 97.384%\n",
      "Training finished, took 78.513s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.499 took: 4.62s  Val. loss: 0.190  Val. score: 94.330%\n",
      "Epoch 2, 100% \t Train loss: 0.221 took: 4.10s  Val. loss: 0.144  Val. score: 95.764%\n",
      "Epoch 3, 100% \t Train loss: 0.168 took: 4.12s  Val. loss: 0.138  Val. score: 95.944%\n",
      "Epoch 4, 100% \t Train loss: 0.142 took: 4.27s  Val. loss: 0.124  Val. score: 96.454%\n",
      "Epoch 5, 100% \t Train loss: 0.126 took: 4.59s  Val. loss: 0.112  Val. score: 96.916%\n",
      "Epoch 6, 100% \t Train loss: 0.112 took: 4.52s  Val. loss: 0.113  Val. score: 96.826%\n",
      "Epoch 7, 100% \t Train loss: 0.100 took: 4.08s  Val. loss: 0.108  Val. score: 97.138%\n",
      "Epoch 8, 100% \t Train loss: 0.090 took: 4.10s  Val. loss: 0.110  Val. score: 97.126%\n",
      "Epoch 9, 100% \t Train loss: 0.082 took: 4.37s  Val. loss: 0.102  Val. score: 97.210%\n",
      "Epoch 10, 100% \t Train loss: 0.076 took: 4.54s  Val. loss: 0.104  Val. score: 97.246%\n",
      "Training finished, took 78.549s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.539 took: 4.15s  Val. loss: 0.229  Val. score: 93.466%\n",
      "Epoch 2, 100% \t Train loss: 0.238 took: 4.15s  Val. loss: 0.175  Val. score: 94.984%\n",
      "Epoch 3, 100% \t Train loss: 0.187 took: 4.20s  Val. loss: 0.154  Val. score: 95.596%\n",
      "Epoch 4, 100% \t Train loss: 0.162 took: 4.10s  Val. loss: 0.138  Val. score: 96.004%\n",
      "Epoch 5, 100% \t Train loss: 0.139 took: 4.46s  Val. loss: 0.134  Val. score: 96.172%\n",
      "Epoch 6, 100% \t Train loss: 0.122 took: 4.50s  Val. loss: 0.125  Val. score: 96.478%\n",
      "Epoch 7, 100% \t Train loss: 0.111 took: 4.25s  Val. loss: 0.124  Val. score: 96.568%\n",
      "Epoch 8, 100% \t Train loss: 0.100 took: 4.47s  Val. loss: 0.117  Val. score: 96.778%\n",
      "Epoch 9, 100% \t Train loss: 0.090 took: 4.58s  Val. loss: 0.117  Val. score: 96.910%\n",
      "Epoch 10, 100% \t Train loss: 0.085 took: 4.23s  Val. loss: 0.117  Val. score: 96.934%\n",
      "Training finished, took 78.175s\n",
      "\n",
      "Parameters configuration 42 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.023619406971909812\n",
      "h_sizes \t [784, 274, 94, 37]\n",
      "penalty \t 0.001479273982522288\n",
      "dropout \t 0.24512489943438218\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.1879 +/- 0.1882\n",
      "Time for evaluation: 236.3 s\n",
      "Estimated time to finish : 5.52 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.419 took: 6.43s  Val. loss: 0.191  Val. score: 94.258%\n",
      "Epoch 2, 100% \t Train loss: 0.141 took: 6.59s  Val. loss: 0.144  Val. score: 95.770%\n",
      "Epoch 3, 100% \t Train loss: 0.095 took: 6.79s  Val. loss: 0.129  Val. score: 96.304%\n",
      "Epoch 4, 100% \t Train loss: 0.067 took: 7.80s  Val. loss: 0.137  Val. score: 96.268%\n",
      "Epoch 5, 100% \t Train loss: 0.051 took: 7.30s  Val. loss: 0.149  Val. score: 95.962%\n",
      "Epoch 6, 100% \t Train loss: 0.039 took: 7.35s  Val. loss: 0.126  Val. score: 97.012%\n",
      "Epoch 7, 100% \t Train loss: 0.026 took: 7.99s  Val. loss: 0.136  Val. score: 96.748%\n",
      "Epoch 8, 100% \t Train loss: 0.022 took: 7.30s  Val. loss: 0.157  Val. score: 96.772%\n",
      "Epoch 9, 100% \t Train loss: 0.018 took: 7.31s  Val. loss: 0.144  Val. score: 96.802%\n",
      "Epoch 10, 100% \t Train loss: 0.014 took: 7.49s  Val. loss: 0.150  Val. score: 97.006%\n",
      "Training finished, took 111.992s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.439 took: 6.46s  Val. loss: 0.187  Val. score: 94.468%\n",
      "Epoch 2, 100% \t Train loss: 0.147 took: 6.43s  Val. loss: 0.156  Val. score: 95.362%\n",
      "Epoch 3, 100% \t Train loss: 0.099 took: 7.44s  Val. loss: 0.152  Val. score: 95.416%\n",
      "Epoch 4, 100% \t Train loss: 0.073 took: 7.70s  Val. loss: 0.120  Val. score: 96.280%\n",
      "Epoch 5, 100% \t Train loss: 0.055 took: 7.90s  Val. loss: 0.102  Val. score: 97.270%\n",
      "Epoch 6, 100% \t Train loss: 0.039 took: 7.78s  Val. loss: 0.114  Val. score: 97.090%\n",
      "Epoch 7, 100% \t Train loss: 0.036 took: 7.53s  Val. loss: 0.108  Val. score: 97.204%\n",
      "Epoch 8, 100% \t Train loss: 0.024 took: 8.06s  Val. loss: 0.116  Val. score: 97.102%\n",
      "Epoch 9, 100% \t Train loss: 0.018 took: 7.80s  Val. loss: 0.116  Val. score: 97.354%\n",
      "Epoch 10, 100% \t Train loss: 0.020 took: 7.12s  Val. loss: 0.116  Val. score: 97.474%\n",
      "Training finished, took 113.999s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.414 took: 6.41s  Val. loss: 0.181  Val. score: 94.276%\n",
      "Epoch 2, 100% \t Train loss: 0.152 took: 6.45s  Val. loss: 0.135  Val. score: 96.028%\n",
      "Epoch 3, 100% \t Train loss: 0.101 took: 7.55s  Val. loss: 0.112  Val. score: 96.550%\n",
      "Epoch 4, 100% \t Train loss: 0.071 took: 7.91s  Val. loss: 0.125  Val. score: 96.490%\n",
      "Epoch 5, 100% \t Train loss: 0.057 took: 7.84s  Val. loss: 0.098  Val. score: 97.288%\n",
      "Epoch 6, 100% \t Train loss: 0.045 took: 7.29s  Val. loss: 0.106  Val. score: 97.006%\n",
      "Epoch 7, 100% \t Train loss: 0.032 took: 7.19s  Val. loss: 0.106  Val. score: 97.288%\n",
      "Epoch 8, 100% \t Train loss: 0.026 took: 7.85s  Val. loss: 0.103  Val. score: 97.372%\n",
      "Epoch 9, 100% \t Train loss: 0.016 took: 7.32s  Val. loss: 0.104  Val. score: 97.498%\n",
      "Epoch 10, 100% \t Train loss: 0.013 took: 7.62s  Val. loss: 0.108  Val. score: 97.678%\n",
      "Training finished, took 113.031s\n",
      "\n",
      "Parameters configuration 43 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.010775198163807087\n",
      "h_sizes \t [784, 304, 139, 57, 24]\n",
      "penalty \t 0.00405721974217973\n",
      "dropout \t 0.00010730503789690982\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.3859 +/- 0.2813\n",
      "Time for evaluation: 340.1 s\n",
      "Estimated time to finish : 5.42 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.852 took: 3.20s  Val. loss: 0.512  Val. score: 87.297%\n",
      "Epoch 2, 100% \t Train loss: 0.451 took: 3.12s  Val. loss: 0.410  Val. score: 89.224%\n",
      "Epoch 3, 100% \t Train loss: 0.384 took: 3.15s  Val. loss: 0.369  Val. score: 89.914%\n",
      "Epoch 4, 100% \t Train loss: 0.351 took: 3.40s  Val. loss: 0.345  Val. score: 90.598%\n",
      "Epoch 5, 100% \t Train loss: 0.331 took: 3.43s  Val. loss: 0.332  Val. score: 90.886%\n",
      "Epoch 6, 100% \t Train loss: 0.316 took: 3.37s  Val. loss: 0.319  Val. score: 91.066%\n",
      "Epoch 7, 100% \t Train loss: 0.306 took: 3.34s  Val. loss: 0.313  Val. score: 91.150%\n",
      "Epoch 8, 100% \t Train loss: 0.297 took: 3.40s  Val. loss: 0.306  Val. score: 91.354%\n",
      "Epoch 9, 100% \t Train loss: 0.289 took: 3.09s  Val. loss: 0.297  Val. score: 91.516%\n",
      "Epoch 10, 100% \t Train loss: 0.282 took: 3.17s  Val. loss: 0.295  Val. score: 91.516%\n",
      "Training finished, took 63.057s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.853 took: 3.12s  Val. loss: 0.514  Val. score: 87.249%\n",
      "Epoch 2, 100% \t Train loss: 0.447 took: 3.36s  Val. loss: 0.405  Val. score: 89.332%\n",
      "Epoch 3, 100% \t Train loss: 0.380 took: 3.45s  Val. loss: 0.366  Val. score: 89.848%\n",
      "Epoch 4, 100% \t Train loss: 0.348 took: 3.40s  Val. loss: 0.342  Val. score: 90.394%\n",
      "Epoch 5, 100% \t Train loss: 0.329 took: 3.40s  Val. loss: 0.329  Val. score: 90.754%\n",
      "Epoch 6, 100% \t Train loss: 0.315 took: 3.28s  Val. loss: 0.316  Val. score: 91.144%\n",
      "Epoch 7, 100% \t Train loss: 0.305 took: 3.35s  Val. loss: 0.308  Val. score: 91.168%\n",
      "Epoch 8, 100% \t Train loss: 0.296 took: 3.29s  Val. loss: 0.300  Val. score: 91.462%\n",
      "Epoch 9, 100% \t Train loss: 0.289 took: 3.31s  Val. loss: 0.294  Val. score: 91.612%\n",
      "Epoch 10, 100% \t Train loss: 0.282 took: 3.10s  Val. loss: 0.290  Val. score: 91.780%\n",
      "Training finished, took 63.552s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.871 took: 3.43s  Val. loss: 0.511  Val. score: 87.489%\n",
      "Epoch 2, 100% \t Train loss: 0.444 took: 3.12s  Val. loss: 0.408  Val. score: 89.206%\n",
      "Epoch 3, 100% \t Train loss: 0.381 took: 3.11s  Val. loss: 0.374  Val. score: 89.986%\n",
      "Epoch 4, 100% \t Train loss: 0.351 took: 3.43s  Val. loss: 0.348  Val. score: 90.448%\n",
      "Epoch 5, 100% \t Train loss: 0.331 took: 3.09s  Val. loss: 0.334  Val. score: 90.676%\n",
      "Epoch 6, 100% \t Train loss: 0.318 took: 3.13s  Val. loss: 0.323  Val. score: 91.006%\n",
      "Epoch 7, 100% \t Train loss: 0.308 took: 3.44s  Val. loss: 0.315  Val. score: 91.222%\n",
      "Epoch 8, 100% \t Train loss: 0.300 took: 3.11s  Val. loss: 0.306  Val. score: 91.408%\n",
      "Epoch 9, 100% \t Train loss: 0.292 took: 3.35s  Val. loss: 0.300  Val. score: 91.612%\n",
      "Epoch 10, 100% \t Train loss: 0.285 took: 3.11s  Val. loss: 0.295  Val. score: 91.792%\n",
      "Training finished, took 62.589s\n",
      "\n",
      "Parameters configuration 44 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.001635176252047257\n",
      "h_sizes \t [784, 193, 47]\n",
      "penalty \t 0.00019633309036954866\n",
      "dropout \t 0.0015152021977760666\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 91.6957 +/- 0.1274\n",
      "Time for evaluation: 190.3 s\n",
      "Estimated time to finish : 5.27 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.337 took: 7.99s  Val. loss: 0.886  Val. score: 73.005%\n",
      "Epoch 2, 100% \t Train loss: 1.553 took: 8.79s  Val. loss: 2.304  Val. score: 10.446%\n",
      "Epoch 3, 100% \t Train loss: 2.304 took: 9.90s  Val. loss: 2.304  Val. score: 10.446%\n",
      "Epoch 4, 100% \t Train loss: 2.304 took: 13.17s  Val. loss: 2.302  Val. score: 10.446%\n",
      "Epoch 5, 100% \t Train loss: 2.305 took: 12.89s  Val. loss: 2.303  Val. score: 9.984%\n",
      "Epoch 6, 100% \t Train loss: 2.304 took: 13.46s  Val. loss: 2.302  Val. score: 11.496%\n",
      "Epoch 7, 100% \t Train loss: 2.304 took: 12.86s  Val. loss: 2.305  Val. score: 9.876%\n",
      "Epoch 8, 100% \t Train loss: 2.305 took: 13.57s  Val. loss: 2.304  Val. score: 9.684%\n",
      "Epoch 9, 100% \t Train loss: 2.304 took: 13.73s  Val. loss: 2.306  Val. score: 11.496%\n",
      "Epoch 10, 100% \t Train loss: 2.304 took: 13.92s  Val. loss: 2.303  Val. score: 9.984%\n",
      "Training finished, took 170.642s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.908 took: 9.02s  Val. loss: 1.386  Val. score: 43.562%\n",
      "Epoch 2, 100% \t Train loss: 1.335 took: 8.05s  Val. loss: 1.420  Val. score: 42.116%\n",
      "Epoch 3, 100% \t Train loss: 2.172 took: 10.31s  Val. loss: 2.303  Val. score: 11.064%\n",
      "Epoch 4, 100% \t Train loss: 2.307 took: 14.02s  Val. loss: 2.306  Val. score: 10.602%\n",
      "Epoch 5, 100% \t Train loss: 2.305 took: 13.59s  Val. loss: 2.302  Val. score: 11.064%\n",
      "Epoch 6, 100% \t Train loss: 2.304 took: 13.69s  Val. loss: 2.305  Val. score: 11.064%\n",
      "Epoch 7, 100% \t Train loss: 2.304 took: 13.00s  Val. loss: 2.303  Val. score: 10.602%\n",
      "Epoch 8, 100% \t Train loss: 2.335 took: 13.79s  Val. loss: 2.302  Val. score: 11.064%\n",
      "Epoch 9, 100% \t Train loss: 2.304 took: 13.86s  Val. loss: 2.304  Val. score: 10.230%\n",
      "Epoch 10, 100% \t Train loss: 2.304 took: 13.85s  Val. loss: 2.305  Val. score: 11.064%\n",
      "Training finished, took 173.215s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.331 took: 8.44s  Val. loss: 0.931  Val. score: 70.599%\n",
      "Epoch 2, 100% \t Train loss: 1.483 took: 7.99s  Val. loss: 1.537  Val. score: 42.224%\n",
      "Epoch 3, 100% \t Train loss: 1.310 took: 9.58s  Val. loss: 1.112  Val. score: 57.476%\n",
      "Epoch 4, 100% \t Train loss: 1.160 took: 13.95s  Val. loss: 1.122  Val. score: 56.246%\n",
      "Epoch 5, 100% \t Train loss: 1.229 took: 13.35s  Val. loss: 1.139  Val. score: 55.886%\n",
      "Epoch 6, 100% \t Train loss: 1.360 took: 13.02s  Val. loss: 1.572  Val. score: 41.618%\n",
      "Epoch 7, 100% \t Train loss: 2.165 took: 13.54s  Val. loss: 2.044  Val. score: 20.857%\n",
      "Epoch 8, 100% \t Train loss: 2.033 took: 13.40s  Val. loss: 2.038  Val. score: 20.059%\n",
      "Epoch 9, 100% \t Train loss: 2.125 took: 12.75s  Val. loss: 2.165  Val. score: 18.925%\n",
      "Epoch 10, 100% \t Train loss: 2.171 took: 12.95s  Val. loss: 2.166  Val. score: 18.925%\n",
      "Training finished, took 168.440s\n",
      "\n",
      "Parameters configuration 45 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.051568221454798176\n",
      "h_sizes \t [784, 433, 214, 117, 57, 33, 18]\n",
      "penalty \t 0.0011448632640503613\n",
      "dropout \t 0.0027434773820436686\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 13.3245 +/- 3.9844\n",
      "Time for evaluation: 513.4 s\n",
      "Estimated time to finish : 5.24 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.325 took: 4.43s  Val. loss: 0.168  Val. score: 94.876%\n",
      "Epoch 2, 100% \t Train loss: 0.139 took: 4.42s  Val. loss: 0.134  Val. score: 95.908%\n",
      "Epoch 3, 100% \t Train loss: 0.102 took: 4.50s  Val. loss: 0.115  Val. score: 96.616%\n",
      "Epoch 4, 100% \t Train loss: 0.078 took: 4.76s  Val. loss: 0.099  Val. score: 96.964%\n",
      "Epoch 5, 100% \t Train loss: 0.063 took: 4.42s  Val. loss: 0.108  Val. score: 96.844%\n",
      "Epoch 6, 100% \t Train loss: 0.049 took: 4.35s  Val. loss: 0.126  Val. score: 96.538%\n",
      "Epoch 7, 100% \t Train loss: 0.041 took: 4.75s  Val. loss: 0.110  Val. score: 97.132%\n",
      "Epoch 8, 100% \t Train loss: 0.034 took: 4.65s  Val. loss: 0.119  Val. score: 96.934%\n",
      "Epoch 9, 100% \t Train loss: 0.030 took: 4.76s  Val. loss: 0.110  Val. score: 97.342%\n",
      "Epoch 10, 100% \t Train loss: 0.026 took: 4.69s  Val. loss: 0.115  Val. score: 97.222%\n",
      "Training finished, took 76.334s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.329 took: 4.45s  Val. loss: 0.171  Val. score: 94.744%\n",
      "Epoch 2, 100% \t Train loss: 0.138 took: 4.42s  Val. loss: 0.126  Val. score: 96.082%\n",
      "Epoch 3, 100% \t Train loss: 0.097 took: 4.49s  Val. loss: 0.114  Val. score: 96.526%\n",
      "Epoch 4, 100% \t Train loss: 0.075 took: 4.73s  Val. loss: 0.102  Val. score: 96.790%\n",
      "Epoch 5, 100% \t Train loss: 0.060 took: 4.94s  Val. loss: 0.117  Val. score: 96.676%\n",
      "Epoch 6, 100% \t Train loss: 0.046 took: 4.85s  Val. loss: 0.101  Val. score: 97.096%\n",
      "Epoch 7, 100% \t Train loss: 0.041 took: 4.45s  Val. loss: 0.105  Val. score: 97.240%\n",
      "Epoch 8, 100% \t Train loss: 0.032 took: 4.79s  Val. loss: 0.127  Val. score: 96.694%\n",
      "Epoch 9, 100% \t Train loss: 0.029 took: 4.82s  Val. loss: 0.109  Val. score: 97.234%\n",
      "Epoch 10, 100% \t Train loss: 0.023 took: 4.80s  Val. loss: 0.112  Val. score: 97.294%\n",
      "Training finished, took 77.429s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.339 took: 4.45s  Val. loss: 0.173  Val. score: 94.714%\n",
      "Epoch 2, 100% \t Train loss: 0.139 took: 4.42s  Val. loss: 0.125  Val. score: 96.226%\n",
      "Epoch 3, 100% \t Train loss: 0.102 took: 4.30s  Val. loss: 0.112  Val. score: 96.562%\n",
      "Epoch 4, 100% \t Train loss: 0.078 took: 4.47s  Val. loss: 0.112  Val. score: 96.826%\n",
      "Epoch 5, 100% \t Train loss: 0.062 took: 4.42s  Val. loss: 0.111  Val. score: 96.862%\n",
      "Epoch 6, 100% \t Train loss: 0.050 took: 4.69s  Val. loss: 0.098  Val. score: 97.252%\n",
      "Epoch 7, 100% \t Train loss: 0.044 took: 4.50s  Val. loss: 0.111  Val. score: 97.054%\n",
      "Epoch 8, 100% \t Train loss: 0.035 took: 4.44s  Val. loss: 0.119  Val. score: 97.066%\n",
      "Epoch 9, 100% \t Train loss: 0.034 took: 4.70s  Val. loss: 0.121  Val. score: 97.204%\n",
      "Epoch 10, 100% \t Train loss: 0.027 took: 4.72s  Val. loss: 0.120  Val. score: 97.078%\n",
      "Training finished, took 75.664s\n",
      "\n",
      "Parameters configuration 46 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.019924549276729427\n",
      "h_sizes \t [784, 195, 39]\n",
      "penalty \t 0.0005329682713549593\n",
      "dropout \t 0.035150887278989545\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.1979 +/- 0.0898\n",
      "Time for evaluation: 230.5 s\n",
      "Estimated time to finish : 5.11 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.851 took: 3.83s  Val. loss: 0.280  Val. score: 92.056%\n",
      "Epoch 2, 100% \t Train loss: 0.405 took: 4.17s  Val. loss: 0.254  Val. score: 92.446%\n",
      "Epoch 3, 100% \t Train loss: 0.337 took: 4.08s  Val. loss: 0.198  Val. score: 94.270%\n",
      "Epoch 4, 100% \t Train loss: 0.306 took: 5.05s  Val. loss: 0.195  Val. score: 94.480%\n",
      "Epoch 5, 100% \t Train loss: 0.285 took: 4.87s  Val. loss: 0.183  Val. score: 94.846%\n",
      "Epoch 6, 100% \t Train loss: 0.265 took: 5.37s  Val. loss: 0.187  Val. score: 94.780%\n",
      "Epoch 7, 100% \t Train loss: 0.256 took: 4.90s  Val. loss: 0.195  Val. score: 94.564%\n",
      "Epoch 8, 100% \t Train loss: 0.242 took: 5.31s  Val. loss: 0.183  Val. score: 95.104%\n",
      "Epoch 9, 100% \t Train loss: 0.234 took: 4.92s  Val. loss: 0.198  Val. score: 94.516%\n",
      "Epoch 10, 100% \t Train loss: 0.236 took: 5.07s  Val. loss: 0.180  Val. score: 94.918%\n",
      "Training finished, took 77.391s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.746 took: 4.24s  Val. loss: 0.267  Val. score: 92.602%\n",
      "Epoch 2, 100% \t Train loss: 0.334 took: 4.41s  Val. loss: 0.206  Val. score: 94.312%\n",
      "Epoch 3, 100% \t Train loss: 0.280 took: 4.49s  Val. loss: 0.188  Val. score: 94.708%\n",
      "Epoch 4, 100% \t Train loss: 0.249 took: 5.40s  Val. loss: 0.170  Val. score: 95.146%\n",
      "Epoch 5, 100% \t Train loss: 0.227 took: 5.22s  Val. loss: 0.165  Val. score: 95.272%\n",
      "Epoch 6, 100% \t Train loss: 0.213 took: 4.81s  Val. loss: 0.147  Val. score: 95.950%\n",
      "Epoch 7, 100% \t Train loss: 0.203 took: 5.23s  Val. loss: 0.168  Val. score: 95.422%\n",
      "Epoch 8, 100% \t Train loss: 0.189 took: 5.22s  Val. loss: 0.168  Val. score: 95.266%\n",
      "Epoch 9, 100% \t Train loss: 0.182 took: 5.22s  Val. loss: 0.150  Val. score: 95.818%\n",
      "Epoch 10, 100% \t Train loss: 0.178 took: 5.20s  Val. loss: 0.146  Val. score: 96.058%\n",
      "Training finished, took 79.480s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.670 took: 3.81s  Val. loss: 0.261  Val. score: 92.686%\n",
      "Epoch 2, 100% \t Train loss: 0.354 took: 3.83s  Val. loss: 0.254  Val. score: 92.812%\n",
      "Epoch 3, 100% \t Train loss: 0.301 took: 4.08s  Val. loss: 0.207  Val. score: 94.138%\n",
      "Epoch 4, 100% \t Train loss: 0.275 took: 5.21s  Val. loss: 0.183  Val. score: 94.582%\n",
      "Epoch 5, 100% \t Train loss: 0.251 took: 5.19s  Val. loss: 0.181  Val. score: 95.032%\n",
      "Epoch 6, 100% \t Train loss: 0.232 took: 4.92s  Val. loss: 0.168  Val. score: 95.218%\n",
      "Epoch 7, 100% \t Train loss: 0.222 took: 5.27s  Val. loss: 0.176  Val. score: 95.206%\n",
      "Epoch 8, 100% \t Train loss: 0.208 took: 5.36s  Val. loss: 0.161  Val. score: 95.554%\n",
      "Epoch 9, 100% \t Train loss: 0.203 took: 5.32s  Val. loss: 0.168  Val. score: 95.524%\n",
      "Epoch 10, 100% \t Train loss: 0.194 took: 4.82s  Val. loss: 0.156  Val. score: 95.746%\n",
      "Training finished, took 77.715s\n",
      "\n",
      "Parameters configuration 47 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.05215110649264988\n",
      "h_sizes \t [784, 187, 39]\n",
      "penalty \t 0.000823299943953609\n",
      "dropout \t 0.24151906255207303\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 95.5738 +/- 0.4811\n",
      "Time for evaluation: 235.7 s\n",
      "Estimated time to finish : 4.98 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.180 took: 6.72s  Val. loss: 0.643  Val. score: 78.609%\n",
      "Epoch 2, 100% \t Train loss: 0.707 took: 6.69s  Val. loss: 0.448  Val. score: 87.682%\n",
      "Epoch 3, 100% \t Train loss: 0.570 took: 6.65s  Val. loss: 0.363  Val. score: 90.292%\n",
      "Epoch 4, 100% \t Train loss: 0.495 took: 6.06s  Val. loss: 0.326  Val. score: 91.150%\n",
      "Epoch 5, 100% \t Train loss: 0.450 took: 6.04s  Val. loss: 0.294  Val. score: 91.828%\n",
      "Epoch 6, 100% \t Train loss: 0.410 took: 6.50s  Val. loss: 0.276  Val. score: 92.260%\n",
      "Epoch 7, 100% \t Train loss: 0.382 took: 6.22s  Val. loss: 0.258  Val. score: 92.662%\n",
      "Epoch 8, 100% \t Train loss: 0.361 took: 6.75s  Val. loss: 0.243  Val. score: 93.124%\n",
      "Epoch 9, 100% \t Train loss: 0.344 took: 6.68s  Val. loss: 0.239  Val. score: 93.412%\n",
      "Epoch 10, 100% \t Train loss: 0.328 took: 6.31s  Val. loss: 0.227  Val. score: 93.688%\n",
      "Training finished, took 109.561s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.195 took: 6.03s  Val. loss: 0.569  Val. score: 85.599%\n",
      "Epoch 2, 100% \t Train loss: 0.710 took: 6.33s  Val. loss: 0.435  Val. score: 88.402%\n",
      "Epoch 3, 100% \t Train loss: 0.587 took: 6.06s  Val. loss: 0.357  Val. score: 91.042%\n",
      "Epoch 4, 100% \t Train loss: 0.520 took: 6.15s  Val. loss: 0.319  Val. score: 91.984%\n",
      "Epoch 5, 100% \t Train loss: 0.467 took: 6.06s  Val. loss: 0.293  Val. score: 92.806%\n",
      "Epoch 6, 100% \t Train loss: 0.431 took: 6.69s  Val. loss: 0.269  Val. score: 93.274%\n",
      "Epoch 7, 100% \t Train loss: 0.402 took: 6.08s  Val. loss: 0.259  Val. score: 93.436%\n",
      "Epoch 8, 100% \t Train loss: 0.374 took: 6.33s  Val. loss: 0.247  Val. score: 93.646%\n",
      "Epoch 9, 100% \t Train loss: 0.357 took: 6.07s  Val. loss: 0.235  Val. score: 94.036%\n",
      "Epoch 10, 100% \t Train loss: 0.341 took: 6.45s  Val. loss: 0.225  Val. score: 94.216%\n",
      "Training finished, took 106.921s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.532 took: 6.58s  Val. loss: 1.153  Val. score: 58.640%\n",
      "Epoch 2, 100% \t Train loss: 1.132 took: 6.33s  Val. loss: 0.818  Val. score: 71.163%\n",
      "Epoch 3, 100% \t Train loss: 0.888 took: 6.45s  Val. loss: 0.612  Val. score: 85.221%\n",
      "Epoch 4, 100% \t Train loss: 0.749 took: 6.10s  Val. loss: 0.522  Val. score: 87.934%\n",
      "Epoch 5, 100% \t Train loss: 0.659 took: 6.44s  Val. loss: 0.455  Val. score: 89.506%\n",
      "Epoch 6, 100% \t Train loss: 0.605 took: 6.58s  Val. loss: 0.410  Val. score: 90.532%\n",
      "Epoch 7, 100% \t Train loss: 0.555 took: 6.01s  Val. loss: 0.369  Val. score: 91.018%\n",
      "Epoch 8, 100% \t Train loss: 0.503 took: 6.57s  Val. loss: 0.331  Val. score: 91.840%\n",
      "Epoch 9, 100% \t Train loss: 0.465 took: 6.04s  Val. loss: 0.308  Val. score: 92.260%\n",
      "Epoch 10, 100% \t Train loss: 0.439 took: 6.02s  Val. loss: 0.289  Val. score: 92.572%\n",
      "Training finished, took 108.232s\n",
      "\n",
      "Parameters configuration 48 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002738006756293353\n",
      "h_sizes \t [784, 359, 173, 81, 40, 12]\n",
      "penalty \t 0.00012562630368413155\n",
      "dropout \t 0.11993636262909585\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 93.4917 +/- 0.6853\n",
      "Time for evaluation: 325.8 s\n",
      "Estimated time to finish : 4.88 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.537 took: 4.75s  Val. loss: 0.351  Val. score: 92.092%\n",
      "Epoch 2, 100% \t Train loss: 0.348 took: 4.55s  Val. loss: 0.289  Val. score: 92.914%\n",
      "Epoch 3, 100% \t Train loss: 0.309 took: 4.96s  Val. loss: 0.275  Val. score: 93.148%\n",
      "Epoch 4, 100% \t Train loss: 0.310 took: 6.96s  Val. loss: 0.261  Val. score: 93.628%\n",
      "Epoch 5, 100% \t Train loss: 0.272 took: 6.79s  Val. loss: 0.254  Val. score: 94.186%\n",
      "Epoch 6, 100% \t Train loss: 0.295 took: 6.82s  Val. loss: 0.243  Val. score: 94.486%\n",
      "Epoch 7, 100% \t Train loss: 0.275 took: 6.34s  Val. loss: 0.260  Val. score: 95.038%\n",
      "Epoch 8, 100% \t Train loss: 0.266 took: 6.82s  Val. loss: 0.260  Val. score: 93.778%\n",
      "Epoch 9, 100% \t Train loss: 0.305 took: 6.94s  Val. loss: 0.368  Val. score: 93.058%\n",
      "Epoch 10, 100% \t Train loss: 0.303 took: 7.01s  Val. loss: 0.316  Val. score: 93.928%\n",
      "Training finished, took 96.654s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.752 took: 4.37s  Val. loss: 0.355  Val. score: 90.862%\n",
      "Epoch 2, 100% \t Train loss: 0.381 took: 4.87s  Val. loss: 0.303  Val. score: 92.170%\n",
      "Epoch 3, 100% \t Train loss: 0.329 took: 5.44s  Val. loss: 0.290  Val. score: 92.932%\n",
      "Epoch 4, 100% \t Train loss: 0.289 took: 6.46s  Val. loss: 0.278  Val. score: 93.640%\n",
      "Epoch 5, 100% \t Train loss: 0.288 took: 6.46s  Val. loss: 0.316  Val. score: 93.136%\n",
      "Epoch 6, 100% \t Train loss: 0.309 took: 6.86s  Val. loss: 0.339  Val. score: 92.380%\n",
      "Epoch 7, 100% \t Train loss: 0.285 took: 6.91s  Val. loss: 0.283  Val. score: 93.526%\n",
      "Epoch 8, 100% \t Train loss: 0.279 took: 6.60s  Val. loss: 0.300  Val. score: 92.854%\n",
      "Epoch 9, 100% \t Train loss: 0.256 took: 6.76s  Val. loss: 0.274  Val. score: 93.946%\n",
      "Epoch 10, 100% \t Train loss: 0.286 took: 6.57s  Val. loss: 0.290  Val. score: 94.150%\n",
      "Training finished, took 95.803s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.569 took: 4.60s  Val. loss: 0.323  Val. score: 92.086%\n",
      "Epoch 2, 100% \t Train loss: 0.348 took: 4.95s  Val. loss: 0.260  Val. score: 93.286%\n",
      "Epoch 3, 100% \t Train loss: 0.314 took: 5.25s  Val. loss: 0.253  Val. score: 93.424%\n",
      "Epoch 4, 100% \t Train loss: 0.308 took: 6.78s  Val. loss: 0.298  Val. score: 93.658%\n",
      "Epoch 5, 100% \t Train loss: 0.299 took: 6.27s  Val. loss: 0.274  Val. score: 93.568%\n",
      "Epoch 6, 100% \t Train loss: 0.300 took: 6.77s  Val. loss: 0.270  Val. score: 94.168%\n",
      "Epoch 7, 100% \t Train loss: 0.314 took: 6.90s  Val. loss: 0.321  Val. score: 92.836%\n",
      "Epoch 8, 100% \t Train loss: 0.286 took: 7.00s  Val. loss: 0.269  Val. score: 94.270%\n",
      "Epoch 9, 100% \t Train loss: 0.281 took: 6.62s  Val. loss: 0.250  Val. score: 94.810%\n",
      "Epoch 10, 100% \t Train loss: 0.283 took: 6.60s  Val. loss: 0.279  Val. score: 94.048%\n",
      "Training finished, took 96.663s\n",
      "\n",
      "Parameters configuration 49 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.028660208258474564\n",
      "h_sizes \t [784, 260, 90, 22]\n",
      "penalty \t 0.00034786273066751943\n",
      "dropout \t 0.06280119239803944\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 94.0418 +/- 0.0907\n",
      "Time for evaluation: 290.2 s\n",
      "Estimated time to finish : 4.77 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.559 took: 3.92s  Val. loss: 0.246  Val. score: 92.758%\n",
      "Epoch 2, 100% \t Train loss: 0.240 took: 3.96s  Val. loss: 0.178  Val. score: 94.738%\n",
      "Epoch 3, 100% \t Train loss: 0.175 took: 3.97s  Val. loss: 0.140  Val. score: 95.668%\n",
      "Epoch 4, 100% \t Train loss: 0.137 took: 4.02s  Val. loss: 0.120  Val. score: 96.304%\n",
      "Epoch 5, 100% \t Train loss: 0.114 took: 3.96s  Val. loss: 0.110  Val. score: 96.526%\n",
      "Epoch 6, 100% \t Train loss: 0.094 took: 3.88s  Val. loss: 0.102  Val. score: 96.826%\n",
      "Epoch 7, 100% \t Train loss: 0.082 took: 3.90s  Val. loss: 0.092  Val. score: 97.066%\n",
      "Epoch 8, 100% \t Train loss: 0.072 took: 3.98s  Val. loss: 0.093  Val. score: 97.198%\n",
      "Epoch 9, 100% \t Train loss: 0.063 took: 4.01s  Val. loss: 0.093  Val. score: 97.306%\n",
      "Epoch 10, 100% \t Train loss: 0.056 took: 4.00s  Val. loss: 0.093  Val. score: 97.264%\n",
      "Training finished, took 69.890s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.568 took: 3.98s  Val. loss: 0.246  Val. score: 92.782%\n",
      "Epoch 2, 100% \t Train loss: 0.237 took: 3.95s  Val. loss: 0.169  Val. score: 94.882%\n",
      "Epoch 3, 100% \t Train loss: 0.175 took: 3.95s  Val. loss: 0.141  Val. score: 95.518%\n",
      "Epoch 4, 100% \t Train loss: 0.137 took: 3.83s  Val. loss: 0.126  Val. score: 96.220%\n",
      "Epoch 5, 100% \t Train loss: 0.113 took: 3.98s  Val. loss: 0.112  Val. score: 96.550%\n",
      "Epoch 6, 100% \t Train loss: 0.096 took: 4.06s  Val. loss: 0.105  Val. score: 96.796%\n",
      "Epoch 7, 100% \t Train loss: 0.081 took: 4.03s  Val. loss: 0.101  Val. score: 96.970%\n",
      "Epoch 8, 100% \t Train loss: 0.070 took: 4.03s  Val. loss: 0.097  Val. score: 97.036%\n",
      "Epoch 9, 100% \t Train loss: 0.063 took: 3.80s  Val. loss: 0.099  Val. score: 97.060%\n",
      "Epoch 10, 100% \t Train loss: 0.057 took: 4.03s  Val. loss: 0.097  Val. score: 97.204%\n",
      "Training finished, took 69.781s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.572 took: 3.93s  Val. loss: 0.255  Val. score: 92.662%\n",
      "Epoch 2, 100% \t Train loss: 0.249 took: 4.05s  Val. loss: 0.180  Val. score: 94.654%\n",
      "Epoch 3, 100% \t Train loss: 0.182 took: 3.92s  Val. loss: 0.143  Val. score: 95.668%\n",
      "Epoch 4, 100% \t Train loss: 0.141 took: 4.00s  Val. loss: 0.122  Val. score: 96.322%\n",
      "Epoch 5, 100% \t Train loss: 0.119 took: 3.60s  Val. loss: 0.110  Val. score: 96.664%\n",
      "Epoch 6, 100% \t Train loss: 0.097 took: 3.62s  Val. loss: 0.109  Val. score: 96.778%\n",
      "Epoch 7, 100% \t Train loss: 0.084 took: 4.01s  Val. loss: 0.103  Val. score: 97.018%\n",
      "Epoch 8, 100% \t Train loss: 0.075 took: 4.02s  Val. loss: 0.101  Val. score: 97.150%\n",
      "Epoch 9, 100% \t Train loss: 0.063 took: 4.04s  Val. loss: 0.094  Val. score: 97.204%\n",
      "Epoch 10, 100% \t Train loss: 0.057 took: 3.99s  Val. loss: 0.102  Val. score: 97.156%\n",
      "Training finished, took 69.318s\n",
      "\n",
      "Parameters configuration 50 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0012868819504405363\n",
      "h_sizes \t [784, 196, 45]\n",
      "penalty \t 0.007622722881057016\n",
      "dropout \t 0.15528939591430263\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.2079 +/- 0.0442\n",
      "Time for evaluation: 210.1 s\n",
      "Estimated time to finish : 4.64 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.910 took: 4.01s  Val. loss: 0.261  Val. score: 92.374%\n",
      "Epoch 2, 100% \t Train loss: 0.314 took: 3.83s  Val. loss: 0.208  Val. score: 94.024%\n",
      "Epoch 3, 100% \t Train loss: 0.242 took: 3.96s  Val. loss: 0.162  Val. score: 95.578%\n",
      "Epoch 4, 100% \t Train loss: 0.208 took: 3.72s  Val. loss: 0.143  Val. score: 95.812%\n",
      "Epoch 5, 100% \t Train loss: 0.184 took: 3.74s  Val. loss: 0.138  Val. score: 96.178%\n",
      "Epoch 6, 100% \t Train loss: 0.166 took: 4.11s  Val. loss: 0.136  Val. score: 96.208%\n",
      "Epoch 7, 100% \t Train loss: 0.153 took: 3.83s  Val. loss: 0.123  Val. score: 96.628%\n",
      "Epoch 8, 100% \t Train loss: 0.133 took: 3.90s  Val. loss: 0.123  Val. score: 96.682%\n",
      "Epoch 9, 100% \t Train loss: 0.126 took: 3.88s  Val. loss: 0.126  Val. score: 96.742%\n",
      "Epoch 10, 100% \t Train loss: 0.114 took: 3.83s  Val. loss: 0.120  Val. score: 96.814%\n",
      "Training finished, took 72.441s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.955 took: 3.83s  Val. loss: 0.277  Val. score: 92.536%\n",
      "Epoch 2, 100% \t Train loss: 0.320 took: 4.01s  Val. loss: 0.194  Val. score: 94.588%\n",
      "Epoch 3, 100% \t Train loss: 0.248 took: 4.20s  Val. loss: 0.174  Val. score: 95.110%\n",
      "Epoch 4, 100% \t Train loss: 0.210 took: 3.93s  Val. loss: 0.168  Val. score: 95.506%\n",
      "Epoch 5, 100% \t Train loss: 0.188 took: 3.99s  Val. loss: 0.159  Val. score: 95.788%\n",
      "Epoch 6, 100% \t Train loss: 0.168 took: 3.95s  Val. loss: 0.155  Val. score: 95.806%\n",
      "Epoch 7, 100% \t Train loss: 0.154 took: 3.88s  Val. loss: 0.144  Val. score: 96.154%\n",
      "Epoch 8, 100% \t Train loss: 0.143 took: 3.72s  Val. loss: 0.145  Val. score: 96.142%\n",
      "Epoch 9, 100% \t Train loss: 0.133 took: 3.73s  Val. loss: 0.144  Val. score: 96.214%\n",
      "Epoch 10, 100% \t Train loss: 0.125 took: 3.81s  Val. loss: 0.137  Val. score: 96.484%\n",
      "Training finished, took 72.508s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.974 took: 3.79s  Val. loss: 0.291  Val. score: 91.984%\n",
      "Epoch 2, 100% \t Train loss: 0.309 took: 4.05s  Val. loss: 0.200  Val. score: 94.546%\n",
      "Epoch 3, 100% \t Train loss: 0.251 took: 3.92s  Val. loss: 0.186  Val. score: 94.882%\n",
      "Epoch 4, 100% \t Train loss: 0.209 took: 3.89s  Val. loss: 0.168  Val. score: 95.362%\n",
      "Epoch 5, 100% \t Train loss: 0.183 took: 3.72s  Val. loss: 0.156  Val. score: 95.794%\n",
      "Epoch 6, 100% \t Train loss: 0.164 took: 3.73s  Val. loss: 0.147  Val. score: 95.956%\n",
      "Epoch 7, 100% \t Train loss: 0.149 took: 3.82s  Val. loss: 0.146  Val. score: 96.196%\n",
      "Epoch 8, 100% \t Train loss: 0.138 took: 4.14s  Val. loss: 0.142  Val. score: 96.370%\n",
      "Epoch 9, 100% \t Train loss: 0.130 took: 4.06s  Val. loss: 0.139  Val. score: 96.316%\n",
      "Epoch 10, 100% \t Train loss: 0.122 took: 3.74s  Val. loss: 0.140  Val. score: 96.430%\n",
      "Training finished, took 72.368s\n",
      "\n",
      "Parameters configuration 51 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.08293585215254763\n",
      "h_sizes \t [784, 243, 77, 24]\n",
      "penalty \t 0.0067654299237902464\n",
      "dropout \t 0.1704427090684666\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 96.5759 +/- 0.1697\n",
      "Time for evaluation: 218.4 s\n",
      "Estimated time to finish : 4.52 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.492 took: 11.82s  Val. loss: 1.039  Val. score: 61.892%\n",
      "Epoch 2, 100% \t Train loss: 0.837 took: 11.85s  Val. loss: 0.528  Val. score: 83.085%\n",
      "Epoch 3, 100% \t Train loss: 0.615 took: 12.04s  Val. loss: 0.447  Val. score: 84.525%\n",
      "Epoch 4, 100% \t Train loss: 0.464 took: 12.83s  Val. loss: 0.426  Val. score: 84.891%\n",
      "Epoch 5, 100% \t Train loss: 0.412 took: 12.94s  Val. loss: 0.390  Val. score: 85.503%\n",
      "Epoch 6, 100% \t Train loss: 0.376 took: 11.91s  Val. loss: 0.387  Val. score: 86.241%\n",
      "Epoch 7, 100% \t Train loss: 0.368 took: 12.12s  Val. loss: 0.388  Val. score: 86.187%\n",
      "Epoch 8, 100% \t Train loss: 0.341 took: 12.37s  Val. loss: 0.391  Val. score: 86.751%\n",
      "Epoch 9, 100% \t Train loss: 0.326 took: 13.63s  Val. loss: 0.461  Val. score: 89.020%\n",
      "Epoch 10, 100% \t Train loss: 0.306 took: 12.94s  Val. loss: 0.366  Val. score: 94.150%\n",
      "Training finished, took 195.155s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.705 took: 12.04s  Val. loss: 1.291  Val. score: 50.576%\n",
      "Epoch 2, 100% \t Train loss: 0.992 took: 13.14s  Val. loss: 0.902  Val. score: 65.103%\n",
      "Epoch 3, 100% \t Train loss: 0.819 took: 11.84s  Val. loss: 0.787  Val. score: 73.149%\n",
      "Epoch 4, 100% \t Train loss: 0.716 took: 13.22s  Val. loss: 0.789  Val. score: 75.963%\n",
      "Epoch 5, 100% \t Train loss: 0.659 took: 13.44s  Val. loss: 0.817  Val. score: 81.711%\n",
      "Epoch 6, 100% \t Train loss: 0.612 took: 12.79s  Val. loss: 0.764  Val. score: 82.551%\n",
      "Epoch 7, 100% \t Train loss: 0.570 took: 13.39s  Val. loss: 0.923  Val. score: 81.975%\n",
      "Epoch 8, 100% \t Train loss: 0.551 took: 13.51s  Val. loss: 0.792  Val. score: 84.813%\n",
      "Epoch 9, 100% \t Train loss: 0.495 took: 12.00s  Val. loss: 1.350  Val. score: 87.868%\n",
      "Epoch 10, 100% \t Train loss: 0.460 took: 13.94s  Val. loss: 1.353  Val. score: 87.556%\n",
      "Training finished, took 199.655s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.600 took: 11.98s  Val. loss: 1.182  Val. score: 50.222%\n",
      "Epoch 2, 100% \t Train loss: 1.085 took: 13.24s  Val. loss: 0.971  Val. score: 61.448%\n",
      "Epoch 3, 100% \t Train loss: 0.936 took: 11.83s  Val. loss: 0.899  Val. score: 66.885%\n",
      "Epoch 4, 100% \t Train loss: 0.817 took: 12.05s  Val. loss: 0.763  Val. score: 80.475%\n",
      "Epoch 5, 100% \t Train loss: 0.691 took: 13.28s  Val. loss: 0.818  Val. score: 84.417%\n",
      "Epoch 6, 100% \t Train loss: 0.647 took: 13.23s  Val. loss: 0.715  Val. score: 88.708%\n",
      "Epoch 7, 100% \t Train loss: 0.603 took: 13.25s  Val. loss: 0.728  Val. score: 85.755%\n",
      "Epoch 8, 100% \t Train loss: 0.660 took: 11.98s  Val. loss: 0.670  Val. score: 84.939%\n",
      "Epoch 9, 100% \t Train loss: 0.546 took: 12.69s  Val. loss: 0.823  Val. score: 89.212%\n",
      "Epoch 10, 100% \t Train loss: 0.550 took: 15.58s  Val. loss: 0.789  Val. score: 86.643%\n",
      "Training finished, took 198.911s\n",
      "\n",
      "Parameters configuration 52 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.02408867561976459\n",
      "h_sizes \t [784, 536, 361, 245, 163, 109, 72, 48, 30, 16, 6]\n",
      "penalty \t 0.0002385632785467408\n",
      "dropout \t 0.03274539494544193\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 89.4496 +/- 3.3443\n",
      "Time for evaluation: 594.8 s\n",
      "Estimated time to finish : 4.50 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.315 took: 4.44s  Val. loss: 0.164  Val. score: 94.810%\n",
      "Epoch 2, 100% \t Train loss: 0.136 took: 3.79s  Val. loss: 0.121  Val. score: 96.340%\n",
      "Epoch 3, 100% \t Train loss: 0.096 took: 3.82s  Val. loss: 0.114  Val. score: 96.490%\n",
      "Epoch 4, 100% \t Train loss: 0.077 took: 3.91s  Val. loss: 0.107  Val. score: 96.850%\n",
      "Epoch 5, 100% \t Train loss: 0.060 took: 3.94s  Val. loss: 0.104  Val. score: 97.096%\n",
      "Epoch 6, 100% \t Train loss: 0.048 took: 4.19s  Val. loss: 0.113  Val. score: 96.934%\n",
      "Epoch 7, 100% \t Train loss: 0.041 took: 4.26s  Val. loss: 0.104  Val. score: 97.204%\n",
      "Epoch 8, 100% \t Train loss: 0.032 took: 4.22s  Val. loss: 0.125  Val. score: 96.970%\n",
      "Epoch 9, 100% \t Train loss: 0.027 took: 4.16s  Val. loss: 0.119  Val. score: 97.204%\n",
      "Epoch 10, 100% \t Train loss: 0.024 took: 3.96s  Val. loss: 0.116  Val. score: 97.414%\n",
      "Training finished, took 70.286s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.316 took: 4.17s  Val. loss: 0.164  Val. score: 95.068%\n",
      "Epoch 2, 100% \t Train loss: 0.139 took: 4.21s  Val. loss: 0.123  Val. score: 96.352%\n",
      "Epoch 3, 100% \t Train loss: 0.097 took: 3.89s  Val. loss: 0.111  Val. score: 96.682%\n",
      "Epoch 4, 100% \t Train loss: 0.078 took: 3.82s  Val. loss: 0.106  Val. score: 96.880%\n",
      "Epoch 5, 100% \t Train loss: 0.059 took: 4.25s  Val. loss: 0.104  Val. score: 97.114%\n",
      "Epoch 6, 100% \t Train loss: 0.048 took: 4.22s  Val. loss: 0.111  Val. score: 97.078%\n",
      "Epoch 7, 100% \t Train loss: 0.042 took: 4.07s  Val. loss: 0.118  Val. score: 96.868%\n",
      "Epoch 8, 100% \t Train loss: 0.033 took: 4.13s  Val. loss: 0.102  Val. score: 97.498%\n",
      "Epoch 9, 100% \t Train loss: 0.028 took: 3.78s  Val. loss: 0.104  Val. score: 97.552%\n",
      "Epoch 10, 100% \t Train loss: 0.026 took: 3.86s  Val. loss: 0.114  Val. score: 97.348%\n",
      "Training finished, took 69.944s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.333 took: 3.82s  Val. loss: 0.155  Val. score: 95.140%\n",
      "Epoch 2, 100% \t Train loss: 0.135 took: 4.11s  Val. loss: 0.127  Val. score: 96.154%\n",
      "Epoch 3, 100% \t Train loss: 0.102 took: 4.18s  Val. loss: 0.123  Val. score: 96.178%\n",
      "Epoch 4, 100% \t Train loss: 0.079 took: 4.24s  Val. loss: 0.108  Val. score: 96.880%\n",
      "Epoch 5, 100% \t Train loss: 0.061 took: 4.16s  Val. loss: 0.099  Val. score: 97.174%\n",
      "Epoch 6, 100% \t Train loss: 0.051 took: 4.23s  Val. loss: 0.101  Val. score: 97.264%\n",
      "Epoch 7, 100% \t Train loss: 0.041 took: 4.14s  Val. loss: 0.118  Val. score: 96.862%\n",
      "Epoch 8, 100% \t Train loss: 0.033 took: 3.98s  Val. loss: 0.099  Val. score: 97.330%\n",
      "Epoch 9, 100% \t Train loss: 0.031 took: 4.24s  Val. loss: 0.120  Val. score: 97.066%\n",
      "Epoch 10, 100% \t Train loss: 0.026 took: 4.22s  Val. loss: 0.115  Val. score: 97.348%\n",
      "Training finished, took 70.842s\n",
      "\n",
      "Parameters configuration 53 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.018530861530015867\n",
      "h_sizes \t [784, 184, 42]\n",
      "penalty \t 0.0002273396633902985\n",
      "dropout \t 0.045489897069608515\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.3699 +/- 0.0311\n",
      "Time for evaluation: 212.1 s\n",
      "Estimated time to finish : 4.37 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.417 took: 4.99s  Val. loss: 0.234  Val. score: 92.986%\n",
      "Epoch 2, 100% \t Train loss: 0.214 took: 5.26s  Val. loss: 0.150  Val. score: 95.842%\n",
      "Epoch 3, 100% \t Train loss: 0.184 took: 5.56s  Val. loss: 0.147  Val. score: 96.268%\n",
      "Epoch 4, 100% \t Train loss: 0.156 took: 6.13s  Val. loss: 0.142  Val. score: 96.046%\n",
      "Epoch 5, 100% \t Train loss: 0.144 took: 6.05s  Val. loss: 0.155  Val. score: 95.986%\n",
      "Epoch 6, 100% \t Train loss: 0.144 took: 6.04s  Val. loss: 0.144  Val. score: 96.664%\n",
      "Epoch 7, 100% \t Train loss: 0.131 took: 5.97s  Val. loss: 0.145  Val. score: 96.646%\n",
      "Epoch 8, 100% \t Train loss: 0.122 took: 5.75s  Val. loss: 0.157  Val. score: 96.754%\n",
      "Epoch 9, 100% \t Train loss: 0.127 took: 5.90s  Val. loss: 0.145  Val. score: 96.478%\n",
      "Epoch 10, 100% \t Train loss: 0.118 took: 5.87s  Val. loss: 0.149  Val. score: 96.754%\n",
      "Training finished, took 93.643s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.432 took: 4.79s  Val. loss: 0.217  Val. score: 93.892%\n",
      "Epoch 2, 100% \t Train loss: 0.228 took: 4.89s  Val. loss: 0.164  Val. score: 95.572%\n",
      "Epoch 3, 100% \t Train loss: 0.183 took: 5.61s  Val. loss: 0.167  Val. score: 95.710%\n",
      "Epoch 4, 100% \t Train loss: 0.162 took: 5.86s  Val. loss: 0.168  Val. score: 95.458%\n",
      "Epoch 5, 100% \t Train loss: 0.147 took: 6.07s  Val. loss: 0.152  Val. score: 96.424%\n",
      "Epoch 6, 100% \t Train loss: 0.137 took: 5.67s  Val. loss: 0.145  Val. score: 96.718%\n",
      "Epoch 7, 100% \t Train loss: 0.138 took: 6.09s  Val. loss: 0.139  Val. score: 96.760%\n",
      "Epoch 8, 100% \t Train loss: 0.139 took: 6.30s  Val. loss: 0.146  Val. score: 96.664%\n",
      "Epoch 9, 100% \t Train loss: 0.114 took: 6.30s  Val. loss: 0.149  Val. score: 96.658%\n",
      "Epoch 10, 100% \t Train loss: 0.123 took: 6.40s  Val. loss: 0.159  Val. score: 96.376%\n",
      "Training finished, took 93.679s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.438 took: 5.43s  Val. loss: 0.210  Val. score: 93.778%\n",
      "Epoch 2, 100% \t Train loss: 0.227 took: 4.72s  Val. loss: 0.168  Val. score: 95.446%\n",
      "Epoch 3, 100% \t Train loss: 0.186 took: 5.66s  Val. loss: 0.144  Val. score: 95.926%\n",
      "Epoch 4, 100% \t Train loss: 0.167 took: 5.93s  Val. loss: 0.146  Val. score: 96.232%\n",
      "Epoch 5, 100% \t Train loss: 0.155 took: 6.11s  Val. loss: 0.127  Val. score: 96.418%\n",
      "Epoch 6, 100% \t Train loss: 0.148 took: 5.72s  Val. loss: 0.151  Val. score: 96.646%\n",
      "Epoch 7, 100% \t Train loss: 0.143 took: 5.72s  Val. loss: 0.129  Val. score: 96.568%\n",
      "Epoch 8, 100% \t Train loss: 0.130 took: 6.45s  Val. loss: 0.143  Val. score: 96.604%\n",
      "Epoch 9, 100% \t Train loss: 0.128 took: 6.22s  Val. loss: 0.140  Val. score: 96.778%\n",
      "Epoch 10, 100% \t Train loss: 0.119 took: 6.56s  Val. loss: 0.149  Val. score: 96.868%\n",
      "Training finished, took 94.264s\n",
      "\n",
      "Parameters configuration 54 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00832535814576171\n",
      "h_sizes \t [784, 277, 102, 42]\n",
      "penalty \t 0.008361853977780893\n",
      "dropout \t 0.18445865828079366\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.6659 +/- 0.2103\n",
      "Time for evaluation: 282.7 s\n",
      "Estimated time to finish : 4.27 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.554 took: 7.02s  Val. loss: 0.249  Val. score: 93.208%\n",
      "Epoch 2, 100% \t Train loss: 0.227 took: 6.99s  Val. loss: 0.162  Val. score: 95.650%\n",
      "Epoch 3, 100% \t Train loss: 0.168 took: 7.70s  Val. loss: 0.151  Val. score: 95.944%\n",
      "Epoch 4, 100% \t Train loss: 0.139 took: 8.27s  Val. loss: 0.135  Val. score: 96.586%\n",
      "Epoch 5, 100% \t Train loss: 0.118 took: 8.51s  Val. loss: 0.139  Val. score: 96.664%\n",
      "Epoch 6, 100% \t Train loss: 0.101 took: 7.99s  Val. loss: 0.134  Val. score: 96.712%\n",
      "Epoch 7, 100% \t Train loss: 0.088 took: 8.65s  Val. loss: 0.131  Val. score: 97.048%\n",
      "Epoch 8, 100% \t Train loss: 0.081 took: 8.27s  Val. loss: 0.138  Val. score: 96.862%\n",
      "Epoch 9, 100% \t Train loss: 0.073 took: 8.39s  Val. loss: 0.123  Val. score: 97.186%\n",
      "Epoch 10, 100% \t Train loss: 0.062 took: 7.88s  Val. loss: 0.133  Val. score: 97.138%\n",
      "Training finished, took 120.081s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.546 took: 6.86s  Val. loss: 0.204  Val. score: 94.102%\n",
      "Epoch 2, 100% \t Train loss: 0.234 took: 6.94s  Val. loss: 0.157  Val. score: 95.668%\n",
      "Epoch 3, 100% \t Train loss: 0.167 took: 7.62s  Val. loss: 0.150  Val. score: 96.082%\n",
      "Epoch 4, 100% \t Train loss: 0.144 took: 8.33s  Val. loss: 0.133  Val. score: 96.418%\n",
      "Epoch 5, 100% \t Train loss: 0.119 took: 8.72s  Val. loss: 0.125  Val. score: 96.730%\n",
      "Epoch 6, 100% \t Train loss: 0.105 took: 8.42s  Val. loss: 0.114  Val. score: 97.078%\n",
      "Epoch 7, 100% \t Train loss: 0.097 took: 8.34s  Val. loss: 0.118  Val. score: 97.162%\n",
      "Epoch 8, 100% \t Train loss: 0.084 took: 8.70s  Val. loss: 0.114  Val. score: 97.360%\n",
      "Epoch 9, 100% \t Train loss: 0.072 took: 8.47s  Val. loss: 0.123  Val. score: 97.318%\n",
      "Epoch 10, 100% \t Train loss: 0.070 took: 7.88s  Val. loss: 0.129  Val. score: 97.150%\n",
      "Training finished, took 120.586s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.538 took: 7.14s  Val. loss: 0.218  Val. score: 94.240%\n",
      "Epoch 2, 100% \t Train loss: 0.234 took: 7.14s  Val. loss: 0.162  Val. score: 95.878%\n",
      "Epoch 3, 100% \t Train loss: 0.176 took: 7.63s  Val. loss: 0.161  Val. score: 96.202%\n",
      "Epoch 4, 100% \t Train loss: 0.142 took: 8.57s  Val. loss: 0.142  Val. score: 96.682%\n",
      "Epoch 5, 100% \t Train loss: 0.118 took: 8.45s  Val. loss: 0.134  Val. score: 96.736%\n",
      "Epoch 6, 100% \t Train loss: 0.104 took: 8.09s  Val. loss: 0.128  Val. score: 96.742%\n",
      "Epoch 7, 100% \t Train loss: 0.099 took: 8.35s  Val. loss: 0.124  Val. score: 97.144%\n",
      "Epoch 8, 100% \t Train loss: 0.084 took: 8.39s  Val. loss: 0.121  Val. score: 97.270%\n",
      "Epoch 9, 100% \t Train loss: 0.076 took: 8.31s  Val. loss: 0.142  Val. score: 97.018%\n",
      "Epoch 10, 100% \t Train loss: 0.073 took: 8.21s  Val. loss: 0.125  Val. score: 97.144%\n",
      "Training finished, took 120.450s\n",
      "\n",
      "Parameters configuration 55 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.02198551312074487\n",
      "h_sizes \t [784, 326, 143, 56, 24]\n",
      "penalty \t 0.0008554686653340579\n",
      "dropout \t 0.14885943020590423\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.1439 +/- 0.0049\n",
      "Time for evaluation: 362.2 s\n",
      "Estimated time to finish : 4.18 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.513 took: 3.85s  Val. loss: 0.216  Val. score: 93.538%\n",
      "Epoch 2, 100% \t Train loss: 0.215 took: 3.80s  Val. loss: 0.158  Val. score: 95.278%\n",
      "Epoch 3, 100% \t Train loss: 0.158 took: 3.76s  Val. loss: 0.129  Val. score: 96.124%\n",
      "Epoch 4, 100% \t Train loss: 0.129 took: 3.82s  Val. loss: 0.115  Val. score: 96.598%\n",
      "Epoch 5, 100% \t Train loss: 0.107 took: 3.49s  Val. loss: 0.105  Val. score: 97.066%\n",
      "Epoch 6, 100% \t Train loss: 0.093 took: 3.45s  Val. loss: 0.100  Val. score: 97.120%\n",
      "Epoch 7, 100% \t Train loss: 0.082 took: 3.86s  Val. loss: 0.092  Val. score: 97.324%\n",
      "Epoch 8, 100% \t Train loss: 0.075 took: 3.82s  Val. loss: 0.089  Val. score: 97.420%\n",
      "Epoch 9, 100% \t Train loss: 0.067 took: 3.86s  Val. loss: 0.088  Val. score: 97.570%\n",
      "Epoch 10, 100% \t Train loss: 0.062 took: 3.85s  Val. loss: 0.099  Val. score: 97.288%\n",
      "Training finished, took 67.408s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.512 took: 3.88s  Val. loss: 0.209  Val. score: 93.826%\n",
      "Epoch 2, 100% \t Train loss: 0.225 took: 3.47s  Val. loss: 0.156  Val. score: 95.284%\n",
      "Epoch 3, 100% \t Train loss: 0.165 took: 3.82s  Val. loss: 0.130  Val. score: 96.022%\n",
      "Epoch 4, 100% \t Train loss: 0.133 took: 3.84s  Val. loss: 0.111  Val. score: 96.646%\n",
      "Epoch 5, 100% \t Train loss: 0.112 took: 3.85s  Val. loss: 0.110  Val. score: 96.640%\n",
      "Epoch 6, 100% \t Train loss: 0.094 took: 3.90s  Val. loss: 0.101  Val. score: 96.916%\n",
      "Epoch 7, 100% \t Train loss: 0.084 took: 3.46s  Val. loss: 0.099  Val. score: 97.180%\n",
      "Epoch 8, 100% \t Train loss: 0.071 took: 3.52s  Val. loss: 0.096  Val. score: 97.162%\n",
      "Epoch 9, 100% \t Train loss: 0.069 took: 3.43s  Val. loss: 0.102  Val. score: 97.072%\n",
      "Epoch 10, 100% \t Train loss: 0.063 took: 3.81s  Val. loss: 0.098  Val. score: 97.258%\n",
      "Training finished, took 66.438s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.531 took: 3.85s  Val. loss: 0.229  Val. score: 93.016%\n",
      "Epoch 2, 100% \t Train loss: 0.219 took: 3.88s  Val. loss: 0.156  Val. score: 95.092%\n",
      "Epoch 3, 100% \t Train loss: 0.160 took: 3.52s  Val. loss: 0.132  Val. score: 95.920%\n",
      "Epoch 4, 100% \t Train loss: 0.130 took: 3.60s  Val. loss: 0.116  Val. score: 96.424%\n",
      "Epoch 5, 100% \t Train loss: 0.106 took: 3.79s  Val. loss: 0.112  Val. score: 96.634%\n",
      "Epoch 6, 100% \t Train loss: 0.093 took: 3.87s  Val. loss: 0.105  Val. score: 96.952%\n",
      "Epoch 7, 100% \t Train loss: 0.081 took: 3.83s  Val. loss: 0.103  Val. score: 96.874%\n",
      "Epoch 8, 100% \t Train loss: 0.077 took: 3.44s  Val. loss: 0.097  Val. score: 97.150%\n",
      "Epoch 9, 100% \t Train loss: 0.065 took: 3.46s  Val. loss: 0.104  Val. score: 97.090%\n",
      "Epoch 10, 100% \t Train loss: 0.059 took: 3.86s  Val. loss: 0.104  Val. score: 97.078%\n",
      "Training finished, took 66.767s\n",
      "\n",
      "Parameters configuration 56 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0021422450455047086\n",
      "h_sizes \t [784, 186, 35]\n",
      "penalty \t 0.0008060169352221008\n",
      "dropout \t 0.1824585453898257\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.2079 +/- 0.0927\n",
      "Time for evaluation: 201.7 s\n",
      "Estimated time to finish : 4.06 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.709 took: 3.17s  Val. loss: 0.405  Val. score: 89.380%\n",
      "Epoch 2, 100% \t Train loss: 0.405 took: 3.54s  Val. loss: 0.340  Val. score: 90.718%\n",
      "Epoch 3, 100% \t Train loss: 0.352 took: 3.49s  Val. loss: 0.312  Val. score: 91.408%\n",
      "Epoch 4, 100% \t Train loss: 0.328 took: 3.20s  Val. loss: 0.294  Val. score: 91.846%\n",
      "Epoch 5, 100% \t Train loss: 0.309 took: 3.21s  Val. loss: 0.283  Val. score: 92.080%\n",
      "Epoch 6, 100% \t Train loss: 0.292 took: 3.63s  Val. loss: 0.268  Val. score: 92.398%\n",
      "Epoch 7, 100% \t Train loss: 0.278 took: 3.33s  Val. loss: 0.260  Val. score: 92.800%\n",
      "Epoch 8, 100% \t Train loss: 0.268 took: 3.35s  Val. loss: 0.251  Val. score: 93.022%\n",
      "Epoch 9, 100% \t Train loss: 0.260 took: 3.56s  Val. loss: 0.244  Val. score: 93.226%\n",
      "Epoch 10, 100% \t Train loss: 0.252 took: 3.56s  Val. loss: 0.238  Val. score: 93.352%\n",
      "Training finished, took 64.707s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.680 took: 3.59s  Val. loss: 0.389  Val. score: 89.692%\n",
      "Epoch 2, 100% \t Train loss: 0.401 took: 3.47s  Val. loss: 0.331  Val. score: 90.832%\n",
      "Epoch 3, 100% \t Train loss: 0.356 took: 3.50s  Val. loss: 0.304  Val. score: 91.366%\n",
      "Epoch 4, 100% \t Train loss: 0.329 took: 3.40s  Val. loss: 0.288  Val. score: 91.750%\n",
      "Epoch 5, 100% \t Train loss: 0.309 took: 3.50s  Val. loss: 0.274  Val. score: 92.236%\n",
      "Epoch 6, 100% \t Train loss: 0.299 took: 3.31s  Val. loss: 0.268  Val. score: 92.542%\n",
      "Epoch 7, 100% \t Train loss: 0.284 took: 3.45s  Val. loss: 0.254  Val. score: 92.818%\n",
      "Epoch 8, 100% \t Train loss: 0.269 took: 3.56s  Val. loss: 0.247  Val. score: 92.914%\n",
      "Epoch 9, 100% \t Train loss: 0.263 took: 3.28s  Val. loss: 0.241  Val. score: 93.214%\n",
      "Epoch 10, 100% \t Train loss: 0.255 took: 3.24s  Val. loss: 0.234  Val. score: 93.274%\n",
      "Training finished, took 65.016s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.682 took: 3.35s  Val. loss: 0.387  Val. score: 89.350%\n",
      "Epoch 2, 100% \t Train loss: 0.394 took: 3.19s  Val. loss: 0.328  Val. score: 90.820%\n",
      "Epoch 3, 100% \t Train loss: 0.346 took: 3.45s  Val. loss: 0.302  Val. score: 91.234%\n",
      "Epoch 4, 100% \t Train loss: 0.321 took: 3.42s  Val. loss: 0.286  Val. score: 91.828%\n",
      "Epoch 5, 100% \t Train loss: 0.302 took: 3.42s  Val. loss: 0.272  Val. score: 92.176%\n",
      "Epoch 6, 100% \t Train loss: 0.289 took: 3.52s  Val. loss: 0.261  Val. score: 92.410%\n",
      "Epoch 7, 100% \t Train loss: 0.278 took: 3.56s  Val. loss: 0.253  Val. score: 92.596%\n",
      "Epoch 8, 100% \t Train loss: 0.267 took: 3.56s  Val. loss: 0.246  Val. score: 92.758%\n",
      "Epoch 9, 100% \t Train loss: 0.260 took: 3.43s  Val. loss: 0.240  Val. score: 93.016%\n",
      "Epoch 10, 100% \t Train loss: 0.253 took: 3.59s  Val. loss: 0.233  Val. score: 93.106%\n",
      "Training finished, took 65.369s\n",
      "\n",
      "Parameters configuration 57 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0027916068503331527\n",
      "h_sizes \t [784, 198, 44]\n",
      "penalty \t 0.0007188550564236634\n",
      "dropout \t 0.08257223213831072\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 93.2437 +/- 0.1026\n",
      "Time for evaluation: 196.2 s\n",
      "Estimated time to finish : 3.94 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.744 took: 4.37s  Val. loss: 0.362  Val. score: 89.674%\n",
      "Epoch 2, 100% \t Train loss: 0.340 took: 4.37s  Val. loss: 0.290  Val. score: 91.852%\n",
      "Epoch 3, 100% \t Train loss: 0.278 took: 4.39s  Val. loss: 0.250  Val. score: 92.794%\n",
      "Epoch 4, 100% \t Train loss: 0.238 took: 3.98s  Val. loss: 0.225  Val. score: 93.496%\n",
      "Epoch 5, 100% \t Train loss: 0.205 took: 4.04s  Val. loss: 0.200  Val. score: 94.234%\n",
      "Epoch 6, 100% \t Train loss: 0.181 took: 4.43s  Val. loss: 0.182  Val. score: 94.576%\n",
      "Epoch 7, 100% \t Train loss: 0.161 took: 4.42s  Val. loss: 0.168  Val. score: 94.990%\n",
      "Epoch 8, 100% \t Train loss: 0.146 took: 4.43s  Val. loss: 0.156  Val. score: 95.362%\n",
      "Epoch 9, 100% \t Train loss: 0.131 took: 4.40s  Val. loss: 0.148  Val. score: 95.566%\n",
      "Epoch 10, 100% \t Train loss: 0.119 took: 4.14s  Val. loss: 0.137  Val. score: 95.842%\n",
      "Training finished, took 73.035s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.745 took: 4.40s  Val. loss: 0.351  Val. score: 89.968%\n",
      "Epoch 2, 100% \t Train loss: 0.343 took: 4.08s  Val. loss: 0.282  Val. score: 91.696%\n",
      "Epoch 3, 100% \t Train loss: 0.282 took: 4.38s  Val. loss: 0.241  Val. score: 92.920%\n",
      "Epoch 4, 100% \t Train loss: 0.239 took: 4.43s  Val. loss: 0.210  Val. score: 93.652%\n",
      "Epoch 5, 100% \t Train loss: 0.205 took: 4.39s  Val. loss: 0.181  Val. score: 94.630%\n",
      "Epoch 6, 100% \t Train loss: 0.180 took: 4.41s  Val. loss: 0.162  Val. score: 95.164%\n",
      "Epoch 7, 100% \t Train loss: 0.161 took: 4.44s  Val. loss: 0.149  Val. score: 95.584%\n",
      "Epoch 8, 100% \t Train loss: 0.142 took: 4.34s  Val. loss: 0.140  Val. score: 95.788%\n",
      "Epoch 9, 100% \t Train loss: 0.128 took: 4.01s  Val. loss: 0.129  Val. score: 96.076%\n",
      "Epoch 10, 100% \t Train loss: 0.119 took: 4.46s  Val. loss: 0.119  Val. score: 96.310%\n",
      "Training finished, took 73.775s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.757 took: 4.36s  Val. loss: 0.345  Val. score: 90.646%\n",
      "Epoch 2, 100% \t Train loss: 0.348 took: 3.96s  Val. loss: 0.280  Val. score: 91.924%\n",
      "Epoch 3, 100% \t Train loss: 0.284 took: 4.12s  Val. loss: 0.235  Val. score: 93.448%\n",
      "Epoch 4, 100% \t Train loss: 0.240 took: 4.39s  Val. loss: 0.206  Val. score: 94.228%\n",
      "Epoch 5, 100% \t Train loss: 0.209 took: 4.44s  Val. loss: 0.185  Val. score: 94.582%\n",
      "Epoch 6, 100% \t Train loss: 0.182 took: 3.98s  Val. loss: 0.169  Val. score: 94.990%\n",
      "Epoch 7, 100% \t Train loss: 0.160 took: 4.47s  Val. loss: 0.155  Val. score: 95.422%\n",
      "Epoch 8, 100% \t Train loss: 0.144 took: 4.40s  Val. loss: 0.144  Val. score: 95.788%\n",
      "Epoch 9, 100% \t Train loss: 0.129 took: 4.47s  Val. loss: 0.135  Val. score: 95.956%\n",
      "Epoch 10, 100% \t Train loss: 0.119 took: 3.96s  Val. loss: 0.129  Val. score: 96.076%\n",
      "Training finished, took 72.701s\n",
      "\n",
      "Parameters configuration 58 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0011689952044494595\n",
      "h_sizes \t [784, 193, 50]\n",
      "penalty \t 0.000132336553776008\n",
      "dropout \t 0.07809963019141042\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 96.0758 +/- 0.1911\n",
      "Time for evaluation: 220.6 s\n",
      "Estimated time to finish : 3.82 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.450 took: 4.17s  Val. loss: 0.170  Val. score: 94.744%\n",
      "Epoch 2, 100% \t Train loss: 0.145 took: 4.69s  Val. loss: 0.157  Val. score: 95.176%\n",
      "Epoch 3, 100% \t Train loss: 0.102 took: 4.65s  Val. loss: 0.114  Val. score: 96.514%\n",
      "Epoch 4, 100% \t Train loss: 0.077 took: 4.22s  Val. loss: 0.097  Val. score: 97.066%\n",
      "Epoch 5, 100% \t Train loss: 0.061 took: 4.52s  Val. loss: 0.101  Val. score: 96.928%\n",
      "Epoch 6, 100% \t Train loss: 0.048 took: 4.56s  Val. loss: 0.089  Val. score: 97.180%\n",
      "Epoch 7, 100% \t Train loss: 0.041 took: 4.41s  Val. loss: 0.087  Val. score: 97.354%\n",
      "Epoch 8, 100% \t Train loss: 0.033 took: 4.55s  Val. loss: 0.090  Val. score: 97.354%\n",
      "Epoch 9, 100% \t Train loss: 0.030 took: 4.41s  Val. loss: 0.092  Val. score: 97.264%\n",
      "Epoch 10, 100% \t Train loss: 0.024 took: 4.52s  Val. loss: 0.097  Val. score: 97.252%\n",
      "Training finished, took 80.042s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.401 took: 4.52s  Val. loss: 0.179  Val. score: 94.756%\n",
      "Epoch 2, 100% \t Train loss: 0.136 took: 4.68s  Val. loss: 0.135  Val. score: 95.932%\n",
      "Epoch 3, 100% \t Train loss: 0.094 took: 4.16s  Val. loss: 0.116  Val. score: 96.622%\n",
      "Epoch 4, 100% \t Train loss: 0.074 took: 4.17s  Val. loss: 0.122  Val. score: 96.382%\n",
      "Epoch 5, 100% \t Train loss: 0.057 took: 4.27s  Val. loss: 0.105  Val. score: 96.964%\n",
      "Epoch 6, 100% \t Train loss: 0.045 took: 4.48s  Val. loss: 0.116  Val. score: 96.706%\n",
      "Epoch 7, 100% \t Train loss: 0.040 took: 4.35s  Val. loss: 0.098  Val. score: 97.216%\n",
      "Epoch 8, 100% \t Train loss: 0.032 took: 4.19s  Val. loss: 0.095  Val. score: 97.312%\n",
      "Epoch 9, 100% \t Train loss: 0.027 took: 4.39s  Val. loss: 0.096  Val. score: 97.414%\n",
      "Epoch 10, 100% \t Train loss: 0.023 took: 4.47s  Val. loss: 0.097  Val. score: 97.444%\n",
      "Training finished, took 79.147s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.442 took: 4.19s  Val. loss: 0.182  Val. score: 94.516%\n",
      "Epoch 2, 100% \t Train loss: 0.145 took: 4.56s  Val. loss: 0.149  Val. score: 95.662%\n",
      "Epoch 3, 100% \t Train loss: 0.102 took: 4.52s  Val. loss: 0.117  Val. score: 96.394%\n",
      "Epoch 4, 100% \t Train loss: 0.079 took: 4.38s  Val. loss: 0.103  Val. score: 96.874%\n",
      "Epoch 5, 100% \t Train loss: 0.063 took: 4.55s  Val. loss: 0.101  Val. score: 97.120%\n",
      "Epoch 6, 100% \t Train loss: 0.051 took: 4.15s  Val. loss: 0.094  Val. score: 97.222%\n",
      "Epoch 7, 100% \t Train loss: 0.041 took: 4.18s  Val. loss: 0.097  Val. score: 97.288%\n",
      "Epoch 8, 100% \t Train loss: 0.035 took: 4.19s  Val. loss: 0.094  Val. score: 97.324%\n",
      "Epoch 9, 100% \t Train loss: 0.029 took: 4.44s  Val. loss: 0.095  Val. score: 97.450%\n",
      "Epoch 10, 100% \t Train loss: 0.026 took: 4.18s  Val. loss: 0.097  Val. score: 97.360%\n",
      "Training finished, took 78.833s\n",
      "\n",
      "Parameters configuration 59 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.02732593305277972\n",
      "h_sizes \t [784, 278, 100, 39]\n",
      "penalty \t 0.0014455825401777954\n",
      "dropout \t 0.03538387763815615\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.3519 +/- 0.0786\n",
      "Time for evaluation: 239.1 s\n",
      "Estimated time to finish : 3.72 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.833 took: 11.98s  Val. loss: 2.117  Val. score: 19.159%\n",
      "Epoch 2, 100% \t Train loss: 2.265 took: 11.34s  Val. loss: 2.122  Val. score: 18.577%\n",
      "Epoch 3, 100% \t Train loss: 2.429 took: 14.35s  Val. loss: 2.302  Val. score: 11.310%\n",
      "Epoch 4, 100% \t Train loss: 2.302 took: 19.66s  Val. loss: 2.301  Val. score: 11.310%\n",
      "Epoch 5, 100% \t Train loss: 2.308 took: 18.52s  Val. loss: 2.302  Val. score: 10.836%\n",
      "Epoch 6, 100% \t Train loss: 2.304 took: 19.21s  Val. loss: 2.302  Val. score: 11.310%\n",
      "Epoch 7, 100% \t Train loss: 2.301 took: 19.43s  Val. loss: 2.303  Val. score: 11.310%\n",
      "Epoch 8, 100% \t Train loss: 2.303 took: 19.77s  Val. loss: 2.302  Val. score: 11.310%\n",
      "Epoch 9, 100% \t Train loss: 2.303 took: 19.93s  Val. loss: 2.305  Val. score: 9.726%\n",
      "Epoch 10, 100% \t Train loss: 2.303 took: 19.11s  Val. loss: 2.303  Val. score: 11.310%\n",
      "Training finished, took 235.559s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.909 took: 12.97s  Val. loss: 1.931  Val. score: 30.943%\n",
      "Epoch 2, 100% \t Train loss: 2.410 took: 12.92s  Val. loss: 2.302  Val. score: 9.912%\n",
      "Epoch 3, 100% \t Train loss: 2.304 took: 14.97s  Val. loss: 2.302  Val. score: 10.632%\n",
      "Epoch 4, 100% \t Train loss: 2.309 took: 19.61s  Val. loss: 2.302  Val. score: 11.364%\n",
      "Epoch 5, 100% \t Train loss: 2.303 took: 18.83s  Val. loss: 2.301  Val. score: 11.364%\n",
      "Epoch 6, 100% \t Train loss: 2.303 took: 19.24s  Val. loss: 2.303  Val. score: 11.364%\n",
      "Epoch 7, 100% \t Train loss: 2.303 took: 18.69s  Val. loss: 2.302  Val. score: 11.364%\n",
      "Epoch 8, 100% \t Train loss: 2.303 took: 19.83s  Val. loss: 2.304  Val. score: 11.364%\n",
      "Epoch 9, 100% \t Train loss: 2.303 took: 19.33s  Val. loss: 2.303  Val. score: 10.632%\n",
      "Epoch 10, 100% \t Train loss: 2.303 took: 19.34s  Val. loss: 2.302  Val. score: 11.364%\n",
      "Training finished, took 238.081s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.941 took: 12.70s  Val. loss: 2.317  Val. score: 11.664%\n",
      "Epoch 2, 100% \t Train loss: 2.581 took: 12.60s  Val. loss: 2.303  Val. score: 11.082%\n",
      "Epoch 3, 100% \t Train loss: 2.302 took: 15.57s  Val. loss: 2.304  Val. score: 9.702%\n",
      "Epoch 4, 100% \t Train loss: 2.303 took: 19.47s  Val. loss: 2.305  Val. score: 10.152%\n",
      "Epoch 5, 100% \t Train loss: 2.302 took: 18.83s  Val. loss: 2.304  Val. score: 11.082%\n",
      "Epoch 6, 100% \t Train loss: 2.302 took: 18.72s  Val. loss: 2.304  Val. score: 10.152%\n",
      "Epoch 7, 100% \t Train loss: 2.302 took: 19.94s  Val. loss: 2.302  Val. score: 11.082%\n",
      "Epoch 8, 100% \t Train loss: 2.302 took: 19.49s  Val. loss: 2.305  Val. score: 10.014%\n",
      "Epoch 9, 100% \t Train loss: 2.302 took: 18.74s  Val. loss: 2.303  Val. score: 11.082%\n",
      "Epoch 10, 100% \t Train loss: 2.302 took: 19.42s  Val. loss: 2.304  Val. score: 9.702%\n",
      "Training finished, took 238.015s\n",
      "\n",
      "Parameters configuration 60 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.024705431497769364\n",
      "h_sizes \t [784, 513, 332, 192, 109, 76, 51, 33, 17, 12]\n",
      "penalty \t 0.0077311463166655735\n",
      "dropout \t 0.14665653202738396\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 10.7924 +/- 0.7711\n",
      "Time for evaluation: 712.8 s\n",
      "Estimated time to finish : 3.70 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.734 took: 5.53s  Val. loss: 0.236  Val. score: 93.604%\n",
      "Epoch 2, 100% \t Train loss: 0.296 took: 5.65s  Val. loss: 0.202  Val. score: 94.438%\n",
      "Epoch 3, 100% \t Train loss: 0.229 took: 5.38s  Val. loss: 0.163  Val. score: 95.494%\n",
      "Epoch 4, 100% \t Train loss: 0.194 took: 5.96s  Val. loss: 0.155  Val. score: 95.764%\n",
      "Epoch 5, 100% \t Train loss: 0.175 took: 5.26s  Val. loss: 0.145  Val. score: 96.166%\n",
      "Epoch 6, 100% \t Train loss: 0.153 took: 5.23s  Val. loss: 0.146  Val. score: 96.262%\n",
      "Epoch 7, 100% \t Train loss: 0.138 took: 5.24s  Val. loss: 0.154  Val. score: 96.046%\n",
      "Epoch 8, 100% \t Train loss: 0.126 took: 5.75s  Val. loss: 0.139  Val. score: 96.298%\n",
      "Epoch 9, 100% \t Train loss: 0.121 took: 5.89s  Val. loss: 0.160  Val. score: 95.728%\n",
      "Epoch 10, 100% \t Train loss: 0.112 took: 5.38s  Val. loss: 0.133  Val. score: 96.616%\n",
      "Training finished, took 96.052s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.840 took: 5.74s  Val. loss: 0.251  Val. score: 93.436%\n",
      "Epoch 2, 100% \t Train loss: 0.302 took: 5.77s  Val. loss: 0.199  Val. score: 94.558%\n",
      "Epoch 3, 100% \t Train loss: 0.230 took: 5.77s  Val. loss: 0.172  Val. score: 95.350%\n",
      "Epoch 4, 100% \t Train loss: 0.198 took: 5.90s  Val. loss: 0.163  Val. score: 95.710%\n",
      "Epoch 5, 100% \t Train loss: 0.169 took: 5.95s  Val. loss: 0.165  Val. score: 95.764%\n",
      "Epoch 6, 100% \t Train loss: 0.156 took: 5.25s  Val. loss: 0.147  Val. score: 96.046%\n",
      "Epoch 7, 100% \t Train loss: 0.133 took: 5.26s  Val. loss: 0.156  Val. score: 96.178%\n",
      "Epoch 8, 100% \t Train loss: 0.124 took: 5.41s  Val. loss: 0.152  Val. score: 96.298%\n",
      "Epoch 9, 100% \t Train loss: 0.113 took: 5.88s  Val. loss: 0.147  Val. score: 96.454%\n",
      "Epoch 10, 100% \t Train loss: 0.113 took: 5.54s  Val. loss: 0.143  Val. score: 96.514%\n",
      "Training finished, took 97.808s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.816 took: 5.62s  Val. loss: 0.258  Val. score: 93.070%\n",
      "Epoch 2, 100% \t Train loss: 0.314 took: 5.30s  Val. loss: 0.204  Val. score: 94.324%\n",
      "Epoch 3, 100% \t Train loss: 0.248 took: 5.56s  Val. loss: 0.175  Val. score: 95.482%\n",
      "Epoch 4, 100% \t Train loss: 0.211 took: 5.26s  Val. loss: 0.165  Val. score: 95.692%\n",
      "Epoch 5, 100% \t Train loss: 0.185 took: 5.26s  Val. loss: 0.159  Val. score: 95.950%\n",
      "Epoch 6, 100% \t Train loss: 0.164 took: 5.26s  Val. loss: 0.140  Val. score: 96.418%\n",
      "Epoch 7, 100% \t Train loss: 0.151 took: 5.90s  Val. loss: 0.145  Val. score: 96.310%\n",
      "Epoch 8, 100% \t Train loss: 0.137 took: 5.26s  Val. loss: 0.133  Val. score: 96.592%\n",
      "Epoch 9, 100% \t Train loss: 0.131 took: 5.27s  Val. loss: 0.138  Val. score: 96.628%\n",
      "Epoch 10, 100% \t Train loss: 0.122 took: 5.29s  Val. loss: 0.137  Val. score: 96.526%\n",
      "Training finished, took 95.310s\n",
      "\n",
      "Parameters configuration 61 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.05109488264187131\n",
      "h_sizes \t [784, 342, 145, 61, 25]\n",
      "penalty \t 0.0002808154016195489\n",
      "dropout \t 0.16838520513594574\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.5519 +/- 0.0455\n",
      "Time for evaluation: 290.3 s\n",
      "Estimated time to finish : 3.60 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.740 took: 6.53s  Val. loss: 0.272  Val. score: 92.602%\n",
      "Epoch 2, 100% \t Train loss: 0.217 took: 6.29s  Val. loss: 0.197  Val. score: 94.624%\n",
      "Epoch 3, 100% \t Train loss: 0.152 took: 6.47s  Val. loss: 0.183  Val. score: 95.428%\n",
      "Epoch 4, 100% \t Train loss: 0.117 took: 6.57s  Val. loss: 0.149  Val. score: 96.310%\n",
      "Epoch 5, 100% \t Train loss: 0.092 took: 6.54s  Val. loss: 0.143  Val. score: 96.430%\n",
      "Epoch 6, 100% \t Train loss: 0.078 took: 5.95s  Val. loss: 0.124  Val. score: 96.844%\n",
      "Epoch 7, 100% \t Train loss: 0.058 took: 6.73s  Val. loss: 0.141  Val. score: 96.808%\n",
      "Epoch 8, 100% \t Train loss: 0.053 took: 6.64s  Val. loss: 0.134  Val. score: 96.916%\n",
      "Epoch 9, 100% \t Train loss: 0.045 took: 6.71s  Val. loss: 0.133  Val. score: 96.964%\n",
      "Epoch 10, 100% \t Train loss: 0.039 took: 6.61s  Val. loss: 0.125  Val. score: 97.156%\n",
      "Training finished, took 108.634s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.656 took: 6.62s  Val. loss: 0.240  Val. score: 93.148%\n",
      "Epoch 2, 100% \t Train loss: 0.186 took: 6.64s  Val. loss: 0.157  Val. score: 95.602%\n",
      "Epoch 3, 100% \t Train loss: 0.125 took: 6.32s  Val. loss: 0.149  Val. score: 95.950%\n",
      "Epoch 4, 100% \t Train loss: 0.095 took: 6.53s  Val. loss: 0.125  Val. score: 96.592%\n",
      "Epoch 5, 100% \t Train loss: 0.078 took: 6.70s  Val. loss: 0.117  Val. score: 96.892%\n",
      "Epoch 6, 100% \t Train loss: 0.063 took: 6.60s  Val. loss: 0.120  Val. score: 96.790%\n",
      "Epoch 7, 100% \t Train loss: 0.051 took: 5.93s  Val. loss: 0.122  Val. score: 97.000%\n",
      "Epoch 8, 100% \t Train loss: 0.042 took: 6.57s  Val. loss: 0.120  Val. score: 97.120%\n",
      "Epoch 9, 100% \t Train loss: 0.039 took: 6.48s  Val. loss: 0.112  Val. score: 97.234%\n",
      "Epoch 10, 100% \t Train loss: 0.032 took: 6.52s  Val. loss: 0.117  Val. score: 97.288%\n",
      "Training finished, took 109.013s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.680 took: 6.68s  Val. loss: 0.216  Val. score: 93.928%\n",
      "Epoch 2, 100% \t Train loss: 0.190 took: 6.42s  Val. loss: 0.161  Val. score: 95.476%\n",
      "Epoch 3, 100% \t Train loss: 0.133 took: 6.69s  Val. loss: 0.137  Val. score: 96.280%\n",
      "Epoch 4, 100% \t Train loss: 0.100 took: 6.38s  Val. loss: 0.128  Val. score: 96.508%\n",
      "Epoch 5, 100% \t Train loss: 0.081 took: 6.52s  Val. loss: 0.124  Val. score: 96.694%\n",
      "Epoch 6, 100% \t Train loss: 0.066 took: 6.44s  Val. loss: 0.109  Val. score: 97.192%\n",
      "Epoch 7, 100% \t Train loss: 0.055 took: 5.93s  Val. loss: 0.115  Val. score: 97.132%\n",
      "Epoch 8, 100% \t Train loss: 0.044 took: 6.03s  Val. loss: 0.111  Val. score: 97.330%\n",
      "Epoch 9, 100% \t Train loss: 0.040 took: 5.96s  Val. loss: 0.121  Val. score: 97.282%\n",
      "Epoch 10, 100% \t Train loss: 0.034 took: 5.93s  Val. loss: 0.116  Val. score: 97.342%\n",
      "Training finished, took 107.097s\n",
      "\n",
      "Parameters configuration 62 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.029287638420366868\n",
      "h_sizes \t [784, 376, 178, 75, 43, 25]\n",
      "penalty \t 0.00043440603957187017\n",
      "dropout \t 0.04314147063796506\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.2619 +/- 0.0781\n",
      "Time for evaluation: 325.8 s\n",
      "Estimated time to finish : 3.50 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.676 took: 5.17s  Val. loss: 0.231  Val. score: 93.256%\n",
      "Epoch 2, 100% \t Train loss: 0.259 took: 5.04s  Val. loss: 0.151  Val. score: 95.356%\n",
      "Epoch 3, 100% \t Train loss: 0.183 took: 5.49s  Val. loss: 0.138  Val. score: 95.824%\n",
      "Epoch 4, 100% \t Train loss: 0.143 took: 5.71s  Val. loss: 0.112  Val. score: 96.664%\n",
      "Epoch 5, 100% \t Train loss: 0.118 took: 5.55s  Val. loss: 0.116  Val. score: 96.676%\n",
      "Epoch 6, 100% \t Train loss: 0.102 took: 5.30s  Val. loss: 0.096  Val. score: 97.000%\n",
      "Epoch 7, 100% \t Train loss: 0.084 took: 5.39s  Val. loss: 0.091  Val. score: 97.228%\n",
      "Epoch 8, 100% \t Train loss: 0.079 took: 5.26s  Val. loss: 0.092  Val. score: 97.402%\n",
      "Epoch 9, 100% \t Train loss: 0.069 took: 5.28s  Val. loss: 0.099  Val. score: 97.324%\n",
      "Epoch 10, 100% \t Train loss: 0.062 took: 5.63s  Val. loss: 0.096  Val. score: 97.450%\n",
      "Training finished, took 90.360s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.649 took: 5.29s  Val. loss: 0.249  Val. score: 92.608%\n",
      "Epoch 2, 100% \t Train loss: 0.256 took: 5.28s  Val. loss: 0.163  Val. score: 94.990%\n",
      "Epoch 3, 100% \t Train loss: 0.180 took: 5.34s  Val. loss: 0.141  Val. score: 95.884%\n",
      "Epoch 4, 100% \t Train loss: 0.145 took: 5.59s  Val. loss: 0.124  Val. score: 96.346%\n",
      "Epoch 5, 100% \t Train loss: 0.119 took: 5.52s  Val. loss: 0.109  Val. score: 96.712%\n",
      "Epoch 6, 100% \t Train loss: 0.102 took: 5.70s  Val. loss: 0.103  Val. score: 97.030%\n",
      "Epoch 7, 100% \t Train loss: 0.088 took: 5.61s  Val. loss: 0.107  Val. score: 97.018%\n",
      "Epoch 8, 100% \t Train loss: 0.077 took: 5.59s  Val. loss: 0.106  Val. score: 97.060%\n",
      "Epoch 9, 100% \t Train loss: 0.068 took: 5.11s  Val. loss: 0.101  Val. score: 97.180%\n",
      "Epoch 10, 100% \t Train loss: 0.061 took: 5.13s  Val. loss: 0.102  Val. score: 97.318%\n",
      "Training finished, took 90.724s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.677 took: 4.84s  Val. loss: 0.236  Val. score: 93.202%\n",
      "Epoch 2, 100% \t Train loss: 0.252 took: 5.23s  Val. loss: 0.159  Val. score: 95.590%\n",
      "Epoch 3, 100% \t Train loss: 0.177 took: 4.99s  Val. loss: 0.136  Val. score: 96.082%\n",
      "Epoch 4, 100% \t Train loss: 0.136 took: 5.13s  Val. loss: 0.121  Val. score: 96.466%\n",
      "Epoch 5, 100% \t Train loss: 0.113 took: 5.24s  Val. loss: 0.116  Val. score: 96.742%\n",
      "Epoch 6, 100% \t Train loss: 0.097 took: 5.17s  Val. loss: 0.101  Val. score: 97.150%\n",
      "Epoch 7, 100% \t Train loss: 0.081 took: 5.68s  Val. loss: 0.109  Val. score: 97.228%\n",
      "Epoch 8, 100% \t Train loss: 0.073 took: 5.24s  Val. loss: 0.103  Val. score: 97.294%\n",
      "Epoch 9, 100% \t Train loss: 0.067 took: 5.16s  Val. loss: 0.105  Val. score: 97.360%\n",
      "Epoch 10, 100% \t Train loss: 0.058 took: 5.54s  Val. loss: 0.104  Val. score: 97.432%\n",
      "Training finished, took 88.509s\n",
      "\n",
      "Parameters configuration 63 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0012985192830829973\n",
      "h_sizes \t [784, 286, 92, 31]\n",
      "penalty \t 0.0013038960917419018\n",
      "dropout \t 0.20171874231851802\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.3999 +/- 0.0584\n",
      "Time for evaluation: 270.7 s\n",
      "Estimated time to finish : 3.40 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.589 took: 5.13s  Val. loss: 0.330  Val. score: 92.092%\n",
      "Epoch 2, 100% \t Train loss: 0.439 took: 5.24s  Val. loss: 0.256  Val. score: 93.538%\n",
      "Epoch 3, 100% \t Train loss: 0.401 took: 5.54s  Val. loss: 0.252  Val. score: 93.652%\n",
      "Epoch 4, 100% \t Train loss: 0.390 took: 6.45s  Val. loss: 0.275  Val. score: 93.436%\n",
      "Epoch 5, 100% \t Train loss: 0.375 took: 6.89s  Val. loss: 0.256  Val. score: 93.592%\n",
      "Epoch 6, 100% \t Train loss: 0.371 took: 6.56s  Val. loss: 0.289  Val. score: 93.364%\n",
      "Epoch 7, 100% \t Train loss: 0.362 took: 6.61s  Val. loss: 0.249  Val. score: 94.348%\n",
      "Epoch 8, 100% \t Train loss: 0.365 took: 6.70s  Val. loss: 0.281  Val. score: 94.444%\n",
      "Epoch 9, 100% \t Train loss: 0.363 took: 6.66s  Val. loss: 0.285  Val. score: 94.066%\n",
      "Epoch 10, 100% \t Train loss: 0.359 took: 7.28s  Val. loss: 0.287  Val. score: 94.240%\n",
      "Training finished, took 98.443s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.637 took: 5.26s  Val. loss: 0.278  Val. score: 93.064%\n",
      "Epoch 2, 100% \t Train loss: 0.458 took: 5.32s  Val. loss: 0.284  Val. score: 93.094%\n",
      "Epoch 3, 100% \t Train loss: 0.425 took: 5.38s  Val. loss: 0.265  Val. score: 93.898%\n",
      "Epoch 4, 100% \t Train loss: 0.414 took: 6.80s  Val. loss: 0.306  Val. score: 93.448%\n",
      "Epoch 5, 100% \t Train loss: 0.411 took: 6.86s  Val. loss: 0.268  Val. score: 93.676%\n",
      "Epoch 6, 100% \t Train loss: 0.399 took: 6.82s  Val. loss: 0.303  Val. score: 92.902%\n",
      "Epoch 7, 100% \t Train loss: 0.382 took: 6.64s  Val. loss: 0.233  Val. score: 94.546%\n",
      "Epoch 8, 100% \t Train loss: 0.378 took: 6.74s  Val. loss: 0.217  Val. score: 95.020%\n",
      "Epoch 9, 100% \t Train loss: 0.352 took: 7.05s  Val. loss: 0.249  Val. score: 94.144%\n",
      "Epoch 10, 100% \t Train loss: 0.357 took: 6.99s  Val. loss: 0.281  Val. score: 94.258%\n",
      "Training finished, took 99.316s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.634 took: 4.96s  Val. loss: 0.277  Val. score: 92.770%\n",
      "Epoch 2, 100% \t Train loss: 0.447 took: 5.34s  Val. loss: 0.323  Val. score: 92.566%\n",
      "Epoch 3, 100% \t Train loss: 0.434 took: 5.69s  Val. loss: 0.292  Val. score: 93.094%\n",
      "Epoch 4, 100% \t Train loss: 0.406 took: 7.19s  Val. loss: 0.309  Val. score: 92.512%\n",
      "Epoch 5, 100% \t Train loss: 0.387 took: 6.55s  Val. loss: 0.269  Val. score: 93.946%\n",
      "Epoch 6, 100% \t Train loss: 0.435 took: 6.65s  Val. loss: 0.303  Val. score: 93.286%\n",
      "Epoch 7, 100% \t Train loss: 0.398 took: 6.67s  Val. loss: 0.231  Val. score: 94.420%\n",
      "Epoch 8, 100% \t Train loss: 0.389 took: 6.98s  Val. loss: 0.286  Val. score: 94.018%\n",
      "Epoch 9, 100% \t Train loss: 0.377 took: 7.26s  Val. loss: 0.265  Val. score: 93.952%\n",
      "Epoch 10, 100% \t Train loss: 0.400 took: 6.96s  Val. loss: 0.285  Val. score: 93.106%\n",
      "Training finished, took 99.377s\n",
      "\n",
      "Parameters configuration 64 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.021018873037980793\n",
      "h_sizes \t [784, 271, 93, 34]\n",
      "penalty \t 0.001095996666790129\n",
      "dropout \t 0.2278369253463069\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 93.8678 +/- 0.5389\n",
      "Time for evaluation: 298.2 s\n",
      "Estimated time to finish : 3.30 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.141 took: 7.95s  Val. loss: 0.605  Val. score: 79.671%\n",
      "Epoch 2, 100% \t Train loss: 0.701 took: 9.22s  Val. loss: 0.467  Val. score: 88.594%\n",
      "Epoch 3, 100% \t Train loss: 0.589 took: 9.27s  Val. loss: 0.361  Val. score: 91.252%\n",
      "Epoch 4, 100% \t Train loss: 0.543 took: 9.73s  Val. loss: 0.313  Val. score: 92.656%\n",
      "Epoch 5, 100% \t Train loss: 0.489 took: 10.72s  Val. loss: 0.324  Val. score: 91.888%\n",
      "Epoch 6, 100% \t Train loss: 0.508 took: 10.74s  Val. loss: 0.280  Val. score: 93.514%\n",
      "Epoch 7, 100% \t Train loss: 0.474 took: 11.44s  Val. loss: 0.312  Val. score: 93.592%\n",
      "Epoch 8, 100% \t Train loss: 0.461 took: 12.16s  Val. loss: 0.286  Val. score: 93.472%\n",
      "Epoch 9, 100% \t Train loss: 0.455 took: 12.79s  Val. loss: 0.300  Val. score: 93.772%\n",
      "Epoch 10, 100% \t Train loss: 0.460 took: 13.77s  Val. loss: 0.348  Val. score: 93.412%\n",
      "Training finished, took 156.545s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.198 took: 7.89s  Val. loss: 0.645  Val. score: 81.963%\n",
      "Epoch 2, 100% \t Train loss: 0.772 took: 8.38s  Val. loss: 0.479  Val. score: 88.942%\n",
      "Epoch 3, 100% \t Train loss: 0.612 took: 10.07s  Val. loss: 0.331  Val. score: 92.488%\n",
      "Epoch 4, 100% \t Train loss: 0.528 took: 9.68s  Val. loss: 0.337  Val. score: 91.654%\n",
      "Epoch 5, 100% \t Train loss: 0.504 took: 11.12s  Val. loss: 0.281  Val. score: 92.770%\n",
      "Epoch 6, 100% \t Train loss: 0.481 took: 10.05s  Val. loss: 0.270  Val. score: 94.384%\n",
      "Epoch 7, 100% \t Train loss: 0.465 took: 11.18s  Val. loss: 0.291  Val. score: 94.342%\n",
      "Epoch 8, 100% \t Train loss: 0.456 took: 11.68s  Val. loss: 0.247  Val. score: 94.510%\n",
      "Epoch 9, 100% \t Train loss: 0.427 took: 12.05s  Val. loss: 0.238  Val. score: 95.122%\n",
      "Epoch 10, 100% \t Train loss: 0.410 took: 11.62s  Val. loss: 0.232  Val. score: 93.946%\n",
      "Training finished, took 152.421s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.992 took: 8.50s  Val. loss: 0.413  Val. score: 90.928%\n",
      "Epoch 2, 100% \t Train loss: 0.547 took: 8.48s  Val. loss: 0.264  Val. score: 93.850%\n",
      "Epoch 3, 100% \t Train loss: 0.461 took: 8.60s  Val. loss: 0.258  Val. score: 94.450%\n",
      "Epoch 4, 100% \t Train loss: 0.420 took: 9.69s  Val. loss: 0.252  Val. score: 94.966%\n",
      "Epoch 5, 100% \t Train loss: 0.383 took: 9.99s  Val. loss: 0.219  Val. score: 94.666%\n",
      "Epoch 6, 100% \t Train loss: 0.379 took: 9.45s  Val. loss: 0.234  Val. score: 94.786%\n",
      "Epoch 7, 100% \t Train loss: 0.377 took: 11.06s  Val. loss: 0.204  Val. score: 95.782%\n",
      "Epoch 8, 100% \t Train loss: 0.390 took: 10.90s  Val. loss: 0.256  Val. score: 94.570%\n",
      "Epoch 9, 100% \t Train loss: 0.396 took: 11.03s  Val. loss: 0.228  Val. score: 95.374%\n",
      "Epoch 10, 100% \t Train loss: 0.366 took: 12.56s  Val. loss: 0.216  Val. score: 95.308%\n",
      "Training finished, took 148.613s\n",
      "\n",
      "Parameters configuration 65 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.007911234094433662\n",
      "h_sizes \t [784, 414, 221, 111, 52, 30, 14]\n",
      "penalty \t 0.002987934642494971\n",
      "dropout \t 0.23892697450806277\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 94.2218 +/- 0.7983\n",
      "Time for evaluation: 458.7 s\n",
      "Estimated time to finish : 3.23 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.526 took: 3.19s  Val. loss: 0.273  Val. score: 92.062%\n",
      "Epoch 2, 100% \t Train loss: 0.300 took: 3.59s  Val. loss: 0.212  Val. score: 93.706%\n",
      "Epoch 3, 100% \t Train loss: 0.254 took: 3.41s  Val. loss: 0.189  Val. score: 94.264%\n",
      "Epoch 4, 100% \t Train loss: 0.226 took: 3.25s  Val. loss: 0.169  Val. score: 94.906%\n",
      "Epoch 5, 100% \t Train loss: 0.209 took: 3.18s  Val. loss: 0.157  Val. score: 95.206%\n",
      "Epoch 6, 100% \t Train loss: 0.191 took: 3.58s  Val. loss: 0.149  Val. score: 95.362%\n",
      "Epoch 7, 100% \t Train loss: 0.181 took: 3.21s  Val. loss: 0.142  Val. score: 95.554%\n",
      "Epoch 8, 100% \t Train loss: 0.169 took: 3.52s  Val. loss: 0.136  Val. score: 95.764%\n",
      "Epoch 9, 100% \t Train loss: 0.160 took: 3.53s  Val. loss: 0.133  Val. score: 95.956%\n",
      "Epoch 10, 100% \t Train loss: 0.155 took: 3.18s  Val. loss: 0.126  Val. score: 96.046%\n",
      "Training finished, took 64.150s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.528 took: 3.20s  Val. loss: 0.286  Val. score: 91.474%\n",
      "Epoch 2, 100% \t Train loss: 0.307 took: 3.56s  Val. loss: 0.237  Val. score: 92.968%\n",
      "Epoch 3, 100% \t Train loss: 0.257 took: 3.34s  Val. loss: 0.208  Val. score: 93.778%\n",
      "Epoch 4, 100% \t Train loss: 0.228 took: 3.60s  Val. loss: 0.190  Val. score: 94.294%\n",
      "Epoch 5, 100% \t Train loss: 0.207 took: 3.28s  Val. loss: 0.177  Val. score: 94.720%\n",
      "Epoch 6, 100% \t Train loss: 0.190 took: 3.23s  Val. loss: 0.166  Val. score: 94.912%\n",
      "Epoch 7, 100% \t Train loss: 0.178 took: 3.57s  Val. loss: 0.160  Val. score: 95.128%\n",
      "Epoch 8, 100% \t Train loss: 0.168 took: 3.18s  Val. loss: 0.154  Val. score: 95.350%\n",
      "Epoch 9, 100% \t Train loss: 0.160 took: 3.19s  Val. loss: 0.149  Val. score: 95.542%\n",
      "Epoch 10, 100% \t Train loss: 0.153 took: 3.50s  Val. loss: 0.145  Val. score: 95.620%\n",
      "Training finished, took 64.376s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.521 took: 3.54s  Val. loss: 0.269  Val. score: 92.314%\n",
      "Epoch 2, 100% \t Train loss: 0.296 took: 3.58s  Val. loss: 0.218  Val. score: 93.646%\n",
      "Epoch 3, 100% \t Train loss: 0.248 took: 3.61s  Val. loss: 0.196  Val. score: 94.246%\n",
      "Epoch 4, 100% \t Train loss: 0.224 took: 3.65s  Val. loss: 0.179  Val. score: 94.648%\n",
      "Epoch 5, 100% \t Train loss: 0.201 took: 3.25s  Val. loss: 0.166  Val. score: 95.092%\n",
      "Epoch 6, 100% \t Train loss: 0.188 took: 3.19s  Val. loss: 0.158  Val. score: 95.278%\n",
      "Epoch 7, 100% \t Train loss: 0.176 took: 3.56s  Val. loss: 0.149  Val. score: 95.614%\n",
      "Epoch 8, 100% \t Train loss: 0.167 took: 3.53s  Val. loss: 0.140  Val. score: 95.848%\n",
      "Epoch 9, 100% \t Train loss: 0.160 took: 3.55s  Val. loss: 0.138  Val. score: 95.914%\n",
      "Epoch 10, 100% \t Train loss: 0.151 took: 3.55s  Val. loss: 0.132  Val. score: 96.112%\n",
      "Training finished, took 65.830s\n",
      "\n",
      "Parameters configuration 66 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008356840227188436\n",
      "h_sizes \t [784, 203, 47]\n",
      "penalty \t 0.003585294788687961\n",
      "dropout \t 0.24830568165062988\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 95.9258 +/- 0.2181\n",
      "Time for evaluation: 195.4 s\n",
      "Estimated time to finish : 3.12 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.454 took: 4.08s  Val. loss: 0.195  Val. score: 94.420%\n",
      "Epoch 2, 100% \t Train loss: 0.229 took: 4.16s  Val. loss: 0.161  Val. score: 95.488%\n",
      "Epoch 3, 100% \t Train loss: 0.189 took: 3.81s  Val. loss: 0.144  Val. score: 95.896%\n",
      "Epoch 4, 100% \t Train loss: 0.161 took: 3.75s  Val. loss: 0.148  Val. score: 96.004%\n",
      "Epoch 5, 100% \t Train loss: 0.145 took: 3.76s  Val. loss: 0.131  Val. score: 96.322%\n",
      "Epoch 6, 100% \t Train loss: 0.131 took: 4.17s  Val. loss: 0.132  Val. score: 96.532%\n",
      "Epoch 7, 100% \t Train loss: 0.131 took: 3.77s  Val. loss: 0.131  Val. score: 96.538%\n",
      "Epoch 8, 100% \t Train loss: 0.117 took: 4.17s  Val. loss: 0.123  Val. score: 96.664%\n",
      "Epoch 9, 100% \t Train loss: 0.109 took: 4.11s  Val. loss: 0.127  Val. score: 96.754%\n",
      "Epoch 10, 100% \t Train loss: 0.099 took: 4.14s  Val. loss: 0.133  Val. score: 96.712%\n",
      "Training finished, took 69.077s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.472 took: 4.21s  Val. loss: 0.188  Val. score: 94.522%\n",
      "Epoch 2, 100% \t Train loss: 0.239 took: 4.13s  Val. loss: 0.155  Val. score: 95.314%\n",
      "Epoch 3, 100% \t Train loss: 0.193 took: 4.18s  Val. loss: 0.144  Val. score: 95.842%\n",
      "Epoch 4, 100% \t Train loss: 0.172 took: 4.10s  Val. loss: 0.124  Val. score: 96.538%\n",
      "Epoch 5, 100% \t Train loss: 0.153 took: 4.27s  Val. loss: 0.129  Val. score: 96.304%\n",
      "Epoch 6, 100% \t Train loss: 0.142 took: 4.14s  Val. loss: 0.122  Val. score: 96.466%\n",
      "Epoch 7, 100% \t Train loss: 0.133 took: 4.17s  Val. loss: 0.120  Val. score: 96.622%\n",
      "Epoch 8, 100% \t Train loss: 0.121 took: 4.15s  Val. loss: 0.120  Val. score: 96.658%\n",
      "Epoch 9, 100% \t Train loss: 0.114 took: 4.15s  Val. loss: 0.115  Val. score: 96.916%\n",
      "Epoch 10, 100% \t Train loss: 0.112 took: 3.97s  Val. loss: 0.118  Val. score: 96.820%\n",
      "Training finished, took 70.559s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.483 took: 3.76s  Val. loss: 0.200  Val. score: 93.898%\n",
      "Epoch 2, 100% \t Train loss: 0.255 took: 3.88s  Val. loss: 0.160  Val. score: 95.290%\n",
      "Epoch 3, 100% \t Train loss: 0.213 took: 4.20s  Val. loss: 0.156  Val. score: 95.242%\n",
      "Epoch 4, 100% \t Train loss: 0.188 took: 4.10s  Val. loss: 0.152  Val. score: 95.710%\n",
      "Epoch 5, 100% \t Train loss: 0.169 took: 4.18s  Val. loss: 0.141  Val. score: 95.968%\n",
      "Epoch 6, 100% \t Train loss: 0.158 took: 4.19s  Val. loss: 0.134  Val. score: 96.100%\n",
      "Epoch 7, 100% \t Train loss: 0.142 took: 4.11s  Val. loss: 0.121  Val. score: 96.316%\n",
      "Epoch 8, 100% \t Train loss: 0.136 took: 4.09s  Val. loss: 0.131  Val. score: 96.298%\n",
      "Epoch 9, 100% \t Train loss: 0.128 took: 4.18s  Val. loss: 0.128  Val. score: 96.496%\n",
      "Epoch 10, 100% \t Train loss: 0.124 took: 4.11s  Val. loss: 0.129  Val. score: 96.424%\n",
      "Training finished, took 69.924s\n",
      "\n",
      "Parameters configuration 67 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.03224408973474611\n",
      "h_sizes \t [784, 175, 49]\n",
      "penalty \t 0.0004022943536542634\n",
      "dropout \t 0.22347396781393866\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 96.6519 +/- 0.1671\n",
      "Time for evaluation: 210.6 s\n",
      "Estimated time to finish : 3.01 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.542 took: 5.61s  Val. loss: 0.263  Val. score: 92.362%\n",
      "Epoch 2, 100% \t Train loss: 0.232 took: 5.73s  Val. loss: 0.197  Val. score: 93.988%\n",
      "Epoch 3, 100% \t Train loss: 0.164 took: 5.43s  Val. loss: 0.145  Val. score: 95.662%\n",
      "Epoch 4, 100% \t Train loss: 0.128 took: 6.14s  Val. loss: 0.131  Val. score: 96.094%\n",
      "Epoch 5, 100% \t Train loss: 0.102 took: 6.09s  Val. loss: 0.110  Val. score: 96.640%\n",
      "Epoch 6, 100% \t Train loss: 0.082 took: 5.77s  Val. loss: 0.103  Val. score: 96.922%\n",
      "Epoch 7, 100% \t Train loss: 0.068 took: 6.18s  Val. loss: 0.101  Val. score: 96.940%\n",
      "Epoch 8, 100% \t Train loss: 0.055 took: 6.16s  Val. loss: 0.092  Val. score: 97.234%\n",
      "Epoch 9, 100% \t Train loss: 0.046 took: 5.91s  Val. loss: 0.095  Val. score: 97.222%\n",
      "Epoch 10, 100% \t Train loss: 0.038 took: 5.58s  Val. loss: 0.090  Val. score: 97.312%\n",
      "Training finished, took 93.891s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.523 took: 5.49s  Val. loss: 0.277  Val. score: 92.242%\n",
      "Epoch 2, 100% \t Train loss: 0.224 took: 5.31s  Val. loss: 0.183  Val. score: 94.402%\n",
      "Epoch 3, 100% \t Train loss: 0.159 took: 5.42s  Val. loss: 0.146  Val. score: 95.542%\n",
      "Epoch 4, 100% \t Train loss: 0.119 took: 6.13s  Val. loss: 0.124  Val. score: 96.076%\n",
      "Epoch 5, 100% \t Train loss: 0.096 took: 6.21s  Val. loss: 0.116  Val. score: 96.472%\n",
      "Epoch 6, 100% \t Train loss: 0.077 took: 5.98s  Val. loss: 0.113  Val. score: 96.592%\n",
      "Epoch 7, 100% \t Train loss: 0.063 took: 5.99s  Val. loss: 0.107  Val. score: 96.700%\n",
      "Epoch 8, 100% \t Train loss: 0.051 took: 6.17s  Val. loss: 0.101  Val. score: 96.952%\n",
      "Epoch 9, 100% \t Train loss: 0.042 took: 5.97s  Val. loss: 0.105  Val. score: 96.964%\n",
      "Epoch 10, 100% \t Train loss: 0.035 took: 5.59s  Val. loss: 0.101  Val. score: 97.090%\n",
      "Training finished, took 93.570s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.543 took: 5.26s  Val. loss: 0.264  Val. score: 92.212%\n",
      "Epoch 2, 100% \t Train loss: 0.226 took: 5.91s  Val. loss: 0.190  Val. score: 94.246%\n",
      "Epoch 3, 100% \t Train loss: 0.159 took: 5.43s  Val. loss: 0.158  Val. score: 95.422%\n",
      "Epoch 4, 100% \t Train loss: 0.119 took: 5.79s  Val. loss: 0.133  Val. score: 96.076%\n",
      "Epoch 5, 100% \t Train loss: 0.099 took: 5.59s  Val. loss: 0.125  Val. score: 96.382%\n",
      "Epoch 6, 100% \t Train loss: 0.076 took: 6.25s  Val. loss: 0.104  Val. score: 96.994%\n",
      "Epoch 7, 100% \t Train loss: 0.063 took: 6.41s  Val. loss: 0.103  Val. score: 97.006%\n",
      "Epoch 8, 100% \t Train loss: 0.052 took: 5.84s  Val. loss: 0.108  Val. score: 96.886%\n",
      "Epoch 9, 100% \t Train loss: 0.041 took: 6.23s  Val. loss: 0.105  Val. score: 97.084%\n",
      "Epoch 10, 100% \t Train loss: 0.036 took: 6.06s  Val. loss: 0.100  Val. score: 97.168%\n",
      "Training finished, took 94.121s\n",
      "\n",
      "Parameters configuration 68 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00296977292858642\n",
      "h_sizes \t [784, 245, 97, 41]\n",
      "penalty \t 0.00015330974177846243\n",
      "dropout \t 0.02261601854249423\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.1899 +/- 0.0920\n",
      "Time for evaluation: 282.7 s\n",
      "Estimated time to finish : 2.91 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.455 took: 4.39s  Val. loss: 0.191  Val. score: 94.186%\n",
      "Epoch 2, 100% \t Train loss: 0.224 took: 4.34s  Val. loss: 0.159  Val. score: 94.996%\n",
      "Epoch 3, 100% \t Train loss: 0.170 took: 4.09s  Val. loss: 0.126  Val. score: 96.046%\n",
      "Epoch 4, 100% \t Train loss: 0.136 took: 4.50s  Val. loss: 0.117  Val. score: 96.424%\n",
      "Epoch 5, 100% \t Train loss: 0.120 took: 4.35s  Val. loss: 0.103  Val. score: 96.694%\n",
      "Epoch 6, 100% \t Train loss: 0.110 took: 4.40s  Val. loss: 0.097  Val. score: 97.084%\n",
      "Epoch 7, 100% \t Train loss: 0.096 took: 4.70s  Val. loss: 0.096  Val. score: 97.078%\n",
      "Epoch 8, 100% \t Train loss: 0.086 took: 4.31s  Val. loss: 0.099  Val. score: 97.168%\n",
      "Epoch 9, 100% \t Train loss: 0.082 took: 4.33s  Val. loss: 0.094  Val. score: 97.186%\n",
      "Epoch 10, 100% \t Train loss: 0.076 took: 4.70s  Val. loss: 0.095  Val. score: 97.360%\n",
      "Training finished, took 74.567s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.436 took: 4.42s  Val. loss: 0.184  Val. score: 94.426%\n",
      "Epoch 2, 100% \t Train loss: 0.212 took: 4.50s  Val. loss: 0.137  Val. score: 95.734%\n",
      "Epoch 3, 100% \t Train loss: 0.166 took: 4.08s  Val. loss: 0.120  Val. score: 96.388%\n",
      "Epoch 4, 100% \t Train loss: 0.136 took: 4.30s  Val. loss: 0.108  Val. score: 96.652%\n",
      "Epoch 5, 100% \t Train loss: 0.118 took: 4.70s  Val. loss: 0.111  Val. score: 96.856%\n",
      "Epoch 6, 100% \t Train loss: 0.103 took: 4.67s  Val. loss: 0.097  Val. score: 97.216%\n",
      "Epoch 7, 100% \t Train loss: 0.089 took: 4.72s  Val. loss: 0.093  Val. score: 97.432%\n",
      "Epoch 8, 100% \t Train loss: 0.080 took: 4.32s  Val. loss: 0.095  Val. score: 97.360%\n",
      "Epoch 9, 100% \t Train loss: 0.076 took: 4.35s  Val. loss: 0.098  Val. score: 97.348%\n",
      "Epoch 10, 100% \t Train loss: 0.071 took: 4.65s  Val. loss: 0.098  Val. score: 97.546%\n",
      "Training finished, took 75.187s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.432 took: 4.11s  Val. loss: 0.199  Val. score: 93.844%\n",
      "Epoch 2, 100% \t Train loss: 0.215 took: 3.98s  Val. loss: 0.149  Val. score: 95.614%\n",
      "Epoch 3, 100% \t Train loss: 0.162 took: 4.42s  Val. loss: 0.135  Val. score: 95.950%\n",
      "Epoch 4, 100% \t Train loss: 0.136 took: 4.32s  Val. loss: 0.118  Val. score: 96.544%\n",
      "Epoch 5, 100% \t Train loss: 0.115 took: 4.26s  Val. loss: 0.109  Val. score: 96.826%\n",
      "Epoch 6, 100% \t Train loss: 0.104 took: 4.24s  Val. loss: 0.107  Val. score: 97.030%\n",
      "Epoch 7, 100% \t Train loss: 0.088 took: 4.26s  Val. loss: 0.106  Val. score: 96.904%\n",
      "Epoch 8, 100% \t Train loss: 0.085 took: 4.73s  Val. loss: 0.101  Val. score: 97.192%\n",
      "Epoch 9, 100% \t Train loss: 0.076 took: 4.68s  Val. loss: 0.098  Val. score: 97.300%\n",
      "Epoch 10, 100% \t Train loss: 0.066 took: 4.68s  Val. loss: 0.099  Val. score: 97.366%\n",
      "Training finished, took 74.112s\n",
      "\n",
      "Parameters configuration 69 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.010097895651643055\n",
      "h_sizes \t [784, 189, 46]\n",
      "penalty \t 0.00023720847203241894\n",
      "dropout \t 0.24448304630005188\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.4239 +/- 0.0863\n",
      "Time for evaluation: 224.9 s\n",
      "Estimated time to finish : 2.81 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 4.638 took: 10.11s  Val. loss: 2.304  Val. score: 11.184%\n",
      "Epoch 2, 100% \t Train loss: 2.308 took: 10.46s  Val. loss: 2.303  Val. score: 11.184%\n",
      "Epoch 3, 100% \t Train loss: 2.309 took: 12.58s  Val. loss: 2.307  Val. score: 11.184%\n",
      "Epoch 4, 100% \t Train loss: 2.305 took: 17.01s  Val. loss: 2.302  Val. score: 10.638%\n",
      "Epoch 5, 100% \t Train loss: 2.305 took: 17.15s  Val. loss: 2.310  Val. score: 11.184%\n",
      "Epoch 6, 100% \t Train loss: 2.305 took: 17.56s  Val. loss: 2.304  Val. score: 10.494%\n",
      "Epoch 7, 100% \t Train loss: 2.304 took: 16.30s  Val. loss: 2.306  Val. score: 11.184%\n",
      "Epoch 8, 100% \t Train loss: 2.304 took: 16.93s  Val. loss: 2.307  Val. score: 9.702%\n",
      "Epoch 9, 100% \t Train loss: 2.306 took: 17.57s  Val. loss: 2.309  Val. score: 9.666%\n",
      "Epoch 10, 100% \t Train loss: 2.305 took: 17.04s  Val. loss: 2.304  Val. score: 11.184%\n",
      "Training finished, took 209.610s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.388 took: 11.18s  Val. loss: 2.305  Val. score: 9.516%\n",
      "Epoch 2, 100% \t Train loss: 2.319 took: 10.59s  Val. loss: 2.303  Val. score: 11.232%\n",
      "Epoch 3, 100% \t Train loss: 2.305 took: 13.62s  Val. loss: 2.304  Val. score: 10.272%\n",
      "Epoch 4, 100% \t Train loss: 2.305 took: 18.15s  Val. loss: 2.305  Val. score: 11.232%\n",
      "Epoch 5, 100% \t Train loss: 2.305 took: 16.46s  Val. loss: 2.304  Val. score: 10.116%\n",
      "Epoch 6, 100% \t Train loss: 2.304 took: 17.29s  Val. loss: 2.305  Val. score: 10.014%\n",
      "Epoch 7, 100% \t Train loss: 2.305 took: 16.51s  Val. loss: 2.307  Val. score: 11.232%\n",
      "Epoch 8, 100% \t Train loss: 2.305 took: 16.39s  Val. loss: 2.304  Val. score: 10.116%\n",
      "Epoch 9, 100% \t Train loss: 2.305 took: 17.35s  Val. loss: 2.307  Val. score: 11.232%\n",
      "Epoch 10, 100% \t Train loss: 2.305 took: 17.52s  Val. loss: 2.305  Val. score: 10.272%\n",
      "Training finished, took 212.214s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.213 took: 10.11s  Val. loss: 2.055  Val. score: 20.365%\n",
      "Epoch 2, 100% \t Train loss: 2.223 took: 10.87s  Val. loss: 2.306  Val. score: 10.716%\n",
      "Epoch 3, 100% \t Train loss: 2.306 took: 13.50s  Val. loss: 2.306  Val. score: 9.924%\n",
      "Epoch 4, 100% \t Train loss: 2.304 took: 17.90s  Val. loss: 2.303  Val. score: 9.924%\n",
      "Epoch 5, 100% \t Train loss: 2.306 took: 16.41s  Val. loss: 2.303  Val. score: 10.716%\n",
      "Epoch 6, 100% \t Train loss: 2.305 took: 16.37s  Val. loss: 2.304  Val. score: 11.334%\n",
      "Epoch 7, 100% \t Train loss: 2.305 took: 16.93s  Val. loss: 2.309  Val. score: 10.164%\n",
      "Epoch 8, 100% \t Train loss: 2.305 took: 17.30s  Val. loss: 2.305  Val. score: 10.716%\n",
      "Epoch 9, 100% \t Train loss: 2.304 took: 17.24s  Val. loss: 2.304  Val. score: 10.716%\n",
      "Epoch 10, 100% \t Train loss: 2.305 took: 16.37s  Val. loss: 2.306  Val. score: 9.522%\n",
      "Training finished, took 209.807s\n",
      "\n",
      "Parameters configuration 70 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.06094350943284017\n",
      "h_sizes \t [784, 458, 295, 195, 116, 72, 50, 35, 20]\n",
      "penalty \t 0.0044331221754760645\n",
      "dropout \t 0.10719572320826204\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 10.3264 +/- 0.6796\n",
      "Time for evaluation: 632.7 s\n",
      "Estimated time to finish : 2.76 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.911 took: 11.05s  Val. loss: 2.240  Val. score: 19.501%\n",
      "Epoch 2, 100% \t Train loss: 6.325 took: 11.09s  Val. loss: 2.124  Val. score: 24.163%\n",
      "Epoch 3, 100% \t Train loss: 2.331 took: 11.94s  Val. loss: 1.903  Val. score: 24.211%\n",
      "Epoch 4, 100% \t Train loss: 1.952 took: 11.27s  Val. loss: 1.742  Val. score: 28.585%\n",
      "Epoch 5, 100% \t Train loss: 1.839 took: 11.09s  Val. loss: 1.671  Val. score: 32.215%\n",
      "Epoch 6, 100% \t Train loss: 1.720 took: 11.08s  Val. loss: 1.475  Val. score: 37.880%\n",
      "Epoch 7, 100% \t Train loss: 1.566 took: 11.59s  Val. loss: 1.436  Val. score: 38.780%\n",
      "Epoch 8, 100% \t Train loss: 1.599 took: 11.08s  Val. loss: 1.430  Val. score: 45.296%\n",
      "Epoch 9, 100% \t Train loss: 1.524 took: 11.09s  Val. loss: 1.375  Val. score: 44.060%\n",
      "Epoch 10, 100% \t Train loss: 9.458 took: 12.90s  Val. loss: 16.467  Val. score: 9.072%\n",
      "Training finished, took 171.723s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 13.202 took: 11.99s  Val. loss: 3.759  Val. score: 7.218%\n",
      "Epoch 2, 100% \t Train loss: 1525.557 took: 12.26s  Val. loss: 3.268  Val. score: 10.368%\n",
      "Epoch 3, 100% \t Train loss: 29.515 took: 11.31s  Val. loss: 2.318  Val. score: 5.550%\n",
      "Epoch 4, 100% \t Train loss: 2.509 took: 12.73s  Val. loss: 2.305  Val. score: 11.328%\n",
      "Epoch 5, 100% \t Train loss: 199.017 took: 12.46s  Val. loss: 2.366  Val. score: 10.506%\n",
      "Epoch 6, 100% \t Train loss: 2.397 took: 12.23s  Val. loss: 2.306  Val. score: 12.030%\n",
      "Epoch 7, 100% \t Train loss: 2.316 took: 11.28s  Val. loss: 2.303  Val. score: 11.334%\n",
      "Epoch 8, 100% \t Train loss: 2.302 took: 12.28s  Val. loss: 2.303  Val. score: 11.328%\n",
      "Epoch 9, 100% \t Train loss: 2.303 took: 12.25s  Val. loss: 2.303  Val. score: 10.254%\n",
      "Epoch 10, 100% \t Train loss: 2.303 took: 11.33s  Val. loss: 2.303  Val. score: 11.328%\n",
      "Training finished, took 178.943s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 309.934 took: 12.32s  Val. loss: 11.736  Val. score: 9.726%\n",
      "Epoch 2, 100% \t Train loss: 53316.027 took: 13.32s  Val. loss: 2124.452  Val. score: 9.636%\n",
      "Epoch 3, 100% \t Train loss: 305647.862 took: 12.12s  Val. loss: 1610.400  Val. score: 9.714%\n",
      "Epoch 4, 100% \t Train loss: 5338.296 took: 12.73s  Val. loss: 68.655  Val. score: 12.697%\n",
      "Epoch 5, 100% \t Train loss: 1417.752 took: 14.12s  Val. loss: 8.081  Val. score: 12.456%\n",
      "Epoch 6, 100% \t Train loss: 74.499 took: 12.23s  Val. loss: 3.402  Val. score: 14.179%\n",
      "Epoch 7, 100% \t Train loss: 20.643 took: 12.57s  Val. loss: 2.355  Val. score: 13.939%\n",
      "Epoch 8, 100% \t Train loss: 6.788 took: 11.18s  Val. loss: 2.297  Val. score: 11.142%\n",
      "Epoch 9, 100% \t Train loss: 3.432 took: 11.14s  Val. loss: 2.299  Val. score: 11.076%\n",
      "Epoch 10, 100% \t Train loss: 2.839 took: 12.57s  Val. loss: 2.302  Val. score: 10.434%\n",
      "Training finished, took 182.941s\n",
      "\n",
      "Parameters configuration 71 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.04678695060081313\n",
      "h_sizes \t [784, 484, 313, 195, 123, 80, 53, 32, 18]\n",
      "penalty \t 0.0003255073284435559\n",
      "dropout \t 0.2368514146190828\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 10.2784 +/- 0.9276\n",
      "Time for evaluation: 534.7 s\n",
      "Estimated time to finish : 2.69 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.505 took: 4.87s  Val. loss: 0.195  Val. score: 94.066%\n",
      "Epoch 2, 100% \t Train loss: 0.197 took: 5.10s  Val. loss: 0.139  Val. score: 95.752%\n",
      "Epoch 3, 100% \t Train loss: 0.140 took: 5.34s  Val. loss: 0.130  Val. score: 96.112%\n",
      "Epoch 4, 100% \t Train loss: 0.109 took: 5.24s  Val. loss: 0.114  Val. score: 96.730%\n",
      "Epoch 5, 100% \t Train loss: 0.090 took: 5.36s  Val. loss: 0.103  Val. score: 97.096%\n",
      "Epoch 6, 100% \t Train loss: 0.078 took: 5.27s  Val. loss: 0.120  Val. score: 96.820%\n",
      "Epoch 7, 100% \t Train loss: 0.071 took: 5.44s  Val. loss: 0.104  Val. score: 97.258%\n",
      "Epoch 8, 100% \t Train loss: 0.060 took: 5.17s  Val. loss: 0.105  Val. score: 97.270%\n",
      "Epoch 9, 100% \t Train loss: 0.050 took: 4.98s  Val. loss: 0.135  Val. score: 96.700%\n",
      "Epoch 10, 100% \t Train loss: 0.053 took: 5.23s  Val. loss: 0.102  Val. score: 97.564%\n",
      "Training finished, took 87.254s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.509 took: 5.41s  Val. loss: 0.189  Val. score: 94.336%\n",
      "Epoch 2, 100% \t Train loss: 0.197 took: 5.31s  Val. loss: 0.154  Val. score: 95.290%\n",
      "Epoch 3, 100% \t Train loss: 0.141 took: 4.85s  Val. loss: 0.106  Val. score: 96.856%\n",
      "Epoch 4, 100% \t Train loss: 0.110 took: 4.85s  Val. loss: 0.106  Val. score: 96.868%\n",
      "Epoch 5, 100% \t Train loss: 0.094 took: 5.38s  Val. loss: 0.094  Val. score: 97.174%\n",
      "Epoch 6, 100% \t Train loss: 0.078 took: 5.00s  Val. loss: 0.104  Val. score: 97.126%\n",
      "Epoch 7, 100% \t Train loss: 0.071 took: 5.25s  Val. loss: 0.092  Val. score: 97.450%\n",
      "Epoch 8, 100% \t Train loss: 0.059 took: 5.14s  Val. loss: 0.089  Val. score: 97.642%\n",
      "Epoch 9, 100% \t Train loss: 0.055 took: 5.18s  Val. loss: 0.092  Val. score: 97.696%\n",
      "Epoch 10, 100% \t Train loss: 0.052 took: 5.23s  Val. loss: 0.095  Val. score: 97.468%\n",
      "Training finished, took 86.803s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.490 took: 5.54s  Val. loss: 0.210  Val. score: 93.682%\n",
      "Epoch 2, 100% \t Train loss: 0.187 took: 5.30s  Val. loss: 0.144  Val. score: 95.530%\n",
      "Epoch 3, 100% \t Train loss: 0.139 took: 4.83s  Val. loss: 0.131  Val. score: 96.016%\n",
      "Epoch 4, 100% \t Train loss: 0.106 took: 5.36s  Val. loss: 0.120  Val. score: 96.436%\n",
      "Epoch 5, 100% \t Train loss: 0.089 took: 5.05s  Val. loss: 0.107  Val. score: 96.790%\n",
      "Epoch 6, 100% \t Train loss: 0.078 took: 5.36s  Val. loss: 0.117  Val. score: 96.886%\n",
      "Epoch 7, 100% \t Train loss: 0.066 took: 4.83s  Val. loss: 0.112  Val. score: 97.132%\n",
      "Epoch 8, 100% \t Train loss: 0.059 took: 5.30s  Val. loss: 0.101  Val. score: 97.288%\n",
      "Epoch 9, 100% \t Train loss: 0.053 took: 5.49s  Val. loss: 0.113  Val. score: 97.072%\n",
      "Epoch 10, 100% \t Train loss: 0.048 took: 4.84s  Val. loss: 0.117  Val. score: 97.180%\n",
      "Training finished, took 87.292s\n",
      "\n",
      "Parameters configuration 72 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0023764453665107046\n",
      "h_sizes \t [784, 278, 91, 31]\n",
      "penalty \t 0.000981127168384203\n",
      "dropout \t 0.13886607330466164\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.4039 +/- 0.1632\n",
      "Time for evaluation: 262.4 s\n",
      "Estimated time to finish : 2.59 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.570 took: 5.29s  Val. loss: 0.270  Val. score: 93.040%\n",
      "Epoch 2, 100% \t Train loss: 0.353 took: 5.38s  Val. loss: 0.296  Val. score: 93.328%\n",
      "Epoch 3, 100% \t Train loss: 0.320 took: 6.38s  Val. loss: 0.241  Val. score: 94.120%\n",
      "Epoch 4, 100% \t Train loss: 0.317 took: 6.50s  Val. loss: 0.252  Val. score: 93.844%\n",
      "Epoch 5, 100% \t Train loss: 0.331 took: 6.68s  Val. loss: 0.316  Val. score: 93.448%\n",
      "Epoch 6, 100% \t Train loss: 0.386 took: 6.33s  Val. loss: 0.292  Val. score: 93.406%\n",
      "Epoch 7, 100% \t Train loss: 0.391 took: 5.86s  Val. loss: 0.322  Val. score: 92.752%\n",
      "Epoch 8, 100% \t Train loss: 0.459 took: 8.30s  Val. loss: 0.342  Val. score: 91.894%\n",
      "Epoch 9, 100% \t Train loss: 0.428 took: 7.68s  Val. loss: 0.252  Val. score: 93.922%\n",
      "Epoch 10, 100% \t Train loss: 0.543 took: 5.89s  Val. loss: 0.435  Val. score: 89.392%\n",
      "Training finished, took 101.832s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.610 took: 5.64s  Val. loss: 0.342  Val. score: 92.080%\n",
      "Epoch 2, 100% \t Train loss: 0.338 took: 5.83s  Val. loss: 0.276  Val. score: 93.340%\n",
      "Epoch 3, 100% \t Train loss: 0.316 took: 6.47s  Val. loss: 0.270  Val. score: 93.664%\n",
      "Epoch 4, 100% \t Train loss: 0.311 took: 7.03s  Val. loss: 0.258  Val. score: 94.024%\n",
      "Epoch 5, 100% \t Train loss: 0.294 took: 6.17s  Val. loss: 0.307  Val. score: 94.180%\n",
      "Epoch 6, 100% \t Train loss: 0.357 took: 7.79s  Val. loss: 0.334  Val. score: 94.294%\n",
      "Epoch 7, 100% \t Train loss: 0.347 took: 6.80s  Val. loss: 0.264  Val. score: 93.886%\n",
      "Epoch 8, 100% \t Train loss: 0.383 took: 7.54s  Val. loss: 0.314  Val. score: 94.522%\n",
      "Epoch 9, 100% \t Train loss: 0.387 took: 7.06s  Val. loss: 0.284  Val. score: 93.604%\n",
      "Epoch 10, 100% \t Train loss: 0.431 took: 7.09s  Val. loss: 0.405  Val. score: 91.330%\n",
      "Training finished, took 105.255s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.632 took: 5.85s  Val. loss: 0.348  Val. score: 90.838%\n",
      "Epoch 2, 100% \t Train loss: 0.373 took: 5.28s  Val. loss: 0.267  Val. score: 93.148%\n",
      "Epoch 3, 100% \t Train loss: 0.326 took: 6.30s  Val. loss: 0.233  Val. score: 94.348%\n",
      "Epoch 4, 100% \t Train loss: 0.324 took: 5.70s  Val. loss: 0.257  Val. score: 94.120%\n",
      "Epoch 5, 100% \t Train loss: 0.289 took: 6.28s  Val. loss: 0.254  Val. score: 93.940%\n",
      "Epoch 6, 100% \t Train loss: 0.277 took: 7.51s  Val. loss: 0.294  Val. score: 94.228%\n",
      "Epoch 7, 100% \t Train loss: 0.412 took: 7.79s  Val. loss: 0.576  Val. score: 85.809%\n",
      "Epoch 8, 100% \t Train loss: 0.546 took: 7.99s  Val. loss: 0.324  Val. score: 92.212%\n",
      "Epoch 9, 100% \t Train loss: 0.516 took: 7.56s  Val. loss: 0.552  Val. score: 87.694%\n",
      "Epoch 10, 100% \t Train loss: 0.842 took: 7.76s  Val. loss: 0.576  Val. score: 85.173%\n",
      "Training finished, took 105.857s\n",
      "\n",
      "Parameters configuration 73 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.020774002849792864\n",
      "h_sizes \t [784, 302, 134, 47, 17]\n",
      "penalty \t 0.0003726170595747665\n",
      "dropout \t 0.07358155810835007\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 88.6315 +/- 2.5701\n",
      "Time for evaluation: 314.0 s\n",
      "Estimated time to finish : 2.49 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.554 took: 4.26s  Val. loss: 0.257  Val. score: 92.338%\n",
      "Epoch 2, 100% \t Train loss: 0.273 took: 4.23s  Val. loss: 0.194  Val. score: 94.204%\n",
      "Epoch 3, 100% \t Train loss: 0.206 took: 3.91s  Val. loss: 0.158  Val. score: 95.248%\n",
      "Epoch 4, 100% \t Train loss: 0.171 took: 4.01s  Val. loss: 0.142  Val. score: 95.482%\n",
      "Epoch 5, 100% \t Train loss: 0.143 took: 4.35s  Val. loss: 0.122  Val. score: 96.208%\n",
      "Epoch 6, 100% \t Train loss: 0.128 took: 4.40s  Val. loss: 0.120  Val. score: 96.238%\n",
      "Epoch 7, 100% \t Train loss: 0.109 took: 4.41s  Val. loss: 0.108  Val. score: 96.664%\n",
      "Epoch 8, 100% \t Train loss: 0.102 took: 4.42s  Val. loss: 0.105  Val. score: 96.700%\n",
      "Epoch 9, 100% \t Train loss: 0.092 took: 4.03s  Val. loss: 0.096  Val. score: 97.126%\n",
      "Epoch 10, 100% \t Train loss: 0.084 took: 4.36s  Val. loss: 0.094  Val. score: 97.132%\n",
      "Training finished, took 72.697s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.564 took: 4.20s  Val. loss: 0.248  Val. score: 92.818%\n",
      "Epoch 2, 100% \t Train loss: 0.273 took: 3.99s  Val. loss: 0.191  Val. score: 94.378%\n",
      "Epoch 3, 100% \t Train loss: 0.211 took: 3.97s  Val. loss: 0.149  Val. score: 95.404%\n",
      "Epoch 4, 100% \t Train loss: 0.172 took: 4.08s  Val. loss: 0.127  Val. score: 96.208%\n",
      "Epoch 5, 100% \t Train loss: 0.146 took: 4.39s  Val. loss: 0.117  Val. score: 96.568%\n",
      "Epoch 6, 100% \t Train loss: 0.127 took: 4.37s  Val. loss: 0.113  Val. score: 96.652%\n",
      "Epoch 7, 100% \t Train loss: 0.119 took: 4.50s  Val. loss: 0.102  Val. score: 96.934%\n",
      "Epoch 8, 100% \t Train loss: 0.105 took: 4.35s  Val. loss: 0.099  Val. score: 97.114%\n",
      "Epoch 9, 100% \t Train loss: 0.094 took: 4.39s  Val. loss: 0.102  Val. score: 96.976%\n",
      "Epoch 10, 100% \t Train loss: 0.086 took: 4.43s  Val. loss: 0.094  Val. score: 97.186%\n",
      "Training finished, took 72.752s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.577 took: 4.27s  Val. loss: 0.253  Val. score: 92.422%\n",
      "Epoch 2, 100% \t Train loss: 0.278 took: 4.25s  Val. loss: 0.195  Val. score: 94.192%\n",
      "Epoch 3, 100% \t Train loss: 0.213 took: 4.24s  Val. loss: 0.157  Val. score: 95.320%\n",
      "Epoch 4, 100% \t Train loss: 0.182 took: 4.49s  Val. loss: 0.137  Val. score: 95.770%\n",
      "Epoch 5, 100% \t Train loss: 0.155 took: 4.47s  Val. loss: 0.125  Val. score: 96.196%\n",
      "Epoch 6, 100% \t Train loss: 0.133 took: 4.41s  Val. loss: 0.121  Val. score: 96.286%\n",
      "Epoch 7, 100% \t Train loss: 0.121 took: 4.38s  Val. loss: 0.113  Val. score: 96.532%\n",
      "Epoch 8, 100% \t Train loss: 0.111 took: 4.48s  Val. loss: 0.107  Val. score: 96.778%\n",
      "Epoch 9, 100% \t Train loss: 0.100 took: 4.43s  Val. loss: 0.105  Val. score: 96.754%\n",
      "Epoch 10, 100% \t Train loss: 0.092 took: 4.49s  Val. loss: 0.103  Val. score: 96.946%\n",
      "Training finished, took 74.196s\n",
      "\n",
      "Parameters configuration 74 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004129343894066938\n",
      "h_sizes \t [784, 177, 43]\n",
      "penalty \t 0.005218274945274288\n",
      "dropout \t 0.2207080198359869\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.0879 +/- 0.1028\n",
      "Time for evaluation: 220.7 s\n",
      "Estimated time to finish : 2.39 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 40.767 took: 12.52s  Val. loss: 1.849  Val. score: 26.179%\n",
      "Epoch 2, 100% \t Train loss: 1.841 took: 12.59s  Val. loss: 1.624  Val. score: 34.801%\n",
      "Epoch 3, 100% \t Train loss: 1.746 took: 12.59s  Val. loss: 1.622  Val. score: 31.945%\n",
      "Epoch 4, 100% \t Train loss: 1.629 took: 11.20s  Val. loss: 1.502  Val. score: 37.664%\n",
      "Epoch 5, 100% \t Train loss: 1.535 took: 12.80s  Val. loss: 1.490  Val. score: 40.514%\n",
      "Epoch 6, 100% \t Train loss: 1.612 took: 11.45s  Val. loss: 1.403  Val. score: 44.318%\n",
      "Epoch 7, 100% \t Train loss: 1425078412.258 took: 11.43s  Val. loss: 4983512401122.688  Val. score: 9.072%\n",
      "Epoch 8, 100% \t Train loss: 16335778785.567 took: 11.40s  Val. loss: 14928767.405  Val. score: 9.672%\n",
      "Epoch 9, 100% \t Train loss: 20905392.220 took: 11.36s  Val. loss: 5618904.128  Val. score: 10.020%\n",
      "Epoch 10, 100% \t Train loss: 55601696.015 took: 12.92s  Val. loss: 2737006.272  Val. score: 10.128%\n",
      "Training finished, took 180.878s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 140947.619 took: 11.54s  Val. loss: 451.949  Val. score: 10.926%\n",
      "Epoch 2, 100% \t Train loss: 587773917.420 took: 13.22s  Val. loss: 2448717.539  Val. score: 9.948%\n",
      "Epoch 3, 100% \t Train loss: 1049567.837 took: 12.76s  Val. loss: 11063.804  Val. score: 9.846%\n",
      "Epoch 4, 100% \t Train loss: 3271922.816 took: 13.15s  Val. loss: 104112.398  Val. score: 9.960%\n",
      "Epoch 5, 100% \t Train loss: 71098838633.912 took: 11.79s  Val. loss: 18348725.855  Val. score: 9.738%\n",
      "Epoch 6, 100% \t Train loss: 70120368112.245 took: 13.18s  Val. loss: 19951241.969  Val. score: 11.076%\n",
      "Epoch 7, 100% \t Train loss: 62901199428.352 took: 11.99s  Val. loss: 547208098.809  Val. score: 9.846%\n",
      "Epoch 8, 100% \t Train loss: 384884891937.103 took: 13.07s  Val. loss: 1022882449.588  Val. score: 8.988%\n",
      "Epoch 9, 100% \t Train loss: 435597455705.011 took: 11.79s  Val. loss: 586567984.122  Val. score: 9.960%\n",
      "Epoch 10, 100% \t Train loss: 584258975093.211 took: 11.64s  Val. loss: 160396287.389  Val. score: 9.738%\n",
      "Training finished, took 185.704s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 28.810 took: 12.94s  Val. loss: 2.331  Val. score: 8.130%\n",
      "Epoch 2, 100% \t Train loss: 3.666 took: 12.95s  Val. loss: 2.344  Val. score: 11.226%\n",
      "Epoch 3, 100% \t Train loss: 2.096 took: 11.91s  Val. loss: 1.744  Val. score: 29.329%\n",
      "Epoch 4, 100% \t Train loss: 1.778 took: 12.10s  Val. loss: 1.543  Val. score: 44.330%\n",
      "Epoch 5, 100% \t Train loss: 1.592 took: 12.86s  Val. loss: 1.378  Val. score: 51.176%\n",
      "Epoch 6, 100% \t Train loss: 134431389.985 took: 12.87s  Val. loss: 1346851.951  Val. score: 10.050%\n",
      "Epoch 7, 100% \t Train loss: 875889957.794 took: 12.95s  Val. loss: 6015586.538  Val. score: 9.954%\n",
      "Epoch 8, 100% \t Train loss: 6300583.212 took: 12.62s  Val. loss: 187411.074  Val. score: 10.032%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, 100% \t Train loss: 224428.967 took: 13.40s  Val. loss: 35545.162  Val. score: 9.954%\n",
      "Epoch 10, 100% \t Train loss: 631450.098 took: 12.09s  Val. loss: 117702.880  Val. score: 9.642%\n",
      "Training finished, took 187.447s\n",
      "\n",
      "Parameters configuration 75 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.07853705839303185\n",
      "h_sizes \t [784, 504, 312, 208, 133, 93, 59, 42, 26, 17]\n",
      "penalty \t 0.00047760923871105357\n",
      "dropout \t 0.016873261959553826\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 9.8364 +/- 0.2102\n",
      "Time for evaluation: 555.1 s\n",
      "Estimated time to finish : 2.32 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.773 took: 4.09s  Val. loss: 0.370  Val. score: 89.488%\n",
      "Epoch 2, 100% \t Train loss: 0.399 took: 4.43s  Val. loss: 0.288  Val. score: 91.612%\n",
      "Epoch 3, 100% \t Train loss: 0.330 took: 4.55s  Val. loss: 0.252  Val. score: 92.728%\n",
      "Epoch 4, 100% \t Train loss: 0.297 took: 4.13s  Val. loss: 0.235  Val. score: 93.178%\n",
      "Epoch 5, 100% \t Train loss: 0.265 took: 4.11s  Val. loss: 0.213  Val. score: 93.724%\n",
      "Epoch 6, 100% \t Train loss: 0.250 took: 4.12s  Val. loss: 0.202  Val. score: 94.096%\n",
      "Epoch 7, 100% \t Train loss: 0.232 took: 4.43s  Val. loss: 0.188  Val. score: 94.438%\n",
      "Epoch 8, 100% \t Train loss: 0.218 took: 4.59s  Val. loss: 0.183  Val. score: 94.576%\n",
      "Epoch 9, 100% \t Train loss: 0.209 took: 4.48s  Val. loss: 0.176  Val. score: 94.738%\n",
      "Epoch 10, 100% \t Train loss: 0.200 took: 4.34s  Val. loss: 0.171  Val. score: 94.810%\n",
      "Training finished, took 78.965s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.689 took: 4.45s  Val. loss: 0.341  Val. score: 90.376%\n",
      "Epoch 2, 100% \t Train loss: 0.375 took: 4.52s  Val. loss: 0.267  Val. score: 92.362%\n",
      "Epoch 3, 100% \t Train loss: 0.313 took: 5.49s  Val. loss: 0.236  Val. score: 93.274%\n",
      "Epoch 4, 100% \t Train loss: 0.279 took: 4.59s  Val. loss: 0.214  Val. score: 93.736%\n",
      "Epoch 5, 100% \t Train loss: 0.255 took: 4.12s  Val. loss: 0.199  Val. score: 94.108%\n",
      "Epoch 6, 100% \t Train loss: 0.239 took: 4.13s  Val. loss: 0.190  Val. score: 94.462%\n",
      "Epoch 7, 100% \t Train loss: 0.219 took: 4.22s  Val. loss: 0.182  Val. score: 94.606%\n",
      "Epoch 8, 100% \t Train loss: 0.212 took: 4.57s  Val. loss: 0.172  Val. score: 94.930%\n",
      "Epoch 9, 100% \t Train loss: 0.200 took: 4.13s  Val. loss: 0.167  Val. score: 95.050%\n",
      "Epoch 10, 100% \t Train loss: 0.191 took: 4.13s  Val. loss: 0.163  Val. score: 95.206%\n",
      "Training finished, took 81.106s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.737 took: 4.10s  Val. loss: 0.376  Val. score: 89.986%\n",
      "Epoch 2, 100% \t Train loss: 0.410 took: 4.30s  Val. loss: 0.296  Val. score: 91.690%\n",
      "Epoch 3, 100% \t Train loss: 0.341 took: 4.45s  Val. loss: 0.257  Val. score: 92.686%\n",
      "Epoch 4, 100% \t Train loss: 0.302 took: 4.55s  Val. loss: 0.234  Val. score: 93.418%\n",
      "Epoch 5, 100% \t Train loss: 0.274 took: 4.33s  Val. loss: 0.211  Val. score: 94.036%\n",
      "Epoch 6, 100% \t Train loss: 0.253 took: 4.33s  Val. loss: 0.198  Val. score: 94.420%\n",
      "Epoch 7, 100% \t Train loss: 0.237 took: 4.26s  Val. loss: 0.188  Val. score: 94.660%\n",
      "Epoch 8, 100% \t Train loss: 0.221 took: 4.50s  Val. loss: 0.178  Val. score: 94.858%\n",
      "Epoch 9, 100% \t Train loss: 0.211 took: 4.21s  Val. loss: 0.174  Val. score: 95.002%\n",
      "Epoch 10, 100% \t Train loss: 0.202 took: 4.10s  Val. loss: 0.165  Val. score: 95.134%\n",
      "Training finished, took 79.136s\n",
      "\n",
      "Parameters configuration 76 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004401044327699978\n",
      "h_sizes \t [784, 267, 92, 22]\n",
      "penalty \t 0.00041651596897831345\n",
      "dropout \t 0.12530264604839508\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 95.0498 +/- 0.1722\n",
      "Time for evaluation: 240.3 s\n",
      "Estimated time to finish : 2.22 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.574 took: 4.72s  Val. loss: 0.396  Val. score: 89.314%\n",
      "Epoch 2, 100% \t Train loss: 0.387 took: 5.08s  Val. loss: 0.297  Val. score: 92.890%\n",
      "Epoch 3, 100% \t Train loss: 0.364 took: 4.84s  Val. loss: 0.334  Val. score: 91.630%\n",
      "Epoch 4, 100% \t Train loss: 0.364 took: 5.14s  Val. loss: 0.264  Val. score: 93.394%\n",
      "Epoch 5, 100% \t Train loss: 0.331 took: 5.17s  Val. loss: 0.296  Val. score: 92.992%\n",
      "Epoch 6, 100% \t Train loss: 0.376 took: 5.10s  Val. loss: 0.288  Val. score: 93.400%\n",
      "Epoch 7, 100% \t Train loss: 0.343 took: 5.05s  Val. loss: 0.379  Val. score: 91.030%\n",
      "Epoch 8, 100% \t Train loss: 0.582 took: 5.59s  Val. loss: 0.589  Val. score: 84.819%\n",
      "Epoch 9, 100% \t Train loss: 0.874 took: 6.11s  Val. loss: 0.881  Val. score: 72.555%\n",
      "Epoch 10, 100% \t Train loss: 0.730 took: 6.88s  Val. loss: 0.471  Val. score: 89.698%\n",
      "Training finished, took 87.877s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.835 took: 5.13s  Val. loss: 0.375  Val. score: 89.908%\n",
      "Epoch 2, 100% \t Train loss: 0.423 took: 5.48s  Val. loss: 0.299  Val. score: 91.996%\n",
      "Epoch 3, 100% \t Train loss: 0.372 took: 5.79s  Val. loss: 0.285  Val. score: 92.476%\n",
      "Epoch 4, 100% \t Train loss: 0.374 took: 5.17s  Val. loss: 0.280  Val. score: 93.070%\n",
      "Epoch 5, 100% \t Train loss: 0.362 took: 4.88s  Val. loss: 0.338  Val. score: 90.604%\n",
      "Epoch 6, 100% \t Train loss: 0.380 took: 4.78s  Val. loss: 0.322  Val. score: 91.708%\n",
      "Epoch 7, 100% \t Train loss: 0.444 took: 6.04s  Val. loss: 0.479  Val. score: 88.906%\n",
      "Epoch 8, 100% \t Train loss: 0.557 took: 5.92s  Val. loss: 0.361  Val. score: 91.036%\n",
      "Epoch 9, 100% \t Train loss: 0.568 took: 5.42s  Val. loss: 0.434  Val. score: 89.122%\n",
      "Epoch 10, 100% \t Train loss: 0.837 took: 6.35s  Val. loss: 0.653  Val. score: 82.665%\n",
      "Training finished, took 89.807s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.640 took: 5.18s  Val. loss: 0.377  Val. score: 90.844%\n",
      "Epoch 2, 100% \t Train loss: 0.387 took: 5.10s  Val. loss: 0.308  Val. score: 91.750%\n",
      "Epoch 3, 100% \t Train loss: 0.342 took: 4.72s  Val. loss: 0.337  Val. score: 91.600%\n",
      "Epoch 4, 100% \t Train loss: 0.351 took: 5.17s  Val. loss: 0.365  Val. score: 91.666%\n",
      "Epoch 5, 100% \t Train loss: 0.360 took: 5.40s  Val. loss: 0.362  Val. score: 90.388%\n",
      "Epoch 6, 100% \t Train loss: 0.318 took: 4.97s  Val. loss: 0.304  Val. score: 93.082%\n",
      "Epoch 7, 100% \t Train loss: 0.365 took: 5.39s  Val. loss: 0.427  Val. score: 91.150%\n",
      "Epoch 8, 100% \t Train loss: 0.411 took: 5.68s  Val. loss: 0.336  Val. score: 92.164%\n",
      "Epoch 9, 100% \t Train loss: 0.406 took: 5.67s  Val. loss: 0.357  Val. score: 91.858%\n",
      "Epoch 10, 100% \t Train loss: 0.398 took: 6.26s  Val. loss: 0.396  Val. score: 90.712%\n",
      "Training finished, took 88.519s\n",
      "\n",
      "Parameters configuration 77 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.038045634720108634\n",
      "h_sizes \t [784, 277, 94, 35]\n",
      "penalty \t 0.00017712273430963007\n",
      "dropout \t 0.03844956767307764\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 87.6915 +/- 3.5781\n",
      "Time for evaluation: 267.3 s\n",
      "Estimated time to finish : 2.12 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.672 took: 6.13s  Val. loss: 0.235  Val. score: 93.400%\n",
      "Epoch 2, 100% \t Train loss: 0.235 took: 6.15s  Val. loss: 0.187  Val. score: 94.606%\n",
      "Epoch 3, 100% \t Train loss: 0.162 took: 6.15s  Val. loss: 0.140  Val. score: 96.082%\n",
      "Epoch 4, 100% \t Train loss: 0.127 took: 6.75s  Val. loss: 0.130  Val. score: 96.382%\n",
      "Epoch 5, 100% \t Train loss: 0.101 took: 6.14s  Val. loss: 0.113  Val. score: 96.916%\n",
      "Epoch 6, 100% \t Train loss: 0.089 took: 6.08s  Val. loss: 0.110  Val. score: 97.036%\n",
      "Epoch 7, 100% \t Train loss: 0.077 took: 6.71s  Val. loss: 0.113  Val. score: 97.072%\n",
      "Epoch 8, 100% \t Train loss: 0.064 took: 6.74s  Val. loss: 0.107  Val. score: 97.390%\n",
      "Epoch 9, 100% \t Train loss: 0.056 took: 6.45s  Val. loss: 0.113  Val. score: 97.198%\n",
      "Epoch 10, 100% \t Train loss: 0.049 took: 6.06s  Val. loss: 0.112  Val. score: 97.468%\n",
      "Training finished, took 103.728s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.661 took: 6.85s  Val. loss: 0.249  Val. score: 93.130%\n",
      "Epoch 2, 100% \t Train loss: 0.229 took: 6.94s  Val. loss: 0.175  Val. score: 95.080%\n",
      "Epoch 3, 100% \t Train loss: 0.160 took: 6.72s  Val. loss: 0.152  Val. score: 95.728%\n",
      "Epoch 4, 100% \t Train loss: 0.124 took: 6.12s  Val. loss: 0.140  Val. score: 96.394%\n",
      "Epoch 5, 100% \t Train loss: 0.102 took: 6.80s  Val. loss: 0.117  Val. score: 96.820%\n",
      "Epoch 6, 100% \t Train loss: 0.083 took: 6.38s  Val. loss: 0.122  Val. score: 96.808%\n",
      "Epoch 7, 100% \t Train loss: 0.072 took: 6.26s  Val. loss: 0.111  Val. score: 97.228%\n",
      "Epoch 8, 100% \t Train loss: 0.063 took: 6.39s  Val. loss: 0.112  Val. score: 97.324%\n",
      "Epoch 9, 100% \t Train loss: 0.054 took: 6.58s  Val. loss: 0.118  Val. score: 97.246%\n",
      "Epoch 10, 100% \t Train loss: 0.049 took: 6.73s  Val. loss: 0.123  Val. score: 97.246%\n",
      "Training finished, took 106.074s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.653 took: 6.72s  Val. loss: 0.210  Val. score: 94.018%\n",
      "Epoch 2, 100% \t Train loss: 0.230 took: 6.28s  Val. loss: 0.170  Val. score: 95.254%\n",
      "Epoch 3, 100% \t Train loss: 0.161 took: 6.28s  Val. loss: 0.131  Val. score: 96.274%\n",
      "Epoch 4, 100% \t Train loss: 0.124 took: 6.90s  Val. loss: 0.117  Val. score: 96.646%\n",
      "Epoch 5, 100% \t Train loss: 0.098 took: 6.85s  Val. loss: 0.109  Val. score: 97.054%\n",
      "Epoch 6, 100% \t Train loss: 0.086 took: 6.77s  Val. loss: 0.123  Val. score: 96.556%\n",
      "Epoch 7, 100% \t Train loss: 0.075 took: 6.74s  Val. loss: 0.116  Val. score: 97.066%\n",
      "Epoch 8, 100% \t Train loss: 0.069 took: 6.70s  Val. loss: 0.107  Val. score: 97.438%\n",
      "Epoch 9, 100% \t Train loss: 0.057 took: 6.78s  Val. loss: 0.103  Val. score: 97.318%\n",
      "Epoch 10, 100% \t Train loss: 0.049 took: 6.68s  Val. loss: 0.095  Val. score: 97.726%\n",
      "Training finished, took 107.420s\n",
      "\n",
      "Parameters configuration 78 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0017561803613412098\n",
      "h_sizes \t [784, 352, 139, 52, 19]\n",
      "penalty \t 0.00039666081878683983\n",
      "dropout \t 0.10031320460877713\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.4799 +/- 0.1962\n",
      "Time for evaluation: 318.3 s\n",
      "Estimated time to finish : 2.03 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.440 took: 11.97s  Val. loss: 0.737  Val. score: 72.753%\n",
      "Epoch 2, 100% \t Train loss: 0.701 took: 12.04s  Val. loss: 0.419  Val. score: 90.364%\n",
      "Epoch 3, 100% \t Train loss: 0.506 took: 11.95s  Val. loss: 0.312  Val. score: 92.896%\n",
      "Epoch 4, 100% \t Train loss: 0.405 took: 10.78s  Val. loss: 0.271  Val. score: 94.018%\n",
      "Epoch 5, 100% \t Train loss: 0.348 took: 12.16s  Val. loss: 0.244  Val. score: 94.000%\n",
      "Epoch 6, 100% \t Train loss: 0.306 took: 12.17s  Val. loss: 0.227  Val. score: 94.720%\n",
      "Epoch 7, 100% \t Train loss: 0.272 took: 12.00s  Val. loss: 0.227  Val. score: 94.684%\n",
      "Epoch 8, 100% \t Train loss: 0.242 took: 12.21s  Val. loss: 0.220  Val. score: 95.230%\n",
      "Epoch 9, 100% \t Train loss: 0.222 took: 11.95s  Val. loss: 0.203  Val. score: 95.662%\n",
      "Epoch 10, 100% \t Train loss: 0.196 took: 12.14s  Val. loss: 0.213  Val. score: 95.572%\n",
      "Training finished, took 182.542s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.313 took: 12.02s  Val. loss: 0.657  Val. score: 74.481%\n",
      "Epoch 2, 100% \t Train loss: 0.685 took: 11.75s  Val. loss: 0.479  Val. score: 81.729%\n",
      "Epoch 3, 100% \t Train loss: 0.529 took: 10.73s  Val. loss: 0.389  Val. score: 86.337%\n",
      "Epoch 4, 100% \t Train loss: 0.443 took: 12.05s  Val. loss: 0.336  Val. score: 91.324%\n",
      "Epoch 5, 100% \t Train loss: 0.385 took: 10.73s  Val. loss: 0.318  Val. score: 92.590%\n",
      "Epoch 6, 100% \t Train loss: 0.344 took: 12.07s  Val. loss: 0.304  Val. score: 93.778%\n",
      "Epoch 7, 100% \t Train loss: 0.310 took: 11.86s  Val. loss: 0.312  Val. score: 93.796%\n",
      "Epoch 8, 100% \t Train loss: 0.289 took: 11.64s  Val. loss: 0.286  Val. score: 94.774%\n",
      "Epoch 9, 100% \t Train loss: 0.265 took: 11.07s  Val. loss: 0.281  Val. score: 94.834%\n",
      "Epoch 10, 100% \t Train loss: 0.243 took: 12.13s  Val. loss: 0.276  Val. score: 95.146%\n",
      "Training finished, took 179.806s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.704 took: 11.38s  Val. loss: 1.229  Val. score: 55.922%\n",
      "Epoch 2, 100% \t Train loss: 0.951 took: 12.11s  Val. loss: 0.620  Val. score: 74.379%\n",
      "Epoch 3, 100% \t Train loss: 0.676 took: 11.88s  Val. loss: 0.511  Val. score: 77.991%\n",
      "Epoch 4, 100% \t Train loss: 0.552 took: 11.25s  Val. loss: 0.429  Val. score: 91.390%\n",
      "Epoch 5, 100% \t Train loss: 0.433 took: 11.46s  Val. loss: 0.336  Val. score: 92.452%\n",
      "Epoch 6, 100% \t Train loss: 0.364 took: 11.05s  Val. loss: 0.302  Val. score: 92.890%\n",
      "Epoch 7, 100% \t Train loss: 0.321 took: 10.81s  Val. loss: 0.289  Val. score: 94.444%\n",
      "Epoch 8, 100% \t Train loss: 0.290 took: 11.87s  Val. loss: 0.282  Val. score: 94.762%\n",
      "Epoch 9, 100% \t Train loss: 0.263 took: 11.54s  Val. loss: 0.292  Val. score: 94.852%\n",
      "Epoch 10, 100% \t Train loss: 0.242 took: 10.92s  Val. loss: 0.280  Val. score: 95.470%\n",
      "Training finished, took 177.195s\n",
      "\n",
      "Parameters configuration 79 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0050774238043958956\n",
      "h_sizes \t [784, 497, 333, 223, 142, 98, 56, 39, 24, 19]\n",
      "penalty \t 0.007591300999242725\n",
      "dropout \t 0.10661305367710183\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 95.3958 +/- 0.1816\n",
      "Time for evaluation: 540.7 s\n",
      "Estimated time to finish : 1.95 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.504 took: 17.63s  Val. loss: 1.020  Val. score: 61.388%\n",
      "Epoch 2, 100% \t Train loss: 0.698 took: 17.31s  Val. loss: 0.356  Val. score: 91.672%\n",
      "Epoch 3, 100% \t Train loss: 0.295 took: 19.12s  Val. loss: 0.252  Val. score: 94.114%\n",
      "Epoch 4, 100% \t Train loss: 0.187 took: 20.66s  Val. loss: 0.207  Val. score: 95.668%\n",
      "Epoch 5, 100% \t Train loss: 0.141 took: 20.31s  Val. loss: 0.257  Val. score: 95.566%\n",
      "Epoch 6, 100% \t Train loss: 0.107 took: 20.56s  Val. loss: 0.203  Val. score: 96.250%\n",
      "Epoch 7, 100% \t Train loss: 0.086 took: 20.24s  Val. loss: 0.226  Val. score: 95.986%\n",
      "Epoch 8, 100% \t Train loss: 0.074 took: 18.86s  Val. loss: 0.198  Val. score: 96.220%\n",
      "Epoch 9, 100% \t Train loss: 0.063 took: 20.59s  Val. loss: 0.176  Val. score: 96.682%\n",
      "Epoch 10, 100% \t Train loss: 0.050 took: 19.60s  Val. loss: 0.205  Val. score: 96.904%\n",
      "Training finished, took 266.716s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.267 took: 17.39s  Val. loss: 0.661  Val. score: 78.837%\n",
      "Epoch 2, 100% \t Train loss: 0.571 took: 16.45s  Val. loss: 0.342  Val. score: 91.336%\n",
      "Epoch 3, 100% \t Train loss: 0.311 took: 17.71s  Val. loss: 0.259  Val. score: 93.118%\n",
      "Epoch 4, 100% \t Train loss: 0.220 took: 19.43s  Val. loss: 0.213  Val. score: 94.444%\n",
      "Epoch 5, 100% \t Train loss: 0.170 took: 20.28s  Val. loss: 0.206  Val. score: 94.810%\n",
      "Epoch 6, 100% \t Train loss: 0.142 took: 19.99s  Val. loss: 0.179  Val. score: 95.752%\n",
      "Epoch 7, 100% \t Train loss: 0.113 took: 19.96s  Val. loss: 0.171  Val. score: 96.052%\n",
      "Epoch 8, 100% \t Train loss: 0.099 took: 20.19s  Val. loss: 0.184  Val. score: 96.034%\n",
      "Epoch 9, 100% \t Train loss: 0.091 took: 20.28s  Val. loss: 0.161  Val. score: 96.454%\n",
      "Epoch 10, 100% \t Train loss: 0.076 took: 20.38s  Val. loss: 0.163  Val. score: 96.526%\n",
      "Training finished, took 263.796s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.426 took: 16.27s  Val. loss: 0.769  Val. score: 71.037%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.526 took: 17.80s  Val. loss: 0.386  Val. score: 92.170%\n",
      "Epoch 3, 100% \t Train loss: 0.298 took: 19.25s  Val. loss: 0.303  Val. score: 92.554%\n",
      "Epoch 4, 100% \t Train loss: 0.205 took: 20.66s  Val. loss: 0.237  Val. score: 94.924%\n",
      "Epoch 5, 100% \t Train loss: 0.154 took: 19.67s  Val. loss: 0.227  Val. score: 95.722%\n",
      "Epoch 6, 100% \t Train loss: 0.125 took: 20.80s  Val. loss: 0.223  Val. score: 95.638%\n",
      "Epoch 7, 100% \t Train loss: 0.103 took: 21.11s  Val. loss: 0.209  Val. score: 96.040%\n",
      "Epoch 8, 100% \t Train loss: 0.086 took: 20.80s  Val. loss: 0.215  Val. score: 96.184%\n",
      "Epoch 9, 100% \t Train loss: 0.080 took: 20.24s  Val. loss: 0.209  Val. score: 96.472%\n",
      "Epoch 10, 100% \t Train loss: 0.063 took: 20.73s  Val. loss: 0.223  Val. score: 96.430%\n",
      "Training finished, took 269.457s\n",
      "\n",
      "Parameters configuration 80 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0052709222854375555\n",
      "h_sizes \t [784, 539, 361, 237, 164, 108, 69, 48, 38, 25, 18]\n",
      "penalty \t 0.0016777975017644954\n",
      "dropout \t 0.02461036415449397\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.6199 +/- 0.2046\n",
      "Time for evaluation: 801.1 s\n",
      "Estimated time to finish : 1.89 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 7.020 took: 14.28s  Val. loss: 1.751  Val. score: 28.099%\n",
      "Epoch 2, 100% \t Train loss: 1.740 took: 14.58s  Val. loss: 1.551  Val. score: 37.207%\n",
      "Epoch 3, 100% \t Train loss: 1.618 took: 14.11s  Val. loss: 1.479  Val. score: 39.008%\n",
      "Epoch 4, 100% \t Train loss: 1.524 took: 16.02s  Val. loss: 1.305  Val. score: 51.788%\n",
      "Epoch 5, 100% \t Train loss: 1.398 took: 15.25s  Val. loss: 1.217  Val. score: 56.024%\n",
      "Epoch 6, 100% \t Train loss: 1.274 took: 14.26s  Val. loss: 1.105  Val. score: 61.388%\n",
      "Epoch 7, 100% \t Train loss: 1.190 took: 15.85s  Val. loss: 1.010  Val. score: 68.853%\n",
      "Epoch 8, 100% \t Train loss: 1.096 took: 16.99s  Val. loss: 0.932  Val. score: 74.625%\n",
      "Epoch 9, 100% \t Train loss: 1.051 took: 16.33s  Val. loss: 0.861  Val. score: 77.733%\n",
      "Epoch 10, 100% \t Train loss: 0.934 took: 17.56s  Val. loss: 0.771  Val. score: 79.785%\n",
      "Training finished, took 231.199s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 74.886 took: 16.24s  Val. loss: 1.903  Val. score: 32.377%\n",
      "Epoch 2, 100% \t Train loss: 1.860 took: 14.63s  Val. loss: 1.573  Val. score: 43.418%\n",
      "Epoch 3, 100% \t Train loss: 1.667 took: 15.07s  Val. loss: 1.461  Val. score: 48.602%\n",
      "Epoch 4, 100% \t Train loss: 1.549 took: 15.43s  Val. loss: 1.366  Val. score: 54.500%\n",
      "Epoch 5, 100% \t Train loss: 1.454 took: 15.49s  Val. loss: 1.257  Val. score: 64.125%\n",
      "Epoch 6, 100% \t Train loss: 1.370 took: 15.96s  Val. loss: 1.171  Val. score: 62.985%\n",
      "Epoch 7, 100% \t Train loss: 1.290 took: 15.35s  Val. loss: 1.117  Val. score: 66.393%\n",
      "Epoch 8, 100% \t Train loss: 1.226 took: 14.88s  Val. loss: 1.041  Val. score: 67.905%\n",
      "Epoch 9, 100% \t Train loss: 1.165 took: 14.27s  Val. loss: 0.991  Val. score: 69.459%\n",
      "Epoch 10, 100% \t Train loss: 1.116 took: 15.55s  Val. loss: 0.969  Val. score: 74.751%\n",
      "Training finished, took 229.230s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.506 took: 14.18s  Val. loss: 1.432  Val. score: 49.352%\n",
      "Epoch 2, 100% \t Train loss: 1.329 took: 14.09s  Val. loss: 1.049  Val. score: 64.791%\n",
      "Epoch 3, 100% \t Train loss: 1.231 took: 15.87s  Val. loss: 0.934  Val. score: 73.953%\n",
      "Epoch 4, 100% \t Train loss: 1.102 took: 15.49s  Val. loss: 0.922  Val. score: 72.651%\n",
      "Epoch 5, 100% \t Train loss: 0.942 took: 16.04s  Val. loss: 1.368  Val. score: 66.147%\n",
      "Epoch 6, 100% \t Train loss: 0.841 took: 14.77s  Val. loss: 0.726  Val. score: 78.057%\n",
      "Epoch 7, 100% \t Train loss: 0.770 took: 15.87s  Val. loss: 0.666  Val. score: 79.179%\n",
      "Epoch 8, 100% \t Train loss: 0.696 took: 16.60s  Val. loss: 0.617  Val. score: 84.009%\n",
      "Epoch 9, 100% \t Train loss: 0.599 took: 16.52s  Val. loss: 0.481  Val. score: 90.526%\n",
      "Epoch 10, 100% \t Train loss: 0.547 took: 16.68s  Val. loss: 0.513  Val. score: 89.020%\n",
      "Training finished, took 232.102s\n",
      "\n",
      "Parameters configuration 81 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.06627875953395775\n",
      "h_sizes \t [784, 567, 414, 313, 211, 152, 110, 80, 63, 41, 26, 20, 15]\n",
      "penalty \t 0.008042615459276023\n",
      "dropout \t 0.07655014584025518\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 81.1852 +/- 5.9086\n",
      "Time for evaluation: 693.6 s\n",
      "Estimated time to finish : 1.82 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.580 took: 4.78s  Val. loss: 0.266  Val. score: 92.242%\n",
      "Epoch 2, 100% \t Train loss: 0.203 took: 4.54s  Val. loss: 0.179  Val. score: 94.660%\n",
      "Epoch 3, 100% \t Train loss: 0.137 took: 4.54s  Val. loss: 0.131  Val. score: 96.052%\n",
      "Epoch 4, 100% \t Train loss: 0.102 took: 4.66s  Val. loss: 0.134  Val. score: 96.124%\n",
      "Epoch 5, 100% \t Train loss: 0.082 took: 5.22s  Val. loss: 0.110  Val. score: 96.736%\n",
      "Epoch 6, 100% \t Train loss: 0.065 took: 5.05s  Val. loss: 0.109  Val. score: 96.934%\n",
      "Epoch 7, 100% \t Train loss: 0.051 took: 5.17s  Val. loss: 0.106  Val. score: 96.820%\n",
      "Epoch 8, 100% \t Train loss: 0.043 took: 4.69s  Val. loss: 0.098  Val. score: 97.312%\n",
      "Epoch 9, 100% \t Train loss: 0.037 took: 4.70s  Val. loss: 0.094  Val. score: 97.432%\n",
      "Epoch 10, 100% \t Train loss: 0.027 took: 5.23s  Val. loss: 0.104  Val. score: 97.414%\n",
      "Training finished, took 83.079s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.560 took: 4.34s  Val. loss: 0.255  Val. score: 92.446%\n",
      "Epoch 2, 100% \t Train loss: 0.207 took: 4.80s  Val. loss: 0.170  Val. score: 94.888%\n",
      "Epoch 3, 100% \t Train loss: 0.142 took: 4.89s  Val. loss: 0.137  Val. score: 95.800%\n",
      "Epoch 4, 100% \t Train loss: 0.105 took: 5.05s  Val. loss: 0.151  Val. score: 95.392%\n",
      "Epoch 5, 100% \t Train loss: 0.081 took: 5.12s  Val. loss: 0.121  Val. score: 96.406%\n",
      "Epoch 6, 100% \t Train loss: 0.061 took: 5.23s  Val. loss: 0.115  Val. score: 96.550%\n",
      "Epoch 7, 100% \t Train loss: 0.051 took: 5.13s  Val. loss: 0.116  Val. score: 96.616%\n",
      "Epoch 8, 100% \t Train loss: 0.040 took: 4.75s  Val. loss: 0.104  Val. score: 96.940%\n",
      "Epoch 9, 100% \t Train loss: 0.033 took: 4.92s  Val. loss: 0.102  Val. score: 97.198%\n",
      "Epoch 10, 100% \t Train loss: 0.026 took: 4.88s  Val. loss: 0.109  Val. score: 97.234%\n",
      "Training finished, took 83.661s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.589 took: 4.53s  Val. loss: 0.271  Val. score: 92.098%\n",
      "Epoch 2, 100% \t Train loss: 0.221 took: 4.74s  Val. loss: 0.177  Val. score: 94.816%\n",
      "Epoch 3, 100% \t Train loss: 0.149 took: 4.54s  Val. loss: 0.139  Val. score: 95.764%\n",
      "Epoch 4, 100% \t Train loss: 0.114 took: 5.06s  Val. loss: 0.124  Val. score: 96.334%\n",
      "Epoch 5, 100% \t Train loss: 0.088 took: 5.09s  Val. loss: 0.114  Val. score: 96.628%\n",
      "Epoch 6, 100% \t Train loss: 0.069 took: 4.90s  Val. loss: 0.103  Val. score: 96.880%\n",
      "Epoch 7, 100% \t Train loss: 0.055 took: 4.93s  Val. loss: 0.099  Val. score: 97.066%\n",
      "Epoch 8, 100% \t Train loss: 0.045 took: 5.33s  Val. loss: 0.098  Val. score: 97.228%\n",
      "Epoch 9, 100% \t Train loss: 0.037 took: 5.23s  Val. loss: 0.103  Val. score: 97.162%\n",
      "Epoch 10, 100% \t Train loss: 0.030 took: 5.01s  Val. loss: 0.104  Val. score: 97.024%\n",
      "Training finished, took 83.881s\n",
      "\n",
      "Parameters configuration 82 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0012714733011444605\n",
      "h_sizes \t [784, 244, 73, 26]\n",
      "penalty \t 0.001713893298855269\n",
      "dropout \t 0.016934535845452653\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.2239 +/- 0.1594\n",
      "Time for evaluation: 251.7 s\n",
      "Estimated time to finish : 1.72 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 100% \t Train loss: 0.872 took: 8.79s  Val. loss: 0.385  Val. score: 90.628%\n",
      "Epoch 2, 100% \t Train loss: 0.364 took: 8.94s  Val. loss: 0.321  Val. score: 92.476%\n",
      "Epoch 3, 100% \t Train loss: 0.310 took: 11.33s  Val. loss: 0.277  Val. score: 92.968%\n",
      "Epoch 4, 100% \t Train loss: 0.273 took: 9.60s  Val. loss: 0.272  Val. score: 93.742%\n",
      "Epoch 5, 100% \t Train loss: 0.223 took: 11.19s  Val. loss: 0.210  Val. score: 94.804%\n",
      "Epoch 6, 100% \t Train loss: 0.267 took: 8.79s  Val. loss: 0.274  Val. score: 93.970%\n",
      "Epoch 7, 100% \t Train loss: 0.385 took: 10.62s  Val. loss: 0.617  Val. score: 83.715%\n",
      "Epoch 8, 100% \t Train loss: 1.351 took: 9.68s  Val. loss: 2.362  Val. score: 9.768%\n",
      "Epoch 9, 100% \t Train loss: 2.536 took: 8.75s  Val. loss: 1.976  Val. score: 29.881%\n",
      "Epoch 10, 100% \t Train loss: 61.174 took: 8.62s  Val. loss: 1.906  Val. score: 29.059%\n",
      "Training finished, took 143.065s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.818 took: 8.09s  Val. loss: 0.377  Val. score: 91.192%\n",
      "Epoch 2, 100% \t Train loss: 0.346 took: 8.52s  Val. loss: 0.261  Val. score: 93.382%\n",
      "Epoch 3, 100% \t Train loss: 0.264 took: 8.34s  Val. loss: 0.222  Val. score: 94.456%\n",
      "Epoch 4, 100% \t Train loss: 0.225 took: 7.95s  Val. loss: 0.243  Val. score: 95.518%\n",
      "Epoch 5, 100% \t Train loss: 0.244 took: 10.13s  Val. loss: 0.265  Val. score: 94.780%\n",
      "Epoch 6, 100% \t Train loss: 0.228 took: 9.76s  Val. loss: 0.248  Val. score: 94.450%\n",
      "Epoch 7, 100% \t Train loss: 0.348 took: 11.50s  Val. loss: 0.449  Val. score: 92.002%\n",
      "Epoch 8, 100% \t Train loss: 0.601 took: 8.94s  Val. loss: 0.383  Val. score: 89.386%\n",
      "Epoch 9, 100% \t Train loss: 0.352 took: 8.04s  Val. loss: 0.459  Val. score: 91.780%\n",
      "Epoch 10, 100% \t Train loss: 0.419 took: 8.21s  Val. loss: 0.366  Val. score: 91.654%\n",
      "Training finished, took 136.462s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.773 took: 8.72s  Val. loss: 0.353  Val. score: 91.126%\n",
      "Epoch 2, 100% \t Train loss: 0.365 took: 9.25s  Val. loss: 0.290  Val. score: 92.806%\n",
      "Epoch 3, 100% \t Train loss: 0.333 took: 8.81s  Val. loss: 0.246  Val. score: 94.270%\n",
      "Epoch 4, 100% \t Train loss: 0.292 took: 10.98s  Val. loss: 0.264  Val. score: 94.102%\n",
      "Epoch 5, 100% \t Train loss: 0.289 took: 10.34s  Val. loss: 0.317  Val. score: 93.304%\n",
      "Epoch 6, 100% \t Train loss: 0.277 took: 10.41s  Val. loss: 0.299  Val. score: 94.066%\n",
      "Epoch 7, 100% \t Train loss: 0.282 took: 10.48s  Val. loss: 0.257  Val. score: 94.438%\n",
      "Epoch 8, 100% \t Train loss: 0.323 took: 11.51s  Val. loss: 0.418  Val. score: 89.158%\n",
      "Epoch 9, 100% \t Train loss: 0.500 took: 12.30s  Val. loss: 0.675  Val. score: 82.533%\n",
      "Epoch 10, 100% \t Train loss: 0.371 took: 11.24s  Val. loss: 0.269  Val. score: 93.532%\n",
      "Training finished, took 150.873s\n",
      "\n",
      "Parameters configuration 83 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.01440920056199898\n",
      "h_sizes \t [784, 394, 212, 116, 71, 34, 17]\n",
      "penalty \t 0.0001137037998456522\n",
      "dropout \t 0.03412852826201293\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 71.4149 +/- 29.9598\n",
      "Time for evaluation: 431.5 s\n",
      "Estimated time to finish : 1.63 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.593 took: 4.32s  Val. loss: 0.284  Val. score: 91.864%\n",
      "Epoch 2, 100% \t Train loss: 0.305 took: 4.12s  Val. loss: 0.219  Val. score: 93.682%\n",
      "Epoch 3, 100% \t Train loss: 0.249 took: 4.03s  Val. loss: 0.190  Val. score: 94.384%\n",
      "Epoch 4, 100% \t Train loss: 0.216 took: 4.08s  Val. loss: 0.174  Val. score: 94.720%\n",
      "Epoch 5, 100% \t Train loss: 0.196 took: 4.41s  Val. loss: 0.160  Val. score: 95.086%\n",
      "Epoch 6, 100% \t Train loss: 0.178 took: 4.18s  Val. loss: 0.152  Val. score: 95.314%\n",
      "Epoch 7, 100% \t Train loss: 0.165 took: 4.37s  Val. loss: 0.147  Val. score: 95.410%\n",
      "Epoch 8, 100% \t Train loss: 0.156 took: 4.24s  Val. loss: 0.139  Val. score: 95.602%\n",
      "Epoch 9, 100% \t Train loss: 0.145 took: 4.09s  Val. loss: 0.135  Val. score: 95.824%\n",
      "Epoch 10, 100% \t Train loss: 0.137 took: 4.23s  Val. loss: 0.134  Val. score: 95.872%\n",
      "Training finished, took 77.749s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.627 took: 4.42s  Val. loss: 0.299  Val. score: 91.318%\n",
      "Epoch 2, 100% \t Train loss: 0.330 took: 4.13s  Val. loss: 0.236  Val. score: 92.998%\n",
      "Epoch 3, 100% \t Train loss: 0.272 took: 4.37s  Val. loss: 0.211  Val. score: 93.604%\n",
      "Epoch 4, 100% \t Train loss: 0.237 took: 4.31s  Val. loss: 0.184  Val. score: 94.432%\n",
      "Epoch 5, 100% \t Train loss: 0.213 took: 4.33s  Val. loss: 0.169  Val. score: 94.882%\n",
      "Epoch 6, 100% \t Train loss: 0.194 took: 4.31s  Val. loss: 0.160  Val. score: 95.194%\n",
      "Epoch 7, 100% \t Train loss: 0.180 took: 4.37s  Val. loss: 0.153  Val. score: 95.410%\n",
      "Epoch 8, 100% \t Train loss: 0.168 took: 4.35s  Val. loss: 0.144  Val. score: 95.674%\n",
      "Epoch 9, 100% \t Train loss: 0.156 took: 4.17s  Val. loss: 0.140  Val. score: 95.770%\n",
      "Epoch 10, 100% \t Train loss: 0.147 took: 4.44s  Val. loss: 0.134  Val. score: 95.920%\n",
      "Training finished, took 78.750s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.598 took: 4.10s  Val. loss: 0.291  Val. score: 91.354%\n",
      "Epoch 2, 100% \t Train loss: 0.309 took: 4.14s  Val. loss: 0.227  Val. score: 93.448%\n",
      "Epoch 3, 100% \t Train loss: 0.252 took: 4.34s  Val. loss: 0.199  Val. score: 94.102%\n",
      "Epoch 4, 100% \t Train loss: 0.219 took: 4.45s  Val. loss: 0.174  Val. score: 94.948%\n",
      "Epoch 5, 100% \t Train loss: 0.197 took: 4.12s  Val. loss: 0.163  Val. score: 95.176%\n",
      "Epoch 6, 100% \t Train loss: 0.181 took: 4.23s  Val. loss: 0.152  Val. score: 95.500%\n",
      "Epoch 7, 100% \t Train loss: 0.164 took: 4.31s  Val. loss: 0.146  Val. score: 95.602%\n",
      "Epoch 8, 100% \t Train loss: 0.156 took: 4.30s  Val. loss: 0.138  Val. score: 95.818%\n",
      "Epoch 9, 100% \t Train loss: 0.146 took: 3.99s  Val. loss: 0.134  Val. score: 95.980%\n",
      "Epoch 10, 100% \t Train loss: 0.139 took: 4.12s  Val. loss: 0.129  Val. score: 96.130%\n",
      "Training finished, took 77.367s\n",
      "\n",
      "Parameters configuration 84 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.007102334544449898\n",
      "h_sizes \t [784, 260, 85, 24]\n",
      "penalty \t 0.008502319368887819\n",
      "dropout \t 0.12822088041935495\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 95.9738 +/- 0.1120\n",
      "Time for evaluation: 234.9 s\n",
      "Estimated time to finish : 1.52 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.627 took: 4.03s  Val. loss: 0.263  Val. score: 92.272%\n",
      "Epoch 2, 100% \t Train loss: 0.270 took: 4.05s  Val. loss: 0.188  Val. score: 94.462%\n",
      "Epoch 3, 100% \t Train loss: 0.199 took: 4.03s  Val. loss: 0.151  Val. score: 95.350%\n",
      "Epoch 4, 100% \t Train loss: 0.157 took: 3.88s  Val. loss: 0.129  Val. score: 96.022%\n",
      "Epoch 5, 100% \t Train loss: 0.138 took: 4.09s  Val. loss: 0.118  Val. score: 96.430%\n",
      "Epoch 6, 100% \t Train loss: 0.118 took: 3.92s  Val. loss: 0.109  Val. score: 96.826%\n",
      "Epoch 7, 100% \t Train loss: 0.100 took: 4.01s  Val. loss: 0.104  Val. score: 97.012%\n",
      "Epoch 8, 100% \t Train loss: 0.089 took: 3.96s  Val. loss: 0.102  Val. score: 96.922%\n",
      "Epoch 9, 100% \t Train loss: 0.079 took: 3.80s  Val. loss: 0.097  Val. score: 97.048%\n",
      "Epoch 10, 100% \t Train loss: 0.073 took: 4.05s  Val. loss: 0.093  Val. score: 97.132%\n",
      "Training finished, took 70.418s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.624 took: 3.79s  Val. loss: 0.273  Val. score: 92.008%\n",
      "Epoch 2, 100% \t Train loss: 0.272 took: 3.86s  Val. loss: 0.191  Val. score: 94.270%\n",
      "Epoch 3, 100% \t Train loss: 0.205 took: 3.86s  Val. loss: 0.156  Val. score: 95.356%\n",
      "Epoch 4, 100% \t Train loss: 0.169 took: 4.08s  Val. loss: 0.129  Val. score: 96.142%\n",
      "Epoch 5, 100% \t Train loss: 0.137 took: 3.82s  Val. loss: 0.123  Val. score: 96.322%\n",
      "Epoch 6, 100% \t Train loss: 0.117 took: 3.80s  Val. loss: 0.114  Val. score: 96.382%\n",
      "Epoch 7, 100% \t Train loss: 0.103 took: 3.89s  Val. loss: 0.105  Val. score: 96.820%\n",
      "Epoch 8, 100% \t Train loss: 0.092 took: 3.90s  Val. loss: 0.102  Val. score: 96.868%\n",
      "Epoch 9, 100% \t Train loss: 0.083 took: 3.69s  Val. loss: 0.091  Val. score: 97.288%\n",
      "Epoch 10, 100% \t Train loss: 0.074 took: 4.05s  Val. loss: 0.096  Val. score: 97.168%\n",
      "Training finished, took 69.223s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.625 took: 3.68s  Val. loss: 0.253  Val. score: 92.626%\n",
      "Epoch 2, 100% \t Train loss: 0.272 took: 4.05s  Val. loss: 0.182  Val. score: 94.480%\n",
      "Epoch 3, 100% \t Train loss: 0.202 took: 3.66s  Val. loss: 0.147  Val. score: 95.542%\n",
      "Epoch 4, 100% \t Train loss: 0.160 took: 4.14s  Val. loss: 0.131  Val. score: 96.034%\n",
      "Epoch 5, 100% \t Train loss: 0.137 took: 3.89s  Val. loss: 0.114  Val. score: 96.394%\n",
      "Epoch 6, 100% \t Train loss: 0.116 took: 4.08s  Val. loss: 0.108  Val. score: 96.700%\n",
      "Epoch 7, 100% \t Train loss: 0.102 took: 4.04s  Val. loss: 0.104  Val. score: 96.748%\n",
      "Epoch 8, 100% \t Train loss: 0.090 took: 3.65s  Val. loss: 0.095  Val. score: 97.114%\n",
      "Epoch 9, 100% \t Train loss: 0.080 took: 4.00s  Val. loss: 0.094  Val. score: 97.240%\n",
      "Epoch 10, 100% \t Train loss: 0.070 took: 4.06s  Val. loss: 0.091  Val. score: 97.258%\n",
      "Training finished, took 69.839s\n",
      "\n",
      "Parameters configuration 85 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0011391398286245316\n",
      "h_sizes \t [784, 199, 51]\n",
      "penalty \t 0.00010261473403120613\n",
      "dropout \t 0.2490087834704026\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 97.1859 +/- 0.0530\n",
      "Time for evaluation: 210.6 s\n",
      "Estimated time to finish : 1.42 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.200 took: 4.53s  Val. loss: 0.879  Val. score: 80.739%\n",
      "Epoch 2, 100% \t Train loss: 1.015 took: 4.76s  Val. loss: 0.652  Val. score: 83.925%\n",
      "Epoch 3, 100% \t Train loss: 1.084 took: 5.71s  Val. loss: 0.687  Val. score: 83.961%\n",
      "Epoch 4, 100% \t Train loss: 1.131 took: 7.65s  Val. loss: 0.630  Val. score: 86.343%\n",
      "Epoch 5, 100% \t Train loss: 1.130 took: 7.25s  Val. loss: 0.658  Val. score: 85.245%\n",
      "Epoch 6, 100% \t Train loss: 1.311 took: 7.37s  Val. loss: 1.222  Val. score: 58.166%\n",
      "Epoch 7, 100% \t Train loss: 1.288 took: 7.23s  Val. loss: 0.921  Val. score: 74.985%\n",
      "Epoch 8, 100% \t Train loss: 1.248 took: 7.37s  Val. loss: 0.725  Val. score: 82.773%\n",
      "Epoch 9, 100% \t Train loss: 1.240 took: 7.33s  Val. loss: 0.693  Val. score: 84.717%\n",
      "Epoch 10, 100% \t Train loss: 1.193 took: 6.95s  Val. loss: 0.720  Val. score: 84.963%\n",
      "Training finished, took 101.184s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.201 took: 4.79s  Val. loss: 0.639  Val. score: 85.173%\n",
      "Epoch 2, 100% \t Train loss: 0.942 took: 4.90s  Val. loss: 0.588  Val. score: 83.307%\n",
      "Epoch 3, 100% \t Train loss: 1.047 took: 5.31s  Val. loss: 0.760  Val. score: 81.135%\n",
      "Epoch 4, 100% \t Train loss: 1.162 took: 7.43s  Val. loss: 0.644  Val. score: 84.465%\n",
      "Epoch 5, 100% \t Train loss: 0.986 took: 6.90s  Val. loss: 0.626  Val. score: 83.067%\n",
      "Epoch 6, 100% \t Train loss: 0.978 took: 7.20s  Val. loss: 0.615  Val. score: 82.659%\n",
      "Epoch 7, 100% \t Train loss: 1.083 took: 7.05s  Val. loss: 0.709  Val. score: 82.491%\n",
      "Epoch 8, 100% \t Train loss: 1.050 took: 7.07s  Val. loss: 0.768  Val. score: 79.893%\n",
      "Epoch 9, 100% \t Train loss: 1.154 took: 7.50s  Val. loss: 0.812  Val. score: 77.961%\n",
      "Epoch 10, 100% \t Train loss: 1.142 took: 7.27s  Val. loss: 0.851  Val. score: 75.009%\n",
      "Training finished, took 100.533s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.223 took: 4.75s  Val. loss: 0.623  Val. score: 85.047%\n",
      "Epoch 2, 100% \t Train loss: 1.001 took: 5.05s  Val. loss: 0.634  Val. score: 84.351%\n",
      "Epoch 3, 100% \t Train loss: 0.963 took: 5.50s  Val. loss: 0.646  Val. score: 85.575%\n",
      "Epoch 4, 100% \t Train loss: 1.057 took: 7.62s  Val. loss: 0.750  Val. score: 85.101%\n",
      "Epoch 5, 100% \t Train loss: 1.137 took: 6.93s  Val. loss: 1.096  Val. score: 64.215%\n",
      "Epoch 6, 100% \t Train loss: 1.185 took: 7.37s  Val. loss: 0.870  Val. score: 77.841%\n",
      "Epoch 7, 100% \t Train loss: 1.218 took: 6.97s  Val. loss: 0.796  Val. score: 81.351%\n",
      "Epoch 8, 100% \t Train loss: 1.159 took: 7.30s  Val. loss: 0.899  Val. score: 72.195%\n",
      "Epoch 9, 100% \t Train loss: 1.209 took: 7.01s  Val. loss: 0.942  Val. score: 79.023%\n",
      "Epoch 10, 100% \t Train loss: 1.155 took: 7.45s  Val. loss: 0.745  Val. score: 79.635%\n",
      "Training finished, took 100.901s\n",
      "\n",
      "Parameters configuration 86 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.046946892916355225\n",
      "h_sizes \t [784, 271, 91, 24]\n",
      "penalty \t 0.00014291155046154566\n",
      "dropout \t 0.21687360000070438\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 79.8692 +/- 4.0672\n",
      "Time for evaluation: 303.7 s\n",
      "Estimated time to finish : 1.33 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.629 took: 5.25s  Val. loss: 0.255  Val. score: 93.094%\n",
      "Epoch 2, 100% \t Train loss: 0.295 took: 5.12s  Val. loss: 0.187  Val. score: 94.960%\n",
      "Epoch 3, 100% \t Train loss: 0.243 took: 6.03s  Val. loss: 0.175  Val. score: 95.392%\n",
      "Epoch 4, 100% \t Train loss: 0.209 took: 7.58s  Val. loss: 0.160  Val. score: 96.034%\n",
      "Epoch 5, 100% \t Train loss: 0.187 took: 6.83s  Val. loss: 0.159  Val. score: 95.692%\n",
      "Epoch 6, 100% \t Train loss: 0.170 took: 7.26s  Val. loss: 0.157  Val. score: 96.040%\n",
      "Epoch 7, 100% \t Train loss: 0.161 took: 6.82s  Val. loss: 0.146  Val. score: 96.286%\n",
      "Epoch 8, 100% \t Train loss: 0.145 took: 6.84s  Val. loss: 0.133  Val. score: 96.556%\n",
      "Epoch 9, 100% \t Train loss: 0.136 took: 7.26s  Val. loss: 0.137  Val. score: 96.622%\n",
      "Epoch 10, 100% \t Train loss: 0.137 took: 7.30s  Val. loss: 0.137  Val. score: 96.460%\n",
      "Training finished, took 101.563s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.559 took: 5.52s  Val. loss: 0.202  Val. score: 94.072%\n",
      "Epoch 2, 100% \t Train loss: 0.255 took: 5.55s  Val. loss: 0.164  Val. score: 95.086%\n",
      "Epoch 3, 100% \t Train loss: 0.200 took: 5.92s  Val. loss: 0.152  Val. score: 95.866%\n",
      "Epoch 4, 100% \t Train loss: 0.171 took: 7.10s  Val. loss: 0.142  Val. score: 96.082%\n",
      "Epoch 5, 100% \t Train loss: 0.152 took: 7.13s  Val. loss: 0.137  Val. score: 96.436%\n",
      "Epoch 6, 100% \t Train loss: 0.129 took: 6.66s  Val. loss: 0.139  Val. score: 96.502%\n",
      "Epoch 7, 100% \t Train loss: 0.124 took: 7.14s  Val. loss: 0.129  Val. score: 96.460%\n",
      "Epoch 8, 100% \t Train loss: 0.113 took: 7.06s  Val. loss: 0.128  Val. score: 96.754%\n",
      "Epoch 9, 100% \t Train loss: 0.107 took: 6.58s  Val. loss: 0.127  Val. score: 96.706%\n",
      "Epoch 10, 100% \t Train loss: 0.095 took: 7.06s  Val. loss: 0.127  Val. score: 97.114%\n",
      "Training finished, took 100.796s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.489 took: 5.65s  Val. loss: 0.193  Val. score: 94.456%\n",
      "Epoch 2, 100% \t Train loss: 0.234 took: 5.44s  Val. loss: 0.157  Val. score: 95.566%\n",
      "Epoch 3, 100% \t Train loss: 0.186 took: 5.56s  Val. loss: 0.142  Val. score: 95.848%\n",
      "Epoch 4, 100% \t Train loss: 0.155 took: 6.52s  Val. loss: 0.138  Val. score: 96.088%\n",
      "Epoch 5, 100% \t Train loss: 0.139 took: 6.95s  Val. loss: 0.122  Val. score: 96.664%\n",
      "Epoch 6, 100% \t Train loss: 0.120 took: 6.94s  Val. loss: 0.120  Val. score: 96.760%\n",
      "Epoch 7, 100% \t Train loss: 0.109 took: 6.61s  Val. loss: 0.117  Val. score: 96.850%\n",
      "Epoch 8, 100% \t Train loss: 0.102 took: 6.91s  Val. loss: 0.123  Val. score: 97.048%\n",
      "Epoch 9, 100% \t Train loss: 0.098 took: 6.99s  Val. loss: 0.115  Val. score: 96.862%\n",
      "Epoch 10, 100% \t Train loss: 0.090 took: 6.67s  Val. loss: 0.117  Val. score: 96.940%\n",
      "Training finished, took 99.175s\n",
      "\n",
      "Parameters configuration 87 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.028228750676287287\n",
      "h_sizes \t [784, 265, 86, 28]\n",
      "penalty \t 0.0070729965375289595\n",
      "dropout \t 0.1800033267365161\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.8379 +/- 0.2766\n",
      "Time for evaluation: 302.6 s\n",
      "Estimated time to finish : 1.23 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.910 took: 4.05s  Val. loss: 0.523  Val. score: 85.647%\n",
      "Epoch 2, 100% \t Train loss: 0.527 took: 4.40s  Val. loss: 0.425  Val. score: 88.132%\n",
      "Epoch 3, 100% \t Train loss: 0.461 took: 4.30s  Val. loss: 0.383  Val. score: 89.194%\n",
      "Epoch 4, 100% \t Train loss: 0.420 took: 4.32s  Val. loss: 0.358  Val. score: 89.854%\n",
      "Epoch 5, 100% \t Train loss: 0.390 took: 4.39s  Val. loss: 0.340  Val. score: 90.232%\n",
      "Epoch 6, 100% \t Train loss: 0.368 took: 4.19s  Val. loss: 0.322  Val. score: 90.832%\n",
      "Epoch 7, 100% \t Train loss: 0.355 took: 4.38s  Val. loss: 0.310  Val. score: 91.042%\n",
      "Epoch 8, 100% \t Train loss: 0.340 took: 4.33s  Val. loss: 0.300  Val. score: 91.426%\n",
      "Epoch 9, 100% \t Train loss: 0.325 took: 4.32s  Val. loss: 0.291  Val. score: 91.732%\n",
      "Epoch 10, 100% \t Train loss: 0.314 took: 3.97s  Val. loss: 0.283  Val. score: 91.864%\n",
      "Training finished, took 77.109s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.870 took: 4.13s  Val. loss: 0.486  Val. score: 86.751%\n",
      "Epoch 2, 100% \t Train loss: 0.495 took: 4.22s  Val. loss: 0.410  Val. score: 88.522%\n",
      "Epoch 3, 100% \t Train loss: 0.436 took: 4.22s  Val. loss: 0.377  Val. score: 89.362%\n",
      "Epoch 4, 100% \t Train loss: 0.403 took: 4.01s  Val. loss: 0.352  Val. score: 90.058%\n",
      "Epoch 5, 100% \t Train loss: 0.377 took: 4.25s  Val. loss: 0.335  Val. score: 90.412%\n",
      "Epoch 6, 100% \t Train loss: 0.359 took: 4.41s  Val. loss: 0.322  Val. score: 90.922%\n",
      "Epoch 7, 100% \t Train loss: 0.342 took: 3.98s  Val. loss: 0.311  Val. score: 91.210%\n",
      "Epoch 8, 100% \t Train loss: 0.331 took: 3.97s  Val. loss: 0.299  Val. score: 91.414%\n",
      "Epoch 9, 100% \t Train loss: 0.321 took: 4.45s  Val. loss: 0.290  Val. score: 91.738%\n",
      "Epoch 10, 100% \t Train loss: 0.311 took: 4.29s  Val. loss: 0.286  Val. score: 91.918%\n",
      "Training finished, took 75.986s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.865 took: 4.07s  Val. loss: 0.478  Val. score: 86.937%\n",
      "Epoch 2, 100% \t Train loss: 0.494 took: 4.41s  Val. loss: 0.393  Val. score: 89.050%\n",
      "Epoch 3, 100% \t Train loss: 0.431 took: 3.97s  Val. loss: 0.350  Val. score: 90.250%\n",
      "Epoch 4, 100% \t Train loss: 0.395 took: 3.99s  Val. loss: 0.328  Val. score: 90.712%\n",
      "Epoch 5, 100% \t Train loss: 0.368 took: 4.22s  Val. loss: 0.310  Val. score: 90.958%\n",
      "Epoch 6, 100% \t Train loss: 0.349 took: 4.22s  Val. loss: 0.297  Val. score: 91.396%\n",
      "Epoch 7, 100% \t Train loss: 0.334 took: 3.98s  Val. loss: 0.288  Val. score: 91.720%\n",
      "Epoch 8, 100% \t Train loss: 0.324 took: 4.43s  Val. loss: 0.278  Val. score: 92.020%\n",
      "Epoch 9, 100% \t Train loss: 0.313 took: 4.00s  Val. loss: 0.268  Val. score: 92.176%\n",
      "Epoch 10, 100% \t Train loss: 0.302 took: 4.28s  Val. loss: 0.262  Val. score: 92.410%\n",
      "Training finished, took 75.791s\n",
      "\n",
      "Parameters configuration 88 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0017339394488245722\n",
      "h_sizes \t [784, 258, 102, 33]\n",
      "penalty \t 0.00020289231593628796\n",
      "dropout \t 0.06498763109567998\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 92.0637 +/- 0.2457\n",
      "Time for evaluation: 230.0 s\n",
      "Estimated time to finish : 1.13 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.770 took: 5.25s  Val. loss: 2.096  Val. score: 21.223%\n",
      "Epoch 2, 100% \t Train loss: 4.126 took: 4.44s  Val. loss: 1.802  Val. score: 28.957%\n",
      "Epoch 3, 100% \t Train loss: 2.516 took: 4.95s  Val. loss: 1.604  Val. score: 48.416%\n",
      "Epoch 4, 100% \t Train loss: 2.752 took: 5.15s  Val. loss: 1.542  Val. score: 41.894%\n",
      "Epoch 5, 100% \t Train loss: 2.187 took: 4.88s  Val. loss: 1.439  Val. score: 44.366%\n",
      "Epoch 6, 100% \t Train loss: 2.239 took: 4.72s  Val. loss: 1.730  Val. score: 43.046%\n",
      "Epoch 7, 100% \t Train loss: 4.099 took: 4.98s  Val. loss: 1.857  Val. score: 39.860%\n",
      "Epoch 8, 100% \t Train loss: 7.924 took: 5.06s  Val. loss: 2.029  Val. score: 24.865%\n",
      "Epoch 9, 100% \t Train loss: 2.633 took: 5.28s  Val. loss: 1.915  Val. score: 26.821%\n",
      "Epoch 10, 100% \t Train loss: 2.245 took: 5.03s  Val. loss: 1.869  Val. score: 29.317%\n",
      "Training finished, took 84.366s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 4.865 took: 5.03s  Val. loss: 2.539  Val. score: 24.055%\n",
      "Epoch 2, 100% \t Train loss: 4.967 took: 4.75s  Val. loss: 2.286  Val. score: 33.637%\n",
      "Epoch 3, 100% \t Train loss: 7.005 took: 4.90s  Val. loss: 5.612  Val. score: 18.133%\n",
      "Epoch 4, 100% \t Train loss: 10.175 took: 4.90s  Val. loss: 7.125  Val. score: 17.671%\n",
      "Epoch 5, 100% \t Train loss: 8.430 took: 4.95s  Val. loss: 2.635  Val. score: 20.257%\n",
      "Epoch 6, 100% \t Train loss: 3.151 took: 4.37s  Val. loss: 1.950  Val. score: 25.969%\n",
      "Epoch 7, 100% \t Train loss: 3.358 took: 4.41s  Val. loss: 3.260  Val. score: 23.155%\n",
      "Epoch 8, 100% \t Train loss: 5.526 took: 4.95s  Val. loss: 1.963  Val. score: 25.267%\n",
      "Epoch 9, 100% \t Train loss: 2.711 took: 4.75s  Val. loss: 1.912  Val. score: 28.147%\n",
      "Epoch 10, 100% \t Train loss: 2.227 took: 4.93s  Val. loss: 1.863  Val. score: 30.055%\n",
      "Training finished, took 82.383s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.226 took: 5.14s  Val. loss: 1.914  Val. score: 27.133%\n",
      "Epoch 2, 100% \t Train loss: 3.103 took: 4.39s  Val. loss: 2.044  Val. score: 26.533%\n",
      "Epoch 3, 100% \t Train loss: 2.114 took: 4.86s  Val. loss: 1.636  Val. score: 35.155%\n",
      "Epoch 4, 100% \t Train loss: 1.984 took: 4.59s  Val. loss: 1.626  Val. score: 39.344%\n",
      "Epoch 5, 100% \t Train loss: 2.056 took: 4.52s  Val. loss: 1.627  Val. score: 40.298%\n",
      "Epoch 6, 100% \t Train loss: 1.959 took: 4.55s  Val. loss: 1.542  Val. score: 39.014%\n",
      "Epoch 7, 100% \t Train loss: 2.283 took: 4.96s  Val. loss: 1.592  Val. score: 34.753%\n",
      "Epoch 8, 100% \t Train loss: 2.199 took: 4.92s  Val. loss: 1.364  Val. score: 45.632%\n",
      "Epoch 9, 100% \t Train loss: 3.725 took: 4.85s  Val. loss: 1.924  Val. score: 35.563%\n",
      "Epoch 10, 100% \t Train loss: 5.240 took: 4.95s  Val. loss: 1.708  Val. score: 34.195%\n",
      "Training finished, took 82.059s\n",
      "\n",
      "Parameters configuration 89 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.07002218093578078\n",
      "h_sizes \t [784, 265, 88, 32]\n",
      "penalty \t 0.00020719139943243555\n",
      "dropout \t 0.17312047679031223\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 31.1892 +/- 2.1469\n",
      "Time for evaluation: 249.9 s\n",
      "Estimated time to finish : 1.03 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.729 took: 5.70s  Val. loss: 1.238  Val. score: 56.060%\n",
      "Epoch 2, 100% \t Train loss: 1.612 took: 5.90s  Val. loss: 1.306  Val. score: 57.152%\n",
      "Epoch 3, 100% \t Train loss: 1.700 took: 6.95s  Val. loss: 1.583  Val. score: 39.116%\n",
      "Epoch 4, 100% \t Train loss: 1.736 took: 8.88s  Val. loss: 1.428  Val. score: 43.418%\n",
      "Epoch 5, 100% \t Train loss: 1.699 took: 8.98s  Val. loss: 1.415  Val. score: 45.884%\n",
      "Epoch 6, 100% \t Train loss: 1.711 took: 9.26s  Val. loss: 1.361  Val. score: 49.106%\n",
      "Epoch 7, 100% \t Train loss: 1.746 took: 8.90s  Val. loss: 1.507  Val. score: 34.657%\n",
      "Epoch 8, 100% \t Train loss: 1.791 took: 8.71s  Val. loss: 1.652  Val. score: 37.640%\n",
      "Epoch 9, 100% \t Train loss: 1.796 took: 8.61s  Val. loss: 1.513  Val. score: 41.498%\n",
      "Epoch 10, 100% \t Train loss: 1.786 took: 8.84s  Val. loss: 1.598  Val. score: 35.443%\n",
      "Training finished, took 120.530s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.319 took: 6.13s  Val. loss: 2.303  Val. score: 11.604%\n",
      "Epoch 2, 100% \t Train loss: 2.305 took: 5.98s  Val. loss: 2.304  Val. score: 11.604%\n",
      "Epoch 3, 100% \t Train loss: 2.305 took: 7.03s  Val. loss: 2.305  Val. score: 9.750%\n",
      "Epoch 4, 100% \t Train loss: 2.304 took: 9.01s  Val. loss: 2.303  Val. score: 10.608%\n",
      "Epoch 5, 100% \t Train loss: 2.305 took: 8.60s  Val. loss: 2.304  Val. score: 9.462%\n",
      "Epoch 6, 100% \t Train loss: 2.305 took: 8.96s  Val. loss: 2.305  Val. score: 9.630%\n",
      "Epoch 7, 100% \t Train loss: 2.304 took: 8.77s  Val. loss: 2.303  Val. score: 11.604%\n",
      "Epoch 8, 100% \t Train loss: 2.305 took: 8.71s  Val. loss: 2.302  Val. score: 11.604%\n",
      "Epoch 9, 100% \t Train loss: 2.305 took: 8.61s  Val. loss: 2.305  Val. score: 9.750%\n",
      "Epoch 10, 100% \t Train loss: 2.305 took: 8.65s  Val. loss: 2.302  Val. score: 10.608%\n",
      "Training finished, took 119.877s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.733 took: 5.76s  Val. loss: 1.337  Val. score: 47.414%\n",
      "Epoch 2, 100% \t Train loss: 1.618 took: 5.71s  Val. loss: 1.271  Val. score: 49.430%\n",
      "Epoch 3, 100% \t Train loss: 1.757 took: 6.61s  Val. loss: 1.677  Val. score: 28.573%\n",
      "Epoch 4, 100% \t Train loss: 1.963 took: 9.24s  Val. loss: 1.863  Val. score: 20.353%\n",
      "Epoch 5, 100% \t Train loss: 1.998 took: 8.97s  Val. loss: 1.865  Val. score: 19.003%\n",
      "Epoch 6, 100% \t Train loss: 1.977 took: 9.04s  Val. loss: 1.898  Val. score: 19.789%\n",
      "Epoch 7, 100% \t Train loss: 1.973 took: 8.61s  Val. loss: 1.905  Val. score: 19.231%\n",
      "Epoch 8, 100% \t Train loss: 1.973 took: 8.60s  Val. loss: 1.910  Val. score: 19.855%\n",
      "Epoch 9, 100% \t Train loss: 1.984 took: 8.61s  Val. loss: 1.870  Val. score: 17.905%\n",
      "Epoch 10, 100% \t Train loss: 2.052 took: 8.62s  Val. loss: 1.866  Val. score: 19.615%\n",
      "Training finished, took 119.233s\n",
      "\n",
      "Parameters configuration 90 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.05280599623611874\n",
      "h_sizes \t [784, 334, 141, 45, 16]\n",
      "penalty \t 0.0066175357066091895\n",
      "dropout \t 0.17253799926580854\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 21.8889 +/- 10.2656\n",
      "Time for evaluation: 360.7 s\n",
      "Estimated time to finish : 56.44 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.525 took: 7.08s  Val. loss: 0.213  Val. score: 93.838%\n",
      "Epoch 2, 100% \t Train loss: 0.163 took: 7.73s  Val. loss: 0.158  Val. score: 95.266%\n",
      "Epoch 3, 100% \t Train loss: 0.115 took: 8.30s  Val. loss: 0.138  Val. score: 96.052%\n",
      "Epoch 4, 100% \t Train loss: 0.082 took: 8.92s  Val. loss: 0.135  Val. score: 96.424%\n",
      "Epoch 5, 100% \t Train loss: 0.070 took: 8.29s  Val. loss: 0.141  Val. score: 96.286%\n",
      "Epoch 6, 100% \t Train loss: 0.064 took: 8.45s  Val. loss: 0.117  Val. score: 96.862%\n",
      "Epoch 7, 100% \t Train loss: 0.050 took: 8.89s  Val. loss: 0.180  Val. score: 96.010%\n",
      "Epoch 8, 100% \t Train loss: 0.046 took: 8.38s  Val. loss: 0.127  Val. score: 97.054%\n",
      "Epoch 9, 100% \t Train loss: 0.034 took: 8.93s  Val. loss: 0.124  Val. score: 97.084%\n",
      "Epoch 10, 100% \t Train loss: 0.037 took: 8.26s  Val. loss: 0.138  Val. score: 97.006%\n",
      "Training finished, took 128.907s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.506 took: 7.79s  Val. loss: 0.237  Val. score: 93.724%\n",
      "Epoch 2, 100% \t Train loss: 0.162 took: 7.56s  Val. loss: 0.160  Val. score: 95.632%\n",
      "Epoch 3, 100% \t Train loss: 0.113 took: 8.07s  Val. loss: 0.139  Val. score: 96.364%\n",
      "Epoch 4, 100% \t Train loss: 0.079 took: 8.11s  Val. loss: 0.126  Val. score: 96.616%\n",
      "Epoch 5, 100% \t Train loss: 0.071 took: 8.90s  Val. loss: 0.136  Val. score: 96.592%\n",
      "Epoch 6, 100% \t Train loss: 0.056 took: 8.13s  Val. loss: 0.116  Val. score: 96.850%\n",
      "Epoch 7, 100% \t Train loss: 0.045 took: 8.41s  Val. loss: 0.141  Val. score: 96.592%\n",
      "Epoch 8, 100% \t Train loss: 0.045 took: 8.81s  Val. loss: 0.122  Val. score: 97.060%\n",
      "Epoch 9, 100% \t Train loss: 0.040 took: 8.88s  Val. loss: 0.128  Val. score: 96.958%\n",
      "Epoch 10, 100% \t Train loss: 0.036 took: 8.39s  Val. loss: 0.125  Val. score: 97.120%\n",
      "Training finished, took 128.911s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.557 took: 7.75s  Val. loss: 0.235  Val. score: 93.328%\n",
      "Epoch 2, 100% \t Train loss: 0.180 took: 7.64s  Val. loss: 0.174  Val. score: 95.014%\n",
      "Epoch 3, 100% \t Train loss: 0.120 took: 8.18s  Val. loss: 0.139  Val. score: 96.184%\n",
      "Epoch 4, 100% \t Train loss: 0.091 took: 8.64s  Val. loss: 0.128  Val. score: 96.454%\n",
      "Epoch 5, 100% \t Train loss: 0.073 took: 8.48s  Val. loss: 0.116  Val. score: 96.832%\n",
      "Epoch 6, 100% \t Train loss: 0.058 took: 8.27s  Val. loss: 0.148  Val. score: 96.202%\n",
      "Epoch 7, 100% \t Train loss: 0.055 took: 8.83s  Val. loss: 0.121  Val. score: 96.814%\n",
      "Epoch 8, 100% \t Train loss: 0.047 took: 8.56s  Val. loss: 0.112  Val. score: 97.282%\n",
      "Epoch 9, 100% \t Train loss: 0.038 took: 8.38s  Val. loss: 0.146  Val. score: 96.340%\n",
      "Epoch 10, 100% \t Train loss: 0.037 took: 9.18s  Val. loss: 0.173  Val. score: 96.292%\n",
      "Training finished, took 129.431s\n",
      "\n",
      "Parameters configuration 91 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0038624315184015295\n",
      "h_sizes \t [784, 380, 184, 88, 40, 20]\n",
      "penalty \t 0.00012956057793722043\n",
      "dropout \t 1.054559712440617e-05\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.8059 +/- 0.3664\n",
      "Time for evaluation: 388.3 s\n",
      "Estimated time to finish : 50.88 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.399 took: 3.49s  Val. loss: 0.176  Val. score: 95.092%\n",
      "Epoch 2, 100% \t Train loss: 0.196 took: 3.70s  Val. loss: 0.145  Val. score: 95.692%\n",
      "Epoch 3, 100% \t Train loss: 0.154 took: 3.88s  Val. loss: 0.124  Val. score: 96.532%\n",
      "Epoch 4, 100% \t Train loss: 0.128 took: 4.11s  Val. loss: 0.120  Val. score: 96.544%\n",
      "Epoch 5, 100% \t Train loss: 0.115 took: 4.11s  Val. loss: 0.127  Val. score: 96.616%\n",
      "Epoch 6, 100% \t Train loss: 0.115 took: 4.21s  Val. loss: 0.117  Val. score: 96.946%\n",
      "Epoch 7, 100% \t Train loss: 0.108 took: 4.11s  Val. loss: 0.119  Val. score: 96.670%\n",
      "Epoch 8, 100% \t Train loss: 0.098 took: 4.13s  Val. loss: 0.113  Val. score: 97.138%\n",
      "Epoch 9, 100% \t Train loss: 0.099 took: 4.14s  Val. loss: 0.117  Val. score: 97.066%\n",
      "Epoch 10, 100% \t Train loss: 0.090 took: 4.14s  Val. loss: 0.133  Val. score: 96.796%\n",
      "Training finished, took 69.981s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.388 took: 3.78s  Val. loss: 0.170  Val. score: 94.762%\n",
      "Epoch 2, 100% \t Train loss: 0.195 took: 3.59s  Val. loss: 0.143  Val. score: 95.836%\n",
      "Epoch 3, 100% \t Train loss: 0.162 took: 3.67s  Val. loss: 0.126  Val. score: 96.232%\n",
      "Epoch 4, 100% \t Train loss: 0.135 took: 4.11s  Val. loss: 0.115  Val. score: 96.556%\n",
      "Epoch 5, 100% \t Train loss: 0.121 took: 4.18s  Val. loss: 0.115  Val. score: 96.646%\n",
      "Epoch 6, 100% \t Train loss: 0.112 took: 3.84s  Val. loss: 0.117  Val. score: 96.874%\n",
      "Epoch 7, 100% \t Train loss: 0.108 took: 4.19s  Val. loss: 0.122  Val. score: 96.742%\n",
      "Epoch 8, 100% \t Train loss: 0.110 took: 4.15s  Val. loss: 0.138  Val. score: 96.484%\n",
      "Epoch 9, 100% \t Train loss: 0.097 took: 4.05s  Val. loss: 0.128  Val. score: 96.682%\n",
      "Epoch 10, 100% \t Train loss: 0.095 took: 4.26s  Val. loss: 0.117  Val. score: 97.006%\n",
      "Training finished, took 69.799s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.391 took: 3.72s  Val. loss: 0.190  Val. score: 94.246%\n",
      "Epoch 2, 100% \t Train loss: 0.196 took: 3.81s  Val. loss: 0.145  Val. score: 95.782%\n",
      "Epoch 3, 100% \t Train loss: 0.156 took: 3.89s  Val. loss: 0.138  Val. score: 95.866%\n",
      "Epoch 4, 100% \t Train loss: 0.128 took: 4.09s  Val. loss: 0.131  Val. score: 96.142%\n",
      "Epoch 5, 100% \t Train loss: 0.120 took: 3.73s  Val. loss: 0.140  Val. score: 96.154%\n",
      "Epoch 6, 100% \t Train loss: 0.115 took: 4.03s  Val. loss: 0.130  Val. score: 96.454%\n",
      "Epoch 7, 100% \t Train loss: 0.103 took: 3.79s  Val. loss: 0.130  Val. score: 96.388%\n",
      "Epoch 8, 100% \t Train loss: 0.099 took: 4.11s  Val. loss: 0.132  Val. score: 96.520%\n",
      "Epoch 9, 100% \t Train loss: 0.096 took: 4.08s  Val. loss: 0.140  Val. score: 96.484%\n",
      "Epoch 10, 100% \t Train loss: 0.084 took: 4.11s  Val. loss: 0.133  Val. score: 96.658%\n",
      "Training finished, took 69.300s\n",
      "\n",
      "Parameters configuration 92 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.007003761640517866\n",
      "h_sizes \t [784, 182, 46]\n",
      "penalty \t 0.00039049826545493004\n",
      "dropout \t 0.18885246027478317\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 96.8199 +/- 0.1431\n",
      "Time for evaluation: 210.2 s\n",
      "Estimated time to finish : 45.04 min \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.717 took: 3.64s  Val. loss: 0.281  Val. score: 91.552%\n",
      "Epoch 2, 100% \t Train loss: 0.339 took: 4.02s  Val. loss: 0.256  Val. score: 92.680%\n",
      "Epoch 3, 100% \t Train loss: 0.292 took: 4.25s  Val. loss: 0.217  Val. score: 93.748%\n",
      "Epoch 4, 100% \t Train loss: 0.264 took: 5.12s  Val. loss: 0.208  Val. score: 94.138%\n",
      "Epoch 5, 100% \t Train loss: 0.237 took: 4.63s  Val. loss: 0.199  Val. score: 94.588%\n",
      "Epoch 6, 100% \t Train loss: 0.230 took: 5.04s  Val. loss: 0.218  Val. score: 94.456%\n",
      "Epoch 7, 100% \t Train loss: 0.209 took: 4.99s  Val. loss: 0.217  Val. score: 94.108%\n",
      "Epoch 8, 100% \t Train loss: 0.199 took: 4.79s  Val. loss: 0.182  Val. score: 95.020%\n",
      "Epoch 9, 100% \t Train loss: 0.189 took: 5.06s  Val. loss: 0.227  Val. score: 94.516%\n",
      "Epoch 10, 100% \t Train loss: 0.191 took: 4.63s  Val. loss: 0.194  Val. score: 94.726%\n",
      "Training finished, took 75.251s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.256 took: 4.05s  Val. loss: 0.352  Val. score: 89.776%\n",
      "Epoch 2, 100% \t Train loss: 0.429 took: 3.64s  Val. loss: 0.267  Val. score: 92.512%\n",
      "Epoch 3, 100% \t Train loss: 0.343 took: 4.09s  Val. loss: 0.277  Val. score: 92.014%\n",
      "Epoch 4, 100% \t Train loss: 0.306 took: 5.19s  Val. loss: 0.242  Val. score: 93.520%\n",
      "Epoch 5, 100% \t Train loss: 0.290 took: 4.93s  Val. loss: 0.234  Val. score: 93.652%\n",
      "Epoch 6, 100% \t Train loss: 0.274 took: 5.10s  Val. loss: 0.225  Val. score: 93.928%\n",
      "Epoch 7, 100% \t Train loss: 0.256 took: 4.77s  Val. loss: 0.214  Val. score: 94.090%\n",
      "Epoch 8, 100% \t Train loss: 0.249 took: 4.80s  Val. loss: 0.214  Val. score: 94.420%\n",
      "Epoch 9, 100% \t Train loss: 0.247 took: 5.21s  Val. loss: 0.222  Val. score: 94.192%\n",
      "Epoch 10, 100% \t Train loss: 0.231 took: 5.19s  Val. loss: 0.223  Val. score: 94.282%\n",
      "Training finished, took 76.119s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.999 took: 4.03s  Val. loss: 0.368  Val. score: 90.232%\n",
      "Epoch 2, 100% \t Train loss: 0.453 took: 3.62s  Val. loss: 0.303  Val. score: 91.456%\n",
      "Epoch 3, 100% \t Train loss: 0.390 took: 3.89s  Val. loss: 0.275  Val. score: 92.446%\n",
      "Epoch 4, 100% \t Train loss: 0.360 took: 5.46s  Val. loss: 0.262  Val. score: 92.878%\n",
      "Epoch 5, 100% \t Train loss: 0.329 took: 5.27s  Val. loss: 0.253  Val. score: 93.262%\n",
      "Epoch 6, 100% \t Train loss: 0.312 took: 5.27s  Val. loss: 0.233  Val. score: 93.700%\n",
      "Epoch 7, 100% \t Train loss: 0.299 took: 5.08s  Val. loss: 0.222  Val. score: 93.652%\n",
      "Epoch 8, 100% \t Train loss: 0.299 took: 4.77s  Val. loss: 0.229  Val. score: 93.568%\n",
      "Epoch 9, 100% \t Train loss: 0.280 took: 5.30s  Val. loss: 0.226  Val. score: 93.868%\n",
      "Epoch 10, 100% \t Train loss: 0.276 took: 5.30s  Val. loss: 0.236  Val. score: 93.406%\n",
      "Training finished, took 77.221s\n",
      "\n",
      "Parameters configuration 93 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.09925811684379246\n",
      "h_sizes \t [784, 172, 41]\n",
      "penalty \t 0.004059969509368143\n",
      "dropout \t 0.10349644510407358\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 94.1378 +/- 0.5484\n",
      "Time for evaluation: 229.7 s\n",
      "Estimated time to finish : 39.27 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.561 took: 6.44s  Val. loss: 0.229  Val. score: 93.280%\n",
      "Epoch 2, 100% \t Train loss: 0.198 took: 6.35s  Val. loss: 0.154  Val. score: 95.752%\n",
      "Epoch 3, 100% \t Train loss: 0.144 took: 6.73s  Val. loss: 0.132  Val. score: 96.364%\n",
      "Epoch 4, 100% \t Train loss: 0.112 took: 6.57s  Val. loss: 0.133  Val. score: 96.346%\n",
      "Epoch 5, 100% \t Train loss: 0.095 took: 6.74s  Val. loss: 0.133  Val. score: 96.598%\n",
      "Epoch 6, 100% \t Train loss: 0.080 took: 6.58s  Val. loss: 0.125  Val. score: 96.988%\n",
      "Epoch 7, 100% \t Train loss: 0.070 took: 6.96s  Val. loss: 0.120  Val. score: 96.964%\n",
      "Epoch 8, 100% \t Train loss: 0.061 took: 6.98s  Val. loss: 0.120  Val. score: 97.036%\n",
      "Epoch 9, 100% \t Train loss: 0.057 took: 6.94s  Val. loss: 0.113  Val. score: 97.042%\n",
      "Epoch 10, 100% \t Train loss: 0.052 took: 6.63s  Val. loss: 0.112  Val. score: 97.294%\n",
      "Training finished, took 107.994s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.524 took: 6.58s  Val. loss: 0.198  Val. score: 94.222%\n",
      "Epoch 2, 100% \t Train loss: 0.198 took: 6.38s  Val. loss: 0.152  Val. score: 95.686%\n",
      "Epoch 3, 100% \t Train loss: 0.141 took: 6.66s  Val. loss: 0.135  Val. score: 96.178%\n",
      "Epoch 4, 100% \t Train loss: 0.110 took: 6.61s  Val. loss: 0.127  Val. score: 96.430%\n",
      "Epoch 5, 100% \t Train loss: 0.098 took: 6.72s  Val. loss: 0.118  Val. score: 96.880%\n",
      "Epoch 6, 100% \t Train loss: 0.084 took: 6.57s  Val. loss: 0.127  Val. score: 96.736%\n",
      "Epoch 7, 100% \t Train loss: 0.063 took: 6.51s  Val. loss: 0.116  Val. score: 97.138%\n",
      "Epoch 8, 100% \t Train loss: 0.065 took: 6.83s  Val. loss: 0.123  Val. score: 97.012%\n",
      "Epoch 9, 100% \t Train loss: 0.053 took: 6.91s  Val. loss: 0.126  Val. score: 97.192%\n",
      "Epoch 10, 100% \t Train loss: 0.046 took: 6.99s  Val. loss: 0.131  Val. score: 97.204%\n",
      "Training finished, took 107.533s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.552 took: 6.07s  Val. loss: 0.207  Val. score: 93.520%\n",
      "Epoch 2, 100% \t Train loss: 0.204 took: 6.55s  Val. loss: 0.144  Val. score: 95.902%\n",
      "Epoch 3, 100% \t Train loss: 0.144 took: 6.17s  Val. loss: 0.134  Val. score: 96.052%\n",
      "Epoch 4, 100% \t Train loss: 0.117 took: 7.02s  Val. loss: 0.109  Val. score: 96.976%\n",
      "Epoch 5, 100% \t Train loss: 0.093 took: 6.52s  Val. loss: 0.115  Val. score: 96.880%\n",
      "Epoch 6, 100% \t Train loss: 0.081 took: 6.96s  Val. loss: 0.115  Val. score: 97.024%\n",
      "Epoch 7, 100% \t Train loss: 0.072 took: 6.86s  Val. loss: 0.102  Val. score: 97.420%\n",
      "Epoch 8, 100% \t Train loss: 0.064 took: 6.58s  Val. loss: 0.110  Val. score: 97.360%\n",
      "Epoch 9, 100% \t Train loss: 0.055 took: 6.78s  Val. loss: 0.102  Val. score: 97.492%\n",
      "Epoch 10, 100% \t Train loss: 0.048 took: 6.82s  Val. loss: 0.124  Val. score: 97.156%\n",
      "Training finished, took 107.097s\n",
      "\n",
      "Parameters configuration 94 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002927020939018547\n",
      "h_sizes \t [784, 334, 143, 54, 17]\n",
      "penalty \t 0.0025034804225486647\n",
      "dropout \t 0.07907552243823002\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.2179 +/- 0.0572\n",
      "Time for evaluation: 323.7 s\n",
      "Estimated time to finish : 33.65 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.490 took: 4.09s  Val. loss: 0.216  Val. score: 93.670%\n",
      "Epoch 2, 100% \t Train loss: 0.195 took: 4.27s  Val. loss: 0.172  Val. score: 94.774%\n",
      "Epoch 3, 100% \t Train loss: 0.154 took: 4.29s  Val. loss: 0.158  Val. score: 95.392%\n",
      "Epoch 4, 100% \t Train loss: 0.133 took: 3.91s  Val. loss: 0.154  Val. score: 95.698%\n",
      "Epoch 5, 100% \t Train loss: 0.118 took: 4.36s  Val. loss: 0.168  Val. score: 95.062%\n",
      "Epoch 6, 100% \t Train loss: 0.110 took: 3.92s  Val. loss: 0.142  Val. score: 96.028%\n",
      "Epoch 7, 100% \t Train loss: 0.103 took: 3.92s  Val. loss: 0.138  Val. score: 96.340%\n",
      "Epoch 8, 100% \t Train loss: 0.088 took: 4.14s  Val. loss: 0.127  Val. score: 96.508%\n",
      "Epoch 9, 100% \t Train loss: 0.080 took: 3.92s  Val. loss: 0.163  Val. score: 95.920%\n",
      "Epoch 10, 100% \t Train loss: 0.081 took: 4.31s  Val. loss: 0.170  Val. score: 95.764%\n",
      "Training finished, took 70.789s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.509 took: 4.36s  Val. loss: 0.256  Val. score: 92.620%\n",
      "Epoch 2, 100% \t Train loss: 0.208 took: 4.05s  Val. loss: 0.185  Val. score: 94.648%\n",
      "Epoch 3, 100% \t Train loss: 0.172 took: 4.34s  Val. loss: 0.184  Val. score: 94.816%\n",
      "Epoch 4, 100% \t Train loss: 0.145 took: 4.33s  Val. loss: 0.154  Val. score: 95.692%\n",
      "Epoch 5, 100% \t Train loss: 0.120 took: 4.20s  Val. loss: 0.174  Val. score: 95.188%\n",
      "Epoch 6, 100% \t Train loss: 0.119 took: 3.99s  Val. loss: 0.182  Val. score: 95.602%\n",
      "Epoch 7, 100% \t Train loss: 0.107 took: 4.33s  Val. loss: 0.146  Val. score: 96.166%\n",
      "Epoch 8, 100% \t Train loss: 0.093 took: 4.31s  Val. loss: 0.147  Val. score: 96.208%\n",
      "Epoch 9, 100% \t Train loss: 0.087 took: 4.25s  Val. loss: 0.155  Val. score: 96.100%\n",
      "Epoch 10, 100% \t Train loss: 0.082 took: 4.33s  Val. loss: 0.149  Val. score: 96.292%\n",
      "Training finished, took 72.231s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.509 took: 3.89s  Val. loss: 0.213  Val. score: 93.706%\n",
      "Epoch 2, 100% \t Train loss: 0.195 took: 3.91s  Val. loss: 0.184  Val. score: 94.474%\n",
      "Epoch 3, 100% \t Train loss: 0.161 took: 3.91s  Val. loss: 0.183  Val. score: 94.564%\n",
      "Epoch 4, 100% \t Train loss: 0.141 took: 4.28s  Val. loss: 0.177  Val. score: 94.900%\n",
      "Epoch 5, 100% \t Train loss: 0.121 took: 4.34s  Val. loss: 0.181  Val. score: 95.068%\n",
      "Epoch 6, 100% \t Train loss: 0.112 took: 4.33s  Val. loss: 0.197  Val. score: 94.990%\n",
      "Epoch 7, 100% \t Train loss: 0.102 took: 3.96s  Val. loss: 0.160  Val. score: 95.866%\n",
      "Epoch 8, 100% \t Train loss: 0.096 took: 4.32s  Val. loss: 0.154  Val. score: 95.878%\n",
      "Epoch 9, 100% \t Train loss: 0.086 took: 4.34s  Val. loss: 0.160  Val. score: 96.118%\n",
      "Epoch 10, 100% \t Train loss: 0.077 took: 3.92s  Val. loss: 0.170  Val. score: 95.866%\n",
      "Training finished, took 70.800s\n",
      "\n",
      "Parameters configuration 95 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.05715485829844656\n",
      "h_sizes \t [784, 191, 50]\n",
      "penalty \t 0.003621845053393744\n",
      "dropout \t 0.026030328043574524\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 95.9738 +/- 0.2287\n",
      "Time for evaluation: 214.9 s\n",
      "Estimated time to finish : 27.93 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 4.120 took: 13.81s  Val. loss: 1.893  Val. score: 24.391%\n",
      "Epoch 2, 100% \t Train loss: 1.785 took: 12.23s  Val. loss: 1.325  Val. score: 51.398%\n",
      "Epoch 3, 100% \t Train loss: 1.388 took: 12.51s  Val. loss: 1.246  Val. score: 57.530%\n",
      "Epoch 4, 100% \t Train loss: 1.241 took: 12.51s  Val. loss: 1.059  Val. score: 55.934%\n",
      "Epoch 5, 100% \t Train loss: 1.132 took: 14.19s  Val. loss: 1.072  Val. score: 62.961%\n",
      "Epoch 6, 100% \t Train loss: 1.056 took: 13.69s  Val. loss: 1.010  Val. score: 64.947%\n",
      "Epoch 7, 100% \t Train loss: 1.013 took: 14.92s  Val. loss: 0.915  Val. score: 66.621%\n",
      "Epoch 8, 100% \t Train loss: 0.977 took: 14.75s  Val. loss: 0.849  Val. score: 70.137%\n",
      "Epoch 9, 100% \t Train loss: 0.960 took: 14.40s  Val. loss: 0.846  Val. score: 71.895%\n",
      "Epoch 10, 100% \t Train loss: 0.935 took: 13.91s  Val. loss: 0.803  Val. score: 76.791%\n",
      "Training finished, took 208.925s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 6.098 took: 13.49s  Val. loss: 1.728  Val. score: 32.365%\n",
      "Epoch 2, 100% \t Train loss: 1.749 took: 13.62s  Val. loss: 1.449  Val. score: 47.948%\n",
      "Epoch 3, 100% \t Train loss: 1.496 took: 13.53s  Val. loss: 1.310  Val. score: 49.430%\n",
      "Epoch 4, 100% \t Train loss: 1.347 took: 13.50s  Val. loss: 1.267  Val. score: 50.156%\n",
      "Epoch 5, 100% \t Train loss: 1.264 took: 13.70s  Val. loss: 1.234  Val. score: 48.830%\n",
      "Epoch 6, 100% \t Train loss: 1.196 took: 13.83s  Val. loss: 1.076  Val. score: 50.288%\n",
      "Epoch 7, 100% \t Train loss: 1.166 took: 12.73s  Val. loss: 1.145  Val. score: 45.956%\n",
      "Epoch 8, 100% \t Train loss: 1.133 took: 12.34s  Val. loss: 1.309  Val. score: 49.208%\n",
      "Epoch 9, 100% \t Train loss: 1.101 took: 12.51s  Val. loss: 1.005  Val. score: 54.296%\n",
      "Epoch 10, 100% \t Train loss: 1.082 took: 12.59s  Val. loss: 1.039  Val. score: 53.684%\n",
      "Training finished, took 203.456s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 2.974 took: 12.26s  Val. loss: 1.699  Val. score: 28.585%\n",
      "Epoch 2, 100% \t Train loss: 1.557 took: 13.69s  Val. loss: 1.312  Val. score: 46.970%\n",
      "Epoch 3, 100% \t Train loss: 1.372 took: 12.66s  Val. loss: 1.252  Val. score: 44.156%\n",
      "Epoch 4, 100% \t Train loss: 1.276 took: 13.91s  Val. loss: 1.044  Val. score: 61.184%\n",
      "Epoch 5, 100% \t Train loss: 1.147 took: 14.05s  Val. loss: 0.934  Val. score: 63.915%\n",
      "Epoch 6, 100% \t Train loss: 1.065 took: 14.60s  Val. loss: 0.945  Val. score: 59.828%\n",
      "Epoch 7, 100% \t Train loss: 1.004 took: 15.87s  Val. loss: 0.979  Val. score: 58.946%\n",
      "Epoch 8, 100% \t Train loss: 0.984 took: 15.21s  Val. loss: 0.892  Val. score: 60.494%\n",
      "Epoch 9, 100% \t Train loss: 0.951 took: 14.64s  Val. loss: 0.893  Val. score: 67.779%\n",
      "Epoch 10, 100% \t Train loss: 0.906 took: 14.17s  Val. loss: 0.867  Val. score: 68.775%\n",
      "Training finished, took 212.557s\n",
      "\n",
      "Parameters configuration 96 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.06751393376714074\n",
      "h_sizes \t [784, 536, 364, 250, 176, 122, 95, 70, 50, 39, 27, 17]\n",
      "penalty \t 0.0001651487072777321\n",
      "dropout \t 0.2396328141209408\n",
      "optimizer \t <class 'torch.optim.adagrad.Adagrad'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 66.4167 +/- 9.5796\n",
      "Time for evaluation: 626.0 s\n",
      "Estimated time to finish : 22.55 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.529 took: 4.80s  Val. loss: 0.282  Val. score: 92.578%\n",
      "Epoch 2, 100% \t Train loss: 0.346 took: 5.36s  Val. loss: 0.241  Val. score: 93.652%\n",
      "Epoch 3, 100% \t Train loss: 0.350 took: 5.76s  Val. loss: 0.232  Val. score: 94.744%\n",
      "Epoch 4, 100% \t Train loss: 0.323 took: 6.41s  Val. loss: 0.233  Val. score: 94.900%\n",
      "Epoch 5, 100% \t Train loss: 0.291 took: 6.49s  Val. loss: 0.215  Val. score: 95.422%\n",
      "Epoch 6, 100% \t Train loss: 0.279 took: 7.06s  Val. loss: 0.210  Val. score: 95.104%\n",
      "Epoch 7, 100% \t Train loss: 0.268 took: 6.58s  Val. loss: 0.247  Val. score: 94.612%\n",
      "Epoch 8, 100% \t Train loss: 0.271 took: 6.59s  Val. loss: 0.224  Val. score: 95.230%\n",
      "Epoch 9, 100% \t Train loss: 0.293 took: 7.29s  Val. loss: 0.220  Val. score: 94.900%\n",
      "Epoch 10, 100% \t Train loss: 0.279 took: 7.41s  Val. loss: 0.198  Val. score: 95.248%\n",
      "Training finished, took 99.155s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.540 took: 5.33s  Val. loss: 0.258  Val. score: 93.148%\n",
      "Epoch 2, 100% \t Train loss: 0.354 took: 5.28s  Val. loss: 0.246  Val. score: 93.610%\n",
      "Epoch 3, 100% \t Train loss: 0.337 took: 5.89s  Val. loss: 0.226  Val. score: 95.002%\n",
      "Epoch 4, 100% \t Train loss: 0.316 took: 7.08s  Val. loss: 0.236  Val. score: 94.780%\n",
      "Epoch 5, 100% \t Train loss: 0.312 took: 7.19s  Val. loss: 0.230  Val. score: 94.846%\n",
      "Epoch 6, 100% \t Train loss: 0.285 took: 6.45s  Val. loss: 0.215  Val. score: 94.918%\n",
      "Epoch 7, 100% \t Train loss: 0.269 took: 6.57s  Val. loss: 0.250  Val. score: 95.146%\n",
      "Epoch 8, 100% \t Train loss: 0.282 took: 6.68s  Val. loss: 0.223  Val. score: 94.972%\n",
      "Epoch 9, 100% \t Train loss: 0.272 took: 7.19s  Val. loss: 0.208  Val. score: 95.248%\n",
      "Epoch 10, 100% \t Train loss: 0.283 took: 7.19s  Val. loss: 0.238  Val. score: 95.518%\n",
      "Training finished, took 100.406s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.556 took: 5.01s  Val. loss: 0.275  Val. score: 92.716%\n",
      "Epoch 2, 100% \t Train loss: 0.367 took: 4.90s  Val. loss: 0.239  Val. score: 94.012%\n",
      "Epoch 3, 100% \t Train loss: 0.323 took: 5.28s  Val. loss: 0.228  Val. score: 94.006%\n",
      "Epoch 4, 100% \t Train loss: 0.317 took: 6.57s  Val. loss: 0.221  Val. score: 94.750%\n",
      "Epoch 5, 100% \t Train loss: 0.278 took: 6.50s  Val. loss: 0.218  Val. score: 94.852%\n",
      "Epoch 6, 100% \t Train loss: 0.284 took: 6.52s  Val. loss: 0.221  Val. score: 94.978%\n",
      "Epoch 7, 100% \t Train loss: 0.302 took: 6.94s  Val. loss: 0.234  Val. score: 94.606%\n",
      "Epoch 8, 100% \t Train loss: 0.299 took: 7.07s  Val. loss: 0.221  Val. score: 95.182%\n",
      "Epoch 9, 100% \t Train loss: 0.276 took: 7.36s  Val. loss: 0.234  Val. score: 95.038%\n",
      "Epoch 10, 100% \t Train loss: 0.276 took: 6.98s  Val. loss: 0.205  Val. score: 95.116%\n",
      "Training finished, took 98.715s\n",
      "\n",
      "Parameters configuration 97 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.018052581152210583\n",
      "h_sizes \t [784, 274, 101, 33]\n",
      "penalty \t 0.0005598991518943194\n",
      "dropout \t 0.1875503947468227\n",
      "optimizer \t <class 'torch.optim.adamw.AdamW'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 95.2938 +/- 0.1673\n",
      "Time for evaluation: 299.3 s\n",
      "Estimated time to finish : 16.89 min \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.007 took: 10.77s  Val. loss: 0.495  Val. score: 84.837%\n",
      "Epoch 2, 100% \t Train loss: 0.352 took: 10.85s  Val. loss: 0.255  Val. score: 92.704%\n",
      "Epoch 3, 100% \t Train loss: 0.231 took: 11.76s  Val. loss: 0.208  Val. score: 94.006%\n",
      "Epoch 4, 100% \t Train loss: 0.168 took: 11.89s  Val. loss: 0.168  Val. score: 95.206%\n",
      "Epoch 5, 100% \t Train loss: 0.130 took: 10.90s  Val. loss: 0.150  Val. score: 95.794%\n",
      "Epoch 6, 100% \t Train loss: 0.106 took: 10.92s  Val. loss: 0.145  Val. score: 96.106%\n",
      "Epoch 7, 100% \t Train loss: 0.086 took: 10.93s  Val. loss: 0.154  Val. score: 95.710%\n",
      "Epoch 8, 100% \t Train loss: 0.070 took: 11.84s  Val. loss: 0.132  Val. score: 96.340%\n",
      "Epoch 9, 100% \t Train loss: 0.056 took: 11.21s  Val. loss: 0.152  Val. score: 95.938%\n",
      "Epoch 10, 100% \t Train loss: 0.043 took: 11.74s  Val. loss: 0.139  Val. score: 96.526%\n",
      "Training finished, took 167.029s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.217 took: 11.48s  Val. loss: 0.587  Val. score: 82.497%\n",
      "Epoch 2, 100% \t Train loss: 0.492 took: 10.89s  Val. loss: 0.355  Val. score: 90.214%\n",
      "Epoch 3, 100% \t Train loss: 0.320 took: 12.27s  Val. loss: 0.283  Val. score: 92.266%\n",
      "Epoch 4, 100% \t Train loss: 0.244 took: 10.92s  Val. loss: 0.226  Val. score: 93.880%\n",
      "Epoch 5, 100% \t Train loss: 0.189 took: 10.93s  Val. loss: 0.194  Val. score: 94.966%\n",
      "Epoch 6, 100% \t Train loss: 0.156 took: 12.14s  Val. loss: 0.175  Val. score: 95.392%\n",
      "Epoch 7, 100% \t Train loss: 0.124 took: 11.74s  Val. loss: 0.172  Val. score: 95.668%\n",
      "Epoch 8, 100% \t Train loss: 0.101 took: 12.23s  Val. loss: 0.165  Val. score: 95.776%\n",
      "Epoch 9, 100% \t Train loss: 0.082 took: 11.76s  Val. loss: 0.146  Val. score: 96.238%\n",
      "Epoch 10, 100% \t Train loss: 0.067 took: 10.92s  Val. loss: 0.161  Val. score: 96.160%\n",
      "Training finished, took 169.370s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.056 took: 11.71s  Val. loss: 0.552  Val. score: 83.661%\n",
      "Epoch 2, 100% \t Train loss: 0.380 took: 11.22s  Val. loss: 0.297  Val. score: 91.546%\n",
      "Epoch 3, 100% \t Train loss: 0.258 took: 11.94s  Val. loss: 0.242  Val. score: 93.298%\n",
      "Epoch 4, 100% \t Train loss: 0.192 took: 12.57s  Val. loss: 0.202  Val. score: 94.456%\n",
      "Epoch 5, 100% \t Train loss: 0.150 took: 12.33s  Val. loss: 0.188  Val. score: 94.912%\n",
      "Epoch 6, 100% \t Train loss: 0.119 took: 11.77s  Val. loss: 0.162  Val. score: 95.470%\n",
      "Epoch 7, 100% \t Train loss: 0.099 took: 12.16s  Val. loss: 0.172  Val. score: 95.380%\n",
      "Epoch 8, 100% \t Train loss: 0.082 took: 11.20s  Val. loss: 0.176  Val. score: 95.374%\n",
      "Epoch 9, 100% \t Train loss: 0.068 took: 11.91s  Val. loss: 0.152  Val. score: 96.154%\n",
      "Epoch 10, 100% \t Train loss: 0.056 took: 12.06s  Val. loss: 0.166  Val. score: 95.704%\n",
      "Training finished, took 172.910s\n",
      "\n",
      "Parameters configuration 98 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0019497130420817875\n",
      "h_sizes \t [784, 456, 248, 143, 86, 50, 29, 21]\n",
      "penalty \t 0.0004311325884649133\n",
      "dropout \t 0.006901273702664523\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 96.1298 +/- 0.3363\n",
      "Time for evaluation: 510.4 s\n",
      "Estimated time to finish : 11.32 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.696 took: 5.51s  Val. loss: 0.377  Val. score: 91.138%\n",
      "Epoch 2, 100% \t Train loss: 0.438 took: 6.36s  Val. loss: 0.280  Val. score: 93.358%\n",
      "Epoch 3, 100% \t Train loss: 0.434 took: 6.39s  Val. loss: 0.291  Val. score: 92.860%\n",
      "Epoch 4, 100% \t Train loss: 0.406 took: 6.63s  Val. loss: 0.295  Val. score: 93.628%\n",
      "Epoch 5, 100% \t Train loss: 0.445 took: 8.69s  Val. loss: 0.299  Val. score: 93.196%\n",
      "Epoch 6, 100% \t Train loss: 0.423 took: 8.88s  Val. loss: 0.289  Val. score: 94.132%\n",
      "Epoch 7, 100% \t Train loss: 0.493 took: 8.76s  Val. loss: 0.335  Val. score: 93.262%\n",
      "Epoch 8, 100% \t Train loss: 0.460 took: 8.91s  Val. loss: 0.312  Val. score: 92.710%\n",
      "Epoch 9, 100% \t Train loss: 0.526 took: 9.50s  Val. loss: 0.344  Val. score: 91.708%\n",
      "Epoch 10, 100% \t Train loss: 0.476 took: 9.76s  Val. loss: 0.258  Val. score: 94.024%\n",
      "Training finished, took 117.914s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.650 took: 6.29s  Val. loss: 0.337  Val. score: 91.858%\n",
      "Epoch 2, 100% \t Train loss: 0.433 took: 7.20s  Val. loss: 0.300  Val. score: 92.896%\n",
      "Epoch 3, 100% \t Train loss: 0.433 took: 6.88s  Val. loss: 0.283  Val. score: 93.604%\n",
      "Epoch 4, 100% \t Train loss: 0.461 took: 8.19s  Val. loss: 0.293  Val. score: 93.634%\n",
      "Epoch 5, 100% \t Train loss: 0.433 took: 8.25s  Val. loss: 0.323  Val. score: 93.370%\n",
      "Epoch 6, 100% \t Train loss: 0.442 took: 9.51s  Val. loss: 0.331  Val. score: 93.046%\n",
      "Epoch 7, 100% \t Train loss: 0.410 took: 8.66s  Val. loss: 0.266  Val. score: 94.210%\n",
      "Epoch 8, 100% \t Train loss: 0.383 took: 7.87s  Val. loss: 0.316  Val. score: 93.892%\n",
      "Epoch 9, 100% \t Train loss: 0.433 took: 9.72s  Val. loss: 0.316  Val. score: 93.778%\n",
      "Epoch 10, 100% \t Train loss: 0.447 took: 10.91s  Val. loss: 0.290  Val. score: 94.312%\n",
      "Training finished, took 122.045s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.619 took: 6.16s  Val. loss: 0.298  Val. score: 92.752%\n",
      "Epoch 2, 100% \t Train loss: 0.461 took: 6.41s  Val. loss: 0.298  Val. score: 92.296%\n",
      "Epoch 3, 100% \t Train loss: 0.419 took: 7.25s  Val. loss: 0.282  Val. score: 93.322%\n",
      "Epoch 4, 100% \t Train loss: 0.402 took: 7.32s  Val. loss: 0.253  Val. score: 94.336%\n",
      "Epoch 5, 100% \t Train loss: 0.396 took: 8.21s  Val. loss: 0.283  Val. score: 93.496%\n",
      "Epoch 6, 100% \t Train loss: 0.439 took: 8.15s  Val. loss: 0.310  Val. score: 93.682%\n",
      "Epoch 7, 100% \t Train loss: 0.438 took: 9.07s  Val. loss: 0.376  Val. score: 92.368%\n",
      "Epoch 8, 100% \t Train loss: 0.485 took: 10.56s  Val. loss: 0.344  Val. score: 93.196%\n",
      "Epoch 9, 100% \t Train loss: 0.459 took: 9.92s  Val. loss: 0.260  Val. score: 94.342%\n",
      "Epoch 10, 100% \t Train loss: 0.454 took: 9.35s  Val. loss: 0.368  Val. score: 92.254%\n",
      "Training finished, took 121.300s\n",
      "\n",
      "Parameters configuration 99 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.017747928705121752\n",
      "h_sizes \t [784, 323, 126, 59, 30]\n",
      "penalty \t 0.002256007969370328\n",
      "dropout \t 0.1867472496037631\n",
      "optimizer \t <class 'torch.optim.adam.Adam'>\n",
      "act \t \t <function leaky_relu at 0x7f4d34c8bcb0>\n",
      "===========================================================================\n",
      "Loss: 93.5297 +/- 0.9099\n",
      "Time for evaluation: 362.3 s\n",
      "Estimated time to finish : 5.66 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.436 took: 4.05s  Val. loss: 0.219  Val. score: 93.514%\n",
      "Epoch 2, 100% \t Train loss: 0.201 took: 4.35s  Val. loss: 0.157  Val. score: 94.930%\n",
      "Epoch 3, 100% \t Train loss: 0.143 took: 4.62s  Val. loss: 0.127  Val. score: 96.028%\n",
      "Epoch 4, 100% \t Train loss: 0.112 took: 4.58s  Val. loss: 0.111  Val. score: 96.532%\n",
      "Epoch 5, 100% \t Train loss: 0.086 took: 4.63s  Val. loss: 0.102  Val. score: 96.706%\n",
      "Epoch 6, 100% \t Train loss: 0.071 took: 4.61s  Val. loss: 0.098  Val. score: 96.976%\n",
      "Epoch 7, 100% \t Train loss: 0.060 took: 4.65s  Val. loss: 0.096  Val. score: 97.006%\n",
      "Epoch 8, 100% \t Train loss: 0.050 took: 4.43s  Val. loss: 0.089  Val. score: 97.342%\n",
      "Epoch 9, 100% \t Train loss: 0.041 took: 4.28s  Val. loss: 0.085  Val. score: 97.396%\n",
      "Epoch 10, 100% \t Train loss: 0.035 took: 4.46s  Val. loss: 0.093  Val. score: 97.366%\n",
      "Training finished, took 75.634s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.435 took: 4.42s  Val. loss: 0.234  Val. score: 92.956%\n",
      "Epoch 2, 100% \t Train loss: 0.212 took: 4.49s  Val. loss: 0.173  Val. score: 94.888%\n",
      "Epoch 3, 100% \t Train loss: 0.156 took: 4.53s  Val. loss: 0.134  Val. score: 95.944%\n",
      "Epoch 4, 100% \t Train loss: 0.117 took: 4.30s  Val. loss: 0.116  Val. score: 96.502%\n",
      "Epoch 5, 100% \t Train loss: 0.095 took: 4.64s  Val. loss: 0.110  Val. score: 96.670%\n",
      "Epoch 6, 100% \t Train loss: 0.079 took: 4.53s  Val. loss: 0.101  Val. score: 97.018%\n",
      "Epoch 7, 100% \t Train loss: 0.064 took: 4.71s  Val. loss: 0.096  Val. score: 97.222%\n",
      "Epoch 8, 100% \t Train loss: 0.055 took: 4.31s  Val. loss: 0.093  Val. score: 97.306%\n",
      "Epoch 9, 100% \t Train loss: 0.047 took: 4.51s  Val. loss: 0.087  Val. score: 97.492%\n",
      "Epoch 10, 100% \t Train loss: 0.039 took: 4.76s  Val. loss: 0.091  Val. score: 97.366%\n",
      "Training finished, took 76.285s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.443 took: 4.12s  Val. loss: 0.236  Val. score: 93.238%\n",
      "Epoch 2, 100% \t Train loss: 0.202 took: 4.49s  Val. loss: 0.180  Val. score: 94.642%\n",
      "Epoch 3, 100% \t Train loss: 0.145 took: 4.51s  Val. loss: 0.138  Val. score: 95.908%\n",
      "Epoch 4, 100% \t Train loss: 0.114 took: 4.23s  Val. loss: 0.125  Val. score: 96.226%\n",
      "Epoch 5, 100% \t Train loss: 0.091 took: 4.38s  Val. loss: 0.109  Val. score: 96.796%\n",
      "Epoch 6, 100% \t Train loss: 0.072 took: 4.60s  Val. loss: 0.105  Val. score: 96.916%\n",
      "Epoch 7, 100% \t Train loss: 0.062 took: 4.63s  Val. loss: 0.104  Val. score: 97.012%\n",
      "Epoch 8, 100% \t Train loss: 0.053 took: 4.62s  Val. loss: 0.097  Val. score: 97.132%\n",
      "Epoch 9, 100% \t Train loss: 0.044 took: 4.70s  Val. loss: 0.096  Val. score: 97.276%\n",
      "Epoch 10, 100% \t Train loss: 0.038 took: 4.62s  Val. loss: 0.097  Val. score: 97.360%\n",
      "Training finished, took 75.715s\n",
      "\n",
      "Parameters configuration 100 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 10\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004708918432683523\n",
      "h_sizes \t [784, 189, 49]\n",
      "penalty \t 0.0031423858284781903\n",
      "dropout \t 0.062829110179135\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f4d34c8b8c0>\n",
      "===========================================================================\n",
      "Loss: 97.3639 +/- 0.0028\n",
      "Time for evaluation: 228.7 s\n",
      "Estimated time to finish : 0.00 s \n",
      "\n",
      "CPU times: user 15h 27min 28s, sys: 8h 54min 58s, total: 1d 22min 27s\n",
      "Wall time: 9h 24min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scoring, deviations, _ = GridSearchCV(Net, x_training, y_training, list_of_dict, K_folds=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('HP_scoring', scoring) # to make sure of not losing the results of the grid search\n",
    "np.save('HP_deviations', deviations) \n",
    "np.save('dict_list', list_of_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results analysis before second grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = np.load('HP_scoring.npy')\n",
    "deviations = np.load('HP_deviations.npy')\n",
    "list_of_dict = np.load('dict_list.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer vs learning rate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = np.zeros(n_samples)\n",
    "optimizers = []\n",
    "opt_dict = {optim.AdamW:'AdamW', optim.Adam:'Adam', optim.Adamax:'Adamax', optim.Adagrad:'Adagrad'}\n",
    "colors_dict = {'AdamW':'b', 'Adam':'g', 'Adamax':'r', 'Adagrad':'c'}\n",
    "act_dict = {F.relu:'relu',F.leaky_relu:'leaky relu'}\n",
    "colors_dict2 = {'relu':'b', 'leaky relu':'r'}\n",
    "colors = []\n",
    "colors2 = []\n",
    "n_layers = []\n",
    "dropout = np.zeros(n_samples)\n",
    "penalty = np.zeros(n_samples)\n",
    "act = []\n",
    "for i in range(n_samples):\n",
    "    d = list_of_dict[i]\n",
    "    learning_rates[i] = d['lr']\n",
    "    dropout[i] = d['dropout']\n",
    "    penalty[i] = d['penalty']\n",
    "    n_layers.append(len(d['h_sizes'])-1)\n",
    "    optimizers.append(opt_dict[d['optimizer']])\n",
    "    colors.append(colors_dict[optimizers[-1]])\n",
    "    act.append(act_dict[d['act']])\n",
    "    colors2.append(colors_dict2[act[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_record = []\n",
    "for i in range(n_samples):\n",
    "    if optimizers[i] in label_record:\n",
    "        plt.scatter(learning_rates[i],scoring[i],c=colors[i])\n",
    "    else:\n",
    "        plt.scatter(learning_rates[i],scoring[i],c=colors[i], label = optimizers[i])\n",
    "        label_record.append(optimizers[i])\n",
    "plt.xlabel('Learning rate (logscale)', fontsize=16)\n",
    "plt.xlim(1e-3,1e-1)\n",
    "plt.ylabel('Cross entropy loss', fontsize=16)\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that Adamax is the most stable optimizer, hence in the second grid search we are going to use just that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_record = []\n",
    "for i in range(n_samples):\n",
    "    if optimizers[i] in label_record:\n",
    "        plt.scatter(n_layers[i],scoring[i],c=colors[i])\n",
    "    else:\n",
    "        plt.scatter(n_layers[i],scoring[i],c=colors[i], label = optimizers[i])\n",
    "        label_record.append(optimizers[i])\n",
    "plt.ylabel('Score', fontsize=16)\n",
    "plt.xlabel('Number of hidden layers', fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again here the majority of bad performances of Adam seems to be related also to the learning rate. In the next plot I try a visualization using both color and size of the markers to make sense of this situation and understand if that is really the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt0AAAJaCAYAAADzgvuSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzde3yU5Z3//9d1TzKTzOSIkBAwgIBQ5NSWqLjioR6qrd8u7ba1nmrrunVt7fe7uhbdb1fpLnW3W7E/7e72W9eua2s91a7b0m6t9YziFkrQoqCcVYKEhJjzaSaZ+/79cScKmEAOM3Pf98z7+XjwGBgm93wmM8m857o/13UZx3EQEREREZH0sbwuQEREREQk2yl0i4iIiIikmUK3iIiIiEiaKXSLiIiIiKSZQreIiIiISJrleV1AJkycONGZMWOG12WIiIiISJbbtGlTk+M4k468PidC94wZM6itrfW6DBERERHJcsaYt4e6Xu0lIiIiIiJpptAtIiIiIpJmCt0iIiIiImmm0C0iIiIikmYK3SIiIiIiaabQLSIiIiKSZgrdIiIiIiJpptAtIiIiIpJmCt0iIiIiImmm0C0iIiIikmYK3SIiIiIiaabQLSIiIiKSZgrdIiIiIiJpptAtIiIiIpJmCt0iIiIiImmm0C0iIiIikmYK3SIiIiIiaabQLSIiIiKSZnleFyAiIjmgvx8aG2H/fmhqgr4+SCYhFIL8fJg4EaZMgYoKyNNbk4hkH/1mExGR1LFt2LkTNm2C3/8e1q2DPXugsxMiETdgGwOO8/7XDP67rw/icSgqgpkzYdkyOO00WLIETjwRLJ2cFZHgUugWEZHx6eqCp56Cn/0MfvMbN3hblhu0Dw3XPT3un2Npb4c//hE2b4af/OT94110EVxyCZx3HsRi6Xs8IiJpoNAtIiKj5zjwzDNwxx3w/PMQDkNHR+rv49BjPvKIG+oTCTj7bFixAs45xx0pFxHxOYVuEREZubY2uPde+N733BHpzk73+ng8M/c/GMJ/9zt46SUoLYUbb4Q//3P37yIiPqUGORERObaeHvjud+H44+HWW90JkYOB2yudnfDOO3DLLW5d3/3uyNpXREQ8oNAtIiLDSybh3//dDbWrVrlBt7vb66oO193t1rVqlVvnv/+7W7eIiI8odIuIyNC2bYOPfASuvx6am/0Xto/U3e3Wef31bt3btnldkYjIexS6RUTkcMkkfOc78NGPwtat7uokQdLV5db90Y/CP/2TRr1FxBcUukVE5H0HDkBNDdx2m9sfbdteVzQ2tu3Wf9tt7uM5cMDrikQkxyl0i4iIa9MmWLDAHSX2eyvJSA2Oei9YAC+/7HU1IpLDFLpFRAQefhjOPBPefdfdGTKb9PW5j+uMM9y1vkVEPKDQLSKS6773PfiLv8ie0e3hdHfD1Ve7j1dEJMO0OY6IyCDHgbo6aGhw+4ETCXenxcJCqKyE6urs2/3wH/8R/uEfsj9wD+ruhpUr3c18vvlNr6sRkRyi0C0iuauxEdatgw0bYO1at/c3mXSD9pESCQiF3N7gM8+EU0+FZcugoiLzdafKHXfkVuAe1N3tPu5IxN3NUkQkAxS6RSS3OA688AKsXg1PP+0Gr87Ow1fpONquhuvXwx/+AEVF7mjpeefBihVuEA/SKPjDD8O3vpV7gXvQ4Ij31KlwySVeV5P1HMehLh6nIZGgx7ZJ2DZhy6LQsqgMh6mORDBB+vkRGQPjOI7XNaRdTU2NU1tb63UZIuKlri647z43bDc3u/9Oxe8/YyAWgwkT3PB91VXuv/1s0yb3Q0KuBu5DRaPuh7AlS7yuJKs0JhKsa2tjQ3s7a1tb2drdTdJxCA8RrBOOQ8gYFsRinFlayqklJSwrLaViqDNOIgFgjNnkOE7NB65X6BaRrPf88+5oZkdHeoNmNArFxe4KGWefnb77GY8DB9wWmXff9boS/zjuONiyBSZP9rqSQHMchxfa2li9dy9Pt7QQsSw6k0lGs9K7BRSFQsRtm/PKy1kxbRpnlpZqFFwCRaFboVsk93R2uluCP/TQ0VtGUq2wEC6/HO68021D8Ytk0t0oZuvW7FsWcDzy8mDhQti40e3bl1HpSia5r76e1XV1NPf10WXbpCJZGCBmWUzIz2dFdTVXVVUR0/MjATBc6PZ8yUBjzH8YYxqNMVsOuW6CMeYpY8zOgcvygeuNMeafjTG7jDGvGmM+6l3lIuJrL74Is2fDgw9mNnCDe38PPODe/4svZva+j2b1ati5U4H7SP39sGOHO7FURuX5lhZmrV/PzXv2sDcepzNFgRvAATptm73xODfv2cOs9et5vqUlRUcXyTzPQzfwY+DCI677G+AZx3FOBJ4Z+DfAJ4ATB/5cA/wwQzWKSJA89hhccIG79F9vrzc19Pa693/hhfCLX3hTw6G2bYNVq9xedvmgri73+7N9u9eVBEJnfz9/sW0bn3ztNRr6+ui2R9NEMnrdtk1DXx+ffO01vrJ9O539/Wm9P5F08Dx0O47zAtB8xNXLgZ8M/P0nwKcPuf5+x7UeKDPGVGWmUhEJhPvvhy9+MfOj28Pp7nZbTe6/37sakkm4+GLvPoAERW+v+31KJr2uxNdebG1l9oYNPNjYSE+aw/aRemybBxoamL1hAy+2tmb0vkXGy/PQPYxKx3HqB/5+AKgc+PtUoO6Q2+0buO4DjDHXGGNqjTG1Bw8eTF+lIuIfjz0G117rn8A9qKfHrcurEe/77oM9e1KzWks2s23YvRt+/GOvK/GtxxobueDVV2no66M3w4F7UO/AqPeFr77KL/T+LgHi19D9Hsed6TnqdwrHce5xHKfGcZyaSZMmpaEyEfGVF1+EK6/0X+Ae1NPjjnivW5f5+735ZrWVjFRXl/v98uvryEP3HzjAF7dty/jo9nC6bZvL33iD+w8c8LoUkRHxa+huGGwbGbhsHLj+HaD6kNsdP3CdiOSyzk74/Of9v+50T49bZyYD8D//s9pKRqu3F/7lX7yuwlcea2zk2h07fBO4B/XYNtfu2KERbwkEv4buXwFfGvj7l4A1h1x/5cAqJkuBtkPaUEQkV11/PbS1eV3FyLS1wQ03ZO6+brvN/x9G/KarC7797eC8ptLsxdZWrvTRCPeRegZGvNepx1t8zvPQbYx5GPg9MNcYs88YczXwT8D5xpidwHkD/wZ4HNgD7AJ+BHzNg5JFxE+ee85dhzsoo7k9Pe4yhs8/n/77+o//OHx7exk521ZvN+4qJZ/fujXtq5OMV49t8/mtW+nSJFjxMW2OIyLB1dUFs2a5S/MFTWWlO2kvXVvGOw4cfzzs35+e4+eCqVOhrg5yeDfEv9i2jQcbGz2bNDkahZbFFZWV3DN3rtelSI7z7eY4IiJjdt997tbuQdTRkd6R1Gefhfb29B0/F7S1uWdSctRzLS08FJDADe5o94MNDdpAR3xLoVtEgslx3B0Wg9qv3N3t1p+us42rV7sTTGXsOjvh9tu9rsITXckkl77+um/7uIfTbdtc8vrrajMRX1LoFpFgeuEFaD5yX62AaWpKzzbxXV2Z6RnPBc8/H9wPduNwX309HQENrh3JJD+u1xoL4j8K3SISTKtXB3/t6cHR7lR7+mkIh1N/3FwUDrvfzxziOA6r6+p8P3lyON22zeq6OnJhzpoEi0K3SIo0dDawau0q5v7rXKZ8bwpz/3Uuq9auoqEzgJP8/K6x0Q1CQX9TdRx46in38aTSI48Et9fdbzo64Gc/87qKjHqhrY3mvj6vyxiXpr4+XtSSj+IzCt2Sc5qa4Ikn3MtUueN/7mDG92fwnXXfYce7O6jvrGfHuzv4zrrvMOP7M7jjf+5I3Z2Ju6tjJOJ1FakRicBLL6XueLYNv/lN6o4n8Otf59TSi6v37qUr4I+327ZZvXev12WIHEahW3JKUxPMmwcXX+xepiJ43/E/d/Ct579Fb38vvf2HrxU9eN23nv8W3/v998Z/ZynQ1N3EE7ueoKl7lA9+vJ9WWltpuv3veOKLp9F0+9/BeDay2LAheyYJdna6jydVdu7MqYCYEbYNu3Z5XUVGNCYSPN3SQsDPIeEAT7W00JhIeF2KyHsUuiWl1mxbw+K7F7Nm25rD/j7Srxn2Nmtg8WL3cjxqayEed88Yx+Puv8ejobOBW5+7le6+o0+06u7r5pZnbzlqq0mqHuPRNHU3Me8H87j45xcz7wfzRh68x/tp5dlnaTpxKvOa/p6Lj1/PvKa/p2lqubvr31isXZs9wdK23ceTKps2gaVf7SllWe73NROam+Guu1I7SXgUH5jXtbURyZLXT8SyeEktJuIj2fGTJWkxlt/9K59fyasNr/K3T6/kqz93/77y+ZUj+pqj3W7lSnj1VfdyPGpq3LP5xcXuZc0Hlq4/QkMDrFoFc+fClCnu5apV723G8m+b/m3or+suh9//lXs5wGC4Z9M9w35fU/UYj6Z2fy3x/jgdiQ7ivV3UfvqUkaX8Qz+tdHSMaO3i5p5m7lp/Fy31b8Ly5dSWdRMPQUcBxENQOwV6v/0t3ty7+QNnCN4/yBDfLMeBLVtG+IgDYsuW1PWn//732XMWwC86O93vaybcfz/ccIN7OZzR/HIe4QfmNQcPsnjjRh44cIDOgK5acqTOZJINWqtefEShW4Z11N/9ra3wwx/C9de7lwOtAqvOXsWiykWc2r2K+gdXUWUtYtXZq456P4Nfc7TbrVoFixa5l+MxcSK88QY8+qh7OXHiUW58xx0wYwZ85zuwYwfU17uX3/mOe/0dd/Dgaw8OHRg3Xwm/u8u9HNDT38MDrz0w7Pc1VY/xaGqm1BDJi1AcLibSk6DmpTdHlvIHP61EIm743r79mF9y/+b7ueF3N/DKnTeBbVOzHyJJKO51L3vyoOIbDgvvO4VJqyfx7JvPDnGQIb5ZdXXZM8o9KJl0H9cwRtUStG5d8CeY+o3juN/XTLjySrjzTvdyOCMJ5oNGeHpv5Vtv8WpXF0+0tJDKn65PrVvHH6++mk9l6vt3CBtYq5HutGnu6+OuurrAT7rNJG0DL8NqbnZ/p195JUyYcMh/PPssLF/uBp/ubohG3dOva9bAOecc/WuD4o474FvfOvr6vNEof3dOiL+vGWKViO5yN3Avvh+i7++OVlVUxZar9nv6vWnqbqJ2fy01mw8ycdUdbspfvnwEX9jkjnBv3w5f+9oxi2/uaeb+zffzlw9so/AH7hmBpqg7wr2gAU76OnQcMheyOFxM44pGCvIKDjnIEC+kjRvh/PPd3QKzRWmpuxrLEKdemrqbmPuvc+lKdBELx9j+9e1MjB7l02Jp6Yh3olwzF1Z+DFY9B8uP/Tkqt5WU+Oc1N5pfsIMj3fG4+6F5mNGGNQcPsvLNN9nW1UUihdve//Hqq1m8Zw+bZ87kw/feO6ZjlLe3c+WTT3L/xz9OS0nJqL62KBSifdkyTAofU7o0JRLUdnRQU1zMxAAs+XlXXR037N7NnbNmcX11tdfl+Mpw28ArdMvotLZCdfXQp69jMXjnHfdNP8gaGtyR7N5hWh4O0ZtnmH69Q2PRyA4957g5bP96jqWbH/4QvvGNwz7AvFkGC78GXYe8r8TyY7z21dc4ofyEox/vhRfgT//UPwEoFUpL3RUyzjjjA//1xK4n+PQjnyaejBMJRfjlJb/kwtkXAu6P48MPu5+D5s6FSz/fT1llZMRnAhZfC69OhkUHYPPdKX1E2ceyIJGAUMjrSkavqckd4a6pGf70XkcHey+7jA99/ev0pHBloE+tW8e377uPW6+6il8vWzamY/zVf/4nd/3gB1x/3XV8/3OfG9XXFloW2045hWkFBce+sYeaEgnmbdxI3LaJWBZvnHyy74N3c18f9x84wJWTJzMhP39Mx1hz8CAr33qLVTNmsHzSpBRX6J3hQrfaS2R0Hn54+Dd0x4GHHspsPenwb8P0aQ8hZIX42ssjexMuzCvkioVXjLWq4Lr00g9M7KvqBHPE533LWFQVVx37eNm6GkE8PuTVNVNqiIVjREIRYuEYNVPc3+PPPut+/v3GN+D733cvT57eSDJ/5IFp1XNu4F517BZ9iURSv556pkycCBdeeNTAzSmn0PD224RT3Crw62XL+PC99445cAPc//GPc/1113H/xz8+6q8NGxOIFUxqOzqI2zYdySRx26Y2AOvsT8jP5/rq6jEHbni/rWnlW2+lrjAfU+iWkRmcuLN58/AtF93dbs9z0D344IhGuQHyE/1cunlko4oODtcsuWY8lQVTWZnbehSLua1IQEE4yppfFlAcKiSWH6M4XMwvL/nl4a0lw/H56M+YDTO6ODE6ke1f384vL/nle60lra1uR1Bn5/s/jt3dUNq9n874yN8Al293R7jVWjIC+fmwf7/XVaReMgkXXQRvvkmPMb6cD9BSUsL3P/e5UbeWDOrxyxyQo0yArSkuJmJZFIdCRCyLmuJiDwrMvFUzZrAoFmPVjBlel5IReV4XIAExOHHnc59zg9NQwTsahTlzMl9bqo1yhGEKRUTzk0ddNjCaH2XVx1ZRWVQ53uqC6Zxz3Najhx5yP5jNmcM5l11GYyxCfUc9VcVVIwvcAIWF6a3VK0d5XBOjE7lw9oXuqditGzlt2wxs+4OnYifShMPoelebi4u5/+Mf58onn2RCAEbXPGMMHDzodRWp9/jj8MorEI+TyMtzH2eWifsldA++j4K7CMEhJobDvHHyyWPr6Q7wJKrlkyZlVVvJsSh0y8gMzqRfvtxd73UoxsBll2WupnQpLnZXKhmhouOqWPWxa7jl2VsADlvNZDBIrvrYKm487cbU1hk0paXw1a8edlUBHLuH+0iVldnXYpJIQEXFMW82eCr2nZK36O7+4BtVPn0wym1N7v/4x7nh618H4PrHHhvV1+ac/n6vK0i97373vTk64f5+X450j5dv1h0ffB8dZmWaieEwFx533OiPe5QwL/6i0C0jM2HC+z/Ma9a4E9kc5/3VS4yBX/0q+JMoAS6/3F0WcCQtJoWFcMUV3HjajVyx8Aru2XQPD7z2AB3xDoojxVyx8AquWXJN7o5wp0N1dfZt/hIKuY/rGFbNmMHKt97itLoZ/HSIE04hkqMc54Yrn3zysEsZhuNkX+jevfuwTX8K4/GsHOku9Mvvi0PfR49mtCPXxwjz4h8K3TJ6Q7QKcNll2RG4Af7yL93QPRKOA9e4fdqVRZXcetat3HrWrWksTjAGFixI7dbpXluwYERhZ/BUbOuJ8ODXPvj/SUa/ssaEjg6NcI+EMZCX+rfMNWvcpfJHunJnSv3kJ25P94DKlha3xSSLJByHiqDNAxntyPVIw7x4zicf/yRwBlsF7rzTvcyWwA1u+8K3v/3epL9hRaNw223u7SWzzjore0a7Lct9PKMwxNxUolEIRfKJxrJvpNI30hBIM7ET7bD27IFDViupbmzEyrL2kpAxVKdwCcSMGMkGSem0Zg0sXjyy3YplVLLrI61IqnzjG+7I1i1un/ZhrSaD672uWgU35niftldOPRWKika8CYyvFRW5j2eUhjrh9MV5E8lfnl2hyTccB9Iw4WvVqvdHujNuYCfhQQZYsGcPG+bP96CY9FgQiwViY5zDpHnkOmHbHEgk2B+PU59I0JFM0u849DsOScch9Nvfkjd1Knm//jXFf/InVIXDTIlEmBwOE86WwQ6PKHSLDOfGG+GKK+Cee+CBB9xVTYqL3euuuUYj3F5atmzYda0DJx6H008f05d+YG7q/imHjVwCtBbAwwtg+3Ew9124dAuUjWxFTDlUXx9MmZLywy5f7kFbyaCysg9cddbmzWz80Iewg7gJ0BEs4KxsOgs7Cn22zevd3dR2dPBSWxuvd3VxIJGgqa+PHtumwLLINwYHsB3HvRz84i98ASuRwITDWNu2YYA+x6HXtim0LCbm5zM5HOakWIxlpaUsKS7mpGiU/GMF8pFs0pTlFLpFjqayEm691f0j/lFRAeedh/P445ggnw43xt3SfgQrl4xIRcVhH0aePQGWXwK2ge4wRBNw0/mw5hE4583U3GXOiMdT9zz5xcyZkJ+P09dHXUUFDeXlFPX0UJBI0J0FS3MWhUKcOsa1vYNmd08Pa1tbeamtjZfa2tjT20uBZWE7Dl1DLJnYfbRlFI15f9+AQ3r+Abpsm654nLfjcTZ0dPBoYyOWMfTaNjMLCji9tJTTS0s5u6yMmYe+hpqaYN489+coEoE33sjJ4K3QLSLBtGIFZu3a95Y7C6RoFFasSN3x8vLea7tpLXADd+ch7azdA/PJ/vRSeOd7UJolJwsyoqgomFvAD6ExkWBdWxsbli9nbVUVW6dPJ2lZhPv7cYyh2+dbpo9U3LY5PUtHupOOwx/a23ns4EEePXiQpr4+LDgsYPcdEZjT4dD7297Tw/aeHn7W2IgNTMzP5+JJk/jspEmcUltLKB5/fx+M2lp3l9Qco9AtIsF05plu72OQQ/fEiXDGGak95syZ8Mc/8vACd4R7KA7w0EL4am1q7zqrzZrldQXj4jgOL7S1sXrvXp5uaSFiWXQmk9jz5r13mx4P60s1A5xfXh68lUuOImHb/La5mYcbGnh8YFfL7mSS9Efr0RkM4nXxON/ft4976ushGuWTN93EpWvX8oktWwjX1KS3CJ9uGKTQLSLBZIw7SnzzzUPvkOp3g6PcqZ7ktWwZbN7M9uOc90a2j9Qdhh1j2IMjZxmT+g9HGdKVTHJffT2r6+po7uujy7ZxgHgGRkEP07QO3roPZlwFE5el/e6ilsWKadPSfj+ZUNfbyw/eeYe79+/HBjoy/dyNQz/v1/uzZct4/PTTsUIhrm1r47qiIqrTdVbFpxsGaRqqSJbpTSZ5s6eH3gD9Yh6zq65yJ7cGUUkJfPnLqT/uaadBURFz33V7uIcSTcCcd1N/11mrqAiWLk3pIZu6m3hi1xM0dTel7JhHrvT2fEsLs9av5+Y9e9gbj9M5ELg98dZ90LXHvcyAifn5nBHg1hLbcXiquZnzN2/mxA0buGvfPtqSyUAF7qF0GEObbXPXvn2cuGED52/ezFPNzdipnpvj9bKLwzBOkCchjVBNTY1TW6vzqJL9nm1p4dNbtmA7DsYY1ixYwDnl5V6XlV7PPw+f/CT0BOjkeDQKv/kNnH126o+9fTssWUJrsovqGw7v6R4US6ine1RiMXj5ZXddxhRo6m5i3g/mEe+PE8mL8MZ1bzAxOv5JZYsXu2t+z1/osPTR7TzU2EjP0SbMZVIGR7qjlsXtM2dy3fHHp/V+0qHPtvlRfT23vf02HckknQEP2SNRFApRHApxy/TpfKWq6tiroASAMWaT4zgf6KEJ/iMTEcAd4f70li10JJN02TadA//O+hHvs892d0QNyuSvwkK4/PL0BG6AE08Ey6Ks112lJJZ4f8Q7mnD//auHFbhHxbJg9uyUHa52fy3x/jgdiQ7i/XFq96dmUGjVKpg1v599l23jQT8FbnCDds29GWktKQmF+HJVVdrvJ5Vsx+GRhgamrV/PTbt3U59I5ETgBuhMJqlPJLhp926mr1/vTsTM0gFh9XSLZIn6ROIDv6jits0b3d18JKgtGCN1113w3/99+CZGflVa6p72TBfLgosugkce4Zw33RHthxa6Pdxz3oXLXlPgHrVPfSqlO6DWTKkhkueegojkRaiZkppJZf2nNbL//21zw7aP8nYmRS2Lh086iVhAVppxHIcnW1r43zt3Uj/QApSrumybrkSCq7dtY+Wbb/IvJ57I+eXlwdvc6CgUukWyRFU4/IFfTgnH4emWluwP3UVF8POfu0tQ+XlSZWGhW2cslt77ueQSt32lo4PSuFYpGZfiYvjCF1J6yInRibxx3RvU7q+lZkpNSlpL7j9wgGt37PDX6HaGFVoWl1dWcnZAWuo2dXTw1R07eL2ra8i1tHNVl22zo6eHP9u8mZOiUX540kksyZL3MLWXiGSJglCINQsWUBwKEbMsiiyLr02ZwtUBO806ZmecAT/9qRts/aiwEB580F1dJN3OOw8Sw8yilNFJJNzvZ4pNjE7kwtkXpiRwP9bYmPOBG6A0FOLOFLYBpUtvMskNO3dyxiuvUNvRocA9jC5jqO3q4oyXX+aGnTuzolVSEylFskzvQH9cVThMQUBOsabU/ffDtdf6a2JlYSHcfXdmZ9JfeCH87neZu79sdcEF8MQTXlcxrBdbW7nw1VePvsNgDii0LJ5ctIhlQ2xt7ycb2tu5eOtWmvr6cv45G43owPbzj86fH4hdRjWRUiRHFIRCnFBYmJuBG9xg66cR78ER7kwvXbVihdt2I2NXVAQ33eR1FcPq7O/n81u35nx4K7QsHpw3z9eBe3B0+2N//CN74/Gcf85Gq9u22RuP87E//jHQo94K3SKSfT77WXjySZg82btVTQoL3ft/8kn4zGcyf//nnONO2pSxKy2Fj33M6yqGdf2uXbQFNHykSqFlcfecOXxm0iSvSxnWpo4O5v7hD9xTX5/zLUDj1WPb3FNfz9w//IGXB7eUDxCFbskZaw4eZPHGjaw5eNDrUiQTli2DnTvhi19018XOpMJCuOIK2LUrMz3cQzEGbrwx8489W6Rrx9AUea6lhYcaG+nN4RA3OMJ95eTJXpcyrAcPHOCMV17R6HYKDY56n/HKKzzU0OB1OaOinm7JGYs3buTVri4WxWJsPvlkr8uRTHr+eXdFj46O9K5uEo26O00+8gicdVb67mek2trg+OOhs9PrSoKnqAj27fPl2YKuZJJZ69fT0NfndSmeKLQsSkMhfj5/vm9bSpKOw4rdu/m3/fsVttMoallcO2UKt8+aRchHH5DV0y05obmvj7vq6mge4s1o1YwZLIrFWDVjRuYLE2+dfTbs3g233w7TprlL9qXqF7Qx7vGmT3ePv2uXPwI3uIHxlls02j1asRjceqsvAzfAffX1gd8OfKwKLYsrKivZtXSpbwN3e38/52/erMCdAd22zd379/PxzZtp7+/3upxj0ki3ZJW76uq4Yfdu7pw1i+urq70uR/zIceDFF2H1anjqKYhE3JHg0bw5WpY7EhqPw/nnu20IZ5zhz1aEnh53tLu52etKguO449xRbh/ucuo4DjPWr2dvPLd2OIpaFiWhEI/Mn0hpEjcAACAASURBVM9ZPg3bALu6uzl382YaEgniOZCv/CJiDJXhMM8sXsxsHwwyDDfSrc1xJKsM9vb5ucdPPGYMnHmm+6exEV56CTZsgLVrYcsWSCYhHP7g1yUSEArBwoXu1556Kpx+OlRUZP4xjEZhIXz3u3D99dDV5XU1/heLud8vHwZugBfa2oY8k5eNDO8vFbeiupovV1X5eqfJje3tnLd5M53JZK5uCOqZuOOwLx5nyaZNPLN4MTU+XVZQI90iIoMcB+rq3DDe0+OOZEcibnCtqIDqan+OZh9LMgkf+Qhs3Tq6Ef1cY1mwYAG8/LL7AcuH/terr/J4czPZ+s5tAUWhEHHb5vzyclZMm8YZpaW+3wr8pbY2Lti8WRvd+EDMsnhy8WL+xMP2MI10i4gcizFuz/e0aV5XklqhEDz6KHz0o/7aNMhvCgrc75NPA3djIsHTLS1ZE7iLLQvLGBKOQ8gYFsZinFlayqklJZxeWkrFUGecfGhtayuf1AZFvtFl25y/eTOPL1rku1YkhW4RkVzwoQ/BypVw221qMxnK4OTJuXO9rmRY69raiFgW8SyYRBm1LG6eNo0LJkygIhymOhLx/Wj2UP6nrY2LFLh9p9u2uejVVz0f8T6SVi8REckVK1bAiSdCfr7XlfhLXh7MmQPf+IbXlRzVhvZ2OrMgcAP02jYdySQ1JSVMKygIZOCubW/n42op8a0u2+aCzZupbW/3upT3KHSLiOSKUAh++1t3LXF5X2kpPP64b9tKBq1tbc2aCXo2sLatzesyxmxwlRIFbn/rtG3O3byZXencn2EUFLpFRHLJ5Mnwu99p7e5B0Sg8+aT7ffExx3HYkmVtQVu6ugjiYg7t/f2cO7BKifhfZzLJeT5Zx1uhW0Qk1yxZAvfeq+Adjbrfh49+1OtKjqkuHs+aUe5BScehLmDrjScdh09v2UJDIpF1z0e2soEDiQSf2bKFpMcf8hS6RURy0SWXwKpVuRu8o1H49rfd70MANCQShAPY93w0YWNoTCS8LmNUbtq9mw3t7dr4JmDijsP69nZu3r3b0zoUukVEctWNN8Lf/m3uBe9o1H3cf/3XXlcyYj1Z2jscpMf1wIED3K2t3QOr27b54f79PNTQ4FkNCt0iIrnsm9/MrRHvwRHub37T60pGJZGlQS8ekMe1qaODa3bsUOAOuG7b5ivbt7Opo8OT+1foFhHJdTfemBs93oM93AEa4R4UtrLz7ToSgMfVm0zymS1bAjUqL8Prtm3+bMsWej2YCOv/V7uIiKTfJZfACy/Acce561Znk7w893G9+GJgeriPVHiscNrXBs1/cC8D5JiPywf+7549vNvX53UZkkJNfX188803M36//n+1i4hIZixZAlu2wMKF7g6N2SAWcx/Pli2BWKVkOJXhMInhJu/1tcHGL8Hrf+9eBiR4JxzH91u9b2hv59/q69VWkmW6bZu79+9nQ4Y3zlHoFhGR902eDBs3wi23QGEhBGAkckiW5baT3Hqr+3h8vg73sVRHIsO/YXdsB7sPkt3uZcf2TJY2ZiFjqI5EvC5jWL3JJJ/fulVtJVmqx7a5eOvWjLaZBPS3qYiIpE0oBH/zN/DyyzB/fvBGvWMxWLDArf/mm32/0+RIGGNYMNzzUDwXrHwIRd3L4rmZLW6MFsRivt7+XW0l2S/TbSYK3SIiMrQPfQheeQW+/323J9rvEy1jMbfO73/fDdxzgxE+R+qssrKh37TzS+Hkn8BJ33Iv80szXdqoWcBZpf6tc1NHh9pKcsBgm0mmVjNR6BYRkeGFQnD11VBXBytXQlGR/8J3NOrWtXIl7Nvn1psFo9tHOrWkhKLhHld+KUw4JRCBG6AoFOLUkhKvyxiS4zh8dccOehW4c0KvbfO1HTtwMrDhkUK3iIgcW2Gh26qxbx/cdhtMmeIGXS8VFcHUqfCP/+jWddNNUFDgbU1ptKy0NDDrWh9L3LY53cOR7jVrYPFi9/JIT7W08HpXF9pzMjc4wNauLp5uaUn7fSl0i4jIyJWWwg03uCH3l7+ECy6ASASKizNz/8XF7v1dcIGbmOrq4K/+yq0ry1WEw5xXXo5/u6BHxgDnl5d7unLJypXw6qvu5aFsx+HrO3fSlSUfbmRkumybr+/ciZ3m0W6FbhERGT1j4Nxz4Ykn4N134ac/hcsuc0NxLOZejneSnDGHH++yy+CBB6C52b3fc84Z/30EzIpp04gFdUWZAVHLYsW0aZ7WsGoVLFrkXh7q0cZG9sfj3hQlnnonHufnBw+m9T5MJnpYvFZTU+PU1tZ6XYaISPazbdi1CzZtgt//Htatg927obPTHaHOz38/KDvO4X/v64N43G0bmTULli2D005z1w+fPTu4yxemkOM4zFi/nr0BDobTIxHeXLrUdyuXJGyb6evXcyCR8LoU8UhVOMzbS5eSP87fNcaYTY7j1Bx5fZZtOyYiIp6yLJgzx/1z6aXvX59MQmMj7N8PBw9Cf7/7Jy/P/TNpktsnXlGRlZMgU8UYw4rqam7esyeQK2tELYsV1dW+C9wA/15fT0d/v9dliIfa+/v5UX09X5s6NS3HV+gWEZH0C4Wgqsr9I+NyVVUVt739diBDd0koxJd9+BqwHYfb3n5bvdw5rsu2+Ye33+baKVOw0vDBUOfqREREAiQWCvHISSdRGLB2m6hl8fBJJxHz4ZmMZ1pa6MjgzoTiX+3JJM+maSWTYP3EioiICGeXl3NZRQUFAQnehZbF5ZWVnF1e7nUpQ7q9ro5OhW4BOpNJbq+rS8uxg/HTKiIiIoe5a/ZsSn04ajyU0lCIO2fP9rqMIdX19rKurc3rMsRHXmhtZV9vb8qPq9AtGec4Dnt7e9nY3s4Lra083dzMC62tbGxvZ29vb0Z2hRIRCbqivDx+Pn8+UZ+PdhdaFj+fP9+XbSUAP3jnnbSvzyzB84N33kn5MTWRUtKuMZFgXVsbG9rbWdvaytbubpKOQ3iISQoJxyFkDAtiMc4sLeXUkhKWlZZ6uomCiIhfnVFWxk/nzeOKN96gx4eTAAstiwfnzWNZWZnXpQwpYdvcvX8/CYVuOUTccfjh/v38/QknEE7hh1qFbkkLx3F4oa2N1Xv38nRLCxHLojOZ5NC3hJ6jfP369nb+0N5OUShE3LY5r7ycFdOmcWZpqS+XmhIR8cqfTZrE3ckk1+7Y4avgXWhZ3D1nDp+ZNMnrUob12+Zm/PMdEz+xcV8fyydOTNkxFbolpbqSSe6rr2d1XR3NfX102TYOEB/DBBUbdxYxwOPNzaxtbWVCfj4rqqu5qqrKt6cqRUQy7crJk4lZFl/cts0XwXtwhNvPgRvg4YYGrVoiQ+pIJvlZQ0NKQ7e/G8EkUJ5vaWHW+vXcvGcPe+NxOgcCdyo4QKdtszce5+Y9e5i1fj3Pp2lJHxGRIPpsRQVPLlrE5Px8z1Y1KbQsJufn8+SiRb4P3EnH4fHmZq/LEB/7TXNzSvv9Fbpl3Dr7+/mLbdv45Guv0dDXl/YNG7ptm4a+Pj752mt8Zft2OrWDmIgIAMvKyth56ql8sbIy4xMsCy2LKyor2bV0qW97uA/1h/Z2r0sQn3NI7etEoVvG5cXWVmZv2MCDjY0ZP6XZY9s80NDA7A0beLG1NaP3LSLiV0V5edwzdy6/WbiQyvz8tIfv6MDo9m8XLeKeuXMD0/r32MGDdKu1RI6iJ5nksaamlB1PoVvG7LHGRi549VUa+vro9aiHsHdg1PvCV1/lFwcPelKDiIgfnV1ezu6lS7l95kymRSLELItUTUM3QMyymB6JcPvMmexaupSzAjC6fahHDx5EkVuOph94tLExZcdT6JYxuf/AAd9M2AG35eTyN97g/gMHvC5FRMQ3YqEQ1x1/PG8tXcrjixZx0YQJRIyhJBQadQCwgJJQiIgxXDRhAo8vWsSbS5dy3fHHB2Z0e9Dunh6a+vq8LkMC4GBfH7t7jrbe2shp9RIZtccaG323NBW47SbX7thBcSjk+wk8IiKZZIzhzLIyziwrozGR4KXBvRPa2tjS1XXMvRMWHrJ3wulZsHfC2tZWjTrKiFi4O1TOKiwc97EUumVUXmxt5UofjXAfqWdgxPvJ/PxATOQREcm0inCYz0ya9N7ghOM41MXjNCYS9Ng2cdsmYlkUWhYV4TDVkUjW7Y/wUlsbXT59HxN/6bJtXmpr46qqqnEfS6FbRqyzv5/Pb92a9tVJxqvHtvn81q3sWro0cKc8RUQyzRjDtIICphUUeF1KxrzU1uZ1CRIgL6VoBROdXZERu37XLtoCMtO7LZnkhl27vC5DRER8ps+22dPb63UZEiC7e3roT8GAo0K3jMhzLS081Njo2Solo9Vj2zzY0KANdERE5DCvd3d7tnmQBFOBZfF6d/e4j6NXnRxTVzLJpa+/7ts+7uF02zaXvP46XQEZnRcRkfSr7ehI6S6Dkv1sx6G2o2Pcx1HolmO6r76ejoAG145kkh/X13tdhoiI+IQmUcpoDU6mHC+Fbjkqx3FYXVfn+8mTw+m2bVbX1eFoVENERIDXu7q8LkECSO0lknYvtLXRHPANBJr6+nhRM9VFRAQ4kEh4XYIE0IF4fNzHUOiWo1q9d2/gT8N12zar9+71ugwREfEB7UQpY9HU3z/uYyh0y7AaEwmebmkh6I0ZDvBUSwuNGt0QEclpCdsO3KIA4g/dySSJcb52FLplWOva2ohkybJKEcvSZggiIjnuQCKh5QJlTAosi4ZxDt7plSfD2tDeTmdAVy05UmcyyYYU7SglIiLBtD8eJz/LtrSXzMgzhv0K3ZIua1tbyZaTcDawViPdIiI5rT6RCHzLpHinfpyTKRW6ZUiO47Aly5ZV2tLVpaUDRURyWEcyqY1xZExsxxn3niUK3TKkung8a0a5ByUdh7oULPkjIiLB1O84GumWMXFwXz/jodAtQ2pIJAhnWd9b2BitYCIiksP6HSfrBpQkMxS6JW2ydUmlbH1cIiJybEm1lsgYKXRL2ox3LUq/imfp4xIRkWMLZdkZXMkcg7uCyXj4OnQbY24wxmw1xmwxxjxsjCkwxpxgjNlgjNlljPmZMSbsdZ3ZKJyl65hmy7rjIiIyennG+Dv4iG9ldeg2xkwF/g9Q4zjOAiAEXAJ8F7jTcZzZQAtwtXdVZq/CLA2n2fq4RETk2PKMQWPdMhZZHboH5AGFxpg8IArUA+cA/znw/z8BPu1RbVmtMhwmkWW9bwnHoSKsEyMiIrmqOBTCUouJjIFlDMWh0PiOkaJaUs5xnHeAO4C9uGG7DdgEtDqO0z9ws33AVG8qzG7VkYh/XxxjFDKG6kjE6zJERMQjVeFwZke6m9ZB7dXupQRe1TgzhG9zlTGmHFgOnABMAWLAhaP4+muMMbXGmNqDBw+mqcrsZYxhQSzmdRkptSAWw2iEQ0QkZ02JROjL5Fnct+6Drj3upQRav+MwZZxny30buoHzgDcdxznoOE4f8F/A6UDZQLsJwPHAO0N9seM49ziOU+M4Ts2kSZMyU3GWOauszNcvkNGwgLNKS70uQ0REPDQ5HKY3k6tYzbgKYjPdSwm0XtumcpyhO+/YN/HMXmCpMSYK9ADnArXAc8DngEeALwFrPKswy51aUkJRKET7OLc99YOiUIhTS0q8LkNERDwUtiwKLYuuTAXvicvcPxJ40VBo3Cu7+XYg03GcDbgTJl8GXsOt9R7gZuCvjTG7gOOAez0rMsstKy3NmnWt47bN6RrpFhHJeRPz870uQQJoYt74x6n9PNKN4zjfAr51xNV7gFM8KCfnVITDnFdezuPNzQR5HRMDnF9erpVLRESEyeEwb8fjXpchATM5BQsx+HakW/xhxbRpxAK+tnXUslgxbZrXZYiIiA+clGWLBEhmnBSNjvsYwU5TknZnlpYyIeCn4ibm53OGWktERAQ4vbQ08INJklkxy0pJi6pedXJUxhhWVFcTDegvqKhlsaK6WksFiogIADXFxdogR0bFMoaa4uLxHycFtUiWu6qqaty7MHmlJBTiy1VVXpchIiI+cVI0mtllAyXwem1b7SWSGbFQiEdOOonCgI12Ry2Lh086iVhAPzCIiEjq5VsWMwsKvC5DAmRWYSF5KchAwUpR4pmzy8u5rKKCgoAE70LL4vLKSs4uL/e6FBER8RktISujcXqK9vkIRoISX7hr9mxKAzJqXBoKcefs2V6XISIiPqTJlDJSqZpECQrdMgpFeXn8fP5830+qLLQsfj5/vtpKRERkSGeVlaGubhkJG/f1kgr+Tk/iO2eUlfHTefN8299daFk8OG8ey1L0AyIiItlnVmGhdqaUEZmUn8/MwsKUHMufyUl87c8mTeLuOXN8F7wLLYu758zhM5MmeV2KiIj43MWTJqHzoXI0ecDFFRUpO56/UpMExpWTJ/PTD33IN8F7cIT7ysmTvS5FREQC4LOTJhFVG6IcRWEoxGcnTkzZ8fJSdiTJOZ+tqKAyHObzW7fSmkx6su5poWVRGgrx8/nz1VIiIiIjdkqKVqSQ7GVI7evEH8OUEljLysrYeeqpfLGyMuMTLAstiysqK9m1dKkCt4iIjErIGD45YYLXZYiPXTRhQkp3L1XolnErysvjnrlz+c3ChVTm56c9fEcti8n5+fx20SLumTtXq5SIiMiYXFpZGdgdlyW9ikMhvlBZmdJjKnRLypxdXs7upUu5feZMpkUixCyLVH0+NLhrZU6PRLh95kx2LV2asiV8REQkN31iwgQFIRmShfv6SPUxRVImFgpx3fHH89bSpTy+aBEXTZhAxBhKQqFRv9gsoCQUImIMF02YwOOLFvHm0qVcd/zxGt0WEZFxC1sW106ZQjiFLQQSfBFj+OqUKYRTfOZeEyklLYwxnFlWxpllZTQmErzU1saG9nbWtrWxpauLpOMM+Usu4TiEjGFhLMaZpaWcWlLC6aWlVITDHjwKERHJdtdNncpd+/Z5XYb4zHVTp6b8mArdknYV4TCfmTTpvfWzHcehLh6nMZGgx7aJ2zYRy6LQsqgIh6mORDAadRARkQyoLijgjLIynm5p8boU8Ykzy8o4vqAg5cdV6JaMM8YwraCAaWl4QYuIiIzWTdXVrG9vpzOZ9LoU8VhRKMRN1dVpObZ6ukVERCSnnVterlVMBHDnkp1TXp6WYyt0i4iISE6zjOGW6dOJ+WSXZfFGzLL42+nTU7o296H06hIREZGc95WqKorz1HWby0ry8vhKVVXajq/QLSIiIjkv37K4c9YsijTanZOKLIs7Z88mP43Pv15ZIiIiIsDFFRVURSJelyEemBKJ8PmBVdbSRaFbREREBLe3+19PPFG93TkmZln864knpq2Xe5BeVSIiIiIDzi8v56RYDO0WkRsMMD8W47w0rVhyKIVuERERkQHGGH44Zw4FGu3OCQWWxf+bMycjm/LpFSUiIiJyiCXFxfxlVRVRBe+sFrUsrp0yhSXFxRm5P72aRERERI7wnZkzmZif73UZkkYT8/P5xxNOyNj9KXSLiIiIHKEgFOLR+fMp1Gh3Viq0LH4+fz4FGdyJVK8kERERkSGcWlKiNpMsNNhWckpJSUbvV68iERERkWGozST7ZLqtZJBCt4iIiMgwCkIh/mvBArWZZImoZfGLBQsy2lYySK8gERERkaNYUlzMj+bMUZtJwEUtix/NnctHM7RayZH06hERERE5hssnT+baKVMUvAMqall8dcoULqus9KyGPM/uWURExEdaW+Hhh2H7dpg7Fy69FMrKvK5K/OT2WbP4Y2cnL7W1EXccr8uREYoYw2klJdw+a5andSh0i4hIznv2WVi+HGwburshGoWbboI1a+Ccc7yuTvwiZAy/WLCAhRs3si8ex/a6IDkmC5gcDvNfCxZgZWDXyWPVIiIikrNaW93A3dnpBm5wLzs74U//FNravK1P/KUkL49nFi+myIOJeDJ6RaEQz3z4w5TkeT/OrNAtIiI57eGH3RHuoTgOPPRQZusR/5sdjfLM4sXE1N/ta0WWxbMf/jCzCgu9LgVQ6BYRkRy3ffv7I9xH6u6GHTsyW48EQ01JCU8qePtWzLJ4cvFilni0UslQ9EoREZGcNneu28M9lGgU5szJbD0SHH9SWspvFi3SiiY+E7UsHl+0iNNKS70u5TB6lYiISE679FIYLjMZA5ddltl6JFjOKivjKY14+0aRZfHU4sWc6cOlh/QKERGRnFZW5q5SEou9P+Idjbr//tWvwGeDZeJDf1JayvMf/jAloZCClUcsoCQU4rkPf5g/8ekPrfdTOUVERDx2zjnwzjvupMkdO9yWkssuU+CWkaspKWHTkiWcu3kzDYmE1vHOoIgxTA6HecZHkyaHYpwceFHU1NQ4tbW1XpchIiIiWa69v59Pb9nChvZ2uodbFkdSJmpZLC0p4RcLFvhiWUAAY8wmx3FqjrxeZ0FEREREUqQkL4+nFi/WlvEZMLi1+5OLF/smcB+NXg0iIiIiKRQyhu/Nns2P5s5V8E6TfOBHc+dyx+zZhDzeaXKk9EoQERERSYPLKit54SMfYVokovCdYuX5+VxaUeF1GaOiV4CIiIhImiwpLmb7Kafwl1OmUKjgnTLdySTPtbZ6Xcao6NkXERERSaOCUIj/b/Zsnvvwh5kWiSh8pUCnbXP73r1elzEqet5FREREMuDUkhJeXrKEYHQg+9/zra10J5NelzFiCt0iIiIiGbKuvZ1oKOR1GVkhbFk83dLidRkjptAtIiIikiGPNDTQEaDRWT/rSCb5WWOj12WMmEK3iIiISAbYjsNvmpu9LiOr/Prdd7EDstGjQreIiIhIBuzs6QlMQAwK23HY1dPjdRkjotAtIiIikgGbOjqwArKRS1BYxrCpo8PrMkZEoVtEREQkA37f1kan+rlTqjOZ5Pft7V6XMSIK3SIiIiIZsK6tDTWXpJaD+30NAoVuERERkQzY09vrdQlZabd6ukVEREQEoN+21VqSJp3JJMkATFBV6BYRERFJs8a+PiKWYlc6RCyLxkTC6zKOSc++iIiISJrtj8fJ18olaZFvDPsVukVERESkqa8PRe70MMBBhW4RERER6XMcrVySRv3q6RYRERGRIEz0CyoHhW4RERERAULq504bA+QF4Pur0C0iIiKSZvnGqKc7jRS6RURERISJ+fnq6U4TB5gUDntdxjEpdIuIiIik2ZRIhL4A9B0HUZ/jMEWhW0REREQq8vOJ27bXZWSluG1TodAtIiIiInmWRVEo5HUZWakoFArERFWFbhEREZEMmFlQ4HUJWWlWYaHXJYyIQreIiIhIBiwrLdUKJilmgDNKS70uY0QUukVEREQy4LTSUrWYpFhRKMTSkhKvyxgRhW4RERGRDFhSXIytFUxSynYclhQXe13GiCh0i4iIiGTAiYWFWAGY8BckljHMVk+3iIiIiAyyjOGiCRO8LiOrfOq44wLzQUahW0RERCRDLqmspFh93SlRHArxhYoKr8sYMYVuERERkQw5r7ychDbJSYmEbXNeebnXZYyYQreIiIhIhsRCIc4uK/O6jKxwdlkZ0QCdNVDoFhEREcmgFdOmaenAcSqyLG6aNs3rMkZFoVtEREQkg84pK6NUoXtcSvPy+FjAzhgodIuIiIhkkDGGG6uriVqKYWMRtSxWVFdjArJqySA92yIiIiIZ9udVVYFZ6s5vLGP4clWV12WMmkK3iIiISIaV5uVxy7RpGu0epZhlcev06ZTm5XldyqjpmRYRERHxwP85/ngKFLpHpcCy+D9Tp3pdxpjomRYRERHxQGEoxHdnziSm4D0iMcviuzNnUhDQSah6lkVEREQ8clVVFTMLCxXIjsECZhUWBrKXe5CeYxERERGPhIzh0ZNOIqLR7qMqsCwenT+fUIAnn+oZFhEREfHQh2IxVk6frjaTYcQsi5UzZjA3GvW6lHHRsysiIiLisRXTpnFiNEp+gEdy0yEPmBON8o3qaq9LGTeFbhERERGPhYzhtwsXUhLQSYLpUpqXx+MLFwa6rWSQQreIiIiID0yORPjd4sVau3tA1LJ4cvFiJkciXpeSEnpWRURERHxiSXEx986dm/PBO2pZ3Dt3Lh8tLva6lJTx9TNqjCkzxvynMWabMeYNY8xpxpgJxpinjDE7By7Lva5TREREJFUuqaxk1Qkn5GzwjloW3z7hBC6prPS6lJQa97NpjAkbY6qMMRNSUdARvg884TjOh4DFwBvA3wDPOI5zIvDMwL9FREREssaN1dX87fTpORe8o5bF306fzl9nwcTJI435mTTGXGmM2Qh0AfuAOw75v88YYx4yxpwwjuOXAmcC9wI4jpNwHKcVWA78ZOBmPwE+Pdb7EBEREfGrb06fnlMj3oMj3N+cPt3rUtJiTM+iMebHwH3AEqAHOHJK6XbgEuBz46jtBOAgcJ8x5hVjzL8bY2JApeM49QO3OQAMee7BGHONMabWGFN78ODBcZQhIiIi4o0bq6tzosd7sIc7G0e4B436GTTGfAm4EtgM1AClR97GcZzXgTrgE+OoLQ/4KPBDx3E+gjuiflgrieM4DuAM9cWO49zjOE6N4zg1kyZNGkcZIiIiIt65pLKSFz7yEY7LyyPP62JSLA84Li+PFz/ykazr4T7SWD42fQXoAD7lOM7LA8F3KK8BM8ZaGG7Lyj7HcTYM/Ps/cUN4gzGmCmDgsnEc9yEiIiLie0uKi9ly8sksLCrKmp0rY5bFwqIitpx8clatUjKcsTxrC4H1juO8c4zbtQKTx3B8ABzHOQDUGWPmDlx1LvA68CvgSwPXfQlYM9b7EBEREQmKyZEIG5cs4Zbp0ym0LH8vQXcUFm47ya0zZrBxyZKsWYf7WMZyliIf6BzB7SqAvjEc/1D/G3jQGBMG9gBX4T5XjxpjrgbeBi4e532IiIiIBELIGP5m+nQ+PXEiF7/+Ont6euiyba/LGrGYZTGrsJBH589nbjTqdTkZNZbQvRdYcLQbGGNCwHxg91iKGdzBbAAAIABJREFUGuQ4zh9x+8aPdO54jisiIiISZB+KxXilpoYf19dz85499Ng23T4O3zHLosCy+O7MmXy5qiortnUfrbGcmfgdMNsYc8VRbvOXQBXwmzFVJSIiIiJHFTKGq6dMoe6001g5fTpFoZDvVjmJWhZFoRArZ8xg32mncfWUKTkZuGFsI92rcXup/8MYcxLuBEeAAmPMPODzwDeBd4F/SUmVIiIiIjKkwlCIm6dP59qpU/mP+nruqKujvb+fTg9Hvossi9K8PFZUV/PlqipK87Jt3ZXRM8MvPnKULzLmY8BjDLFcIO6a3e3Acsdx1o6vvNSoqalxamtrvS5DREREJO0cx+HZ1lZW793L862thC2LjmQy7fdbHAqRsG3OLivjpmnT+FhZGSYHR7WNMZscx/lAe/SYPnY4jvPcwCj3Dbhrcc8EQrhrc/8WWO04zr5x1CsiIiIiY2CM4dzycs4tL6crmeTplhYebWzk1+++i+04WMbQmUwOvdHJSO8DKAqF3jvep447ji9UVHBeeTnRUChVDyWrjGmkO2g00i0iIiK5znYcdvX0sKmjg9+3t7OurY3dPT10JpNELIt8Y97bYtyBw/7e5zjEbZuiUIhZhYUsKy3ltJISlhQXM7uwECsHR7SHk7KRbmPMfwEHHMf5WkoqExEREZG0s4xhTjTKnGiUSw/Z/THpODQmEuxPJDiYSNDvOPQ7DnnGkGcMk8JhpoTDVITDOTsJMhXG0l5yEfDLVBciIiIiIpkXMoaqSISqHNmkxitjWVfmHdwNckREREREZATGErr/GzjDGJNb2wiJiIiIiIzRWEL33+EuCfifxpjq1JYjIiIiIpJ9xtLTfQewFfhfwE5jzMvA20DPELd1HMe5ehz1iYiIiIgE3lhC95fhvaUdw8DSgT9DcQCFbhERERHJaWMJ3VelvAoRERERkSw26tDtOM5P0lGIiIiIiEi2GstEShERERERGYWxtJe8xxgTBpYAUweuegfY5DhOYryFiYiIiIhkizGFbmNMPu7SgdcBxUf8d6cx5l+Av3ccp2985YmIiIiIBN+oQ7cxJoS7Qc55gAHqgT0D/z0TqAL+L3CyMeaTjuMkU1SriIiIiEggjaWn+xrgfGAn8AnHcaY6jnPGwJ+pwCeAHbih/CupK1VEREREJJjGErqvBLqAcx3H+d2R/zlw3XlAN/Cl8ZUnIiIiIhJ8YwndJwHPOY7zznA3GPi/5wZuKyIiIiKS08YSuvNxR7GPpXvgtiIiIiIiOW0softt4IyB5QKHNPB/ZwzcVkREREQkp40ldP8Kd4WSnxhjyo78T2NMKfAfwGRgzfjKExEREREJvrGs0307cClwMfAJY8yvgTcBB3fJwE/hrt29b+C2IiIiIiI5bdSh23Gcd40x5wAPATXA5biBG9x1uwE2Apc5jtOckipFRERERAJsTDtSOo6z6/9v787DqyrvtY/fP0jIQJCgRCYpg4BEsWohTCKgpRYZIxUt2KLvaZFia5UeC1Y4Im3PEV7F4fgWOlibSEkAOQimcKhFQBQEErUjk4IDgkIYIsGQ+Xn/WDsxs0nYKzsk38917Wuz1/jbayWbez951rMkDTSzYZJGqPxt4F9zzr0RpPoAAACAC169QneJQLgmYAMAAAA1qM+FlAAAAADqoM6h28xuMbPNZnZjDcvcFFjmG+dXHgAAAHDhq09L9/+RdwHl7hqW2S0pQdLd9dg+AAAA0KTUJ3T3l/Q359zn1S3gnDsr6a+SBtW3MAAAAKCpqE/o7iTpcC2WOyzvBjkAAABAs1af0J0nqW0tlmsrqage2wcAAACalPqE7r2ShgVu914lM7tI0jBJB+pbGAAAANBU1Cd0r5F3m/fnzSyi4kwzayXpeUkxkv7n/MoDAAAALnz1uTnOEknfl5QoaY+ZLZe0LzDvCknfkdRd0nuSng1CjQAAAMAFrc6h2zmXY2Y3S1or6VpJcyssYvJGLplU0wgnAAAAQHNRr9vAO+c+MrP+kiZIGi2pmyQn6SNJf5a0zjnnglYlAAAAcAGrV+iWpECoXhd4AAAAAKhGvUN3WWb2LXl9vOMkfSxppXPuL8HYNgAAAHCh+9LRS8xslJntNrOHqpn/B0mrJE2VdLOkf5O00cz+K6iVAgAAABeo2gwZOFrerd/fqDjDzG6XdJe8iyffkfSEvADuJM0xs6HBKxUAAAC4MNWme8kQSSedc5VCt6QfB57/LGmsc65YksxsuqTfSPqepB3BKBQAAAC4UNWmpfsySW9XnBi46+Rgea3aC0oCd8Dzko5KoqUbAAAAzV5tQnecpMwqpicE1j/tnNtZdoZzrkjS3+UFdgAAAKBZq03odpLaVTH9a4HnSq3gAackhdenKAAAAKApqU3oPizpq2ZmFaaPkBfId1Wz3sWSjp9HbQAAAECTUJvQvVVSF0k/KplgZlfJGx5QktZXs9618vp1AwAAAM1abUL3U5IKJD1tZm+Y2Rp5I5K0lJRRsT+3JJlZgqSOknYHs1gAAADgQvSlods5t1/eWNzn5I1GkiipjaRPJE2rZrWZgedNQagRAAAAuKDV6jbwzrmVZrZV0jhJl0r6SNI659zZalbJkPQ3Sa8Go0gAAADgQlar0C1Jzrljkn5fy2WX1LsiAAAAoImpTZ9uAAAAAOeB0A0AAAD4jNANAAAA+IzQDQAAAPiM0A0AAAD4jNANAAAA+IzQDQAAAPiM0A0AAAD4jNANAAAA+IzQDQAAAPiM0A0AAAD4jNANAAAA+IzQDQAAAPiM0A0AAAD4jNANAAAA+IzQDQAAAPiM0A0AAAD4jNANAAAA+IzQDQAAAPiM0A0AAAD4jNANAAAA+IzQDQAAAPiM0A0AAAD4jNANAAAA+IzQDQAAAPiM0A0AAAD4jNANAAAA+IzQDQAAAPiM0A0AAAD4jNANAAAA+IzQDQAAAPiM0A0AAAD4jNANAAAA+IzQDQAAAPiM0A0AAAD4jNANAAAA+IzQDQAAAPiM0A0AAAD4jNANAAAA+IzQDQAAAPis0YduM2tpZu+Y2Z8Cr3uY2S4ze8/MVppZq1DXCAAAANSk0YduSfdL2lvm9SJJTznnekk6Lel7IakKAAAAqKVGHbrN7DJJYyU9F3htkm6StDqwSLKkxNBUBwAAANROow7dkp6WNFtSceD1JZKynHOFgdcfS+pS1Ypmdo+ZZZhZRmZmpv+VAgAAANVotKHbzMZJOu6ce6s+6zvnfuucG+CcGxAXFxfk6gAAAIDaCwt1ATW4XtIEMxsjKVLSRZKekRRrZmGB1u7LJB0JYY0AAADAl2q0Ld3OuZ855y5zznWX9G1Jm51zd0raIum2wGJ3SVoXohIBAACAWmm0obsGcyT9xMzek9fH+/chrgcAAACoUWPuXlLKObdV0tbAvw9JGhjKegAAAIC6uBBbugEAAIALCqEbAAAA8BmhGwAAAPAZoRsAAADwGaEbAAAA8BmhGwAAAPAZoRsAAADwGaEbAAAA8BmhGwAAAPAZoRsAAADwGaEbAAAA8BmhGwAAAPAZoRsAAADwGaEbAAAA8BmhGwAAAL5Yt2+drvn1NVq3b12oSwk5QjcAAAB88cjWR/T3Y3/XI1sfCXUpIUfoBgAAgC9+PvLn+mqHr+rnI38e6lJCLizUBQAAAKBpmth3oib2nRjqMhoFWroBAAAAnxG6AQAAAJ8RugEAAACfEboBAAAAnxG6AQAAAJ8RugEAAACfEboBAAAAnxG6AQAAAJ8RugEAAACfEboBAAAAnxG6AQAAAJ8RugEAAACfEboBAAAAnxG6AQAAAJ8RugEAAACfEboBAAAAnxG6AQAAAJ8RugEAAACfEboBAAAAnxG6AQAAAJ8RugEAAFCtdfvW6ZpfX6N1+9aFupQLGqEbAAAA1Xpk6yP6+7G/65Gtj4S6lAsaoRsAAADV+vnIn+urHb6qn4/8eahLuaCFhboAAAAANF4T+07UxL4TQ13GBY+WbgAAAMBnhG4AAADAZ4RuAAAAwGeEbgAAAMBnhG4AAADAZ4RuAAAAwGeEbgAAAMBnhG4AAADAZ4RuAAAAwGeEbgAAAMBnhG4AAADAZ4RuAAAAwGeEbgAAAMBnhG4AAADAZ4RuAAAAwGeEbgAAAMBnhG4AAADAZ4RuAAAAwGeEbgAAAMBnhG4AAADAZ4RuAAAAwGeEbgAAAMBnhG4AAADAZ4RuAAAAwGeEbgAAAMBnhG4AAADAZ4RuAAAAwGeEbgAAAMBnhG4AAADAZ4RuAACAZupEzgltfG+jTuScCHUpTV5YqAsAAABAwzuRc0Lxv4pXXmGeIsIitPeHe9U+un2oy2qyaOkGAABohjKOZiivME/Z+dnKK8xTxtGMUJfUpNHSDQAA0AwN6DxAEWERkqSIsAgN6DwgxBU1bYRuAACAZqh9dHvt/eFeZRzN0IDOA+ha4jNCNwAAQDPVPrq9RvcaHeoymgX6dAMAAAA+I3QDAAAAPiN0AwAAAD4jdAMAAAA+I3QDAAAAPiN0AwAAAD4jdAMAAAA+Y5zugDNnzuj48eMqKCgIdSnwWXh4uC699FJddNFFoS4FAAA0E4RueYH72LFj6tKli6KiomRmoS4JPnHO6dy5czpy5IgkEbwBAI3SiZwT3CmyiSF0Szp+/Li6dOmi6OjoUJcCn5mZoqOj1aVLFx09epTQDQBodE7knFD8r+KVV5iniLAI7f3hXoJ3E0CfbkkFBQWKiooKdRloQFFRUXQlAgA0ShlHM5RXmKfs/GzlFeYp42hGqEtCENDSHUCXkuaF8w0AaKwGdB6giLAISVJEWIQGdB4Q4ooQDIRuAACARqR9dHvt/eFe+nQ3MYRuAACARqZ9dHuN7jU61GUgiOjT3cRNnz5dZqZZs2bVep2RI0dq5MiR/hUFAADQzBC6m7Bz585p1apVkqSUlBQVFhaGuCIAAIDmqdGGbjPramZbzGyPmf3LzO4PTL/YzP5iZu8GntuFutbGau3atTpz5ozGjBmj48ePa+PGjaEuCQAAoFlqtKFbUqGkf3fOXSlpsKQfmtmVkh6S9KpzrrekVwOvG5esLGnpUumBB7znrKyQlJGcnKx27dopKSlJUVFRSk5OrrTMihUr1LdvX0VEROiqq67SSy+9VGmZ3NxczZo1S/369VNMTIw6duyo8ePHa9++feWWS0pKkplpx44duv3229WmTRt16NBBjz32mCRp48aNuu6669S6dWslJCTorbfeKrf+K6+8ojFjxqhTp06Kjo5Wv379tHjxYhUVFZUu85e//EUtWrTQ008/XW7dO++8UxdffLEOHz5c7+MFAADgl0Z7IaVz7hNJnwT+nW1meyV1kTRR0sjAYsmStkqaE4ISq7Z5szRxolRcLOXkSNHR0uzZ0rp10k03NVgZR48e1aZNmzR9+nTFxcUpMTFRa9as0enTp9WunffHgU2bNmnq1KkaO3asFi9erMzMTN1///0qKCjQFVdcUbqtvLw8ZWdna968eerUqZNOnTqlJUuWaMiQIdq7d686duxYbt933XWXpk2bpnvuuUcvvviiHn74YWVlZWnDhg2aO3euYmJiNHv2bCUmJurgwYNq1aqVJOnQoUP6+te/rvvuu0+RkZHKyMjQo48+qszMTC1cuFCS9I1vfEMPPvigHnroId1444265pprlJSUpJSUFK1evVpdu3ZtoCMMAABQB865Rv+Q1F3SR5IukpRVZrqVfV3do3///q4me/bsqXF+rZ0+7VxMjHNS5Ufr1s5lZQVnP7WwaNEiJ8nt2LHDOefcxo0bnSS3dOnS0mWGDh3q4uPjXVFRUem0N99800lyI0aMqHbbhYWF7vPPP3cxMTHuySefLJ3+hz/8wUlyCxYsKJ1WUFDg4uLiXFhYmDt06FDp9HXr1jlJbuvWrVXuo7i42BUUFLhf/vKXLjY2tlyN+fn5bsCAAS4+Pt698847LiYmxt1zzz21PzgBQTvvAAAAAZIyXBV5tDF3L5EkmVmMpP+R9IBz7kzZeYE35qpZ7x4zyzCzjMzMzAaoVFJqqtfCXRXnpJSUhqlDXteS3r17a8iQIZKkUaNGqXPnzqVdTIqKipSenq7bbrtNLVp88WMwePBgde/evdL2Vq1apUGDBik2NlZhYWFq3bq1zp49q/3791da9pZbbin9d1hYmHr16qU+ffqoR48epdP79u0rSeW6g3zyySeaMWOGunXrplatWik8PFzz5s1TVlaWjh8/XrpceHi4UlJSdPjwYQ0ePFhdu3bVU089Vc8jBQAA4L9GHbrNLFxe4F7unFsTmHzMzDoF5neSdLyqdZ1zv3XODXDODYiLi2uYgvfv97qUVCUnRzpwoEHKyMjI0J49ezRp0iRlZWUpKytL2dnZmjRpknbu3KkDBw7oxIkTKigoUIcOHSqtX3FaWlqa7rjjDsXHxyslJUW7du1Senq64uLilJubW2n9ku4rJVq1alXlNEml6xcXF2vChAn605/+pHnz5mnz5s1KT0/X3Llzyy1Xonfv3ho6dKjy8vJ0zz33KDo6uo5HCQAAoOE02j7d5t2n+/eS9jrnniwz62VJd0laGHheF4LyqnbFFV4f7qqCd3S01KdPg5RR0pq9aNEiLVq0qNL8F154QQsWLFB4eLiOHTtWaf6xY8fUrVu30tcrVqxQr169lJSUVDqtoKBAp06dClrNBw8eVEZGhpYtW6bvfOc7pdPT0tKqXP7555/XK6+8ov79+2vBggWaNGmSvvKVrwStHgAAgGBqzC3d10v6rqSbzOyvgccYeWH7G2b2rqRRgdeNw5QpUotqDqmZNHWq7yXk5+crNTVVgwYN0pYtWyo9rr32Wi1btkwtWrRQQkKCVq9ereIyXWJ27dqlDz74oNw2c3JyFBZW/vvZsmXLyo0qcr5yAl9UwsPDS6cVFBRo+fLllZY9cOCAfvzjH+vee+/V5s2bFRsbqzvvvDOo9QAAAARTo23pds69Ie9Cyap8vSFrqbXYWG+UkgkTvD7cJaOXmEkvvyy1bet7CevXr9fJkye1ePHiKu8qOWPGDM2cOVNbt27VggULdPPNNysxMVEzZsxQZmam5s+fX2k0ktGjR2vt2rWaNWuWxo0bp4yMDD377LOKjY0NWt3x8fHq1q2b5s6dq5YtWyo8PLzKftr5+fmaMmWKevToocWLFysyMlIpKSkaPny4fvnLX2r+/PlBqwkAACBYGnNL94XpppukI0ekJ57wxul+4gnvdQMNF5icnKw2bdpo8uTJVc6fMmVK6Zjdo0aN0vLly7V//35NmjRJjz/+uJ5++ulywwVK3q3k586dq5UrV2r8+PHasGGD0tLS1DaIXyJatWqltWvXqmPHjpo2bZp++MMfavjw4XroofLDsD/88MPas2ePUlNTFRkZKUkaMmSI5s+fr1/84hfasWNH0GoCAAAIFvMGAGnaBgwY4DIyMqqdv3fvXsXHxzdgRWgMOO8AACDYzOwt59yAitNp6QYAAAB8RugGAAAAfEboBgAAAHxG6AYAAAB8RugGAAAAfEboBgAAAHxG6AYAAAB8RugGAAAAfEboBgAAAHxG6AYAAAB8Ruhu4qZPny4z06xZs2q9zsiRIzVy5Ej/igIAAGhmCN1N2Llz57Rq1SpJUkpKigoLC0NcEQAAQPNE6G7C1q5dqzNnzmjMmDE6fvy4Nm7cGOqSAAAAmiVCtw+ycrO0NH2pHtj4gJamL1VWblZI6khOTla7du2UlJSkqKgoJScnV1pmxYoV6tu3ryIiInTVVVfppZdeqrRMbm6uZs2apX79+ikmJkYdO3bU+PHjtW/fvnLLJSUlycy0Y8cO3X777WrTpo06dOigxx57TJK0ceNGXXfddWrdurUSEhL01ltv+fPGAQAAGpmwUBfQ1Gx+f7MmrpioYlesnIIcRYdHa/am2Vr37XW6qcdNDVbH0aNHtWnTJk2fPl1xcXFKTEzUmjVrdPr0abVr106StGnTJk2dOlVjx47V4sWLlZmZqfvvv18FBQW64oorSreVl5en7OxszZs3T506ddKpU6e0ZMkSDRkyRHv37lXHjh3L7fuuu+7StGnTdM899+jFF1/Uww8/rKysLG3YsEFz585VTEyMZs+ercTERB08eFCtWrVqsOMCAAAQCoTuIMrKzdLEFRN1Nv9s6bScghxJ0oTUCTrykyNqG9m2QWr54x//qKKiIk2bNk2SF4RTU1O1cuVK/eAHP5AkzZ8/X3379tW6devUooX3R4++fftqyJAh5UJ327Zt9dxzz5W+Lioq0je/+U116NBBqamplS7S/O53v6v/+I//kORdlPnSSy/pySef1IEDB9SjRw9JUnFxsSZOnKg333xTI0aM8O9AAAAANAJ0Lwmi1H+kqtgVVznPySnlHykNVktycrJ69+6tIUOGSJJGjRqlzp07l3YxKSoqUnp6um677bbSwC1JgwcPVvfu3Sttb9WqVRo0aJBiY2MVFham1q1b6+zZs9q/f3+lZW+55ZbSf4eFhalXr17q06dPaeCWvHAvSYcPHw7K+wUAAGjMCN1BtP/k/tKW7YpyCnJ04OSBBqkjIyNDe/bs0aRJk5SVlaWsrCxlZ2dr0qRJ2rlzpw4cOKATJ06ooKBAHTp0qLR+xWlpaWm64447FB8fr5SUFO3atUvp6emKi4tTbm5upfVLuq+UaNWqVZXTJFW5PgAAQFND95IguuKSKxQdHl1l8I4Oj1afS/o0SB0lrdmLFi3SokWLKs1/4YUXtGDBAoWHh+vYsWOV5h87dkzdunUrfb1ixQr16tVLSUlJpdMKCgp06tSp4BcPAADQBNHSHURTrp6iFlb1ITWZpl491fca8vPzlZqaqkGDBmnLli2VHtdee62WLVumFi1aKCEhQatXr1Zx8RddYnbt2qUPPvig3DZzcnIUFlb++9myZctUVFTk+/sBAABoCmjpDqLYyFit+/Y6TUidICdXOnqJyfTylJcb5CLK9evX6+TJk1q8eHGVd5WcMWOGZs6cqa1bt2rBggW6+eablZiYqBkzZigzM1Pz58+vNBrJ6NGjtXbtWs2aNUvjxo1TRkaGnn32WcXGxvr+fgAAAJoCWrqD7KYeN+nIT47oiW88oQcGPaAnvvGEjvzkSIMNF5icnKw2bdpo8uTJVc6fMmVK6Zjdo0aN0vLly7V//35NmjRJjz/+uJ5++ulyI5dI3q3k586dq5UrV2r8+PHasGGD0tLS1LZtw4zEAgAAcKEz51yoa/DdgAEDXEZGRrXz9+7dq/j4+AasCI0B5x0AAASbmb3lnBtQcTrdSwAAAEIsKzdLqf9I1f6T+3XFJVdoytVTFBtJN86mhNANAAAkSftO7NPm9zfr9Q9f1+4ju3Xi3AkVFhcqrEWY2ke118AuA3VDtxt0U4+b1Ld931CX22Q0lrtZw1+EbgAAmrH8onyt3bdWi95YpL0n9kqSzhWeq7TcmbwzOpR1SOv2r5MkxbeP15xhc3Rr31sV3jK8QWtuShrT3azhLy6kBACgmUo/kq4+z/bR917+nt7+9G2dKzxXZeAuq2SZtz99W997+Xvq/WxvpR9Jb6CKm57GdDdr+IvQDQBAM1NQVKAHX3lQI5JG6MPPPizXyloXZ/PP6sPPPtSIpBF68JUHVVhcGORKm77Gcjdr+I/QDQBAM5JbmKsxKWO0NH3pl7Zq19a5wnNamr5UY5aPUW5hblC22VyU3M26Kg15N2v4jz7dAAA0EwVFBRqfOl7bP9oetMBdIqcwR2989IYmpE7Qhjs3KKwFEaM2plw9RbM3za5yXkPdzTqYuBi3evxGAADQTPzs1Z9px0c7gh64S5wrPKftH23XQ5se0hM3P+HLPpqaxnA36/PFxbi1w81xxE1SmivOO4DmZPeR3RqZNNK3wF1WVFiUXrv7NSV0SfB9X03FZ7mfKeUfKTpw8oD6XNJHU6+eekEE7vQj6Zr84mSdPHeyXtcGxLSK0SVRl+jFyS82mZ8Xbo4DAEAzlV+Ur9tfvL1BArfktXJOfnGy3r3v3WbRglnRwYNScrJ06JCUlSXFxko9e0p33SVdfnnV67SNbKuZCTODV8Opg0r+W7IOnT6krNwsxUbGqme7nrrrmrt0+cXVFFEHBUUF+tmrP9OS9CXn9XN1Nv+szuaf1YikEbo34V4tHLWwyXZN4kLKJm769OkyM82aNavW64wcOVIjR470r6gqzJgxQ1FRUcrPzy83feXKlTIz3X777ZXWmTx5suLi4tQc/loDAOdj7b61OnnuZIPu8+S5k1q7b22D7jOUioqktDRp2DCpXz9p4UJp+XJp/XrveeFCb/qwYd5yRUU+1FBcpLT9aRr2/DD1W9pPC99YqOX/WK71767X8n8s18I3Fqrf0n4a9vwwpe1PU1Fx/YrgYtz6IXQ3YefOndOqVaskSSkpKSosbLxDOQ0fPly5ubnavXt3uenbtm1TdHS0Xn/99UrrvP7667rhhhtkZg1VJgBckBa9sajewwLW19n8s1q0fVGD7jNUsrOlG2+Upk6Vtm+XcnOlgoLyyxQUeNO3b/eWu/FGb72g1ZCXrRuTb9TUNVO1/fB25RbmqqC4fBEFxQXKLczV9sPbNXXNVN2YfKOy8+pWRNmLcXMKqx7qsL7KXozbFIefJHQ3YWvXrtWZM2c0ZswYHT9+XBs3bgx1SdUaMWKEJC9kl7Vt2zZNnz5dn376qQ4c+GKs0v379+vYsWMaPnx4g9YJABeavZl7Sy9ua2h7Mvdo34l9Idl3Q8nOlgYOlHbvls7W8nvN2bPe8oMGfRG8s3KztDR9qR7Y+ICWpi9VVm5W7WvIy9bA5wZq95Hdtf5ydTb/rHYf2a1Bzw2qU/BuyItxmxpCtw+ysqSlS6UHHvCes2r/exNUycnJateunZKSkhQVFaXk5ORKy6xYsUJ9+/ZVRESErrrqKr300kuVlsnNzdWsWbPUr18/xcTEqGPHjhrs3iStAAAgAElEQVQ/frz27Sv/QZqUlCQz044dO3T77berTZs26tChgx577DFJ0saNG3XdddepdevWSkhI0FtvvVW67mWXXaYePXqUC92nTp3Sv/71L02dOlXdunUrN6/k3yVhHQBQtS0fbAnt/t8P7f79VFQkjR0rvf++lJdXt3Xz8rw+3+PHS395b7O6PtVVD/7lQT2z6xk9+JcH1fWprtr8/uYvr6G4SGNTxur90+8rr6huReQV5enQ6UManzq+Vl1Ndh/ZrSXpS4Lewl1RTmGOlqQvaXJ3OiV0B9nmzVLXrtKDD0rPPOM9d+3qTW9IR48e1aZNm3THHXcoLi5OiYmJSktL0+nTp0uX2bRpk6ZOnarevXtrzZo1+ulPf6r7779f+/fvL7etvLw8ZWdna968eVq/fr2WLl2q3NxcDRkyRJ9++mmlfd911126+uqr9dJLLykxMVEPP/yw5syZo5/+9KeaM2eOVq5cqc8//1yJiYnl+nAPHz5cO3bsUFGgo9vrr7+u6Ohofe1rX9MNN9xQKXS3bdtW11xzTbAPHQA0Ka9/+HqDXUBZ0bnCc3rjozdCsu+GsGGD9M47dQ/cJfLypIwMpwm/WKqz+WdL70yZU5Cjs/lnNSF1gj7L/azmGt7doHc+fafOgbu0hqI8vfXJW/rf9/63xuVCdTFuQVHBly98gSB0B1FWljRxovdno5zAl8CcHO/1hAnSZzX/3gTVH//4RxUVFWnatGmSvCCcl5enlStXli4zf/589e3bV+vWrdPYsWN19913a9WqVZWCdNu2bfXcc8/p29/+tkaMGKEJEyZo3bp1KiwsVGpqaqV9f/e739V//Md/aNSoUfrVr36luLg4Pfnkk3r55Zf17W9/W+PGjdPChQv18ccf68033yxdb8SIEcrOztY777wjyQvWgwcPVlhYWJWh+/rrr1eLFvwIA0BNdh/Z/eUL+WjnxztDun8/LVpU+y4l1fn8c1P+aw9UOc/JKeUfKTXXsP38++vXpv89F+OePxJLEKWmSsXFVc9zTkqp+fcmqJKTk9W7d28NGTJEkjRq1Ch17ty5tItJUVGR0tPTddttt5ULroMHD1b37t0rbW/VqlUaNGiQYmNjFRYWptatW+vs2bOVWsUl6ZZbbin9d1hYmHr16qU+ffqoR48epdP79vXuQnX48OHSaSX9s0vC9bZt23TDDTdIkoYNG6YPP/xQhw8f1ocffqiPPvqIriUAUAsnzp0I6f4bOqg1lIMHpTK9JM9L8ZGvSad6VpqeU5CjAycPVLFGoIZTB/XWJ8EpIuNohg6eOljtfC7GPX+E7iDav/+LFu6KcnKkA9X/3gRVRkaG9uzZo0mTJikrK0tZWVnKzs7WpEmTtHPnTh04cEAnTpxQQUGBOnToUGn9itPS0tJ0xx13KD4+XikpKdq1a5fS09MVFxen3NzKw/q0a9eu3OtWrVpVOU1SufUvv/xydenSRdu2bdPZs2f1zjvvlIbu+Ph4XXLJJXrttddKQzkXUQLAlwv1KBAVR9BoKpKTgzjsn2sh/e27lSZHh0erzyV9qq/hb8n1HvavoqLiIr3wtxeqnMfFuMHRNEcfD5ErrpCio6sO3tHRUp/qf2+CqqQ1e9GiRVq0qPI3xBdeeEELFixQeHi4jh07Vmn+sWPH1K1bt9LXK1asUK9evZSUlFQ6raCgQKdOnQp67cOHD9crr7yiN954Qy1atNDgwYMlSWamYcOGadu2bXLOKTo6Wv379w/6/gGgqQn1jUbCWzTNm+McOlR5WMB6K4qQTldu6TaZpl49tfoaTh8K2peaguICHco6VOW8xnAxbt/2fUNaQzDQ0h1EU6ZI1XUxNvPG5fRbfn6+UlNTNWjQIG3ZsqXS49prr9WyZcvUokULJSQkaPXq1Sou0ydm165d+uCDD8ptMycnR2Fh5T+0ly1bVnrBYzANHz5cJ0+e1NKlS/W1r31N0dHRpfNKQve2bds0dOhQhYc3zQ9yAAim9lHtQ7r/S6IuCen+/RLskcla5rVXdLj3f150eLRah7fWy1NervFW8HUZVrA2ss5VvT0uxg0OWrqDKDZWWrfOu2jSOa/FOzraC9wvvyy1rf73JmjWr1+vkydPavHixVXeVXLGjBmaOXOmtm7dqgULFujmm29WYmKiZsyYoczMTM2fP18dO3Yst87o0aO1du1azZo1S+PGjVNGRoaeffZZxcbGBr3+ki4jaWlp+vd///dy82644Qb99Kc/lSR95zvfCfq+AaApGthlYLUtmA1h8GWDQ7ZvPwX7v8DbvjZKI77xhA6cPKA+l/TR1Kun1hi4JSk2MrhFxEZVvT0uxg0OQneQ3XSTdOSId9HkgQNel5KpUxsmcEte15I2bdpo8uTJVc6fMmWKfvKTnyg5OVlJSUlavny5Hn30UU2aNEm9evXS008/rWeeeabcOtOnT9fhw4f1/PPP6ze/+Y0SEhKUlpamW2+9Nej1X3nllYqLi1NmZmZpf+4SJS3fOTk59OcGgFq6odsNWrd/XUhaKqPCojTsK8MafL8NoWdPKTw8OF1MwsOlK3q30syEmXWroV1PhbcID0oXk/AW4eoZW7mLi8TFuMFizrlQ1+C7AQMGuIyMjGrn7927V/Hx8Q1YERoDzjuA5mBv5l71/23/kIXut2e83ST641Z08KDUr593a/fzFRkp/fOf0uWX17GGUwfVb2k/5RaefxGRYZH658x/6vKLKxfR+r9al44hHgrR4dH6/OHPQ7b/ujKzt5xzAypOp083AABNWHxcvOLbh6aB4cq4K5tk4Ja8gBys6/kTEuoeuCXp8osvV/9OwSkioXNClYFb4mLcYCF0AwDQxM0ZNkcxrWIadJ8xrWI05/o5DbrPhjZnjhRznoc1JkaaPfs8arj+/M9tTKsYzb6++iK4GDc4CN0AADRxt/a9tcGDyyVRlyixb2KD7rOhjRkjXXedFBFRv/UjIrzW8jL3lKt7Db3H6LqO1ymiZf2KiGgZof6d+uuWXtUXMbDLwPqWFxRN5WJcQjcAAE1ceMtwrZq8SlFhUQ2yv6iwKL04+UWFt2wa3QKq07KltH69d1FlXYN3RIS3Xlqat51619CipdZPXa+e7XrWOXhHtIxQz3Y9lTYlTS1bVF/EDd1uaLCfnYqa0sW4hG4AAJqBgV0G6t6EexUdFv3lC5+H6LBo3ZtwrxK6JPi6n8aiTRtp1y5p0KDadzWJiZEGD/bWa9MmCDVEtNGu7+/SoMsG1bqrSUyrGA2+bLB2fX+X2kTUXMSN3W88/yLPw409Qrv/YCF0AwDQTDz29cc09CtDfWu1jAqL0vVfuV4LRy30ZfuNVZs20ubNUmqqNGyYNxpJxfu3hYd704cN85Z79dXgBO7SGiLaaPO0zUr9VqqGfWWYIsMiK12AGN4iXJFhkRr2lWFK/VaqXp326pcGbomLcYOFcboBAGgmwluGK21KmiakTtD2j7YrpzB4w8BFh0Xr+q9cr5envBzy0S5CoWVLadw473HwoPTCC96t4rOyvBvp9OwpTZtWv1FKal1Di5Ya12ecxvUZp4OnDuqFv72gQ1mHlHUuS7FRseoZ21PTrplW7SglNZkzbI6+9/L3dDb/rA+VV62pXYzLON1ivObmivMOoLkqLC7UQ5se0pL0JUEZvzsqLEr3JtyrhaMWNsvA3RwUFBWo97O99eFnHzbYPru17aZ373v3grs2gHG6AQCAJG/c5SdufkKv3f2aurXtVu8h52Jaxahb227a9n+26YmbnyBwN2FcjHv+CN0AADRTCV0S9O597+r5Cc+rf6f+igqL+tJQVbJM/0799fyE5/Xufe9qQOdKjXpogrgY9/zwlbSJmz59up577jk98MADeuqpp2q1zsiRIyVJW7du9a8wn1zItQNAKIS3DNfkqyZr8lWTte/EPm15f4ve+OgN7fx4p06eO6mC4gKFtwjXJVGXaPBlgzXsK8N0Y48bm8zFbaibx77+mP527G/a/tH2oHRNqqgpX4xL6G7Czp07p1WrVkmSUlJS9PjjjyssjFMOAKha3/Z91bd9X81MmBnqUtBIcTFu/dG9pAlbu3atzpw5ozFjxuj48ePauHFjqEuqVkFBgZrDRb0AAFzoIsMiteHODZqZMDNofbyjwqI0M2GmNty5QZFhkUHZZmND6G7CkpOT1a5dOyUlJSkqKkrJycmVllmxYoX69u2riIgIXXXVVXrppZcqLZObm6tZs2apX79+iomJUceOHTV+/Hjt27ev0rKbNm3Sddddp8jISPXq1UvPPfec7r77bnXv3r10mQ8++EBmpiVLlmj27Nnq3LmzIiIilJWVpczMTM2YMUN9+vRRdHS0unbtqqlTp+rIkSP1qh0AAAQfF+PWXdN9ZyGWW1SkT/Lz1alVK0Wez/1d6+no0aPatGmTpk+frri4OCUmJmrNmjU6ffq02rVrJ8kLyFOnTtXYsWO1ePFiZWZm6v7771dBQYGuuOKK0m3l5eUpOztb8+bNU6dOnXTq1CktWbJEQ4YM0d69e9WxY0dJ0p49ezR27FgNHDhQK1asUH5+vn7xi1/os88+U4sWlb/f/ed//qcSEhL029/+VkVFRYqMjNRHH32kyMhIPfbYY4qLi9PRo0e1ePFiXX/99dq3b58iIyPrVDsAAPBPycW4a/et1aLti7Qnc48k1djfu6R1/Mq4KzXn+jlK7JvYpEYpqZZzrsk/+vfv72qyZ8+eGufX1aunTrk227a51q+95mK2bXOvnjoV1O3XxqJFi5wkt2PHDueccxs3bnSS3NKlS0uXGTp0qIuPj3dFRUWl0958800nyY0YMaLabRcWFrrPP//cxcTEuCeffLJ0+pQpU1z79u3d559/Xjrt6NGjLiIiwnXr1q102vvvv+8kueuuu84VFxfX+D4KCwvdRx995CS5NWvWnHftZQX7vAMA0Nztzdzrluxe4qaunup6Pt3TtX2srYv+z2jX9rG2rufTPd3U1VPdkt1L3N7MvaEu1TeSMlwVeZSW7iDLLSpS4j//qeyiotJpif/8p44PHdqgLd7Jycnq3bu3hgwZIkkaNWqUOnfurOTkZP3gBz9QUVGR0tPT9dBDD5VrhR48eHC5riAlVq1apcWLF2v//v367LPPSqfv37+/9N87d+7UmDFjFB39xVBCnTp10tChQ3Xo0KFK20xMTJSZVZq+dOlS/frXv9bBgwf1+eefV9pXXWsHAAANg4txq0ef7iD7JD9fxRUuCCx2Tp/k5zdYDRkZGdqzZ48mTZqkrKwsZWVlKTs7W5MmTdLOnTt14MABnThxQgUFBerQoUOl9StOS0tL0x133KH4+HilpKRo165dSk9PV1xcnHJzc0uX++STT3TppZd+6fZKdOrUqdK0Z599Vvfee69GjRqlNWvWaPfu3dq5c6ckle6rLrUDAAA0BrR0B1mnVq0qtd62MFOnVq0arIaSCyYXLVqkRYsWVZr/wgsvaMGCBQoPD9exY8cqzT927Ji6detW+nrFihXq1auXkpKSSqcVFBTo1KlT5dbr1KmTjh8/XuX2qlJVK/eKFSv09a9/XYsXLy6d9v7775dbpn379rWuHQAAoDGgpTvIIlu21Lp+/dSmZUu1btFCbVq21Np+/Rqsa0l+fr5SU1M1aNAgbdmypdLj2muv1bJly9SiRQslJCRo9erVKi4uLl1/165d+uCDD8ptMycnp9L43suWLVNRmS40kte9Y8OGDcrJ+WLMzk8++UTbt2+vdf05OTkKDy9/McUf/vCHcq9btmxZ69oBAAAaA1q6fXBTu3Y6PnRoSEYvWb9+vU6ePKnFixeX3p2xrBkzZmjmzJnaunWrFixYoJtvvlmJiYmaMWOGMjMzNX/+/NLRSEqMHj1aa9eu1axZszRu3DhlZGTo2WefVWxsbLnl5s2bp9WrV+ub3/ymHnzwQeXl5ekXv/iFOnToUOXoJVUZPXq0Fi1apP/6r//SwIEDtXnzZq1evbrScrWtHQAAoDGgpdsnkS1bqkdUVIMPF5icnKw2bdpo8uTJVc6fMmVK6Zjdo0aN0vLly7V//35NmjRJjz/+uJ5++ulKQ+5Nnz5dc+fO1cqVKzV+/Hht2LBBaWlpatu2bbnlrrzySq1fv17Z2dm6/fbb9dBDD+lHP/qR+vfvX2nZ6jzyyCOaMWOGnnrqKd166636+9//rj//+c+Vlqtt7QAAAI2BuWZwF8ABAwa4jIyMaufv3btX8fHxDVhR83H27Fn16tVLY8eO1e9///tQl1MO5x0AAASbmb3lnBtQcTrdSxBU9913n4YOHarOnTvr6NGjeuaZZ3T69Gndf//9oS4NAAAgZAjdCKrc3FzNmTNHx44dU6tWrTRw4EBt2rRJX/3qV0NdGgAAQMgQuhFUv/vd70JdAgAAQKPDhZQAAACAzwjdAAAAgM8I3QHNYRQXfIHzDQAAGhKhW1J4eLjOnTsX6jLQgM6dO1fpzpcAAAB+IXRLuvTSS3XkyBHl5OTQAtrEOeeUk5OjI0eO6NJLLw11OQAAoJlg9BJJF110kSTp6NGjKigoCHE18Ft4eLg6dOhQet4BAAD8RugOuOiiiwhhAAAA8AXdSwAAAACfEboBAAAAnxG6AQAAAJ8RugEAAACfEboBAAAAnxG6AQAAAJ9Zc7gZjJllSvrwPDfTVtJnIdxGfdZtL+lEPfeHmgXj56GxaGzvpaHr8XN/wdw2n0Eoq7H93p6PxvZe+Azyb1vN5TOom3MurtJU5xyPWjwk/TaU26jPupIyQn3cmuojGD8PjeXR2N5LQ9fj5/6CuW0+g3gE++ehsTwa23vhM8i/bTX3zyC6l9ReWoi3EYz9I3ia0vlobO+loevxc3/B3DafQSirKZ2PxvZe+Azyb1vN+jOoWXQvaa7MLMM5NyDUdQBonvgMAhBKje0ziJbupu23oS4AQLPGZxCAUGpUn0G0dAMAAAA+o6UbAAAA8BmhGwAAAPAZoRsAAADwGaEbAAAA8Bmhu5kys3gz+7WZrTazmaGuB0DzYmaJZvY7M1tpZjeHuh4AzYuZ9TSz35vZ6obaJ6H7AmRmz5vZcTP7Z4Xpo81sv5m9Z2YP1bQN59xe59wPJN0u6Xo/6wXQtATpM2itc266pB9IusPPegE0LUH6DDrknPuev5WWx5CBFyAzGy7prKQXnHP9AtNaSjog6RuSPpaULmmKpJaSHquwiX9zzh03swmSZkpa5pxLaaj6AVzYgvUZFFhvsaTlzrm3G6h8ABe4IH8GrXbO3dYQdYc1xE4QXM65bWbWvcLkgZLec84dkiQzWyFponPuMUnjqtnOy5JeNrP1kgjdAGolGJ9BZmaSFkr6XwI3gLoIVg5qaHQvaTq6SDpc5vXHgWlVMrORZvbfZvYbSRv8Lg5Ak1enzyBJ90kaJek2M/uBn4UBaBbqmoMuMbNfS7rOzH7md3ESLd3NlnNuq6StIS4DQDPlnPtvSf8d6joANE/OuZPyrilpMLR0Nx1HJHUt8/qywDQAaAh8BgEIpUb/GUTobjrSJfU2sx5m1krStyW9HOKaADQffAYBCKVG/xlE6L4AmVmqpDclXWFmH5vZ95xzhZJ+JOnPkvZKWuWc+1co6wTQNPEZBCCULtTPIIYMBAAAAHxGSzcAAADgM0I3AAAA4DNCNwAAAOAzQjcAAADgM0I3AAAA4DNCNwAAAOAzQjeASszsAzNzZjYy1LU0JDN7NPC+Hw11Lc2NmbU0s3+Y2YdmFlFhnjMzxretwMy6B47NB0Ha3qzA9sYHY3sAyiN0AwAkSWaWFAhdd4dg9zMl9ZP0qHMuLwT7h7RU0seSnjCz8FAXAzQ1hG4A+ML/kxQfeEYDMbMYSQskvS/phRCX02w553Il/V9JfSTNCHE5QJND6AaAAOfcCefcPufciVDX0szcJeliSUnOuaJQF9PMLZeUJ+nHZmahLgZoSgjdAILCPN82s1fM7ISZ5ZnZR2b2OzPrXs063zKz583sX2aWZWa5Zvaemf3KzLpWs87Wkv7mZjbczNYH9ldsZomBZUq7SZhZLzNLMbNjgZr2mdkcM6v0+Vddn+7Adlxgu23M7HEzez+wvSNmttTMLq7huNxjZu+Y2TkzyzSzNWZ2ddnt1uE4l63lEjP770At+Wa2tj7HtqRvsLzwK0l/KOlHXVV3k8B+fxnog33WzD43s7cDfYLr0y3h3sBznVu5zay9mS0KnNdzZnbGzHaa2b1mFlbNOvU6J4Gf781mdsrMCgI/d/8IHNPLq1g+PLCfLYF1Sn4n/mRmd1ZYtpuZ/Syw7OHAsqcCr6fW9bgEttnazGabWXrguJwL/Dw8at5fFypxzp2S9CdJvSWNqs9+AVStyg8kAKiLQNBaIWmSpHOSMiQdk9dH9/uSvmVmNzvnMiqsulJSrqQ9kjZJipB0rbwQdruZXe+cO1DNbidL+kFg3b9Iai+poMIy10p6RtIJSVskXSrpBkkLJV0m6b46vtW2krZL6iJpm6R/ShoWqGOgmQ12zlWs4TeSpksqlPSapExJAyTtkvR8HfdfVntJ6YGaXpd3zE+WmV+XY3tWUnLgvVweeI/vldlW6b/N7GpJGyV1ltf/d6u8BpxBkp6UNNbMxjjn8mvzJsyst6QrJb3nnPugdm+9dN1ekjZL6irpU0lpkqIl3SjpV5JuNbNxVfQRr/M5CXwRmy/vZ2yHpKOSYiV1l3dMX5d0sMzy7SStlzREXsvxdknH5R236+X9biwvs4vvSvpFYBv7AstfJu/ndWTgZ+vHdTg2l0n6s7xjmynpTXk/DwmB93GrmY10zp2uYvVNkr4laaK83y0AweCc48GDB49yD0kfSHKSRtZy+YWB5V+TdFmFeT8KzHtPUliFebdLiq4wLUxe+HCS/reKfW0NzHOS7qmmnqQyyzwqqUWZecMlFQUeXSus92jJOhWm311me+slxZSZ11nSR4F5d1ZYLzEw/bSkr5WZ3kLS42W2mVSHc1O2lj9LalPNcvU5tiXH7e5qthkl6VBgmYfKnk953UP+UtXx+5L3Mz2wzgs1LOO8/64qTd8dmLdKUmSZ6V0l7Q/Me+x8z4m8Lyw5krIl9amijt6SelSYtjawnR2SOleYFynplgrTEiRdVc22S36+BlWY1z0w/YMK0y2wXyfpWUlRFc7hspp+7iRdE5i/p7bnkQcPHl/+CHkBPHjwaHwP1SF0B8JWSSC5tJpl/hTY3vg61HBEXjBuU2H61sC2Xqlh3ZLwuFuSVTF/Q2D+tArTH60qNOqLoJstqWMV25sdmP98hembA9PnVbFOuKTDNYWfat5bSS35krrX8/xWd2xLjtvd1aw3MzB/ZTXzOwfqyqzquFezzq8C2/xZDctUCt3yWoCdpDOSLq5indFl5pcN5HU+J5LiAtP+Wsv3dG2ZfcfV5xxV2F7JF5PHK0zvrqpD9y2B6W+qzBfOMvNby/tLVIGkdlXMb1VyzMseOx48eJzfg+4lAM7XjfJaz9Y7545Xs8xrksbK+1N7WtkZZtZHXkDqJSlGX1xrEhb4dy9J71SxzTW1qG2Dc85VMX2fvGDSuRbbKOst59yn1WxPZbcX6E88NPAypeIKzrkCM1st6YE61lDibfcl3THO49hWZ0zg+cWqZjrnjprZu/K6NPSWVF3XoLIuDTyfrHGpykYEntOc1w+5Yi0bzewTSZ0k9Ze0vb7nxDmXad5Y2NeY2WJJv3PO7au4fhmjA88vO+cya/uGzCxS0jfltXrHyWthV+A9SN6oIrVRcp7+xzlXXHGmc+5zM8sILJcg6ZUK8/PN7Ky8n5lL5bW0AzhPhG4A56tn4HmsffkNTOJK/hEIQEvk9fmuaZSEi6qZ/mEtaqsuLJwJPEfWYhv13V57eaGpWF7raVVq8x6qU+26QTi21Sk51y/alw9sEafahe62geczNS5VWZfA8/s1LHNIXmAtWfZ8zsk0Sasl/UTST8wsU9JOeV18/uic+6zMst0CzzUF83LMbIi8bjKX1bBYbc9XyXl63Mwe/5Jl46qZfkZe6I4VoRsICkI3gPPVMvC8X14IqcmuMv++X96fzY/KCzI7JB13gYvezGyHvJbx6tLduVrUVqmV7zzVd3vVfRk5n/pqev/ne2yrU3Ku18u7OLUmtW25zgo81/ULQIkv+6JX1/WqPCfOudfNrIekcZJGymsxHydpvKRHAxcKl/zVoE41mVm0pJckdZD0e3k3qXlPUrZzrtjMbpYX7mt7vkrO02vyuorVpLovGSXno6oLLQHUA6EbwPkqaTH8h3Pu7jqsNznwPMM596cq5vc6r6pC76S8/s2t5F3YV1WLbHef9u3XsT0s6QpJS51z6+u5jYpKuiRdUsf1jgSee9awTMm8kmXP65w453LktUavkiQz6yTpKUl3yOubXtJ1paRl+Iqa3kAZw+UF7recc9+vYn5dz1fJ7+SLzrlf1XFdmVkrea3cktc/H0AQME43gPO1Sd4FWaPMLLYO65WMa13pz/xm9g1V/2fvC4Lzhg58M/BySsX5gWEWv+XT7ut7bEuG+auuQeZ/A8+Tq5lfH28Hnq+s43qvBZ7HB4bnK8fMvimva8lZSW9JwT8nzrlPJM0NvLymzKw/B54nmln7Wmyq2vMVUNdxus/3PJWciz3Ou0slgCAgdAM4L865Y/Ja+WIlvWxmfSsuE7hJx1Qz61Bmckl/15lW5kY1gZuM/NrPmhvQs4HnB83s2pKJgff7S0lf8Wm/9T22JS3C8dXM/628YHhX4AYr0RUXMLMeZvadOtS6JfA8pA7ryDn3urxxyttI+pWZlVx0KDPrIunpwMv/VyE41vmcBG5c830zq6oLzPjAc2k3jUA3k7RAbS8FWsTLbi/SzG4pM6nkfN1U9vfHzFqY2SPyxvWui7XyvmiMMLNfWxU3bjKzjmY2vZr1S87FlmrmA6gHupcAqMkSM6vpArdbA619s+WN3HG7pH+a2acIhkQAAAMgSURBVF/1xXjO3eW1AkbIC3PHAus+Jm+UhxmSbjSzd+S1+I2Q1xr5qb74c/0FyTn3P2b2vKR/k5RuZlv1xY1YusrruztTX7QwB0t9j+06SY9IesDM+sm7+U3JUIg7nHNnzWysvCEg50u6z8z+Lq/veBt557eXvL77f6xNoc659wPb+KqZ9XDO1XRhZEVT5QXDKfJuIPO6vrg5TmtJr8obBrLs/upzTtpJ+p28cP9Xed1SWshrEb5K3l96Zleo7W55NxEaJumQmb0R2E9neb8PnynQlcU597aZ/UleH/G/mtmWwPwEeV8C/m8V269WoB94oryhMWdImmpmf5P3hSlS3igoV8rr2vO7KjZRcifKdbXdJ4AvR0s3gJrEy7vTYHWPCMn7s71z7g5JE+QFss7ybkIySl74SZV0q8rcsc8596a8ULFe3ggWE+WN3PCf8oZNq3hnxwvVdHkh7l/yxpb+pqS9kgbLC6vSl1+UWCf1PbbOub/K65+cLi+U/5uk76nMUHXOuX9I+qqkhyW9K+lrkm4LPJ+Qd/Ode+pY8pLA87S6rOSce0/SdfJuapMt732OlHesfyTvBjQV70Yp1f2cHJQ0S163jYvlhePR8i5Y/K2kayv2nQ8MY3iDvLuevi1poLw7tvaQd/fKhyrU9K3AtPcC7+HrgfqG6YvuIrXmnPs4sM8fyRsW8ip552mIvDtTLg7UU06gVXycvHO7qa77BVA9q3oIWwCA38xsk7xwdZtz7n9CXU+omFlred0zzkjq7ZwrCmEtzfqcmNmPJT0j6T7n3P8LdT1AU0JLNwD4yMyuqtj32czCzWyevHCXKa8bQLPlnPtcXneVHqpja3d9cE6qFrg5z2x546v/JsTlAE0OLd0A4CMz+6O8rjVvy7tQMVbS1fK64ORJmuSca3YBryIzaymvG0RbSX2q6RYSrH1xTqpgZrMkPSlpgnMu7cuWB1A3hG4A8FHgwsPp8vo8XyLvAvZP5A1590SgjzQaEOcEQCgQugEAAACf0acbAAAA8BmhGwAAAPAZoRsAAADwGaEbAAAA8BmhGwAAAPDZ/webydbd6jIYgwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "label_record = []\n",
    "for i in range(n_samples):\n",
    "    if optimizers[i] in label_record :\n",
    "        plt.scatter(learning_rates[i],scoring[i], s=1.75*np.exp(n_layers[i]-1.25), c=colors[i], marker='.')\n",
    "    elif ((n_layers[i] <= 4) or (n_layers[i]>6)):\n",
    "        plt.scatter(learning_rates[i],scoring[i], s=1.75*np.exp(n_layers[i]-1.25), c=colors[i], marker='.')\n",
    "    else:\n",
    "        plt.scatter(learning_rates[i],scoring[i], s=1.75*np.exp(n_layers[i]-1.25), c=colors[i], label = optimizers[i], marker='.')\n",
    "        label_record.append(optimizers[i])\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Score', fontsize=22)\n",
    "plt.xlabel('Learning rate (logscale)', fontsize=22)\n",
    "plt.legend(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a bit difficult to visualize, but we can understand that a good portion of the models with bad performances has a combination of high learning rate and high number of number of layers. Again Adamax confirms itself as the most stable optimizer and it seems that the number of hidden layers can be shrinked even more, considering mainly networks with 2 or 3 hidden layers. Finally I will restrict the learning rate between $10^{-3}$ and $10^{-2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_record = []\n",
    "for i in range(n_samples):\n",
    "    if optimizers[i] == 'Adamax':\n",
    "        if act[i] in label_record:\n",
    "            plt.scatter(learning_rates[i], scoring[i],c=colors2[i])\n",
    "        else:\n",
    "            plt.scatter(learning_rates[i], scoring[i],c=colors2[i], label = act[i])\n",
    "            label_record.append(act[i])\n",
    "            \n",
    "plt.ylabel('Score', fontsize=16)\n",
    "plt.xlabel('Learning rate (log scale)', fontsize=16)\n",
    "plt.xscale('log')\n",
    "plt.axvline(2*10**(-2), color = 'c', label='max learning rate')\n",
    "plt.axvline(2*10**(-3), color = 'g', label='min learning rate')\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Optimizer: Adamax', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't seem to be a clear dependence of the performances on the activation function. Instead we can idenfity the interval in which the activation functions seem to be more performing, that is between $2\\cdot10^{-3}$ and  $2\\cdot10^{-2}$. I will restrict the learning rates of the next grid search to that interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "How dropout affects performances of the models that use Adamax and have a learning rate between $2\\cdot10^{-3}$ and  $2\\cdot10^{-2}$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_lr = []\n",
    "drop_act = []\n",
    "drop_scoring = []\n",
    "drop_dropout = []\n",
    "drop_colors = []\n",
    "drop_n_layers = []\n",
    "drop_penalty = []\n",
    "for i in range(n_samples):\n",
    "    if (optimizers[i]=='Adamax') and (learning_rates[i]>2*10**(-3)) and (learning_rates[i]<2*10**(-2)):\n",
    "        drop_lr.append(learning_rates[i])\n",
    "        drop_act.append(act[i])\n",
    "        drop_scoring.append(scoring[i])\n",
    "        drop_dropout.append(dropout[i])\n",
    "        drop_colors.append(colors2[i])\n",
    "        drop_n_layers.append(n_layers[i])\n",
    "        drop_penalty.append(penalty[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(drop_dropout,drop_scoring,c=drop_colors,s=np.exp(np.array(drop_n_layers)/2))\n",
    "plt.ylabel('Score', fontsize=16)\n",
    "plt.xlabel('Dropout', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hidden layers considered:  [4, 4, 3, 6, 3, 5, 11, 2, 4, 4, 2, 2, 3, 2, 2, 10, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of hidden layers considered: \", drop_n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No particular relationship emerges except from the fact that a great number of hidden layers is bad performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty (weight decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(drop_penalty,drop_scoring,c=drop_colors,s=np.exp(np.array(drop_n_layers)/2))\n",
    "plt.ylabel('Score', fontsize=16)\n",
    "plt.xlabel('Penalty', fontsize=16)\n",
    "plt.xlim(10**(-4),10**(-2))\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again no particular trend emerges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 784\n",
    "OUTPUT_DIM = 10\n",
    "C = 3.5\n",
    "\n",
    "def compute_alpha(in_dim, out_dim, compression):\n",
    "    n_layers = np.log(in_dim/out_dim)/np.log(compression) - 1\n",
    "    alpha = np.log(n_layers/(n_layers-1))\n",
    "    return alpha\n",
    "\n",
    "alpha = compute_alpha(INPUT_DIM, OUTPUT_DIM, C)\n",
    "\n",
    "# already discussed\n",
    "n_layers_P_dict = dict(discrete=True,\n",
    "                       var_type='int',\n",
    "                       distribution='exp',\n",
    "                       N_min = 2,\n",
    "                       N_max = 50,\n",
    "                       alpha=alpha)\n",
    "\n",
    "# spans different magnitude scales, use logaritmic distribution for invariance of scale\n",
    "lr_P_dict = dict(discrete=False,\n",
    "                var_type='float',\n",
    "                distribution='log',\n",
    "                x_min = 2*1e-3,\n",
    "                x_max = 2*1e-2)\n",
    "\n",
    "# same thing here\n",
    "penalty_P_dict = dict(discrete=False,\n",
    "                    var_type='float',\n",
    "                    distribution='log',\n",
    "                    x_min = 1e-4,\n",
    "                    x_max = 1e-2)\n",
    "\n",
    "# acts on the number of neurons in a linear way, use uniform distribution\n",
    "dropout_P_dict = dict(discrete=False,\n",
    "                     var_type = 'float',\n",
    "                     distribution='uniform',\n",
    "                     x_min = 0,\n",
    "                     x_max = 0.25)\n",
    "\n",
    "# use custom distribution to encode my personal beliefs on their performances BEFORE testing them in depth\n",
    "optimizer_P_dict = dict(discrete=True,\n",
    "                             var_type = 'str',\n",
    "                             distribution='custom',\n",
    "                             elements=np.array([ optim.Adamax]),\n",
    "                             p = np.array([1]))\n",
    "\n",
    "# use custom distribution to encode my personal beliefs on their performances BEFORE testing them in depth\n",
    "activation_P_dict = dict(discrete=True,\n",
    "                         var_type = 'str',\n",
    "                         distribution='custom',\n",
    "                         elements=np.array([F.relu,F.leaky_relu]),\n",
    "                         p = np.array([0.65,0.35]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_dict = dict(lr=lr_P_dict, \n",
    "              n_layers=n_layers_P_dict, \n",
    "              penalty=penalty_P_dict, \n",
    "              dropout=dropout_P_dict, \n",
    "              optimizer=optimizer_P_dict,\n",
    "              act=activation_P_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "for key in P_dict.keys():\n",
    "    P = prior_distr(**P_dict[key])\n",
    "    if key == 'n_layers':\n",
    "        n_layers= P.sample(n_samples)\n",
    "        N_neurons_samples = sample_neurons(n_samples, n_layers)\n",
    "        params['h_sizes'] = N_neurons_samples \n",
    "    else:\n",
    "        params[key] = P.sample(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we make a list of dictionary instead of a dictionary of lists and we also add the last constant parameters\n",
    "list_of_dict = []\n",
    "for i in range(n_samples):\n",
    "    d = {'out_size' : 10, 'n_epochs' : 15, 'loss' : torch.nn.CrossEntropyLoss()}\n",
    "    for key in params.keys():\n",
    "        d[key] = params[key][i]\n",
    "    list_of_dict.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations:  100\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004586111167879296\n",
      "h_sizes \t [784, 181, 59]\n",
      "penalty \t 0.005109993930533217\n",
      "dropout \t 0.08525392756359634\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.01524403599320976\n",
      "h_sizes \t [784, 350, 142, 63, 26]\n",
      "penalty \t 0.0003476412617405241\n",
      "dropout \t 0.13420882014385638\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.01063277965349671\n",
      "h_sizes \t [784, 162, 47]\n",
      "penalty \t 0.00046322720693077257\n",
      "dropout \t 0.10513450663009169\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002127154319064286\n",
      "h_sizes \t [784, 174, 33]\n",
      "penalty \t 0.005947730126911706\n",
      "dropout \t 0.23362598746376456\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003996024018867443\n",
      "h_sizes \t [784, 278, 94, 24]\n",
      "penalty \t 0.0014430192249231507\n",
      "dropout \t 0.08787206607182774\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.006976691710649004\n",
      "h_sizes \t [784, 178, 42]\n",
      "penalty \t 0.0009339836188174311\n",
      "dropout \t 0.10650789713620981\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0059451919376209625\n",
      "h_sizes \t [784, 334, 146, 63, 21]\n",
      "penalty \t 0.001554835453081733\n",
      "dropout \t 0.11094956824313185\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0029800367698189652\n",
      "h_sizes \t [784, 274, 106, 34]\n",
      "penalty \t 0.005613113079154965\n",
      "dropout \t 0.21114187517953323\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005553663266334762\n",
      "h_sizes \t [784, 201, 45]\n",
      "penalty \t 0.0033449836450673755\n",
      "dropout \t 0.22928445893051744\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002313125799240196\n",
      "h_sizes \t [784, 335, 141, 67, 30]\n",
      "penalty \t 0.0005639313220331014\n",
      "dropout \t 0.1631600963255291\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.014281571697627294\n",
      "h_sizes \t [784, 164, 42]\n",
      "penalty \t 0.00019434485189314754\n",
      "dropout \t 0.16556821676203365\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.006200446240594056\n",
      "h_sizes \t [784, 188, 38]\n",
      "penalty \t 0.005027289538361763\n",
      "dropout \t 0.24514731077452565\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.018295444309838097\n",
      "h_sizes \t [784, 262, 98, 31]\n",
      "penalty \t 0.005730386728131879\n",
      "dropout \t 0.17207494145054458\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008285286736995991\n",
      "h_sizes \t [784, 337, 138, 61, 28]\n",
      "penalty \t 0.0014477797404773732\n",
      "dropout \t 0.09691534546527214\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.012243968374354375\n",
      "h_sizes \t [784, 316, 142, 52, 20]\n",
      "penalty \t 0.001522928672181953\n",
      "dropout \t 0.06816193412041527\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0021991125565293014\n",
      "h_sizes \t [784, 424, 228, 130, 65, 31, 21]\n",
      "penalty \t 0.0002925341298850196\n",
      "dropout \t 0.18711769309525658\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.013978363242923234\n",
      "h_sizes \t [784, 346, 152, 57, 28]\n",
      "penalty \t 0.0002524716537463212\n",
      "dropout \t 0.10887237593590082\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008582688624845214\n",
      "h_sizes \t [784, 202, 50]\n",
      "penalty \t 0.0036763460734183244\n",
      "dropout \t 0.21029295542727858\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004539410644004607\n",
      "h_sizes \t [784, 171, 38]\n",
      "penalty \t 0.0001967010074431286\n",
      "dropout \t 0.07750896302492466\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0032471967584768507\n",
      "h_sizes \t [784, 189, 46]\n",
      "penalty \t 0.001713925332187699\n",
      "dropout \t 0.18698372169408045\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.015481261734608174\n",
      "h_sizes \t [784, 410, 215, 107, 47, 23]\n",
      "penalty \t 0.001119792400730838\n",
      "dropout \t 0.07177034193066756\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005872377709044323\n",
      "h_sizes \t [784, 275, 85, 27]\n",
      "penalty \t 0.004387508751456251\n",
      "dropout \t 0.19204362745606335\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003687605348420281\n",
      "h_sizes \t [784, 289, 90, 26]\n",
      "penalty \t 0.0016725518176625457\n",
      "dropout \t 0.0074038631830046775\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0020430674296646073\n",
      "h_sizes \t [784, 189, 45]\n",
      "penalty \t 0.00048243589313862537\n",
      "dropout \t 0.17330228520124988\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003281509558943158\n",
      "h_sizes \t [784, 329, 154, 61, 27]\n",
      "penalty \t 0.0001971321323496235\n",
      "dropout \t 0.05856873525082368\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.009833930049051871\n",
      "h_sizes \t [784, 269, 94, 36]\n",
      "penalty \t 0.0011941736098904498\n",
      "dropout \t 0.055327458048992334\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.01414588595149499\n",
      "h_sizes \t [784, 177, 40]\n",
      "penalty \t 0.00019923369612961675\n",
      "dropout \t 0.21772291278092462\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005181726987083004\n",
      "h_sizes \t [784, 371, 171, 64, 34, 17]\n",
      "penalty \t 0.004622527164100379\n",
      "dropout \t 0.09180288443376405\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002505005023916352\n",
      "h_sizes \t [784, 190, 47]\n",
      "penalty \t 0.00011942339622755558\n",
      "dropout \t 0.20037572985486035\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.016591819037859452\n",
      "h_sizes \t [784, 375, 191, 88, 48, 25]\n",
      "penalty \t 0.000523814753423382\n",
      "dropout \t 0.06232699861867824\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0025770385156478966\n",
      "h_sizes \t [784, 249, 77, 23]\n",
      "penalty \t 0.0010221995053274957\n",
      "dropout \t 0.15037786999979477\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.007406006706032811\n",
      "h_sizes \t [784, 196, 59]\n",
      "penalty \t 0.00012689429309566718\n",
      "dropout \t 0.05279464277818349\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.006752107978186746\n",
      "h_sizes \t [784, 256, 100, 42]\n",
      "penalty \t 0.0015811061654509675\n",
      "dropout \t 0.03788280586520876\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0035113234137754755\n",
      "h_sizes \t [784, 272, 88, 26]\n",
      "penalty \t 0.0018464191547675997\n",
      "dropout \t 0.15638398289076513\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.015545138195935001\n",
      "h_sizes \t [784, 373, 186, 93, 47, 21]\n",
      "penalty \t 0.002069726141627082\n",
      "dropout \t 0.1811059910810368\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0037120453380267513\n",
      "h_sizes \t [784, 178, 49]\n",
      "penalty \t 0.0001881222863357692\n",
      "dropout \t 0.07927037399245215\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0028222577539235407\n",
      "h_sizes \t [784, 458, 249, 151, 82, 49, 32, 19]\n",
      "penalty \t 0.0002782470598623404\n",
      "dropout \t 0.21368914171565292\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.01833598037179182\n",
      "h_sizes \t [784, 277, 100, 31]\n",
      "penalty \t 0.0001017590647857701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout \t 0.06919644772687822\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0047514779126872735\n",
      "h_sizes \t [784, 410, 221, 121, 53, 25, 16]\n",
      "penalty \t 0.006110586067950274\n",
      "dropout \t 0.004200560732935177\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.009170325296149398\n",
      "h_sizes \t [784, 427, 245, 135, 65, 38, 18]\n",
      "penalty \t 0.0009695171160236083\n",
      "dropout \t 0.09456445608021896\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008725959805404075\n",
      "h_sizes \t [784, 269, 79, 26]\n",
      "penalty \t 0.008162834979702554\n",
      "dropout \t 0.14902353260290122\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004427617629922213\n",
      "h_sizes \t [784, 337, 146, 71, 31]\n",
      "penalty \t 0.0037981640949041177\n",
      "dropout \t 0.03778391548760354\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.007084088878492843\n",
      "h_sizes \t [784, 170, 40]\n",
      "penalty \t 0.0014105081045908856\n",
      "dropout \t 0.16396063703326874\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002660597080053773\n",
      "h_sizes \t [784, 192, 47]\n",
      "penalty \t 0.004747205872354946\n",
      "dropout \t 0.15959281837226263\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0024517471771814178\n",
      "h_sizes \t [784, 397, 202, 102, 56, 27, 17]\n",
      "penalty \t 0.00544791324143448\n",
      "dropout \t 0.23620994231744216\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.014295655103625078\n",
      "h_sizes \t [784, 180, 48]\n",
      "penalty \t 0.00013551795006647217\n",
      "dropout \t 0.043794555689653764\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0027249818406783993\n",
      "h_sizes \t [784, 247, 83, 33]\n",
      "penalty \t 0.0009100398473014092\n",
      "dropout \t 0.018516942383390744\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0033666475018500957\n",
      "h_sizes \t [784, 178, 38]\n",
      "penalty \t 0.0036601726093381938\n",
      "dropout \t 0.13107226000135663\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0037035324424856365\n",
      "h_sizes \t [784, 375, 180, 90, 44, 19]\n",
      "penalty \t 0.002081408396368334\n",
      "dropout \t 0.1805906109347829\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.017631282700654845\n",
      "h_sizes \t [784, 195, 57]\n",
      "penalty \t 0.0002796662436471825\n",
      "dropout \t 0.15863500133922606\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004059616710546901\n",
      "h_sizes \t [784, 243, 77, 26]\n",
      "penalty \t 0.00023151364855912828\n",
      "dropout \t 0.21330184056198584\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004267334464890805\n",
      "h_sizes \t [784, 199, 51]\n",
      "penalty \t 0.00019868212127381767\n",
      "dropout \t 0.20508131040519426\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004652998886743496\n",
      "h_sizes \t [784, 188, 41]\n",
      "penalty \t 0.003212261514776027\n",
      "dropout \t 0.08871846098311928\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.017265976090288824\n",
      "h_sizes \t [784, 582, 454, 351, 257, 195, 151, 120, 92, 69, 50, 36, 34, 27, 25, 20]\n",
      "penalty \t 0.0007048499838027881\n",
      "dropout \t 0.206379645320488\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0033531091949899144\n",
      "h_sizes \t [784, 190, 52]\n",
      "penalty \t 0.0012502629782364465\n",
      "dropout \t 0.19148207562645791\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002227005787023503\n",
      "h_sizes \t [784, 176, 45]\n",
      "penalty \t 0.0006736571039832936\n",
      "dropout \t 0.06569049949560204\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008249523303740786\n",
      "h_sizes \t [784, 192, 42]\n",
      "penalty \t 0.00517351748939074\n",
      "dropout \t 0.19768748736286157\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0032469236985254225\n",
      "h_sizes \t [784, 268, 80, 25]\n",
      "penalty \t 0.00048641540439475165\n",
      "dropout \t 0.22363118687779257\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0030584838248822067\n",
      "h_sizes \t [784, 187, 42]\n",
      "penalty \t 0.0001867424712621452\n",
      "dropout \t 0.17013854999580497\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.014696218671370463\n",
      "h_sizes \t [784, 431, 224, 123, 69, 40, 21]\n",
      "penalty \t 0.000940110672788446\n",
      "dropout \t 0.04132485098406263\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.012079612733427109\n",
      "h_sizes \t [784, 171, 32]\n",
      "penalty \t 0.0007922629325822313\n",
      "dropout \t 0.001652816978295918\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.015389540724715416\n",
      "h_sizes \t [784, 276, 104, 30]\n",
      "penalty \t 0.0006799702539408856\n",
      "dropout \t 0.004042950171734394\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0024735655099754287\n",
      "h_sizes \t [784, 203, 44]\n",
      "penalty \t 0.001556507293493741\n",
      "dropout \t 0.18549367920735485\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.006246113586783729\n",
      "h_sizes \t [784, 187, 48]\n",
      "penalty \t 0.0021836989752139447\n",
      "dropout \t 0.23167648243336392\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.014469070002168016\n",
      "h_sizes \t [784, 174, 29]\n",
      "penalty \t 0.003371452354480753\n",
      "dropout \t 0.21974732157771126\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005352413450006965\n",
      "h_sizes \t [784, 454, 253, 144, 90, 55, 31, 16]\n",
      "penalty \t 0.0002164070392617981\n",
      "dropout \t 0.0894324025959558\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.017409252827701914\n",
      "h_sizes \t [784, 335, 124, 48, 22]\n",
      "penalty \t 0.00022599498781326996\n",
      "dropout \t 0.031551726063454716\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004192838925781067\n",
      "h_sizes \t [784, 173, 48]\n",
      "penalty \t 0.003185094421274093\n",
      "dropout \t 0.02805778770430714\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00900478238752776\n",
      "h_sizes \t [784, 363, 156, 62, 16]\n",
      "penalty \t 0.008494306474535444\n",
      "dropout \t 0.07470528457387518\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0023339755264640957\n",
      "h_sizes \t [784, 273, 104, 28]\n",
      "penalty \t 0.002391632438242522\n",
      "dropout \t 0.07128884721140097\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.011566193764914997\n",
      "h_sizes \t [784, 281, 101, 36]\n",
      "penalty \t 0.00016082339144314823\n",
      "dropout \t 0.1773556365217188\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00244492967648772\n",
      "h_sizes \t [784, 182, 41]\n",
      "penalty \t 0.0001231265576684176\n",
      "dropout \t 0.22580161159598486\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.010849257775159157\n",
      "h_sizes \t [784, 244, 89, 32]\n",
      "penalty \t 0.001891800826918899\n",
      "dropout \t 0.21884735098848143\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.014905145100167234\n",
      "h_sizes \t [784, 180, 40]\n",
      "penalty \t 0.005909636679506393\n",
      "dropout \t 0.12621349618380256\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005806526806521204\n",
      "h_sizes \t [784, 190, 52]\n",
      "penalty \t 0.008738796712367566\n",
      "dropout \t 0.17153043626351422\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0023541243054821114\n",
      "h_sizes \t [784, 165, 43]\n",
      "penalty \t 0.00019911261419852956\n",
      "dropout \t 0.026522144615850257\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00725300156526568\n",
      "h_sizes \t [784, 450, 250, 145, 88, 52, 32, 19]\n",
      "penalty \t 0.0010275147670114097\n",
      "dropout \t 0.06599719668695245\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.009388429321100844\n",
      "h_sizes \t [784, 176, 44]\n",
      "penalty \t 0.001882987655095027\n",
      "dropout \t 0.11315995195569131\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.009132725389088516\n",
      "h_sizes \t [784, 184, 47]\n",
      "penalty \t 0.0016600906122926984\n",
      "dropout \t 0.1028446558133636\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0063841359690157435\n",
      "h_sizes \t [784, 184, 35]\n",
      "penalty \t 0.004410530921923416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout \t 0.17879078646643765\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.009752196267247772\n",
      "h_sizes \t [784, 324, 134, 50, 15]\n",
      "penalty \t 0.0003826375431677099\n",
      "dropout \t 0.24246159332502737\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.013909282948619515\n",
      "h_sizes \t [784, 338, 153, 61, 30]\n",
      "penalty \t 0.0015819485864566184\n",
      "dropout \t 0.14965454364809813\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.016388848637946613\n",
      "h_sizes \t [784, 167, 47]\n",
      "penalty \t 0.00012218545700531748\n",
      "dropout \t 0.1911133678657312\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004177507220179145\n",
      "h_sizes \t [784, 461, 273, 153, 83, 44, 26, 18]\n",
      "penalty \t 0.0001616368621925495\n",
      "dropout \t 0.23491944373257026\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0031908952683813315\n",
      "h_sizes \t [784, 280, 93, 33]\n",
      "penalty \t 0.0012313622487824258\n",
      "dropout \t 0.07076706395508195\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008446811597212667\n",
      "h_sizes \t [784, 511, 321, 207, 120, 84, 54, 37, 18]\n",
      "penalty \t 0.005335661616788348\n",
      "dropout \t 0.06842791454409938\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003432700635609312\n",
      "h_sizes \t [784, 179, 32]\n",
      "penalty \t 0.0009354459154807876\n",
      "dropout \t 0.1048926579957761\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.01572542247335979\n",
      "h_sizes \t [784, 265, 88, 29]\n",
      "penalty \t 0.00013644547818043702\n",
      "dropout \t 0.12356540501116278\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.012112711037655618\n",
      "h_sizes \t [784, 316, 136, 57, 19]\n",
      "penalty \t 0.005332367583470696\n",
      "dropout \t 0.11952940241394577\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0027246045795521023\n",
      "h_sizes \t [784, 458, 259, 157, 99, 65, 40, 23]\n",
      "penalty \t 0.0009123352338428327\n",
      "dropout \t 0.09505034202060961\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00912423331356473\n",
      "h_sizes \t [784, 185, 52]\n",
      "penalty \t 0.005116964279816358\n",
      "dropout \t 0.2011255120090813\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.010805060864098812\n",
      "h_sizes \t [784, 165, 37]\n",
      "penalty \t 0.008465757241652785\n",
      "dropout \t 0.063763057936604\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003233962781215107\n",
      "h_sizes \t [784, 287, 91, 35]\n",
      "penalty \t 0.003116382818302528\n",
      "dropout \t 0.13103538813961335\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008896490515412279\n",
      "h_sizes \t [784, 172, 47]\n",
      "penalty \t 0.004739055219698434\n",
      "dropout \t 0.18488255719514723\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003458581583551235\n",
      "h_sizes \t [784, 383, 176, 78, 33, 20]\n",
      "penalty \t 0.0006185549730053594\n",
      "dropout \t 0.16622836400030946\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005705934084080705\n",
      "h_sizes \t [784, 324, 118, 55, 19]\n",
      "penalty \t 0.00017976461896136996\n",
      "dropout \t 0.047978918639824786\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0029976321452246427\n",
      "h_sizes \t [784, 189, 46]\n",
      "penalty \t 0.00030929693247069704\n",
      "dropout \t 0.02922134765315329\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00534631582989067\n",
      "h_sizes \t [784, 255, 69, 28]\n",
      "penalty \t 0.0004099755295656873\n",
      "dropout \t 0.04854067398332329\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0027067396193755375\n",
      "h_sizes \t [784, 185, 44]\n",
      "penalty \t 0.001314378774496794\n",
      "dropout \t 0.08440170890240617\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.013215368202102893\n",
      "h_sizes \t [784, 332, 135, 56, 21]\n",
      "penalty \t 0.0016787136089521613\n",
      "dropout \t 0.03994474565080411\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of combinations: \", len(list_of_dict))\n",
    "\n",
    "flag = True #set to True to see all combinations\n",
    "if flag == True:\n",
    "    for params in list_of_dict:\n",
    "        print()\n",
    "        print_parameters(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.426 took: 4.97s  Val. loss: 0.219  Val. score: 93.311%\n",
      "Epoch 2, 100% \t Train loss: 0.197 took: 8.34s  Val. loss: 0.165  Val. score: 95.017%\n",
      "Epoch 3, 100% \t Train loss: 0.144 took: 5.82s  Val. loss: 0.131  Val. score: 95.917%\n",
      "Epoch 4, 100% \t Train loss: 0.117 took: 5.07s  Val. loss: 0.120  Val. score: 96.144%\n",
      "Epoch 5, 100% \t Train loss: 0.091 took: 5.04s  Val. loss: 0.111  Val. score: 96.528%\n",
      "Epoch 6, 100% \t Train loss: 0.076 took: 5.17s  Val. loss: 0.101  Val. score: 96.772%\n",
      "Epoch 7, 100% \t Train loss: 0.066 took: 4.97s  Val. loss: 0.098  Val. score: 96.906%\n",
      "Epoch 8, 100% \t Train loss: 0.058 took: 5.14s  Val. loss: 0.093  Val. score: 97.028%\n",
      "Epoch 9, 100% \t Train loss: 0.048 took: 5.15s  Val. loss: 0.091  Val. score: 97.139%\n",
      "Epoch 10, 100% \t Train loss: 0.042 took: 4.74s  Val. loss: 0.092  Val. score: 97.278%\n",
      "Epoch 11, 100% \t Train loss: 0.038 took: 5.16s  Val. loss: 0.090  Val. score: 97.211%\n",
      "Epoch 12, 100% \t Train loss: 0.032 took: 5.13s  Val. loss: 0.091  Val. score: 97.389%\n",
      "Epoch 13, 100% \t Train loss: 0.028 took: 5.18s  Val. loss: 0.096  Val. score: 97.300%\n",
      "Epoch 14, 100% \t Train loss: 0.026 took: 4.81s  Val. loss: 0.106  Val. score: 97.067%\n",
      "Epoch 15, 100% \t Train loss: 0.024 took: 5.17s  Val. loss: 0.088  Val. score: 97.472%\n",
      "Training finished, took 136.994s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.430 took: 5.88s  Val. loss: 0.217  Val. score: 93.494%\n",
      "Epoch 2, 100% \t Train loss: 0.200 took: 4.60s  Val. loss: 0.160  Val. score: 94.983%\n",
      "Epoch 3, 100% \t Train loss: 0.145 took: 5.96s  Val. loss: 0.121  Val. score: 96.344%\n",
      "Epoch 4, 100% \t Train loss: 0.112 took: 4.80s  Val. loss: 0.110  Val. score: 96.650%\n",
      "Epoch 5, 100% \t Train loss: 0.093 took: 5.40s  Val. loss: 0.094  Val. score: 97.117%\n",
      "Epoch 6, 100% \t Train loss: 0.076 took: 4.79s  Val. loss: 0.089  Val. score: 97.322%\n",
      "Epoch 7, 100% \t Train loss: 0.064 took: 5.03s  Val. loss: 0.088  Val. score: 97.222%\n",
      "Epoch 8, 100% \t Train loss: 0.058 took: 4.73s  Val. loss: 0.086  Val. score: 97.400%\n",
      "Epoch 9, 100% \t Train loss: 0.048 took: 5.47s  Val. loss: 0.083  Val. score: 97.472%\n",
      "Epoch 10, 100% \t Train loss: 0.042 took: 4.84s  Val. loss: 0.078  Val. score: 97.606%\n",
      "Epoch 11, 100% \t Train loss: 0.035 took: 4.85s  Val. loss: 0.079  Val. score: 97.533%\n",
      "Epoch 12, 100% \t Train loss: 0.033 took: 5.17s  Val. loss: 0.077  Val. score: 97.733%\n",
      "Epoch 13, 100% \t Train loss: 0.029 took: 4.73s  Val. loss: 0.076  Val. score: 97.717%\n",
      "Epoch 14, 100% \t Train loss: 0.025 took: 4.73s  Val. loss: 0.082  Val. score: 97.594%\n",
      "Epoch 15, 100% \t Train loss: 0.023 took: 5.26s  Val. loss: 0.080  Val. score: 97.711%\n",
      "Training finished, took 129.152s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.445 took: 4.85s  Val. loss: 0.219  Val. score: 93.839%\n",
      "Epoch 2, 100% \t Train loss: 0.200 took: 4.87s  Val. loss: 0.154  Val. score: 95.350%\n",
      "Epoch 3, 100% \t Train loss: 0.146 took: 4.89s  Val. loss: 0.142  Val. score: 95.961%\n",
      "Epoch 4, 100% \t Train loss: 0.115 took: 4.74s  Val. loss: 0.120  Val. score: 96.444%\n",
      "Epoch 5, 100% \t Train loss: 0.092 took: 4.76s  Val. loss: 0.107  Val. score: 96.944%\n",
      "Epoch 6, 100% \t Train loss: 0.077 took: 4.71s  Val. loss: 0.101  Val. score: 97.172%\n",
      "Epoch 7, 100% \t Train loss: 0.066 took: 5.12s  Val. loss: 0.101  Val. score: 97.122%\n",
      "Epoch 8, 100% \t Train loss: 0.058 took: 4.73s  Val. loss: 0.090  Val. score: 97.478%\n",
      "Epoch 9, 100% \t Train loss: 0.047 took: 4.95s  Val. loss: 0.093  Val. score: 97.406%\n",
      "Epoch 10, 100% \t Train loss: 0.041 took: 5.17s  Val. loss: 0.096  Val. score: 97.378%\n",
      "Epoch 11, 100% \t Train loss: 0.036 took: 5.07s  Val. loss: 0.092  Val. score: 97.461%\n",
      "Epoch 12, 100% \t Train loss: 0.034 took: 5.16s  Val. loss: 0.090  Val. score: 97.706%\n",
      "Epoch 13, 100% \t Train loss: 0.031 took: 4.95s  Val. loss: 0.104  Val. score: 97.217%\n",
      "Epoch 14, 100% \t Train loss: 0.026 took: 5.14s  Val. loss: 0.089  Val. score: 97.739%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 4.89s  Val. loss: 0.092  Val. score: 97.667%\n",
      "Training finished, took 124.695s\n",
      "\n",
      "Parameters configuration 1 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004586111167879296\n",
      "h_sizes \t [784, 181, 59]\n",
      "penalty \t 0.005109993930533217\n",
      "dropout \t 0.08525392756359634\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6167 +/- 0.1037\n",
      "Time for evaluation: 392.3 s\n",
      "Estimated time to finish : 10.79 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.514 took: 8.14s  Val. loss: 0.180  Val. score: 94.983%\n",
      "Epoch 2, 100% \t Train loss: 0.198 took: 7.85s  Val. loss: 0.146  Val. score: 95.900%\n",
      "Epoch 3, 100% \t Train loss: 0.144 took: 8.98s  Val. loss: 0.120  Val. score: 96.694%\n",
      "Epoch 4, 100% \t Train loss: 0.121 took: 9.55s  Val. loss: 0.119  Val. score: 96.911%\n",
      "Epoch 5, 100% \t Train loss: 0.099 took: 9.09s  Val. loss: 0.112  Val. score: 96.900%\n",
      "Epoch 6, 100% \t Train loss: 0.086 took: 9.67s  Val. loss: 0.113  Val. score: 97.206%\n",
      "Epoch 7, 100% \t Train loss: 0.072 took: 9.58s  Val. loss: 0.105  Val. score: 97.317%\n",
      "Epoch 8, 100% \t Train loss: 0.059 took: 9.11s  Val. loss: 0.102  Val. score: 97.611%\n",
      "Epoch 9, 100% \t Train loss: 0.058 took: 9.69s  Val. loss: 0.115  Val. score: 97.350%\n",
      "Epoch 10, 100% \t Train loss: 0.050 took: 9.07s  Val. loss: 0.103  Val. score: 97.583%\n",
      "Epoch 11, 100% \t Train loss: 0.045 took: 8.98s  Val. loss: 0.112  Val. score: 97.722%\n",
      "Epoch 12, 100% \t Train loss: 0.038 took: 9.12s  Val. loss: 0.112  Val. score: 97.583%\n",
      "Epoch 13, 100% \t Train loss: 0.035 took: 9.04s  Val. loss: 0.107  Val. score: 97.828%\n",
      "Epoch 14, 100% \t Train loss: 0.034 took: 9.51s  Val. loss: 0.115  Val. score: 97.811%\n",
      "Epoch 15, 100% \t Train loss: 0.030 took: 9.02s  Val. loss: 0.115  Val. score: 97.750%\n",
      "Training finished, took 205.745s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.593 took: 7.82s  Val. loss: 0.209  Val. score: 94.083%\n",
      "Epoch 2, 100% \t Train loss: 0.226 took: 7.89s  Val. loss: 0.163  Val. score: 95.561%\n",
      "Epoch 3, 100% \t Train loss: 0.167 took: 9.12s  Val. loss: 0.158  Val. score: 95.928%\n",
      "Epoch 4, 100% \t Train loss: 0.135 took: 10.55s  Val. loss: 0.132  Val. score: 96.461%\n",
      "Epoch 5, 100% \t Train loss: 0.115 took: 9.69s  Val. loss: 0.131  Val. score: 96.433%\n",
      "Epoch 6, 100% \t Train loss: 0.104 took: 10.54s  Val. loss: 0.118  Val. score: 97.106%\n",
      "Epoch 7, 100% \t Train loss: 0.091 took: 10.58s  Val. loss: 0.117  Val. score: 96.978%\n",
      "Epoch 8, 100% \t Train loss: 0.079 took: 9.95s  Val. loss: 0.113  Val. score: 97.328%\n",
      "Epoch 9, 100% \t Train loss: 0.072 took: 9.73s  Val. loss: 0.119  Val. score: 96.989%\n",
      "Epoch 10, 100% \t Train loss: 0.064 took: 10.64s  Val. loss: 0.121  Val. score: 97.256%\n",
      "Epoch 11, 100% \t Train loss: 0.057 took: 10.02s  Val. loss: 0.117  Val. score: 97.394%\n",
      "Epoch 12, 100% \t Train loss: 0.053 took: 9.71s  Val. loss: 0.111  Val. score: 97.467%\n",
      "Epoch 13, 100% \t Train loss: 0.048 took: 10.15s  Val. loss: 0.132  Val. score: 97.033%\n",
      "Epoch 14, 100% \t Train loss: 0.047 took: 10.04s  Val. loss: 0.114  Val. score: 97.456%\n",
      "Epoch 15, 100% \t Train loss: 0.043 took: 9.87s  Val. loss: 0.127  Val. score: 97.411%\n",
      "Training finished, took 215.915s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.504 took: 8.66s  Val. loss: 0.181  Val. score: 95.122%\n",
      "Epoch 2, 100% \t Train loss: 0.205 took: 7.82s  Val. loss: 0.152  Val. score: 95.833%\n",
      "Epoch 3, 100% \t Train loss: 0.151 took: 9.05s  Val. loss: 0.130  Val. score: 96.567%\n",
      "Epoch 4, 100% \t Train loss: 0.126 took: 9.89s  Val. loss: 0.118  Val. score: 96.694%\n",
      "Epoch 5, 100% \t Train loss: 0.105 took: 9.78s  Val. loss: 0.114  Val. score: 97.072%\n",
      "Epoch 6, 100% \t Train loss: 0.087 took: 9.84s  Val. loss: 0.113  Val. score: 97.161%\n",
      "Epoch 7, 100% \t Train loss: 0.080 took: 10.19s  Val. loss: 0.132  Val. score: 96.556%\n",
      "Epoch 8, 100% \t Train loss: 0.070 took: 9.73s  Val. loss: 0.117  Val. score: 97.022%\n",
      "Epoch 9, 100% \t Train loss: 0.064 took: 9.92s  Val. loss: 0.104  Val. score: 97.422%\n",
      "Epoch 10, 100% \t Train loss: 0.055 took: 9.54s  Val. loss: 0.114  Val. score: 97.472%\n",
      "Epoch 11, 100% \t Train loss: 0.051 took: 9.59s  Val. loss: 0.115  Val. score: 97.400%\n",
      "Epoch 12, 100% \t Train loss: 0.046 took: 10.03s  Val. loss: 0.106  Val. score: 97.578%\n",
      "Epoch 13, 100% \t Train loss: 0.042 took: 10.13s  Val. loss: 0.116  Val. score: 97.672%\n",
      "Epoch 14, 100% \t Train loss: 0.041 took: 9.50s  Val. loss: 0.112  Val. score: 97.700%\n",
      "Epoch 15, 100% \t Train loss: 0.037 took: 9.57s  Val. loss: 0.110  Val. score: 97.572%\n",
      "Training finished, took 212.686s\n",
      "\n",
      "Parameters configuration 2 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.01524403599320976\n",
      "h_sizes \t [784, 350, 142, 63, 26]\n",
      "penalty \t 0.0003476412617405241\n",
      "dropout \t 0.13420882014385638\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5778 +/- 0.1384\n",
      "Time for evaluation: 635.5 s\n",
      "Estimated time to finish : 13.99 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.366 took: 4.38s  Val. loss: 0.175  Val. score: 94.633%\n",
      "Epoch 2, 100% \t Train loss: 0.169 took: 4.15s  Val. loss: 0.132  Val. score: 95.989%\n",
      "Epoch 3, 100% \t Train loss: 0.125 took: 4.64s  Val. loss: 0.115  Val. score: 96.539%\n",
      "Epoch 4, 100% \t Train loss: 0.096 took: 4.72s  Val. loss: 0.109  Val. score: 96.706%\n",
      "Epoch 5, 100% \t Train loss: 0.080 took: 4.79s  Val. loss: 0.097  Val. score: 97.122%\n",
      "Epoch 6, 100% \t Train loss: 0.069 took: 4.68s  Val. loss: 0.091  Val. score: 97.339%\n",
      "Epoch 7, 100% \t Train loss: 0.055 took: 4.58s  Val. loss: 0.096  Val. score: 97.317%\n",
      "Epoch 8, 100% \t Train loss: 0.050 took: 4.73s  Val. loss: 0.101  Val. score: 97.406%\n",
      "Epoch 9, 100% \t Train loss: 0.046 took: 4.66s  Val. loss: 0.097  Val. score: 97.422%\n",
      "Epoch 10, 100% \t Train loss: 0.037 took: 4.90s  Val. loss: 0.096  Val. score: 97.572%\n",
      "Epoch 11, 100% \t Train loss: 0.035 took: 4.55s  Val. loss: 0.107  Val. score: 97.306%\n",
      "Epoch 12, 100% \t Train loss: 0.031 took: 4.54s  Val. loss: 0.097  Val. score: 97.672%\n",
      "Epoch 13, 100% \t Train loss: 0.026 took: 4.51s  Val. loss: 0.106  Val. score: 97.494%\n",
      "Epoch 14, 100% \t Train loss: 0.025 took: 4.59s  Val. loss: 0.097  Val. score: 97.689%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 4.46s  Val. loss: 0.100  Val. score: 97.617%\n",
      "Training finished, took 117.945s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.359 took: 4.32s  Val. loss: 0.178  Val. score: 94.522%\n",
      "Epoch 2, 100% \t Train loss: 0.165 took: 4.23s  Val. loss: 0.133  Val. score: 95.900%\n",
      "Epoch 3, 100% \t Train loss: 0.121 took: 4.70s  Val. loss: 0.125  Val. score: 96.161%\n",
      "Epoch 4, 100% \t Train loss: 0.095 took: 4.82s  Val. loss: 0.101  Val. score: 97.017%\n",
      "Epoch 5, 100% \t Train loss: 0.079 took: 4.93s  Val. loss: 0.096  Val. score: 97.244%\n",
      "Epoch 6, 100% \t Train loss: 0.067 took: 4.41s  Val. loss: 0.102  Val. score: 96.950%\n",
      "Epoch 7, 100% \t Train loss: 0.059 took: 4.85s  Val. loss: 0.098  Val. score: 97.228%\n",
      "Epoch 8, 100% \t Train loss: 0.049 took: 4.44s  Val. loss: 0.098  Val. score: 97.261%\n",
      "Epoch 9, 100% \t Train loss: 0.043 took: 4.49s  Val. loss: 0.095  Val. score: 97.556%\n",
      "Epoch 10, 100% \t Train loss: 0.041 took: 4.57s  Val. loss: 0.101  Val. score: 97.300%\n",
      "Epoch 11, 100% \t Train loss: 0.032 took: 4.64s  Val. loss: 0.110  Val. score: 97.244%\n",
      "Epoch 12, 100% \t Train loss: 0.032 took: 4.56s  Val. loss: 0.099  Val. score: 97.533%\n",
      "Epoch 13, 100% \t Train loss: 0.029 took: 4.79s  Val. loss: 0.108  Val. score: 97.289%\n",
      "Epoch 14, 100% \t Train loss: 0.027 took: 4.54s  Val. loss: 0.101  Val. score: 97.450%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 4.55s  Val. loss: 0.103  Val. score: 97.556%\n",
      "Training finished, took 118.463s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.354 took: 4.59s  Val. loss: 0.173  Val. score: 94.761%\n",
      "Epoch 2, 100% \t Train loss: 0.160 took: 4.48s  Val. loss: 0.137  Val. score: 95.839%\n",
      "Epoch 3, 100% \t Train loss: 0.120 took: 4.52s  Val. loss: 0.110  Val. score: 96.817%\n",
      "Epoch 4, 100% \t Train loss: 0.095 took: 4.64s  Val. loss: 0.105  Val. score: 96.928%\n",
      "Epoch 5, 100% \t Train loss: 0.078 took: 4.47s  Val. loss: 0.095  Val. score: 97.278%\n",
      "Epoch 6, 100% \t Train loss: 0.066 took: 4.46s  Val. loss: 0.090  Val. score: 97.361%\n",
      "Epoch 7, 100% \t Train loss: 0.058 took: 4.80s  Val. loss: 0.088  Val. score: 97.494%\n",
      "Epoch 8, 100% \t Train loss: 0.047 took: 4.50s  Val. loss: 0.096  Val. score: 97.344%\n",
      "Epoch 9, 100% \t Train loss: 0.042 took: 4.53s  Val. loss: 0.103  Val. score: 97.294%\n",
      "Epoch 10, 100% \t Train loss: 0.036 took: 4.46s  Val. loss: 0.095  Val. score: 97.583%\n",
      "Epoch 11, 100% \t Train loss: 0.034 took: 4.53s  Val. loss: 0.099  Val. score: 97.522%\n",
      "Epoch 12, 100% \t Train loss: 0.032 took: 4.66s  Val. loss: 0.093  Val. score: 97.656%\n",
      "Epoch 13, 100% \t Train loss: 0.026 took: 4.72s  Val. loss: 0.103  Val. score: 97.600%\n",
      "Epoch 14, 100% \t Train loss: 0.027 took: 4.44s  Val. loss: 0.095  Val. score: 97.711%\n",
      "Epoch 15, 100% \t Train loss: 0.024 took: 4.59s  Val. loss: 0.094  Val. score: 97.622%\n",
      "Training finished, took 118.272s\n",
      "\n",
      "Parameters configuration 3 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.01063277965349671\n",
      "h_sizes \t [784, 162, 47]\n",
      "penalty \t 0.00046322720693077257\n",
      "dropout \t 0.10513450663009169\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5981 +/- 0.0302\n",
      "Time for evaluation: 355.9 s\n",
      "Estimated time to finish : 12.43 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.751 took: 4.18s  Val. loss: 0.329  Val. score: 90.761%\n",
      "Epoch 2, 100% \t Train loss: 0.376 took: 4.51s  Val. loss: 0.244  Val. score: 92.883%\n",
      "Epoch 3, 100% \t Train loss: 0.291 took: 4.51s  Val. loss: 0.202  Val. score: 94.022%\n",
      "Epoch 4, 100% \t Train loss: 0.244 took: 4.48s  Val. loss: 0.176  Val. score: 94.722%\n",
      "Epoch 5, 100% \t Train loss: 0.212 took: 4.41s  Val. loss: 0.154  Val. score: 95.272%\n",
      "Epoch 6, 100% \t Train loss: 0.187 took: 4.23s  Val. loss: 0.140  Val. score: 95.822%\n",
      "Epoch 7, 100% \t Train loss: 0.168 took: 4.38s  Val. loss: 0.131  Val. score: 95.978%\n",
      "Epoch 8, 100% \t Train loss: 0.152 took: 4.57s  Val. loss: 0.123  Val. score: 96.156%\n",
      "Epoch 9, 100% \t Train loss: 0.142 took: 4.46s  Val. loss: 0.115  Val. score: 96.461%\n",
      "Epoch 10, 100% \t Train loss: 0.130 took: 4.21s  Val. loss: 0.112  Val. score: 96.550%\n",
      "Epoch 11, 100% \t Train loss: 0.123 took: 4.56s  Val. loss: 0.106  Val. score: 96.817%\n",
      "Epoch 12, 100% \t Train loss: 0.117 took: 4.60s  Val. loss: 0.100  Val. score: 96.939%\n",
      "Epoch 13, 100% \t Train loss: 0.105 took: 4.58s  Val. loss: 0.099  Val. score: 97.000%\n",
      "Epoch 14, 100% \t Train loss: 0.102 took: 4.51s  Val. loss: 0.095  Val. score: 97.117%\n",
      "Epoch 15, 100% \t Train loss: 0.097 took: 4.59s  Val. loss: 0.093  Val. score: 97.200%\n",
      "Training finished, took 115.883s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.725 took: 4.52s  Val. loss: 0.314  Val. score: 90.761%\n",
      "Epoch 2, 100% \t Train loss: 0.353 took: 4.56s  Val. loss: 0.238  Val. score: 92.994%\n",
      "Epoch 3, 100% \t Train loss: 0.278 took: 4.16s  Val. loss: 0.201  Val. score: 93.983%\n",
      "Epoch 4, 100% \t Train loss: 0.235 took: 4.47s  Val. loss: 0.173  Val. score: 94.772%\n",
      "Epoch 5, 100% \t Train loss: 0.200 took: 4.42s  Val. loss: 0.152  Val. score: 95.450%\n",
      "Epoch 6, 100% \t Train loss: 0.178 took: 4.63s  Val. loss: 0.140  Val. score: 95.722%\n",
      "Epoch 7, 100% \t Train loss: 0.161 took: 4.64s  Val. loss: 0.129  Val. score: 96.150%\n",
      "Epoch 8, 100% \t Train loss: 0.147 took: 4.38s  Val. loss: 0.122  Val. score: 96.272%\n",
      "Epoch 9, 100% \t Train loss: 0.136 took: 4.29s  Val. loss: 0.118  Val. score: 96.478%\n",
      "Epoch 10, 100% \t Train loss: 0.123 took: 4.68s  Val. loss: 0.112  Val. score: 96.678%\n",
      "Epoch 11, 100% \t Train loss: 0.117 took: 4.65s  Val. loss: 0.107  Val. score: 96.806%\n",
      "Epoch 12, 100% \t Train loss: 0.111 took: 4.59s  Val. loss: 0.105  Val. score: 96.950%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, 100% \t Train loss: 0.103 took: 4.34s  Val. loss: 0.105  Val. score: 96.889%\n",
      "Epoch 14, 100% \t Train loss: 0.099 took: 4.52s  Val. loss: 0.102  Val. score: 96.994%\n",
      "Epoch 15, 100% \t Train loss: 0.092 took: 4.65s  Val. loss: 0.101  Val. score: 97.061%\n",
      "Training finished, took 117.040s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.751 took: 4.56s  Val. loss: 0.338  Val. score: 90.417%\n",
      "Epoch 2, 100% \t Train loss: 0.368 took: 4.41s  Val. loss: 0.250  Val. score: 92.783%\n",
      "Epoch 3, 100% \t Train loss: 0.290 took: 4.30s  Val. loss: 0.205  Val. score: 93.933%\n",
      "Epoch 4, 100% \t Train loss: 0.243 took: 4.37s  Val. loss: 0.179  Val. score: 94.594%\n",
      "Epoch 5, 100% \t Train loss: 0.214 took: 4.58s  Val. loss: 0.158  Val. score: 95.267%\n",
      "Epoch 6, 100% \t Train loss: 0.188 took: 4.31s  Val. loss: 0.143  Val. score: 95.672%\n",
      "Epoch 7, 100% \t Train loss: 0.171 took: 4.51s  Val. loss: 0.135  Val. score: 96.017%\n",
      "Epoch 8, 100% \t Train loss: 0.159 took: 4.52s  Val. loss: 0.123  Val. score: 96.333%\n",
      "Epoch 9, 100% \t Train loss: 0.140 took: 4.31s  Val. loss: 0.120  Val. score: 96.483%\n",
      "Epoch 10, 100% \t Train loss: 0.133 took: 4.54s  Val. loss: 0.114  Val. score: 96.578%\n",
      "Epoch 11, 100% \t Train loss: 0.119 took: 4.51s  Val. loss: 0.107  Val. score: 96.794%\n",
      "Epoch 12, 100% \t Train loss: 0.115 took: 4.36s  Val. loss: 0.104  Val. score: 96.894%\n",
      "Epoch 13, 100% \t Train loss: 0.109 took: 4.54s  Val. loss: 0.101  Val. score: 96.939%\n",
      "Epoch 14, 100% \t Train loss: 0.104 took: 4.27s  Val. loss: 0.097  Val. score: 97.122%\n",
      "Epoch 15, 100% \t Train loss: 0.096 took: 4.44s  Val. loss: 0.099  Val. score: 97.072%\n",
      "Training finished, took 115.602s\n",
      "\n",
      "Parameters configuration 4 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002127154319064286\n",
      "h_sizes \t [784, 174, 33]\n",
      "penalty \t 0.005947730126911706\n",
      "dropout \t 0.23362598746376456\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.1111 +/- 0.0630\n",
      "Time for evaluation: 349.7 s\n",
      "Estimated time to finish : 11.56 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.559 took: 6.55s  Val. loss: 0.245  Val. score: 92.944%\n",
      "Epoch 2, 100% \t Train loss: 0.230 took: 6.69s  Val. loss: 0.168  Val. score: 95.128%\n",
      "Epoch 3, 100% \t Train loss: 0.166 took: 7.03s  Val. loss: 0.131  Val. score: 96.117%\n",
      "Epoch 4, 100% \t Train loss: 0.131 took: 6.86s  Val. loss: 0.121  Val. score: 96.528%\n",
      "Epoch 5, 100% \t Train loss: 0.104 took: 7.05s  Val. loss: 0.109  Val. score: 96.833%\n",
      "Epoch 6, 100% \t Train loss: 0.086 took: 7.28s  Val. loss: 0.102  Val. score: 97.139%\n",
      "Epoch 7, 100% \t Train loss: 0.070 took: 6.82s  Val. loss: 0.099  Val. score: 97.278%\n",
      "Epoch 8, 100% \t Train loss: 0.059 took: 6.99s  Val. loss: 0.098  Val. score: 97.289%\n",
      "Epoch 9, 100% \t Train loss: 0.051 took: 6.97s  Val. loss: 0.093  Val. score: 97.489%\n",
      "Epoch 10, 100% \t Train loss: 0.044 took: 6.65s  Val. loss: 0.091  Val. score: 97.639%\n",
      "Epoch 11, 100% \t Train loss: 0.036 took: 6.65s  Val. loss: 0.098  Val. score: 97.550%\n",
      "Epoch 12, 100% \t Train loss: 0.030 took: 7.24s  Val. loss: 0.100  Val. score: 97.622%\n",
      "Epoch 13, 100% \t Train loss: 0.028 took: 7.13s  Val. loss: 0.093  Val. score: 97.667%\n",
      "Epoch 14, 100% \t Train loss: 0.025 took: 6.94s  Val. loss: 0.098  Val. score: 97.628%\n",
      "Epoch 15, 100% \t Train loss: 0.021 took: 6.73s  Val. loss: 0.100  Val. score: 97.678%\n",
      "Training finished, took 164.613s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.560 took: 6.18s  Val. loss: 0.217  Val. score: 93.744%\n",
      "Epoch 2, 100% \t Train loss: 0.223 took: 6.09s  Val. loss: 0.159  Val. score: 95.244%\n",
      "Epoch 3, 100% \t Train loss: 0.157 took: 7.05s  Val. loss: 0.129  Val. score: 96.244%\n",
      "Epoch 4, 100% \t Train loss: 0.123 took: 6.87s  Val. loss: 0.121  Val. score: 96.294%\n",
      "Epoch 5, 100% \t Train loss: 0.098 took: 6.84s  Val. loss: 0.105  Val. score: 96.844%\n",
      "Epoch 6, 100% \t Train loss: 0.080 took: 7.23s  Val. loss: 0.097  Val. score: 97.161%\n",
      "Epoch 7, 100% \t Train loss: 0.067 took: 6.87s  Val. loss: 0.093  Val. score: 97.294%\n",
      "Epoch 8, 100% \t Train loss: 0.058 took: 7.07s  Val. loss: 0.089  Val. score: 97.406%\n",
      "Epoch 9, 100% \t Train loss: 0.049 took: 7.16s  Val. loss: 0.090  Val. score: 97.317%\n",
      "Epoch 10, 100% \t Train loss: 0.042 took: 6.69s  Val. loss: 0.087  Val. score: 97.567%\n",
      "Epoch 11, 100% \t Train loss: 0.035 took: 7.13s  Val. loss: 0.088  Val. score: 97.717%\n",
      "Epoch 12, 100% \t Train loss: 0.032 took: 7.08s  Val. loss: 0.085  Val. score: 97.661%\n",
      "Epoch 13, 100% \t Train loss: 0.026 took: 6.92s  Val. loss: 0.091  Val. score: 97.683%\n",
      "Epoch 14, 100% \t Train loss: 0.022 took: 6.74s  Val. loss: 0.090  Val. score: 97.794%\n",
      "Epoch 15, 100% \t Train loss: 0.023 took: 7.02s  Val. loss: 0.088  Val. score: 97.678%\n",
      "Training finished, took 164.905s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.551 took: 6.71s  Val. loss: 0.229  Val. score: 93.056%\n",
      "Epoch 2, 100% \t Train loss: 0.230 took: 6.67s  Val. loss: 0.180  Val. score: 94.472%\n",
      "Epoch 3, 100% \t Train loss: 0.166 took: 6.63s  Val. loss: 0.132  Val. score: 96.078%\n",
      "Epoch 4, 100% \t Train loss: 0.128 took: 7.01s  Val. loss: 0.118  Val. score: 96.417%\n",
      "Epoch 5, 100% \t Train loss: 0.106 took: 6.90s  Val. loss: 0.112  Val. score: 96.683%\n",
      "Epoch 6, 100% \t Train loss: 0.087 took: 7.35s  Val. loss: 0.106  Val. score: 96.894%\n",
      "Epoch 7, 100% \t Train loss: 0.072 took: 6.87s  Val. loss: 0.096  Val. score: 97.083%\n",
      "Epoch 8, 100% \t Train loss: 0.063 took: 7.34s  Val. loss: 0.099  Val. score: 97.128%\n",
      "Epoch 9, 100% \t Train loss: 0.050 took: 7.14s  Val. loss: 0.094  Val. score: 97.250%\n",
      "Epoch 10, 100% \t Train loss: 0.045 took: 7.07s  Val. loss: 0.096  Val. score: 97.439%\n",
      "Epoch 11, 100% \t Train loss: 0.039 took: 7.09s  Val. loss: 0.099  Val. score: 97.350%\n",
      "Epoch 12, 100% \t Train loss: 0.033 took: 7.15s  Val. loss: 0.096  Val. score: 97.422%\n",
      "Epoch 13, 100% \t Train loss: 0.031 took: 7.52s  Val. loss: 0.101  Val. score: 97.406%\n",
      "Epoch 14, 100% \t Train loss: 0.025 took: 6.90s  Val. loss: 0.098  Val. score: 97.450%\n",
      "Epoch 15, 100% \t Train loss: 0.023 took: 7.27s  Val. loss: 0.091  Val. score: 97.722%\n",
      "Training finished, took 167.189s\n",
      "\n",
      "Parameters configuration 5 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003996024018867443\n",
      "h_sizes \t [784, 278, 94, 24]\n",
      "penalty \t 0.0014430192249231507\n",
      "dropout \t 0.08787206607182774\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6926 +/- 0.0210\n",
      "Time for evaluation: 497.9 s\n",
      "Estimated time to finish : 11.78 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.438 took: 4.52s  Val. loss: 0.191  Val. score: 94.456%\n",
      "Epoch 2, 100% \t Train loss: 0.198 took: 4.50s  Val. loss: 0.137  Val. score: 95.872%\n",
      "Epoch 3, 100% \t Train loss: 0.146 took: 5.03s  Val. loss: 0.117  Val. score: 96.600%\n",
      "Epoch 4, 100% \t Train loss: 0.114 took: 4.80s  Val. loss: 0.104  Val. score: 96.822%\n",
      "Epoch 5, 100% \t Train loss: 0.093 took: 5.16s  Val. loss: 0.098  Val. score: 97.161%\n",
      "Epoch 6, 100% \t Train loss: 0.078 took: 5.32s  Val. loss: 0.090  Val. score: 97.361%\n",
      "Epoch 7, 100% \t Train loss: 0.068 took: 4.86s  Val. loss: 0.086  Val. score: 97.467%\n",
      "Epoch 8, 100% \t Train loss: 0.057 took: 5.29s  Val. loss: 0.086  Val. score: 97.622%\n",
      "Epoch 9, 100% \t Train loss: 0.051 took: 5.25s  Val. loss: 0.085  Val. score: 97.733%\n",
      "Epoch 10, 100% \t Train loss: 0.048 took: 5.18s  Val. loss: 0.085  Val. score: 97.700%\n",
      "Epoch 11, 100% \t Train loss: 0.040 took: 5.06s  Val. loss: 0.092  Val. score: 97.728%\n",
      "Epoch 12, 100% \t Train loss: 0.037 took: 4.83s  Val. loss: 0.090  Val. score: 97.683%\n",
      "Epoch 13, 100% \t Train loss: 0.033 took: 5.05s  Val. loss: 0.088  Val. score: 97.783%\n",
      "Epoch 14, 100% \t Train loss: 0.031 took: 4.83s  Val. loss: 0.089  Val. score: 97.761%\n",
      "Epoch 15, 100% \t Train loss: 0.029 took: 5.10s  Val. loss: 0.092  Val. score: 97.728%\n",
      "Training finished, took 125.433s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 100% \t Train loss: 0.431 took: 4.54s  Val. loss: 0.218  Val. score: 93.450%\n",
      "Epoch 2, 100% \t Train loss: 0.199 took: 4.69s  Val. loss: 0.149  Val. score: 95.567%\n",
      "Epoch 3, 100% \t Train loss: 0.142 took: 4.51s  Val. loss: 0.123  Val. score: 96.200%\n",
      "Epoch 4, 100% \t Train loss: 0.111 took: 4.68s  Val. loss: 0.111  Val. score: 96.656%\n",
      "Epoch 5, 100% \t Train loss: 0.089 took: 5.05s  Val. loss: 0.101  Val. score: 96.906%\n",
      "Epoch 6, 100% \t Train loss: 0.077 took: 5.05s  Val. loss: 0.101  Val. score: 96.989%\n",
      "Epoch 7, 100% \t Train loss: 0.065 took: 5.07s  Val. loss: 0.097  Val. score: 97.222%\n",
      "Epoch 8, 100% \t Train loss: 0.056 took: 4.75s  Val. loss: 0.101  Val. score: 97.156%\n",
      "Epoch 9, 100% \t Train loss: 0.050 took: 5.13s  Val. loss: 0.097  Val. score: 97.256%\n",
      "Epoch 10, 100% \t Train loss: 0.042 took: 5.14s  Val. loss: 0.097  Val. score: 97.400%\n",
      "Epoch 11, 100% \t Train loss: 0.036 took: 5.11s  Val. loss: 0.093  Val. score: 97.450%\n",
      "Epoch 12, 100% \t Train loss: 0.034 took: 4.90s  Val. loss: 0.096  Val. score: 97.461%\n",
      "Epoch 13, 100% \t Train loss: 0.029 took: 5.22s  Val. loss: 0.101  Val. score: 97.494%\n",
      "Epoch 14, 100% \t Train loss: 0.027 took: 4.63s  Val. loss: 0.102  Val. score: 97.544%\n",
      "Epoch 15, 100% \t Train loss: 0.024 took: 5.03s  Val. loss: 0.102  Val. score: 97.606%\n",
      "Training finished, took 124.463s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.416 took: 4.53s  Val. loss: 0.212  Val. score: 93.622%\n",
      "Epoch 2, 100% \t Train loss: 0.187 took: 4.76s  Val. loss: 0.145  Val. score: 95.478%\n",
      "Epoch 3, 100% \t Train loss: 0.139 took: 4.61s  Val. loss: 0.128  Val. score: 95.956%\n",
      "Epoch 4, 100% \t Train loss: 0.108 took: 5.01s  Val. loss: 0.109  Val. score: 96.544%\n",
      "Epoch 5, 100% \t Train loss: 0.088 took: 5.03s  Val. loss: 0.108  Val. score: 96.728%\n",
      "Epoch 6, 100% \t Train loss: 0.076 took: 4.86s  Val. loss: 0.091  Val. score: 97.156%\n",
      "Epoch 7, 100% \t Train loss: 0.063 took: 4.76s  Val. loss: 0.089  Val. score: 97.194%\n",
      "Epoch 8, 100% \t Train loss: 0.058 took: 5.18s  Val. loss: 0.089  Val. score: 97.278%\n",
      "Epoch 9, 100% \t Train loss: 0.046 took: 5.03s  Val. loss: 0.083  Val. score: 97.461%\n",
      "Epoch 10, 100% \t Train loss: 0.042 took: 4.97s  Val. loss: 0.088  Val. score: 97.406%\n",
      "Epoch 11, 100% \t Train loss: 0.040 took: 5.13s  Val. loss: 0.083  Val. score: 97.550%\n",
      "Epoch 12, 100% \t Train loss: 0.033 took: 5.07s  Val. loss: 0.085  Val. score: 97.556%\n",
      "Epoch 13, 100% \t Train loss: 0.030 took: 5.06s  Val. loss: 0.088  Val. score: 97.444%\n",
      "Epoch 14, 100% \t Train loss: 0.027 took: 5.06s  Val. loss: 0.086  Val. score: 97.583%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 4.75s  Val. loss: 0.084  Val. score: 97.772%\n",
      "Training finished, took 124.696s\n",
      "\n",
      "Parameters configuration 6 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.006976691710649004\n",
      "h_sizes \t [784, 178, 42]\n",
      "penalty \t 0.0009339836188174311\n",
      "dropout \t 0.10650789713620981\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.7019 +/- 0.0705\n",
      "Time for evaluation: 375.8 s\n",
      "Estimated time to finish : 11.35 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.597 took: 8.63s  Val. loss: 0.265  Val. score: 92.194%\n",
      "Epoch 2, 100% \t Train loss: 0.217 took: 8.38s  Val. loss: 0.153  Val. score: 95.533%\n",
      "Epoch 3, 100% \t Train loss: 0.152 took: 9.09s  Val. loss: 0.144  Val. score: 96.006%\n",
      "Epoch 4, 100% \t Train loss: 0.119 took: 8.67s  Val. loss: 0.126  Val. score: 96.722%\n",
      "Epoch 5, 100% \t Train loss: 0.095 took: 9.38s  Val. loss: 0.114  Val. score: 97.067%\n",
      "Epoch 6, 100% \t Train loss: 0.080 took: 9.31s  Val. loss: 0.115  Val. score: 97.211%\n",
      "Epoch 7, 100% \t Train loss: 0.069 took: 9.08s  Val. loss: 0.109  Val. score: 97.433%\n",
      "Epoch 8, 100% \t Train loss: 0.055 took: 8.98s  Val. loss: 0.109  Val. score: 97.378%\n",
      "Epoch 9, 100% \t Train loss: 0.048 took: 9.41s  Val. loss: 0.112  Val. score: 97.411%\n",
      "Epoch 10, 100% \t Train loss: 0.043 took: 9.15s  Val. loss: 0.111  Val. score: 97.572%\n",
      "Epoch 11, 100% \t Train loss: 0.037 took: 8.63s  Val. loss: 0.129  Val. score: 97.539%\n",
      "Epoch 12, 100% \t Train loss: 0.032 took: 8.97s  Val. loss: 0.127  Val. score: 97.422%\n",
      "Epoch 13, 100% \t Train loss: 0.031 took: 8.79s  Val. loss: 0.120  Val. score: 97.706%\n",
      "Epoch 14, 100% \t Train loss: 0.025 took: 9.12s  Val. loss: 0.130  Val. score: 97.622%\n",
      "Epoch 15, 100% \t Train loss: 0.024 took: 9.36s  Val. loss: 0.139  Val. score: 97.467%\n",
      "Training finished, took 205.799s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.650 took: 8.71s  Val. loss: 0.227  Val. score: 93.361%\n",
      "Epoch 2, 100% \t Train loss: 0.236 took: 8.04s  Val. loss: 0.152  Val. score: 95.478%\n",
      "Epoch 3, 100% \t Train loss: 0.163 took: 8.44s  Val. loss: 0.136  Val. score: 96.133%\n",
      "Epoch 4, 100% \t Train loss: 0.131 took: 8.76s  Val. loss: 0.123  Val. score: 96.383%\n",
      "Epoch 5, 100% \t Train loss: 0.104 took: 8.69s  Val. loss: 0.105  Val. score: 97.167%\n",
      "Epoch 6, 100% \t Train loss: 0.084 took: 9.19s  Val. loss: 0.106  Val. score: 97.272%\n",
      "Epoch 7, 100% \t Train loss: 0.073 took: 9.20s  Val. loss: 0.121  Val. score: 96.778%\n",
      "Epoch 8, 100% \t Train loss: 0.060 took: 9.05s  Val. loss: 0.100  Val. score: 97.422%\n",
      "Epoch 9, 100% \t Train loss: 0.052 took: 9.28s  Val. loss: 0.104  Val. score: 97.472%\n",
      "Epoch 10, 100% \t Train loss: 0.046 took: 9.43s  Val. loss: 0.107  Val. score: 97.444%\n",
      "Epoch 11, 100% \t Train loss: 0.039 took: 8.95s  Val. loss: 0.105  Val. score: 97.528%\n",
      "Epoch 12, 100% \t Train loss: 0.034 took: 9.09s  Val. loss: 0.104  Val. score: 97.517%\n",
      "Epoch 13, 100% \t Train loss: 0.034 took: 8.80s  Val. loss: 0.100  Val. score: 97.711%\n",
      "Epoch 14, 100% \t Train loss: 0.026 took: 9.20s  Val. loss: 0.111  Val. score: 97.661%\n",
      "Epoch 15, 100% \t Train loss: 0.026 took: 8.79s  Val. loss: 0.125  Val. score: 97.472%\n",
      "Training finished, took 203.460s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.585 took: 8.70s  Val. loss: 0.206  Val. score: 94.217%\n",
      "Epoch 2, 100% \t Train loss: 0.219 took: 8.41s  Val. loss: 0.137  Val. score: 96.150%\n",
      "Epoch 3, 100% \t Train loss: 0.153 took: 8.73s  Val. loss: 0.134  Val. score: 96.256%\n",
      "Epoch 4, 100% \t Train loss: 0.120 took: 8.68s  Val. loss: 0.104  Val. score: 97.017%\n",
      "Epoch 5, 100% \t Train loss: 0.101 took: 8.71s  Val. loss: 0.109  Val. score: 97.222%\n",
      "Epoch 6, 100% \t Train loss: 0.081 took: 8.80s  Val. loss: 0.101  Val. score: 97.300%\n",
      "Epoch 7, 100% \t Train loss: 0.067 took: 8.60s  Val. loss: 0.099  Val. score: 97.433%\n",
      "Epoch 8, 100% \t Train loss: 0.057 took: 8.54s  Val. loss: 0.104  Val. score: 97.500%\n",
      "Epoch 9, 100% \t Train loss: 0.047 took: 8.62s  Val. loss: 0.107  Val. score: 97.522%\n",
      "Epoch 10, 100% \t Train loss: 0.042 took: 9.25s  Val. loss: 0.103  Val. score: 97.650%\n",
      "Epoch 11, 100% \t Train loss: 0.035 took: 8.83s  Val. loss: 0.102  Val. score: 97.694%\n",
      "Epoch 12, 100% \t Train loss: 0.033 took: 8.55s  Val. loss: 0.106  Val. score: 97.506%\n",
      "Epoch 13, 100% \t Train loss: 0.028 took: 8.93s  Val. loss: 0.112  Val. score: 97.689%\n",
      "Epoch 14, 100% \t Train loss: 0.026 took: 9.35s  Val. loss: 0.113  Val. score: 97.556%\n",
      "Epoch 15, 100% \t Train loss: 0.024 took: 8.71s  Val. loss: 0.112  Val. score: 97.550%\n",
      "Training finished, took 201.576s\n",
      "\n",
      "Parameters configuration 7 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0059451919376209625\n",
      "h_sizes \t [784, 334, 146, 63, 21]\n",
      "penalty \t 0.001554835453081733\n",
      "dropout \t 0.11094956824313185\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4963 +/- 0.0380\n",
      "Time for evaluation: 612.0 s\n",
      "Estimated time to finish : 11.88 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.660 took: 6.24s  Val. loss: 0.262  Val. score: 92.344%\n",
      "Epoch 2, 100% \t Train loss: 0.280 took: 6.92s  Val. loss: 0.185  Val. score: 94.656%\n",
      "Epoch 3, 100% \t Train loss: 0.203 took: 7.06s  Val. loss: 0.148  Val. score: 95.700%\n",
      "Epoch 4, 100% \t Train loss: 0.162 took: 6.85s  Val. loss: 0.134  Val. score: 96.022%\n",
      "Epoch 5, 100% \t Train loss: 0.138 took: 6.86s  Val. loss: 0.121  Val. score: 96.511%\n",
      "Epoch 6, 100% \t Train loss: 0.116 took: 6.68s  Val. loss: 0.119  Val. score: 96.722%\n",
      "Epoch 7, 100% \t Train loss: 0.103 took: 7.26s  Val. loss: 0.110  Val. score: 96.978%\n",
      "Epoch 8, 100% \t Train loss: 0.086 took: 7.10s  Val. loss: 0.105  Val. score: 97.094%\n",
      "Epoch 9, 100% \t Train loss: 0.081 took: 7.08s  Val. loss: 0.111  Val. score: 97.050%\n",
      "Epoch 10, 100% \t Train loss: 0.075 took: 6.86s  Val. loss: 0.103  Val. score: 97.289%\n",
      "Epoch 11, 100% \t Train loss: 0.063 took: 6.95s  Val. loss: 0.104  Val. score: 97.283%\n",
      "Epoch 12, 100% \t Train loss: 0.061 took: 6.88s  Val. loss: 0.095  Val. score: 97.428%\n",
      "Epoch 13, 100% \t Train loss: 0.053 took: 7.19s  Val. loss: 0.097  Val. score: 97.494%\n",
      "Epoch 14, 100% \t Train loss: 0.051 took: 7.07s  Val. loss: 0.097  Val. score: 97.556%\n",
      "Epoch 15, 100% \t Train loss: 0.047 took: 7.38s  Val. loss: 0.093  Val. score: 97.606%\n",
      "Training finished, took 166.448s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.670 took: 6.24s  Val. loss: 0.265  Val. score: 92.150%\n",
      "Epoch 2, 100% \t Train loss: 0.296 took: 6.26s  Val. loss: 0.189  Val. score: 94.561%\n",
      "Epoch 3, 100% \t Train loss: 0.220 took: 6.52s  Val. loss: 0.154  Val. score: 95.433%\n",
      "Epoch 4, 100% \t Train loss: 0.175 took: 6.91s  Val. loss: 0.140  Val. score: 95.800%\n",
      "Epoch 5, 100% \t Train loss: 0.150 took: 6.76s  Val. loss: 0.118  Val. score: 96.617%\n",
      "Epoch 6, 100% \t Train loss: 0.125 took: 6.99s  Val. loss: 0.116  Val. score: 96.767%\n",
      "Epoch 7, 100% \t Train loss: 0.111 took: 6.64s  Val. loss: 0.102  Val. score: 97.167%\n",
      "Epoch 8, 100% \t Train loss: 0.095 took: 6.77s  Val. loss: 0.100  Val. score: 97.294%\n",
      "Epoch 9, 100% \t Train loss: 0.086 took: 6.71s  Val. loss: 0.101  Val. score: 97.278%\n",
      "Epoch 10, 100% \t Train loss: 0.078 took: 6.93s  Val. loss: 0.095  Val. score: 97.400%\n",
      "Epoch 11, 100% \t Train loss: 0.067 took: 6.82s  Val. loss: 0.098  Val. score: 97.378%\n",
      "Epoch 12, 100% \t Train loss: 0.061 took: 7.13s  Val. loss: 0.092  Val. score: 97.567%\n",
      "Epoch 13, 100% \t Train loss: 0.058 took: 7.00s  Val. loss: 0.091  Val. score: 97.589%\n",
      "Epoch 14, 100% \t Train loss: 0.051 took: 6.65s  Val. loss: 0.099  Val. score: 97.544%\n",
      "Epoch 15, 100% \t Train loss: 0.049 took: 7.01s  Val. loss: 0.095  Val. score: 97.706%\n",
      "Training finished, took 162.609s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.648 took: 6.40s  Val. loss: 0.255  Val. score: 92.289%\n",
      "Epoch 2, 100% \t Train loss: 0.279 took: 6.44s  Val. loss: 0.183  Val. score: 94.450%\n",
      "Epoch 3, 100% \t Train loss: 0.207 took: 6.94s  Val. loss: 0.144  Val. score: 95.644%\n",
      "Epoch 4, 100% \t Train loss: 0.168 took: 6.73s  Val. loss: 0.128  Val. score: 96.039%\n",
      "Epoch 5, 100% \t Train loss: 0.142 took: 6.77s  Val. loss: 0.129  Val. score: 96.061%\n",
      "Epoch 6, 100% \t Train loss: 0.120 took: 6.59s  Val. loss: 0.104  Val. score: 96.911%\n",
      "Epoch 7, 100% \t Train loss: 0.106 took: 7.17s  Val. loss: 0.099  Val. score: 97.044%\n",
      "Epoch 8, 100% \t Train loss: 0.091 took: 6.80s  Val. loss: 0.097  Val. score: 97.150%\n",
      "Epoch 9, 100% \t Train loss: 0.079 took: 7.05s  Val. loss: 0.094  Val. score: 97.367%\n",
      "Epoch 10, 100% \t Train loss: 0.072 took: 7.12s  Val. loss: 0.093  Val. score: 97.344%\n",
      "Epoch 11, 100% \t Train loss: 0.066 took: 7.01s  Val. loss: 0.089  Val. score: 97.461%\n",
      "Epoch 12, 100% \t Train loss: 0.059 took: 7.18s  Val. loss: 0.088  Val. score: 97.567%\n",
      "Epoch 13, 100% \t Train loss: 0.056 took: 7.25s  Val. loss: 0.094  Val. score: 97.472%\n",
      "Epoch 14, 100% \t Train loss: 0.050 took: 6.74s  Val. loss: 0.088  Val. score: 97.622%\n",
      "Epoch 15, 100% \t Train loss: 0.044 took: 6.66s  Val. loss: 0.087  Val. score: 97.661%\n",
      "Training finished, took 163.648s\n",
      "\n",
      "Parameters configuration 8 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0029800367698189652\n",
      "h_sizes \t [784, 274, 106, 34]\n",
      "penalty \t 0.005613113079154965\n",
      "dropout \t 0.21114187517953323\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6574 +/- 0.0409\n",
      "Time for evaluation: 493.9 s\n",
      "Estimated time to finish : 11.86 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.489 took: 4.68s  Val. loss: 0.212  Val. score: 93.883%\n",
      "Epoch 2, 100% \t Train loss: 0.236 took: 4.68s  Val. loss: 0.160  Val. score: 95.306%\n",
      "Epoch 3, 100% \t Train loss: 0.179 took: 4.58s  Val. loss: 0.137  Val. score: 95.944%\n",
      "Epoch 4, 100% \t Train loss: 0.145 took: 4.75s  Val. loss: 0.116  Val. score: 96.633%\n",
      "Epoch 5, 100% \t Train loss: 0.126 took: 4.93s  Val. loss: 0.111  Val. score: 96.717%\n",
      "Epoch 6, 100% \t Train loss: 0.107 took: 5.01s  Val. loss: 0.102  Val. score: 96.972%\n",
      "Epoch 7, 100% \t Train loss: 0.095 took: 4.83s  Val. loss: 0.095  Val. score: 97.206%\n",
      "Epoch 8, 100% \t Train loss: 0.083 took: 5.02s  Val. loss: 0.094  Val. score: 97.439%\n",
      "Epoch 9, 100% \t Train loss: 0.078 took: 4.62s  Val. loss: 0.093  Val. score: 97.356%\n",
      "Epoch 10, 100% \t Train loss: 0.072 took: 4.75s  Val. loss: 0.087  Val. score: 97.489%\n",
      "Epoch 11, 100% \t Train loss: 0.065 took: 4.99s  Val. loss: 0.090  Val. score: 97.628%\n",
      "Epoch 12, 100% \t Train loss: 0.058 took: 5.06s  Val. loss: 0.093  Val. score: 97.500%\n",
      "Epoch 13, 100% \t Train loss: 0.054 took: 4.89s  Val. loss: 0.092  Val. score: 97.578%\n",
      "Epoch 14, 100% \t Train loss: 0.050 took: 4.56s  Val. loss: 0.096  Val. score: 97.617%\n",
      "Epoch 15, 100% \t Train loss: 0.049 took: 4.68s  Val. loss: 0.092  Val. score: 97.644%\n",
      "Training finished, took 123.607s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.481 took: 5.02s  Val. loss: 0.223  Val. score: 93.494%\n",
      "Epoch 2, 100% \t Train loss: 0.224 took: 4.99s  Val. loss: 0.166  Val. score: 95.039%\n",
      "Epoch 3, 100% \t Train loss: 0.170 took: 4.70s  Val. loss: 0.142  Val. score: 95.706%\n",
      "Epoch 4, 100% \t Train loss: 0.138 took: 5.03s  Val. loss: 0.121  Val. score: 96.417%\n",
      "Epoch 5, 100% \t Train loss: 0.119 took: 4.77s  Val. loss: 0.112  Val. score: 96.589%\n",
      "Epoch 6, 100% \t Train loss: 0.104 took: 4.62s  Val. loss: 0.105  Val. score: 96.772%\n",
      "Epoch 7, 100% \t Train loss: 0.095 took: 5.23s  Val. loss: 0.103  Val. score: 96.928%\n",
      "Epoch 8, 100% \t Train loss: 0.083 took: 4.62s  Val. loss: 0.102  Val. score: 97.100%\n",
      "Epoch 9, 100% \t Train loss: 0.078 took: 4.66s  Val. loss: 0.101  Val. score: 97.111%\n",
      "Epoch 10, 100% \t Train loss: 0.068 took: 4.60s  Val. loss: 0.092  Val. score: 97.383%\n",
      "Epoch 11, 100% \t Train loss: 0.062 took: 4.85s  Val. loss: 0.093  Val. score: 97.261%\n",
      "Epoch 12, 100% \t Train loss: 0.058 took: 4.58s  Val. loss: 0.093  Val. score: 97.367%\n",
      "Epoch 13, 100% \t Train loss: 0.054 took: 4.78s  Val. loss: 0.092  Val. score: 97.400%\n",
      "Epoch 14, 100% \t Train loss: 0.047 took: 4.58s  Val. loss: 0.098  Val. score: 97.411%\n",
      "Epoch 15, 100% \t Train loss: 0.048 took: 4.56s  Val. loss: 0.092  Val. score: 97.444%\n",
      "Training finished, took 122.734s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.466 took: 4.56s  Val. loss: 0.207  Val. score: 93.983%\n",
      "Epoch 2, 100% \t Train loss: 0.225 took: 4.70s  Val. loss: 0.155  Val. score: 95.228%\n",
      "Epoch 3, 100% \t Train loss: 0.173 took: 4.78s  Val. loss: 0.130  Val. score: 96.006%\n",
      "Epoch 4, 100% \t Train loss: 0.143 took: 4.98s  Val. loss: 0.106  Val. score: 96.717%\n",
      "Epoch 5, 100% \t Train loss: 0.122 took: 4.58s  Val. loss: 0.102  Val. score: 96.922%\n",
      "Epoch 6, 100% \t Train loss: 0.106 took: 4.69s  Val. loss: 0.103  Val. score: 96.906%\n",
      "Epoch 7, 100% \t Train loss: 0.092 took: 4.88s  Val. loss: 0.089  Val. score: 97.206%\n",
      "Epoch 8, 100% \t Train loss: 0.089 took: 5.09s  Val. loss: 0.089  Val. score: 97.317%\n",
      "Epoch 9, 100% \t Train loss: 0.079 took: 4.69s  Val. loss: 0.090  Val. score: 97.344%\n",
      "Epoch 10, 100% \t Train loss: 0.069 took: 5.03s  Val. loss: 0.085  Val. score: 97.406%\n",
      "Epoch 11, 100% \t Train loss: 0.066 took: 4.92s  Val. loss: 0.081  Val. score: 97.661%\n",
      "Epoch 12, 100% \t Train loss: 0.060 took: 5.05s  Val. loss: 0.086  Val. score: 97.550%\n",
      "Epoch 13, 100% \t Train loss: 0.056 took: 4.84s  Val. loss: 0.085  Val. score: 97.594%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, 100% \t Train loss: 0.053 took: 4.81s  Val. loss: 0.081  Val. score: 97.644%\n",
      "Epoch 15, 100% \t Train loss: 0.049 took: 4.95s  Val. loss: 0.087  Val. score: 97.600%\n",
      "Training finished, took 124.277s\n",
      "\n",
      "Parameters configuration 9 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005553663266334762\n",
      "h_sizes \t [784, 201, 45]\n",
      "penalty \t 0.0033449836450673755\n",
      "dropout \t 0.22928445893051744\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.5630 +/- 0.0857\n",
      "Time for evaluation: 371.8 s\n",
      "Estimated time to finish : 11.47 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.763 took: 8.19s  Val. loss: 0.296  Val. score: 90.961%\n",
      "Epoch 2, 100% \t Train loss: 0.323 took: 8.24s  Val. loss: 0.193  Val. score: 94.122%\n",
      "Epoch 3, 100% \t Train loss: 0.229 took: 8.19s  Val. loss: 0.147  Val. score: 95.561%\n",
      "Epoch 4, 100% \t Train loss: 0.178 took: 8.76s  Val. loss: 0.131  Val. score: 96.011%\n",
      "Epoch 5, 100% \t Train loss: 0.144 took: 8.63s  Val. loss: 0.116  Val. score: 96.606%\n",
      "Epoch 6, 100% \t Train loss: 0.124 took: 8.16s  Val. loss: 0.118  Val. score: 96.539%\n",
      "Epoch 7, 100% \t Train loss: 0.104 took: 8.91s  Val. loss: 0.114  Val. score: 96.683%\n",
      "Epoch 8, 100% \t Train loss: 0.093 took: 8.50s  Val. loss: 0.106  Val. score: 97.050%\n",
      "Epoch 9, 100% \t Train loss: 0.081 took: 8.73s  Val. loss: 0.094  Val. score: 97.350%\n",
      "Epoch 10, 100% \t Train loss: 0.071 took: 8.16s  Val. loss: 0.094  Val. score: 97.528%\n",
      "Epoch 11, 100% \t Train loss: 0.063 took: 8.55s  Val. loss: 0.092  Val. score: 97.594%\n",
      "Epoch 12, 100% \t Train loss: 0.055 took: 8.73s  Val. loss: 0.092  Val. score: 97.661%\n",
      "Epoch 13, 100% \t Train loss: 0.050 took: 8.59s  Val. loss: 0.095  Val. score: 97.650%\n",
      "Epoch 14, 100% \t Train loss: 0.046 took: 8.54s  Val. loss: 0.092  Val. score: 97.728%\n",
      "Epoch 15, 100% \t Train loss: 0.042 took: 8.09s  Val. loss: 0.096  Val. score: 97.683%\n",
      "Training finished, took 196.271s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.830 took: 8.46s  Val. loss: 0.324  Val. score: 90.517%\n",
      "Epoch 2, 100% \t Train loss: 0.330 took: 8.05s  Val. loss: 0.203  Val. score: 94.117%\n",
      "Epoch 3, 100% \t Train loss: 0.229 took: 7.92s  Val. loss: 0.170  Val. score: 95.128%\n",
      "Epoch 4, 100% \t Train loss: 0.182 took: 8.54s  Val. loss: 0.149  Val. score: 95.789%\n",
      "Epoch 5, 100% \t Train loss: 0.150 took: 8.37s  Val. loss: 0.131  Val. score: 96.317%\n",
      "Epoch 6, 100% \t Train loss: 0.125 took: 8.39s  Val. loss: 0.122  Val. score: 96.594%\n",
      "Epoch 7, 100% \t Train loss: 0.104 took: 8.80s  Val. loss: 0.117  Val. score: 96.767%\n",
      "Epoch 8, 100% \t Train loss: 0.090 took: 8.67s  Val. loss: 0.113  Val. score: 96.967%\n",
      "Epoch 9, 100% \t Train loss: 0.079 took: 8.25s  Val. loss: 0.113  Val. score: 97.067%\n",
      "Epoch 10, 100% \t Train loss: 0.072 took: 8.33s  Val. loss: 0.108  Val. score: 97.283%\n",
      "Epoch 11, 100% \t Train loss: 0.062 took: 8.29s  Val. loss: 0.106  Val. score: 97.311%\n",
      "Epoch 12, 100% \t Train loss: 0.054 took: 8.84s  Val. loss: 0.110  Val. score: 97.361%\n",
      "Epoch 13, 100% \t Train loss: 0.052 took: 8.70s  Val. loss: 0.110  Val. score: 97.478%\n",
      "Epoch 14, 100% \t Train loss: 0.045 took: 8.21s  Val. loss: 0.109  Val. score: 97.417%\n",
      "Epoch 15, 100% \t Train loss: 0.039 took: 8.68s  Val. loss: 0.112  Val. score: 97.467%\n",
      "Training finished, took 196.039s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.827 took: 8.79s  Val. loss: 0.292  Val. score: 91.411%\n",
      "Epoch 2, 100% \t Train loss: 0.299 took: 8.24s  Val. loss: 0.188  Val. score: 94.661%\n",
      "Epoch 3, 100% \t Train loss: 0.213 took: 8.03s  Val. loss: 0.162  Val. score: 95.517%\n",
      "Epoch 4, 100% \t Train loss: 0.164 took: 8.89s  Val. loss: 0.144  Val. score: 95.867%\n",
      "Epoch 5, 100% \t Train loss: 0.136 took: 8.36s  Val. loss: 0.124  Val. score: 96.428%\n",
      "Epoch 6, 100% \t Train loss: 0.117 took: 8.13s  Val. loss: 0.121  Val. score: 96.644%\n",
      "Epoch 7, 100% \t Train loss: 0.099 took: 8.30s  Val. loss: 0.112  Val. score: 96.828%\n",
      "Epoch 8, 100% \t Train loss: 0.089 took: 8.22s  Val. loss: 0.114  Val. score: 96.961%\n",
      "Epoch 9, 100% \t Train loss: 0.074 took: 8.89s  Val. loss: 0.109  Val. score: 97.067%\n",
      "Epoch 10, 100% \t Train loss: 0.069 took: 8.13s  Val. loss: 0.105  Val. score: 97.250%\n",
      "Epoch 11, 100% \t Train loss: 0.060 took: 8.15s  Val. loss: 0.114  Val. score: 97.228%\n",
      "Epoch 12, 100% \t Train loss: 0.053 took: 8.79s  Val. loss: 0.105  Val. score: 97.383%\n",
      "Epoch 13, 100% \t Train loss: 0.047 took: 8.39s  Val. loss: 0.108  Val. score: 97.311%\n",
      "Epoch 14, 100% \t Train loss: 0.042 took: 8.68s  Val. loss: 0.100  Val. score: 97.589%\n",
      "Epoch 15, 100% \t Train loss: 0.041 took: 8.98s  Val. loss: 0.110  Val. score: 97.439%\n",
      "Training finished, took 195.958s\n",
      "\n",
      "Parameters configuration 10 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002313125799240196\n",
      "h_sizes \t [784, 335, 141, 67, 30]\n",
      "penalty \t 0.0005639313220331014\n",
      "dropout \t 0.1631600963255291\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5296 +/- 0.1093\n",
      "Time for evaluation: 589.4 s\n",
      "Estimated time to finish : 11.69 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.356 took: 4.49s  Val. loss: 0.175  Val. score: 94.661%\n",
      "Epoch 2, 100% \t Train loss: 0.175 took: 4.49s  Val. loss: 0.139  Val. score: 95.939%\n",
      "Epoch 3, 100% \t Train loss: 0.129 took: 4.65s  Val. loss: 0.120  Val. score: 96.489%\n",
      "Epoch 4, 100% \t Train loss: 0.110 took: 4.66s  Val. loss: 0.114  Val. score: 96.572%\n",
      "Epoch 5, 100% \t Train loss: 0.092 took: 4.76s  Val. loss: 0.105  Val. score: 97.033%\n",
      "Epoch 6, 100% \t Train loss: 0.080 took: 4.81s  Val. loss: 0.105  Val. score: 97.061%\n",
      "Epoch 7, 100% \t Train loss: 0.070 took: 4.78s  Val. loss: 0.114  Val. score: 96.911%\n",
      "Epoch 8, 100% \t Train loss: 0.065 took: 4.74s  Val. loss: 0.102  Val. score: 97.089%\n",
      "Epoch 9, 100% \t Train loss: 0.059 took: 4.42s  Val. loss: 0.111  Val. score: 97.028%\n",
      "Epoch 10, 100% \t Train loss: 0.058 took: 4.41s  Val. loss: 0.114  Val. score: 97.006%\n",
      "Epoch 11, 100% \t Train loss: 0.048 took: 4.49s  Val. loss: 0.120  Val. score: 97.078%\n",
      "Epoch 12, 100% \t Train loss: 0.042 took: 4.43s  Val. loss: 0.109  Val. score: 97.411%\n",
      "Epoch 13, 100% \t Train loss: 0.046 took: 4.69s  Val. loss: 0.106  Val. score: 97.322%\n",
      "Epoch 14, 100% \t Train loss: 0.039 took: 4.65s  Val. loss: 0.110  Val. score: 97.306%\n",
      "Epoch 15, 100% \t Train loss: 0.035 took: 4.49s  Val. loss: 0.107  Val. score: 97.500%\n",
      "Training finished, took 117.115s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.410 took: 4.42s  Val. loss: 0.184  Val. score: 94.539%\n",
      "Epoch 2, 100% \t Train loss: 0.195 took: 4.25s  Val. loss: 0.133  Val. score: 96.067%\n",
      "Epoch 3, 100% \t Train loss: 0.150 took: 4.76s  Val. loss: 0.126  Val. score: 96.328%\n",
      "Epoch 4, 100% \t Train loss: 0.125 took: 4.66s  Val. loss: 0.112  Val. score: 96.722%\n",
      "Epoch 5, 100% \t Train loss: 0.107 took: 4.61s  Val. loss: 0.100  Val. score: 97.228%\n",
      "Epoch 6, 100% \t Train loss: 0.097 took: 4.86s  Val. loss: 0.099  Val. score: 97.194%\n",
      "Epoch 7, 100% \t Train loss: 0.084 took: 4.69s  Val. loss: 0.101  Val. score: 97.328%\n",
      "Epoch 8, 100% \t Train loss: 0.078 took: 4.47s  Val. loss: 0.105  Val. score: 97.394%\n",
      "Epoch 9, 100% \t Train loss: 0.073 took: 4.90s  Val. loss: 0.106  Val. score: 97.156%\n",
      "Epoch 10, 100% \t Train loss: 0.067 took: 4.78s  Val. loss: 0.105  Val. score: 97.306%\n",
      "Epoch 11, 100% \t Train loss: 0.059 took: 4.95s  Val. loss: 0.098  Val. score: 97.539%\n",
      "Epoch 12, 100% \t Train loss: 0.055 took: 4.66s  Val. loss: 0.100  Val. score: 97.433%\n",
      "Epoch 13, 100% \t Train loss: 0.051 took: 4.81s  Val. loss: 0.108  Val. score: 97.417%\n",
      "Epoch 14, 100% \t Train loss: 0.048 took: 4.96s  Val. loss: 0.106  Val. score: 97.389%\n",
      "Epoch 15, 100% \t Train loss: 0.048 took: 4.93s  Val. loss: 0.097  Val. score: 97.678%\n",
      "Training finished, took 119.069s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.374 took: 4.51s  Val. loss: 0.175  Val. score: 94.711%\n",
      "Epoch 2, 100% \t Train loss: 0.179 took: 4.14s  Val. loss: 0.140  Val. score: 95.650%\n",
      "Epoch 3, 100% \t Train loss: 0.136 took: 4.31s  Val. loss: 0.130  Val. score: 96.067%\n",
      "Epoch 4, 100% \t Train loss: 0.112 took: 4.80s  Val. loss: 0.115  Val. score: 96.583%\n",
      "Epoch 5, 100% \t Train loss: 0.096 took: 4.91s  Val. loss: 0.116  Val. score: 96.606%\n",
      "Epoch 6, 100% \t Train loss: 0.084 took: 4.43s  Val. loss: 0.096  Val. score: 97.172%\n",
      "Epoch 7, 100% \t Train loss: 0.072 took: 4.68s  Val. loss: 0.091  Val. score: 97.367%\n",
      "Epoch 8, 100% \t Train loss: 0.063 took: 4.61s  Val. loss: 0.105  Val. score: 97.167%\n",
      "Epoch 9, 100% \t Train loss: 0.057 took: 4.58s  Val. loss: 0.093  Val. score: 97.272%\n",
      "Epoch 10, 100% \t Train loss: 0.055 took: 4.76s  Val. loss: 0.113  Val. score: 96.928%\n",
      "Epoch 11, 100% \t Train loss: 0.051 took: 4.88s  Val. loss: 0.105  Val. score: 97.244%\n",
      "Epoch 12, 100% \t Train loss: 0.043 took: 4.76s  Val. loss: 0.100  Val. score: 97.411%\n",
      "Epoch 13, 100% \t Train loss: 0.044 took: 4.51s  Val. loss: 0.099  Val. score: 97.478%\n",
      "Epoch 14, 100% \t Train loss: 0.042 took: 4.69s  Val. loss: 0.098  Val. score: 97.622%\n",
      "Epoch 15, 100% \t Train loss: 0.037 took: 4.51s  Val. loss: 0.096  Val. score: 97.472%\n",
      "Training finished, took 117.916s\n",
      "\n",
      "Parameters configuration 11 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.014281571697627294\n",
      "h_sizes \t [784, 164, 42]\n",
      "penalty \t 0.00019434485189314754\n",
      "dropout \t 0.16556821676203365\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5500 +/- 0.0911\n",
      "Time for evaluation: 355.3 s\n",
      "Estimated time to finish : 11.30 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.515 took: 4.77s  Val. loss: 0.224  Val. score: 93.528%\n",
      "Epoch 2, 100% \t Train loss: 0.248 took: 4.79s  Val. loss: 0.163  Val. score: 95.183%\n",
      "Epoch 3, 100% \t Train loss: 0.192 took: 5.09s  Val. loss: 0.139  Val. score: 95.933%\n",
      "Epoch 4, 100% \t Train loss: 0.159 took: 5.08s  Val. loss: 0.129  Val. score: 96.172%\n",
      "Epoch 5, 100% \t Train loss: 0.137 took: 5.14s  Val. loss: 0.120  Val. score: 96.483%\n",
      "Epoch 6, 100% \t Train loss: 0.122 took: 5.16s  Val. loss: 0.114  Val. score: 96.700%\n",
      "Epoch 7, 100% \t Train loss: 0.110 took: 4.99s  Val. loss: 0.106  Val. score: 96.911%\n",
      "Epoch 8, 100% \t Train loss: 0.099 took: 4.91s  Val. loss: 0.107  Val. score: 96.922%\n",
      "Epoch 9, 100% \t Train loss: 0.090 took: 4.93s  Val. loss: 0.106  Val. score: 96.989%\n",
      "Epoch 10, 100% \t Train loss: 0.087 took: 4.97s  Val. loss: 0.105  Val. score: 97.100%\n",
      "Epoch 11, 100% \t Train loss: 0.077 took: 4.92s  Val. loss: 0.098  Val. score: 97.294%\n",
      "Epoch 12, 100% \t Train loss: 0.073 took: 4.98s  Val. loss: 0.100  Val. score: 97.256%\n",
      "Epoch 13, 100% \t Train loss: 0.065 took: 4.78s  Val. loss: 0.102  Val. score: 97.294%\n",
      "Epoch 14, 100% \t Train loss: 0.062 took: 4.78s  Val. loss: 0.099  Val. score: 97.378%\n",
      "Epoch 15, 100% \t Train loss: 0.061 took: 4.90s  Val. loss: 0.099  Val. score: 97.467%\n",
      "Training finished, took 125.161s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.499 took: 4.53s  Val. loss: 0.219  Val. score: 93.483%\n",
      "Epoch 2, 100% \t Train loss: 0.241 took: 4.53s  Val. loss: 0.166  Val. score: 94.900%\n",
      "Epoch 3, 100% \t Train loss: 0.188 took: 5.01s  Val. loss: 0.134  Val. score: 95.894%\n",
      "Epoch 4, 100% \t Train loss: 0.153 took: 4.97s  Val. loss: 0.119  Val. score: 96.367%\n",
      "Epoch 5, 100% \t Train loss: 0.137 took: 4.89s  Val. loss: 0.110  Val. score: 96.661%\n",
      "Epoch 6, 100% \t Train loss: 0.119 took: 5.08s  Val. loss: 0.105  Val. score: 96.867%\n",
      "Epoch 7, 100% \t Train loss: 0.103 took: 4.78s  Val. loss: 0.100  Val. score: 97.072%\n",
      "Epoch 8, 100% \t Train loss: 0.095 took: 5.20s  Val. loss: 0.095  Val. score: 97.206%\n",
      "Epoch 9, 100% \t Train loss: 0.087 took: 5.14s  Val. loss: 0.093  Val. score: 97.333%\n",
      "Epoch 10, 100% \t Train loss: 0.082 took: 5.18s  Val. loss: 0.094  Val. score: 97.183%\n",
      "Epoch 11, 100% \t Train loss: 0.076 took: 5.09s  Val. loss: 0.085  Val. score: 97.433%\n",
      "Epoch 12, 100% \t Train loss: 0.071 took: 5.14s  Val. loss: 0.091  Val. score: 97.494%\n",
      "Epoch 13, 100% \t Train loss: 0.067 took: 5.05s  Val. loss: 0.087  Val. score: 97.528%\n",
      "Epoch 14, 100% \t Train loss: 0.059 took: 4.97s  Val. loss: 0.086  Val. score: 97.644%\n",
      "Epoch 15, 100% \t Train loss: 0.059 took: 4.75s  Val. loss: 0.088  Val. score: 97.550%\n",
      "Training finished, took 125.081s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.503 took: 4.90s  Val. loss: 0.218  Val. score: 93.467%\n",
      "Epoch 2, 100% \t Train loss: 0.251 took: 4.82s  Val. loss: 0.161  Val. score: 95.033%\n",
      "Epoch 3, 100% \t Train loss: 0.191 took: 4.68s  Val. loss: 0.133  Val. score: 95.978%\n",
      "Epoch 4, 100% \t Train loss: 0.161 took: 4.77s  Val. loss: 0.125  Val. score: 96.261%\n",
      "Epoch 5, 100% \t Train loss: 0.135 took: 4.82s  Val. loss: 0.116  Val. score: 96.567%\n",
      "Epoch 6, 100% \t Train loss: 0.123 took: 5.18s  Val. loss: 0.107  Val. score: 96.939%\n",
      "Epoch 7, 100% \t Train loss: 0.108 took: 5.20s  Val. loss: 0.102  Val. score: 97.067%\n",
      "Epoch 8, 100% \t Train loss: 0.098 took: 5.15s  Val. loss: 0.098  Val. score: 97.206%\n",
      "Epoch 9, 100% \t Train loss: 0.091 took: 4.99s  Val. loss: 0.093  Val. score: 97.317%\n",
      "Epoch 10, 100% \t Train loss: 0.084 took: 4.86s  Val. loss: 0.097  Val. score: 97.333%\n",
      "Epoch 11, 100% \t Train loss: 0.076 took: 5.21s  Val. loss: 0.095  Val. score: 97.367%\n",
      "Epoch 12, 100% \t Train loss: 0.071 took: 4.94s  Val. loss: 0.093  Val. score: 97.456%\n",
      "Epoch 13, 100% \t Train loss: 0.066 took: 4.82s  Val. loss: 0.091  Val. score: 97.483%\n",
      "Epoch 14, 100% \t Train loss: 0.063 took: 5.06s  Val. loss: 0.091  Val. score: 97.589%\n",
      "Epoch 15, 100% \t Train loss: 0.063 took: 5.14s  Val. loss: 0.092  Val. score: 97.522%\n",
      "Training finished, took 125.618s\n",
      "\n",
      "Parameters configuration 12 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.006200446240594056\n",
      "h_sizes \t [784, 188, 38]\n",
      "penalty \t 0.005027289538361763\n",
      "dropout \t 0.24514731077452565\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5130 +/- 0.0346\n",
      "Time for evaluation: 377.0 s\n",
      "Estimated time to finish : 11.01 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.412 took: 5.89s  Val. loss: 0.177  Val. score: 94.706%\n",
      "Epoch 2, 100% \t Train loss: 0.185 took: 6.06s  Val. loss: 0.138  Val. score: 96.183%\n",
      "Epoch 3, 100% \t Train loss: 0.144 took: 6.26s  Val. loss: 0.126  Val. score: 96.428%\n",
      "Epoch 4, 100% \t Train loss: 0.117 took: 5.93s  Val. loss: 0.112  Val. score: 96.822%\n",
      "Epoch 5, 100% \t Train loss: 0.102 took: 5.90s  Val. loss: 0.111  Val. score: 96.989%\n",
      "Epoch 6, 100% \t Train loss: 0.086 took: 6.27s  Val. loss: 0.108  Val. score: 97.239%\n",
      "Epoch 7, 100% \t Train loss: 0.077 took: 6.40s  Val. loss: 0.103  Val. score: 97.556%\n",
      "Epoch 8, 100% \t Train loss: 0.071 took: 6.33s  Val. loss: 0.109  Val. score: 97.400%\n",
      "Epoch 9, 100% \t Train loss: 0.069 took: 6.49s  Val. loss: 0.106  Val. score: 97.483%\n",
      "Epoch 10, 100% \t Train loss: 0.060 took: 6.01s  Val. loss: 0.110  Val. score: 97.350%\n",
      "Epoch 11, 100% \t Train loss: 0.049 took: 5.96s  Val. loss: 0.108  Val. score: 97.583%\n",
      "Epoch 12, 100% \t Train loss: 0.052 took: 6.48s  Val. loss: 0.104  Val. score: 97.600%\n",
      "Epoch 13, 100% \t Train loss: 0.044 took: 6.45s  Val. loss: 0.107  Val. score: 97.578%\n",
      "Epoch 14, 100% \t Train loss: 0.040 took: 6.28s  Val. loss: 0.112  Val. score: 97.611%\n",
      "Epoch 15, 100% \t Train loss: 0.040 took: 6.22s  Val. loss: 0.120  Val. score: 97.589%\n",
      "Training finished, took 151.525s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.439 took: 6.13s  Val. loss: 0.171  Val. score: 94.950%\n",
      "Epoch 2, 100% \t Train loss: 0.199 took: 6.38s  Val. loss: 0.127  Val. score: 96.317%\n",
      "Epoch 3, 100% \t Train loss: 0.148 took: 6.39s  Val. loss: 0.132  Val. score: 96.333%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, 100% \t Train loss: 0.124 took: 6.23s  Val. loss: 0.110  Val. score: 96.867%\n",
      "Epoch 5, 100% \t Train loss: 0.105 took: 6.36s  Val. loss: 0.103  Val. score: 97.133%\n",
      "Epoch 6, 100% \t Train loss: 0.091 took: 6.26s  Val. loss: 0.100  Val. score: 97.189%\n",
      "Epoch 7, 100% \t Train loss: 0.082 took: 6.57s  Val. loss: 0.095  Val. score: 97.467%\n",
      "Epoch 8, 100% \t Train loss: 0.075 took: 5.93s  Val. loss: 0.098  Val. score: 97.572%\n",
      "Epoch 9, 100% \t Train loss: 0.072 took: 5.98s  Val. loss: 0.093  Val. score: 97.572%\n",
      "Epoch 10, 100% \t Train loss: 0.063 took: 5.89s  Val. loss: 0.095  Val. score: 97.667%\n",
      "Epoch 11, 100% \t Train loss: 0.060 took: 6.67s  Val. loss: 0.099  Val. score: 97.433%\n",
      "Epoch 12, 100% \t Train loss: 0.052 took: 6.01s  Val. loss: 0.115  Val. score: 97.450%\n",
      "Epoch 13, 100% \t Train loss: 0.053 took: 6.38s  Val. loss: 0.108  Val. score: 97.572%\n",
      "Epoch 14, 100% \t Train loss: 0.046 took: 6.49s  Val. loss: 0.110  Val. score: 97.394%\n",
      "Epoch 15, 100% \t Train loss: 0.043 took: 6.11s  Val. loss: 0.100  Val. score: 97.728%\n",
      "Training finished, took 152.837s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.469 took: 6.16s  Val. loss: 0.198  Val. score: 94.394%\n",
      "Epoch 2, 100% \t Train loss: 0.199 took: 6.45s  Val. loss: 0.154  Val. score: 95.717%\n",
      "Epoch 3, 100% \t Train loss: 0.153 took: 5.92s  Val. loss: 0.137  Val. score: 96.228%\n",
      "Epoch 4, 100% \t Train loss: 0.132 took: 6.25s  Val. loss: 0.134  Val. score: 96.306%\n",
      "Epoch 5, 100% \t Train loss: 0.111 took: 6.08s  Val. loss: 0.120  Val. score: 96.822%\n",
      "Epoch 6, 100% \t Train loss: 0.098 took: 5.95s  Val. loss: 0.122  Val. score: 96.833%\n",
      "Epoch 7, 100% \t Train loss: 0.088 took: 6.59s  Val. loss: 0.124  Val. score: 96.750%\n",
      "Epoch 8, 100% \t Train loss: 0.079 took: 6.78s  Val. loss: 0.115  Val. score: 96.950%\n",
      "Epoch 9, 100% \t Train loss: 0.070 took: 6.35s  Val. loss: 0.111  Val. score: 97.233%\n",
      "Epoch 10, 100% \t Train loss: 0.066 took: 5.97s  Val. loss: 0.128  Val. score: 96.867%\n",
      "Epoch 11, 100% \t Train loss: 0.063 took: 6.16s  Val. loss: 0.118  Val. score: 97.061%\n",
      "Epoch 12, 100% \t Train loss: 0.056 took: 6.21s  Val. loss: 0.128  Val. score: 97.050%\n",
      "Epoch 13, 100% \t Train loss: 0.055 took: 6.17s  Val. loss: 0.120  Val. score: 97.261%\n",
      "Epoch 14, 100% \t Train loss: 0.047 took: 5.92s  Val. loss: 0.126  Val. score: 97.206%\n",
      "Epoch 15, 100% \t Train loss: 0.048 took: 6.25s  Val. loss: 0.128  Val. score: 97.233%\n",
      "Training finished, took 152.475s\n",
      "\n",
      "Parameters configuration 13 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.018295444309838097\n",
      "h_sizes \t [784, 262, 98, 31]\n",
      "penalty \t 0.005730386728131879\n",
      "dropout \t 0.17207494145054458\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.5167 +/- 0.2082\n",
      "Time for evaluation: 458.0 s\n",
      "Estimated time to finish : 10.90 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.486 took: 8.23s  Val. loss: 0.198  Val. score: 94.172%\n",
      "Epoch 2, 100% \t Train loss: 0.181 took: 7.85s  Val. loss: 0.142  Val. score: 95.817%\n",
      "Epoch 3, 100% \t Train loss: 0.132 took: 8.55s  Val. loss: 0.124  Val. score: 96.322%\n",
      "Epoch 4, 100% \t Train loss: 0.108 took: 9.02s  Val. loss: 0.121  Val. score: 96.467%\n",
      "Epoch 5, 100% \t Train loss: 0.085 took: 9.47s  Val. loss: 0.112  Val. score: 96.961%\n",
      "Epoch 6, 100% \t Train loss: 0.073 took: 8.85s  Val. loss: 0.109  Val. score: 97.050%\n",
      "Epoch 7, 100% \t Train loss: 0.057 took: 9.00s  Val. loss: 0.105  Val. score: 97.411%\n",
      "Epoch 8, 100% \t Train loss: 0.051 took: 9.40s  Val. loss: 0.098  Val. score: 97.406%\n",
      "Epoch 9, 100% \t Train loss: 0.041 took: 9.36s  Val. loss: 0.100  Val. score: 97.467%\n",
      "Epoch 10, 100% \t Train loss: 0.041 took: 9.11s  Val. loss: 0.094  Val. score: 97.822%\n",
      "Epoch 11, 100% \t Train loss: 0.033 took: 9.30s  Val. loss: 0.101  Val. score: 97.539%\n",
      "Epoch 12, 100% \t Train loss: 0.028 took: 9.43s  Val. loss: 0.112  Val. score: 97.511%\n",
      "Epoch 13, 100% \t Train loss: 0.025 took: 8.95s  Val. loss: 0.107  Val. score: 97.622%\n",
      "Epoch 14, 100% \t Train loss: 0.023 took: 8.82s  Val. loss: 0.119  Val. score: 97.517%\n",
      "Epoch 15, 100% \t Train loss: 0.023 took: 8.87s  Val. loss: 0.101  Val. score: 97.833%\n",
      "Training finished, took 204.664s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.480 took: 8.05s  Val. loss: 0.190  Val. score: 94.506%\n",
      "Epoch 2, 100% \t Train loss: 0.178 took: 8.60s  Val. loss: 0.141  Val. score: 95.911%\n",
      "Epoch 3, 100% \t Train loss: 0.132 took: 8.86s  Val. loss: 0.119  Val. score: 96.794%\n",
      "Epoch 4, 100% \t Train loss: 0.100 took: 9.05s  Val. loss: 0.114  Val. score: 97.044%\n",
      "Epoch 5, 100% \t Train loss: 0.079 took: 9.11s  Val. loss: 0.114  Val. score: 96.978%\n",
      "Epoch 6, 100% \t Train loss: 0.066 took: 9.41s  Val. loss: 0.104  Val. score: 97.333%\n",
      "Epoch 7, 100% \t Train loss: 0.052 took: 9.34s  Val. loss: 0.103  Val. score: 97.544%\n",
      "Epoch 8, 100% \t Train loss: 0.049 took: 9.33s  Val. loss: 0.103  Val. score: 97.417%\n",
      "Epoch 9, 100% \t Train loss: 0.038 took: 9.24s  Val. loss: 0.106  Val. score: 97.506%\n",
      "Epoch 10, 100% \t Train loss: 0.033 took: 9.25s  Val. loss: 0.109  Val. score: 97.611%\n",
      "Epoch 11, 100% \t Train loss: 0.031 took: 9.39s  Val. loss: 0.124  Val. score: 97.344%\n",
      "Epoch 12, 100% \t Train loss: 0.030 took: 9.47s  Val. loss: 0.113  Val. score: 97.544%\n",
      "Epoch 13, 100% \t Train loss: 0.022 took: 9.57s  Val. loss: 0.116  Val. score: 97.661%\n",
      "Epoch 14, 100% \t Train loss: 0.025 took: 9.32s  Val. loss: 0.115  Val. score: 97.744%\n",
      "Epoch 15, 100% \t Train loss: 0.018 took: 9.50s  Val. loss: 0.119  Val. score: 97.828%\n",
      "Training finished, took 208.937s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.492 took: 8.61s  Val. loss: 0.181  Val. score: 94.750%\n",
      "Epoch 2, 100% \t Train loss: 0.190 took: 8.62s  Val. loss: 0.139  Val. score: 95.839%\n",
      "Epoch 3, 100% \t Train loss: 0.135 took: 8.92s  Val. loss: 0.108  Val. score: 96.878%\n",
      "Epoch 4, 100% \t Train loss: 0.106 took: 9.47s  Val. loss: 0.113  Val. score: 96.889%\n",
      "Epoch 5, 100% \t Train loss: 0.084 took: 9.42s  Val. loss: 0.107  Val. score: 96.939%\n",
      "Epoch 6, 100% \t Train loss: 0.070 took: 9.78s  Val. loss: 0.102  Val. score: 97.222%\n",
      "Epoch 7, 100% \t Train loss: 0.057 took: 9.46s  Val. loss: 0.103  Val. score: 97.456%\n",
      "Epoch 8, 100% \t Train loss: 0.049 took: 9.91s  Val. loss: 0.100  Val. score: 97.556%\n",
      "Epoch 9, 100% \t Train loss: 0.039 took: 9.69s  Val. loss: 0.099  Val. score: 97.467%\n",
      "Epoch 10, 100% \t Train loss: 0.035 took: 9.66s  Val. loss: 0.108  Val. score: 97.433%\n",
      "Epoch 11, 100% \t Train loss: 0.029 took: 9.58s  Val. loss: 0.102  Val. score: 97.656%\n",
      "Epoch 12, 100% \t Train loss: 0.025 took: 9.64s  Val. loss: 0.105  Val. score: 97.778%\n",
      "Epoch 13, 100% \t Train loss: 0.025 took: 9.15s  Val. loss: 0.114  Val. score: 97.539%\n",
      "Epoch 14, 100% \t Train loss: 0.022 took: 9.18s  Val. loss: 0.123  Val. score: 97.494%\n",
      "Epoch 15, 100% \t Train loss: 0.020 took: 9.67s  Val. loss: 0.124  Val. score: 97.567%\n",
      "Training finished, took 213.248s\n",
      "\n",
      "Parameters configuration 14 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008285286736995991\n",
      "h_sizes \t [784, 337, 138, 61, 28]\n",
      "penalty \t 0.0014477797404773732\n",
      "dropout \t 0.09691534546527214\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.7426 +/- 0.1244\n",
      "Time for evaluation: 628.1 s\n",
      "Estimated time to finish : 11.08 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.531 took: 7.83s  Val. loss: 0.221  Val. score: 93.861%\n",
      "Epoch 2, 100% \t Train loss: 0.187 took: 8.14s  Val. loss: 0.157  Val. score: 95.433%\n",
      "Epoch 3, 100% \t Train loss: 0.131 took: 8.69s  Val. loss: 0.146  Val. score: 96.189%\n",
      "Epoch 4, 100% \t Train loss: 0.101 took: 8.90s  Val. loss: 0.132  Val. score: 96.644%\n",
      "Epoch 5, 100% \t Train loss: 0.084 took: 9.12s  Val. loss: 0.117  Val. score: 96.994%\n",
      "Epoch 6, 100% \t Train loss: 0.066 took: 9.11s  Val. loss: 0.127  Val. score: 96.922%\n",
      "Epoch 7, 100% \t Train loss: 0.060 took: 8.77s  Val. loss: 0.112  Val. score: 97.217%\n",
      "Epoch 8, 100% \t Train loss: 0.050 took: 9.03s  Val. loss: 0.109  Val. score: 97.400%\n",
      "Epoch 9, 100% \t Train loss: 0.041 took: 8.62s  Val. loss: 0.131  Val. score: 97.122%\n",
      "Epoch 10, 100% \t Train loss: 0.037 took: 8.95s  Val. loss: 0.128  Val. score: 97.261%\n",
      "Epoch 11, 100% \t Train loss: 0.030 took: 8.54s  Val. loss: 0.128  Val. score: 97.394%\n",
      "Epoch 12, 100% \t Train loss: 0.027 took: 8.94s  Val. loss: 0.130  Val. score: 97.567%\n",
      "Epoch 13, 100% \t Train loss: 0.024 took: 9.00s  Val. loss: 0.137  Val. score: 97.228%\n",
      "Epoch 14, 100% \t Train loss: 0.023 took: 8.85s  Val. loss: 0.136  Val. score: 97.222%\n",
      "Epoch 15, 100% \t Train loss: 0.021 took: 8.85s  Val. loss: 0.130  Val. score: 97.544%\n",
      "Training finished, took 200.287s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.496 took: 7.92s  Val. loss: 0.196  Val. score: 94.472%\n",
      "Epoch 2, 100% \t Train loss: 0.187 took: 8.19s  Val. loss: 0.153  Val. score: 95.689%\n",
      "Epoch 3, 100% \t Train loss: 0.136 took: 8.26s  Val. loss: 0.129  Val. score: 96.367%\n",
      "Epoch 4, 100% \t Train loss: 0.106 took: 9.23s  Val. loss: 0.111  Val. score: 96.972%\n",
      "Epoch 5, 100% \t Train loss: 0.084 took: 8.82s  Val. loss: 0.123  Val. score: 96.767%\n",
      "Epoch 6, 100% \t Train loss: 0.069 took: 9.16s  Val. loss: 0.109  Val. score: 97.172%\n",
      "Epoch 7, 100% \t Train loss: 0.056 took: 8.74s  Val. loss: 0.110  Val. score: 97.289%\n",
      "Epoch 8, 100% \t Train loss: 0.051 took: 8.83s  Val. loss: 0.098  Val. score: 97.478%\n",
      "Epoch 9, 100% \t Train loss: 0.042 took: 8.96s  Val. loss: 0.114  Val. score: 97.272%\n",
      "Epoch 10, 100% \t Train loss: 0.034 took: 8.80s  Val. loss: 0.103  Val. score: 97.561%\n",
      "Epoch 11, 100% \t Train loss: 0.033 took: 10.85s  Val. loss: 0.115  Val. score: 97.489%\n",
      "Epoch 12, 100% \t Train loss: 0.028 took: 8.87s  Val. loss: 0.110  Val. score: 97.733%\n",
      "Epoch 13, 100% \t Train loss: 0.025 took: 9.02s  Val. loss: 0.126  Val. score: 97.561%\n",
      "Epoch 14, 100% \t Train loss: 0.021 took: 8.88s  Val. loss: 0.138  Val. score: 97.322%\n",
      "Epoch 15, 100% \t Train loss: 0.021 took: 8.46s  Val. loss: 0.124  Val. score: 97.667%\n",
      "Training finished, took 202.111s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.514 took: 7.54s  Val. loss: 0.201  Val. score: 94.300%\n",
      "Epoch 2, 100% \t Train loss: 0.189 took: 7.40s  Val. loss: 0.147  Val. score: 95.911%\n",
      "Epoch 3, 100% \t Train loss: 0.133 took: 8.41s  Val. loss: 0.127  Val. score: 96.478%\n",
      "Epoch 4, 100% \t Train loss: 0.098 took: 8.70s  Val. loss: 0.121  Val. score: 96.667%\n",
      "Epoch 5, 100% \t Train loss: 0.080 took: 8.92s  Val. loss: 0.125  Val. score: 96.850%\n",
      "Epoch 6, 100% \t Train loss: 0.067 took: 8.91s  Val. loss: 0.120  Val. score: 96.900%\n",
      "Epoch 7, 100% \t Train loss: 0.058 took: 8.72s  Val. loss: 0.111  Val. score: 97.272%\n",
      "Epoch 8, 100% \t Train loss: 0.050 took: 9.01s  Val. loss: 0.100  Val. score: 97.500%\n",
      "Epoch 9, 100% \t Train loss: 0.041 took: 8.58s  Val. loss: 0.116  Val. score: 97.239%\n",
      "Epoch 10, 100% \t Train loss: 0.033 took: 9.11s  Val. loss: 0.124  Val. score: 97.494%\n",
      "Epoch 11, 100% \t Train loss: 0.032 took: 9.27s  Val. loss: 0.128  Val. score: 97.483%\n",
      "Epoch 12, 100% \t Train loss: 0.029 took: 8.63s  Val. loss: 0.125  Val. score: 97.606%\n",
      "Epoch 13, 100% \t Train loss: 0.025 took: 8.63s  Val. loss: 0.120  Val. score: 97.583%\n",
      "Epoch 14, 100% \t Train loss: 0.022 took: 8.95s  Val. loss: 0.119  Val. score: 97.600%\n",
      "Epoch 15, 100% \t Train loss: 0.022 took: 8.90s  Val. loss: 0.122  Val. score: 97.594%\n",
      "Training finished, took 197.026s\n",
      "\n",
      "Parameters configuration 15 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.012243968374354375\n",
      "h_sizes \t [784, 316, 142, 52, 20]\n",
      "penalty \t 0.001522928672181953\n",
      "dropout \t 0.06816193412041527\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6019 +/- 0.0502\n",
      "Time for evaluation: 600.6 s\n",
      "Estimated time to finish : 11.17 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.290 took: 12.66s  Val. loss: 0.441  Val. score: 88.267%\n",
      "Epoch 2, 100% \t Train loss: 0.493 took: 11.93s  Val. loss: 0.260  Val. score: 92.961%\n",
      "Epoch 3, 100% \t Train loss: 0.345 took: 11.85s  Val. loss: 0.213  Val. score: 94.606%\n",
      "Epoch 4, 100% \t Train loss: 0.278 took: 12.09s  Val. loss: 0.185  Val. score: 95.333%\n",
      "Epoch 5, 100% \t Train loss: 0.232 took: 12.17s  Val. loss: 0.185  Val. score: 95.556%\n",
      "Epoch 6, 100% \t Train loss: 0.196 took: 12.94s  Val. loss: 0.163  Val. score: 96.194%\n",
      "Epoch 7, 100% \t Train loss: 0.175 took: 11.96s  Val. loss: 0.166  Val. score: 96.350%\n",
      "Epoch 8, 100% \t Train loss: 0.152 took: 12.93s  Val. loss: 0.157  Val. score: 96.439%\n",
      "Epoch 9, 100% \t Train loss: 0.137 took: 13.24s  Val. loss: 0.148  Val. score: 96.806%\n",
      "Epoch 10, 100% \t Train loss: 0.122 took: 12.96s  Val. loss: 0.157  Val. score: 96.794%\n",
      "Epoch 11, 100% \t Train loss: 0.112 took: 12.58s  Val. loss: 0.156  Val. score: 96.928%\n",
      "Epoch 12, 100% \t Train loss: 0.104 took: 13.00s  Val. loss: 0.144  Val. score: 97.178%\n",
      "Epoch 13, 100% \t Train loss: 0.092 took: 12.41s  Val. loss: 0.149  Val. score: 97.122%\n",
      "Epoch 14, 100% \t Train loss: 0.085 took: 12.44s  Val. loss: 0.157  Val. score: 97.172%\n",
      "Epoch 15, 100% \t Train loss: 0.080 took: 12.49s  Val. loss: 0.159  Val. score: 97.072%\n",
      "Training finished, took 275.997s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.390 took: 11.83s  Val. loss: 0.609  Val. score: 81.178%\n",
      "Epoch 2, 100% \t Train loss: 0.617 took: 12.45s  Val. loss: 0.346  Val. score: 90.611%\n",
      "Epoch 3, 100% \t Train loss: 0.414 took: 12.02s  Val. loss: 0.243  Val. score: 93.728%\n",
      "Epoch 4, 100% \t Train loss: 0.309 took: 12.75s  Val. loss: 0.196  Val. score: 95.050%\n",
      "Epoch 5, 100% \t Train loss: 0.249 took: 12.89s  Val. loss: 0.179  Val. score: 95.672%\n",
      "Epoch 6, 100% \t Train loss: 0.210 took: 12.91s  Val. loss: 0.175  Val. score: 95.617%\n",
      "Epoch 7, 100% \t Train loss: 0.185 took: 13.17s  Val. loss: 0.153  Val. score: 96.256%\n",
      "Epoch 8, 100% \t Train loss: 0.163 took: 12.09s  Val. loss: 0.151  Val. score: 96.472%\n",
      "Epoch 9, 100% \t Train loss: 0.147 took: 12.14s  Val. loss: 0.151  Val. score: 96.589%\n",
      "Epoch 10, 100% \t Train loss: 0.130 took: 13.05s  Val. loss: 0.142  Val. score: 96.928%\n",
      "Epoch 11, 100% \t Train loss: 0.117 took: 12.43s  Val. loss: 0.136  Val. score: 97.078%\n",
      "Epoch 12, 100% \t Train loss: 0.108 took: 13.06s  Val. loss: 0.140  Val. score: 97.100%\n",
      "Epoch 13, 100% \t Train loss: 0.097 took: 12.34s  Val. loss: 0.134  Val. score: 97.278%\n",
      "Epoch 14, 100% \t Train loss: 0.091 took: 12.23s  Val. loss: 0.131  Val. score: 97.300%\n",
      "Epoch 15, 100% \t Train loss: 0.081 took: 12.80s  Val. loss: 0.140  Val. score: 97.333%\n",
      "Training finished, took 276.015s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.151 took: 12.31s  Val. loss: 0.420  Val. score: 88.322%\n",
      "Epoch 2, 100% \t Train loss: 0.503 took: 11.69s  Val. loss: 0.266  Val. score: 92.744%\n",
      "Epoch 3, 100% \t Train loss: 0.348 took: 12.45s  Val. loss: 0.203  Val. score: 94.533%\n",
      "Epoch 4, 100% \t Train loss: 0.271 took: 12.56s  Val. loss: 0.178  Val. score: 95.111%\n",
      "Epoch 5, 100% \t Train loss: 0.225 took: 12.35s  Val. loss: 0.171  Val. score: 95.583%\n",
      "Epoch 6, 100% \t Train loss: 0.193 took: 12.48s  Val. loss: 0.154  Val. score: 96.156%\n",
      "Epoch 7, 100% \t Train loss: 0.170 took: 12.51s  Val. loss: 0.140  Val. score: 96.389%\n",
      "Epoch 8, 100% \t Train loss: 0.153 took: 12.36s  Val. loss: 0.141  Val. score: 96.606%\n",
      "Epoch 9, 100% \t Train loss: 0.138 took: 12.43s  Val. loss: 0.125  Val. score: 96.917%\n",
      "Epoch 10, 100% \t Train loss: 0.122 took: 12.51s  Val. loss: 0.127  Val. score: 96.967%\n",
      "Epoch 11, 100% \t Train loss: 0.114 took: 12.66s  Val. loss: 0.125  Val. score: 97.172%\n",
      "Epoch 12, 100% \t Train loss: 0.102 took: 12.60s  Val. loss: 0.136  Val. score: 96.789%\n",
      "Epoch 13, 100% \t Train loss: 0.094 took: 12.43s  Val. loss: 0.123  Val. score: 97.278%\n",
      "Epoch 14, 100% \t Train loss: 0.087 took: 12.97s  Val. loss: 0.124  Val. score: 97.144%\n",
      "Epoch 15, 100% \t Train loss: 0.082 took: 12.41s  Val. loss: 0.128  Val. score: 97.267%\n",
      "Training finished, took 275.570s\n",
      "\n",
      "Parameters configuration 16 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0021991125565293014\n",
      "h_sizes \t [784, 424, 228, 130, 65, 31, 21]\n",
      "penalty \t 0.0002925341298850196\n",
      "dropout \t 0.18711769309525658\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.2241 +/- 0.1108\n",
      "Time for evaluation: 828.8 s\n",
      "Estimated time to finish : 11.55 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.446 took: 8.22s  Val. loss: 0.170  Val. score: 94.989%\n",
      "Epoch 2, 100% \t Train loss: 0.170 took: 8.15s  Val. loss: 0.138  Val. score: 96.183%\n",
      "Epoch 3, 100% \t Train loss: 0.130 took: 8.74s  Val. loss: 0.108  Val. score: 96.889%\n",
      "Epoch 4, 100% \t Train loss: 0.103 took: 9.35s  Val. loss: 0.114  Val. score: 96.900%\n",
      "Epoch 5, 100% \t Train loss: 0.084 took: 9.50s  Val. loss: 0.105  Val. score: 97.156%\n",
      "Epoch 6, 100% \t Train loss: 0.069 took: 9.29s  Val. loss: 0.111  Val. score: 97.361%\n",
      "Epoch 7, 100% \t Train loss: 0.060 took: 9.52s  Val. loss: 0.096  Val. score: 97.656%\n",
      "Epoch 8, 100% \t Train loss: 0.051 took: 9.32s  Val. loss: 0.106  Val. score: 97.433%\n",
      "Epoch 9, 100% \t Train loss: 0.048 took: 9.64s  Val. loss: 0.112  Val. score: 97.550%\n",
      "Epoch 10, 100% \t Train loss: 0.040 took: 9.33s  Val. loss: 0.114  Val. score: 97.511%\n",
      "Epoch 11, 100% \t Train loss: 0.037 took: 9.44s  Val. loss: 0.108  Val. score: 97.667%\n",
      "Epoch 12, 100% \t Train loss: 0.033 took: 9.32s  Val. loss: 0.099  Val. score: 97.811%\n",
      "Epoch 13, 100% \t Train loss: 0.028 took: 9.76s  Val. loss: 0.122  Val. score: 97.600%\n",
      "Epoch 14, 100% \t Train loss: 0.029 took: 9.92s  Val. loss: 0.107  Val. score: 97.767%\n",
      "Epoch 15, 100% \t Train loss: 0.029 took: 9.84s  Val. loss: 0.106  Val. score: 97.789%\n",
      "Training finished, took 210.139s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.536 took: 8.04s  Val. loss: 0.215  Val. score: 94.117%\n",
      "Epoch 2, 100% \t Train loss: 0.205 took: 8.01s  Val. loss: 0.164  Val. score: 95.522%\n",
      "Epoch 3, 100% \t Train loss: 0.154 took: 9.22s  Val. loss: 0.154  Val. score: 95.972%\n",
      "Epoch 4, 100% \t Train loss: 0.123 took: 10.15s  Val. loss: 0.136  Val. score: 96.439%\n",
      "Epoch 5, 100% \t Train loss: 0.101 took: 10.07s  Val. loss: 0.135  Val. score: 96.678%\n",
      "Epoch 6, 100% \t Train loss: 0.088 took: 10.14s  Val. loss: 0.126  Val. score: 96.911%\n",
      "Epoch 7, 100% \t Train loss: 0.074 took: 9.86s  Val. loss: 0.128  Val. score: 97.050%\n",
      "Epoch 8, 100% \t Train loss: 0.063 took: 10.49s  Val. loss: 0.128  Val. score: 97.056%\n",
      "Epoch 9, 100% \t Train loss: 0.055 took: 10.20s  Val. loss: 0.124  Val. score: 97.133%\n",
      "Epoch 10, 100% \t Train loss: 0.050 took: 9.93s  Val. loss: 0.130  Val. score: 97.156%\n",
      "Epoch 11, 100% \t Train loss: 0.048 took: 9.80s  Val. loss: 0.124  Val. score: 97.467%\n",
      "Epoch 12, 100% \t Train loss: 0.042 took: 9.93s  Val. loss: 0.126  Val. score: 97.417%\n",
      "Epoch 13, 100% \t Train loss: 0.039 took: 10.02s  Val. loss: 0.124  Val. score: 97.422%\n",
      "Epoch 14, 100% \t Train loss: 0.042 took: 9.80s  Val. loss: 0.129  Val. score: 97.339%\n",
      "Epoch 15, 100% \t Train loss: 0.032 took: 10.00s  Val. loss: 0.139  Val. score: 97.394%\n",
      "Training finished, took 214.978s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.516 took: 7.80s  Val. loss: 0.176  Val. score: 94.928%\n",
      "Epoch 2, 100% \t Train loss: 0.181 took: 8.58s  Val. loss: 0.138  Val. score: 96.083%\n",
      "Epoch 3, 100% \t Train loss: 0.132 took: 8.92s  Val. loss: 0.143  Val. score: 96.189%\n",
      "Epoch 4, 100% \t Train loss: 0.103 took: 9.60s  Val. loss: 0.110  Val. score: 97.106%\n",
      "Epoch 5, 100% \t Train loss: 0.083 took: 9.08s  Val. loss: 0.111  Val. score: 97.056%\n",
      "Epoch 6, 100% \t Train loss: 0.070 took: 9.72s  Val. loss: 0.108  Val. score: 97.272%\n",
      "Epoch 7, 100% \t Train loss: 0.057 took: 8.82s  Val. loss: 0.103  Val. score: 97.511%\n",
      "Epoch 8, 100% \t Train loss: 0.052 took: 8.83s  Val. loss: 0.110  Val. score: 97.389%\n",
      "Epoch 9, 100% \t Train loss: 0.043 took: 9.09s  Val. loss: 0.114  Val. score: 97.517%\n",
      "Epoch 10, 100% \t Train loss: 0.037 took: 9.13s  Val. loss: 0.114  Val. score: 97.528%\n",
      "Epoch 11, 100% \t Train loss: 0.036 took: 9.77s  Val. loss: 0.119  Val. score: 97.294%\n",
      "Epoch 12, 100% \t Train loss: 0.033 took: 9.27s  Val. loss: 0.111  Val. score: 97.606%\n",
      "Epoch 13, 100% \t Train loss: 0.026 took: 9.39s  Val. loss: 0.111  Val. score: 97.656%\n",
      "Epoch 14, 100% \t Train loss: 0.024 took: 9.55s  Val. loss: 0.121  Val. score: 97.539%\n",
      "Epoch 15, 100% \t Train loss: 0.023 took: 9.57s  Val. loss: 0.140  Val. score: 97.422%\n",
      "Training finished, took 206.034s\n",
      "\n",
      "Parameters configuration 17 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.013978363242923234\n",
      "h_sizes \t [784, 346, 152, 57, 28]\n",
      "penalty \t 0.0002524716537463212\n",
      "dropout \t 0.10887237593590082\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5352 +/- 0.1798\n",
      "Time for evaluation: 632.3 s\n",
      "Estimated time to finish : 11.60 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.400 took: 4.72s  Val. loss: 0.183  Val. score: 94.339%\n",
      "Epoch 2, 100% \t Train loss: 0.194 took: 5.06s  Val. loss: 0.138  Val. score: 95.828%\n",
      "Epoch 3, 100% \t Train loss: 0.146 took: 5.31s  Val. loss: 0.121  Val. score: 96.339%\n",
      "Epoch 4, 100% \t Train loss: 0.119 took: 5.09s  Val. loss: 0.109  Val. score: 96.872%\n",
      "Epoch 5, 100% \t Train loss: 0.100 took: 5.35s  Val. loss: 0.098  Val. score: 97.072%\n",
      "Epoch 6, 100% \t Train loss: 0.086 took: 5.12s  Val. loss: 0.107  Val. score: 96.961%\n",
      "Epoch 7, 100% \t Train loss: 0.077 took: 5.09s  Val. loss: 0.100  Val. score: 97.150%\n",
      "Epoch 8, 100% \t Train loss: 0.068 took: 5.38s  Val. loss: 0.093  Val. score: 97.344%\n",
      "Epoch 9, 100% \t Train loss: 0.058 took: 5.47s  Val. loss: 0.090  Val. score: 97.522%\n",
      "Epoch 10, 100% \t Train loss: 0.056 took: 5.50s  Val. loss: 0.090  Val. score: 97.561%\n",
      "Epoch 11, 100% \t Train loss: 0.050 took: 5.53s  Val. loss: 0.095  Val. score: 97.367%\n",
      "Epoch 12, 100% \t Train loss: 0.048 took: 5.18s  Val. loss: 0.093  Val. score: 97.617%\n",
      "Epoch 13, 100% \t Train loss: 0.043 took: 5.70s  Val. loss: 0.091  Val. score: 97.583%\n",
      "Epoch 14, 100% \t Train loss: 0.038 took: 5.30s  Val. loss: 0.092  Val. score: 97.700%\n",
      "Epoch 15, 100% \t Train loss: 0.036 took: 5.39s  Val. loss: 0.096  Val. score: 97.578%\n",
      "Training finished, took 131.631s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.412 took: 5.07s  Val. loss: 0.197  Val. score: 94.106%\n",
      "Epoch 2, 100% \t Train loss: 0.198 took: 5.15s  Val. loss: 0.152  Val. score: 95.511%\n",
      "Epoch 3, 100% \t Train loss: 0.147 took: 5.21s  Val. loss: 0.125  Val. score: 96.239%\n",
      "Epoch 4, 100% \t Train loss: 0.122 took: 5.36s  Val. loss: 0.107  Val. score: 96.711%\n",
      "Epoch 5, 100% \t Train loss: 0.102 took: 5.50s  Val. loss: 0.098  Val. score: 97.111%\n",
      "Epoch 6, 100% \t Train loss: 0.088 took: 5.41s  Val. loss: 0.092  Val. score: 97.328%\n",
      "Epoch 7, 100% \t Train loss: 0.078 took: 5.45s  Val. loss: 0.096  Val. score: 97.111%\n",
      "Epoch 8, 100% \t Train loss: 0.072 took: 5.45s  Val. loss: 0.092  Val. score: 97.367%\n",
      "Epoch 9, 100% \t Train loss: 0.062 took: 5.45s  Val. loss: 0.095  Val. score: 97.306%\n",
      "Epoch 10, 100% \t Train loss: 0.058 took: 5.25s  Val. loss: 0.090  Val. score: 97.494%\n",
      "Epoch 11, 100% \t Train loss: 0.051 took: 5.43s  Val. loss: 0.097  Val. score: 97.417%\n",
      "Epoch 12, 100% \t Train loss: 0.048 took: 5.26s  Val. loss: 0.090  Val. score: 97.511%\n",
      "Epoch 13, 100% \t Train loss: 0.045 took: 5.47s  Val. loss: 0.090  Val. score: 97.583%\n",
      "Epoch 14, 100% \t Train loss: 0.039 took: 5.05s  Val. loss: 0.090  Val. score: 97.550%\n",
      "Epoch 15, 100% \t Train loss: 0.039 took: 5.27s  Val. loss: 0.089  Val. score: 97.750%\n",
      "Training finished, took 132.194s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.416 took: 4.74s  Val. loss: 0.191  Val. score: 94.267%\n",
      "Epoch 2, 100% \t Train loss: 0.204 took: 5.17s  Val. loss: 0.139  Val. score: 95.700%\n",
      "Epoch 3, 100% \t Train loss: 0.151 took: 5.25s  Val. loss: 0.125  Val. score: 96.139%\n",
      "Epoch 4, 100% \t Train loss: 0.125 took: 5.37s  Val. loss: 0.111  Val. score: 96.706%\n",
      "Epoch 5, 100% \t Train loss: 0.106 took: 5.36s  Val. loss: 0.101  Val. score: 96.889%\n",
      "Epoch 6, 100% \t Train loss: 0.091 took: 5.40s  Val. loss: 0.092  Val. score: 97.244%\n",
      "Epoch 7, 100% \t Train loss: 0.085 took: 5.50s  Val. loss: 0.092  Val. score: 97.278%\n",
      "Epoch 8, 100% \t Train loss: 0.075 took: 5.47s  Val. loss: 0.090  Val. score: 97.344%\n",
      "Epoch 9, 100% \t Train loss: 0.068 took: 5.29s  Val. loss: 0.090  Val. score: 97.406%\n",
      "Epoch 10, 100% \t Train loss: 0.059 took: 5.63s  Val. loss: 0.089  Val. score: 97.411%\n",
      "Epoch 11, 100% \t Train loss: 0.054 took: 5.49s  Val. loss: 0.088  Val. score: 97.506%\n",
      "Epoch 12, 100% \t Train loss: 0.051 took: 5.46s  Val. loss: 0.086  Val. score: 97.661%\n",
      "Epoch 13, 100% \t Train loss: 0.046 took: 5.32s  Val. loss: 0.088  Val. score: 97.617%\n",
      "Epoch 14, 100% \t Train loss: 0.045 took: 5.32s  Val. loss: 0.093  Val. score: 97.633%\n",
      "Epoch 15, 100% \t Train loss: 0.043 took: 5.12s  Val. loss: 0.090  Val. score: 97.506%\n",
      "Training finished, took 132.505s\n",
      "\n",
      "Parameters configuration 18 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008582688624845214\n",
      "h_sizes \t [784, 202, 50]\n",
      "penalty \t 0.0036763460734183244\n",
      "dropout \t 0.21029295542727858\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6111 +/- 0.1025\n",
      "Time for evaluation: 397.5 s\n",
      "Estimated time to finish : 11.33 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.477 took: 4.22s  Val. loss: 0.243  Val. score: 93.089%\n",
      "Epoch 2, 100% \t Train loss: 0.225 took: 4.66s  Val. loss: 0.175  Val. score: 94.794%\n",
      "Epoch 3, 100% \t Train loss: 0.167 took: 4.62s  Val. loss: 0.141  Val. score: 95.728%\n",
      "Epoch 4, 100% \t Train loss: 0.132 took: 4.81s  Val. loss: 0.127  Val. score: 96.111%\n",
      "Epoch 5, 100% \t Train loss: 0.107 took: 4.55s  Val. loss: 0.109  Val. score: 96.750%\n",
      "Epoch 6, 100% \t Train loss: 0.090 took: 4.85s  Val. loss: 0.101  Val. score: 97.006%\n",
      "Epoch 7, 100% \t Train loss: 0.079 took: 4.88s  Val. loss: 0.095  Val. score: 97.117%\n",
      "Epoch 8, 100% \t Train loss: 0.067 took: 4.69s  Val. loss: 0.099  Val. score: 97.000%\n",
      "Epoch 9, 100% \t Train loss: 0.058 took: 4.79s  Val. loss: 0.090  Val. score: 97.411%\n",
      "Epoch 10, 100% \t Train loss: 0.052 took: 5.04s  Val. loss: 0.089  Val. score: 97.328%\n",
      "Epoch 11, 100% \t Train loss: 0.045 took: 4.53s  Val. loss: 0.084  Val. score: 97.600%\n",
      "Epoch 12, 100% \t Train loss: 0.042 took: 4.49s  Val. loss: 0.086  Val. score: 97.506%\n",
      "Epoch 13, 100% \t Train loss: 0.035 took: 4.86s  Val. loss: 0.086  Val. score: 97.694%\n",
      "Epoch 14, 100% \t Train loss: 0.032 took: 4.54s  Val. loss: 0.085  Val. score: 97.628%\n",
      "Epoch 15, 100% \t Train loss: 0.031 took: 4.87s  Val. loss: 0.085  Val. score: 97.650%\n",
      "Training finished, took 120.215s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.461 took: 4.67s  Val. loss: 0.247  Val. score: 92.856%\n",
      "Epoch 2, 100% \t Train loss: 0.217 took: 4.46s  Val. loss: 0.172  Val. score: 95.189%\n",
      "Epoch 3, 100% \t Train loss: 0.157 took: 4.71s  Val. loss: 0.139  Val. score: 95.872%\n",
      "Epoch 4, 100% \t Train loss: 0.122 took: 5.20s  Val. loss: 0.122  Val. score: 96.361%\n",
      "Epoch 5, 100% \t Train loss: 0.102 took: 4.80s  Val. loss: 0.110  Val. score: 96.661%\n",
      "Epoch 6, 100% \t Train loss: 0.084 took: 4.71s  Val. loss: 0.104  Val. score: 96.906%\n",
      "Epoch 7, 100% \t Train loss: 0.070 took: 4.48s  Val. loss: 0.108  Val. score: 96.772%\n",
      "Epoch 8, 100% \t Train loss: 0.062 took: 4.80s  Val. loss: 0.098  Val. score: 96.978%\n",
      "Epoch 9, 100% \t Train loss: 0.053 took: 4.47s  Val. loss: 0.099  Val. score: 97.011%\n",
      "Epoch 10, 100% \t Train loss: 0.048 took: 4.74s  Val. loss: 0.094  Val. score: 97.194%\n",
      "Epoch 11, 100% \t Train loss: 0.041 took: 4.47s  Val. loss: 0.095  Val. score: 97.261%\n",
      "Epoch 12, 100% \t Train loss: 0.037 took: 4.77s  Val. loss: 0.095  Val. score: 97.367%\n",
      "Epoch 13, 100% \t Train loss: 0.031 took: 4.85s  Val. loss: 0.093  Val. score: 97.350%\n",
      "Epoch 14, 100% \t Train loss: 0.028 took: 4.86s  Val. loss: 0.094  Val. score: 97.394%\n",
      "Epoch 15, 100% \t Train loss: 0.026 took: 4.53s  Val. loss: 0.094  Val. score: 97.433%\n",
      "Training finished, took 121.046s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.465 took: 4.58s  Val. loss: 0.237  Val. score: 92.867%\n",
      "Epoch 2, 100% \t Train loss: 0.212 took: 4.30s  Val. loss: 0.169  Val. score: 94.833%\n",
      "Epoch 3, 100% \t Train loss: 0.158 took: 4.52s  Val. loss: 0.126  Val. score: 96.211%\n",
      "Epoch 4, 100% \t Train loss: 0.120 took: 4.83s  Val. loss: 0.117  Val. score: 96.483%\n",
      "Epoch 5, 100% \t Train loss: 0.098 took: 4.94s  Val. loss: 0.107  Val. score: 96.733%\n",
      "Epoch 6, 100% \t Train loss: 0.083 took: 4.59s  Val. loss: 0.108  Val. score: 96.678%\n",
      "Epoch 7, 100% \t Train loss: 0.072 took: 4.66s  Val. loss: 0.097  Val. score: 96.961%\n",
      "Epoch 8, 100% \t Train loss: 0.060 took: 4.76s  Val. loss: 0.101  Val. score: 96.972%\n",
      "Epoch 9, 100% \t Train loss: 0.052 took: 4.84s  Val. loss: 0.088  Val. score: 97.300%\n",
      "Epoch 10, 100% \t Train loss: 0.046 took: 4.57s  Val. loss: 0.091  Val. score: 97.233%\n",
      "Epoch 11, 100% \t Train loss: 0.040 took: 4.56s  Val. loss: 0.091  Val. score: 97.367%\n",
      "Epoch 12, 100% \t Train loss: 0.035 took: 4.78s  Val. loss: 0.092  Val. score: 97.417%\n",
      "Epoch 13, 100% \t Train loss: 0.030 took: 4.55s  Val. loss: 0.089  Val. score: 97.472%\n",
      "Epoch 14, 100% \t Train loss: 0.029 took: 4.88s  Val. loss: 0.090  Val. score: 97.406%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 4.58s  Val. loss: 0.092  Val. score: 97.372%\n",
      "Training finished, took 119.985s\n",
      "\n",
      "Parameters configuration 19 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004539410644004607\n",
      "h_sizes \t [784, 171, 38]\n",
      "penalty \t 0.0001967010074431286\n",
      "dropout \t 0.07750896302492466\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4852 +/- 0.1192\n",
      "Time for evaluation: 362.4 s\n",
      "Estimated time to finish : 11.03 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.550 took: 5.31s  Val. loss: 0.260  Val. score: 92.461%\n",
      "Epoch 2, 100% \t Train loss: 0.270 took: 4.54s  Val. loss: 0.180  Val. score: 94.750%\n",
      "Epoch 3, 100% \t Train loss: 0.202 took: 4.71s  Val. loss: 0.148  Val. score: 95.506%\n",
      "Epoch 4, 100% \t Train loss: 0.164 took: 4.79s  Val. loss: 0.127  Val. score: 96.033%\n",
      "Epoch 5, 100% \t Train loss: 0.139 took: 4.96s  Val. loss: 0.116  Val. score: 96.589%\n",
      "Epoch 6, 100% \t Train loss: 0.117 took: 4.81s  Val. loss: 0.106  Val. score: 96.783%\n",
      "Epoch 7, 100% \t Train loss: 0.102 took: 4.93s  Val. loss: 0.097  Val. score: 97.044%\n",
      "Epoch 8, 100% \t Train loss: 0.093 took: 4.81s  Val. loss: 0.094  Val. score: 97.128%\n",
      "Epoch 9, 100% \t Train loss: 0.082 took: 5.07s  Val. loss: 0.090  Val. score: 97.194%\n",
      "Epoch 10, 100% \t Train loss: 0.076 took: 4.92s  Val. loss: 0.089  Val. score: 97.228%\n",
      "Epoch 11, 100% \t Train loss: 0.068 took: 4.83s  Val. loss: 0.087  Val. score: 97.439%\n",
      "Epoch 12, 100% \t Train loss: 0.064 took: 4.83s  Val. loss: 0.084  Val. score: 97.422%\n",
      "Epoch 13, 100% \t Train loss: 0.057 took: 4.85s  Val. loss: 0.086  Val. score: 97.506%\n",
      "Epoch 14, 100% \t Train loss: 0.054 took: 5.25s  Val. loss: 0.083  Val. score: 97.489%\n",
      "Epoch 15, 100% \t Train loss: 0.051 took: 5.14s  Val. loss: 0.088  Val. score: 97.522%\n",
      "Training finished, took 125.206s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.549 took: 4.92s  Val. loss: 0.265  Val. score: 92.083%\n",
      "Epoch 2, 100% \t Train loss: 0.266 took: 4.91s  Val. loss: 0.190  Val. score: 94.289%\n",
      "Epoch 3, 100% \t Train loss: 0.201 took: 5.00s  Val. loss: 0.162  Val. score: 95.117%\n",
      "Epoch 4, 100% \t Train loss: 0.164 took: 5.23s  Val. loss: 0.137  Val. score: 95.800%\n",
      "Epoch 5, 100% \t Train loss: 0.140 took: 5.04s  Val. loss: 0.123  Val. score: 96.256%\n",
      "Epoch 6, 100% \t Train loss: 0.121 took: 5.01s  Val. loss: 0.122  Val. score: 96.289%\n",
      "Epoch 7, 100% \t Train loss: 0.106 took: 5.17s  Val. loss: 0.110  Val. score: 96.589%\n",
      "Epoch 8, 100% \t Train loss: 0.092 took: 5.29s  Val. loss: 0.101  Val. score: 96.917%\n",
      "Epoch 9, 100% \t Train loss: 0.083 took: 5.04s  Val. loss: 0.098  Val. score: 97.111%\n",
      "Epoch 10, 100% \t Train loss: 0.076 took: 4.86s  Val. loss: 0.097  Val. score: 97.067%\n",
      "Epoch 11, 100% \t Train loss: 0.071 took: 5.07s  Val. loss: 0.092  Val. score: 97.150%\n",
      "Epoch 12, 100% \t Train loss: 0.064 took: 5.15s  Val. loss: 0.091  Val. score: 97.361%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, 100% \t Train loss: 0.057 took: 4.95s  Val. loss: 0.089  Val. score: 97.328%\n",
      "Epoch 14, 100% \t Train loss: 0.053 took: 4.93s  Val. loss: 0.090  Val. score: 97.483%\n",
      "Epoch 15, 100% \t Train loss: 0.050 took: 4.80s  Val. loss: 0.088  Val. score: 97.533%\n",
      "Training finished, took 126.781s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.544 took: 4.57s  Val. loss: 0.257  Val. score: 92.561%\n",
      "Epoch 2, 100% \t Train loss: 0.259 took: 4.95s  Val. loss: 0.192  Val. score: 94.289%\n",
      "Epoch 3, 100% \t Train loss: 0.203 took: 4.75s  Val. loss: 0.148  Val. score: 95.517%\n",
      "Epoch 4, 100% \t Train loss: 0.161 took: 4.84s  Val. loss: 0.130  Val. score: 96.194%\n",
      "Epoch 5, 100% \t Train loss: 0.136 took: 4.79s  Val. loss: 0.121  Val. score: 96.367%\n",
      "Epoch 6, 100% \t Train loss: 0.118 took: 5.00s  Val. loss: 0.109  Val. score: 96.728%\n",
      "Epoch 7, 100% \t Train loss: 0.105 took: 4.75s  Val. loss: 0.102  Val. score: 97.006%\n",
      "Epoch 8, 100% \t Train loss: 0.091 took: 4.85s  Val. loss: 0.100  Val. score: 97.028%\n",
      "Epoch 9, 100% \t Train loss: 0.085 took: 4.91s  Val. loss: 0.095  Val. score: 97.133%\n",
      "Epoch 10, 100% \t Train loss: 0.077 took: 4.83s  Val. loss: 0.092  Val. score: 97.322%\n",
      "Epoch 11, 100% \t Train loss: 0.071 took: 5.04s  Val. loss: 0.091  Val. score: 97.389%\n",
      "Epoch 12, 100% \t Train loss: 0.061 took: 5.17s  Val. loss: 0.090  Val. score: 97.406%\n",
      "Epoch 13, 100% \t Train loss: 0.057 took: 4.83s  Val. loss: 0.089  Val. score: 97.533%\n",
      "Epoch 14, 100% \t Train loss: 0.052 took: 5.03s  Val. loss: 0.094  Val. score: 97.328%\n",
      "Epoch 15, 100% \t Train loss: 0.048 took: 5.13s  Val. loss: 0.087  Val. score: 97.494%\n",
      "Training finished, took 124.751s\n",
      "\n",
      "Parameters configuration 20 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0032471967584768507\n",
      "h_sizes \t [784, 189, 46]\n",
      "penalty \t 0.001713925332187699\n",
      "dropout \t 0.18698372169408045\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5167 +/- 0.0164\n",
      "Time for evaluation: 377.9 s\n",
      "Estimated time to finish : 10.77 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.545 took: 10.31s  Val. loss: 0.197  Val. score: 94.544%\n",
      "Epoch 2, 100% \t Train loss: 0.190 took: 10.99s  Val. loss: 0.148  Val. score: 96.017%\n",
      "Epoch 3, 100% \t Train loss: 0.139 took: 11.41s  Val. loss: 0.126  Val. score: 96.644%\n",
      "Epoch 4, 100% \t Train loss: 0.107 took: 12.02s  Val. loss: 0.119  Val. score: 96.806%\n",
      "Epoch 5, 100% \t Train loss: 0.089 took: 12.27s  Val. loss: 0.102  Val. score: 97.356%\n",
      "Epoch 6, 100% \t Train loss: 0.076 took: 11.88s  Val. loss: 0.125  Val. score: 96.800%\n",
      "Epoch 7, 100% \t Train loss: 0.063 took: 12.39s  Val. loss: 0.112  Val. score: 97.289%\n",
      "Epoch 8, 100% \t Train loss: 0.052 took: 11.90s  Val. loss: 0.111  Val. score: 97.456%\n",
      "Epoch 9, 100% \t Train loss: 0.047 took: 12.24s  Val. loss: 0.109  Val. score: 97.456%\n",
      "Epoch 10, 100% \t Train loss: 0.035 took: 11.86s  Val. loss: 0.115  Val. score: 97.511%\n",
      "Epoch 11, 100% \t Train loss: 0.037 took: 12.65s  Val. loss: 0.110  Val. score: 97.633%\n",
      "Epoch 12, 100% \t Train loss: 0.030 took: 12.82s  Val. loss: 0.126  Val. score: 97.622%\n",
      "Epoch 13, 100% \t Train loss: 0.028 took: 12.46s  Val. loss: 0.119  Val. score: 97.783%\n",
      "Epoch 14, 100% \t Train loss: 0.024 took: 12.84s  Val. loss: 0.121  Val. score: 97.589%\n",
      "Epoch 15, 100% \t Train loss: 0.021 took: 12.04s  Val. loss: 0.124  Val. score: 97.594%\n",
      "Training finished, took 260.660s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.523 took: 10.82s  Val. loss: 0.198  Val. score: 94.800%\n",
      "Epoch 2, 100% \t Train loss: 0.191 took: 10.92s  Val. loss: 0.156  Val. score: 95.828%\n",
      "Epoch 3, 100% \t Train loss: 0.129 took: 11.70s  Val. loss: 0.153  Val. score: 95.978%\n",
      "Epoch 4, 100% \t Train loss: 0.103 took: 12.29s  Val. loss: 0.146  Val. score: 96.578%\n",
      "Epoch 5, 100% \t Train loss: 0.078 took: 12.96s  Val. loss: 0.138  Val. score: 96.961%\n",
      "Epoch 6, 100% \t Train loss: 0.068 took: 12.87s  Val. loss: 0.132  Val. score: 97.067%\n",
      "Epoch 7, 100% \t Train loss: 0.057 took: 12.52s  Val. loss: 0.141  Val. score: 97.078%\n",
      "Epoch 8, 100% \t Train loss: 0.053 took: 12.69s  Val. loss: 0.141  Val. score: 96.917%\n",
      "Epoch 9, 100% \t Train loss: 0.040 took: 12.94s  Val. loss: 0.128  Val. score: 97.339%\n",
      "Epoch 10, 100% \t Train loss: 0.037 took: 12.13s  Val. loss: 0.136  Val. score: 97.400%\n",
      "Epoch 11, 100% \t Train loss: 0.032 took: 12.22s  Val. loss: 0.143  Val. score: 97.472%\n",
      "Epoch 12, 100% \t Train loss: 0.030 took: 12.90s  Val. loss: 0.140  Val. score: 97.422%\n",
      "Epoch 13, 100% \t Train loss: 0.027 took: 12.28s  Val. loss: 0.147  Val. score: 97.394%\n",
      "Epoch 14, 100% \t Train loss: 0.025 took: 12.13s  Val. loss: 0.139  Val. score: 97.478%\n",
      "Epoch 15, 100% \t Train loss: 0.016 took: 12.19s  Val. loss: 0.174  Val. score: 97.644%\n",
      "Training finished, took 264.625s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.523 took: 10.41s  Val. loss: 0.195  Val. score: 94.611%\n",
      "Epoch 2, 100% \t Train loss: 0.193 took: 10.18s  Val. loss: 0.163  Val. score: 95.461%\n",
      "Epoch 3, 100% \t Train loss: 0.141 took: 12.35s  Val. loss: 0.125  Val. score: 96.800%\n",
      "Epoch 4, 100% \t Train loss: 0.111 took: 13.01s  Val. loss: 0.142  Val. score: 96.289%\n",
      "Epoch 5, 100% \t Train loss: 0.095 took: 12.97s  Val. loss: 0.119  Val. score: 96.761%\n",
      "Epoch 6, 100% \t Train loss: 0.075 took: 13.38s  Val. loss: 0.115  Val. score: 97.206%\n",
      "Epoch 7, 100% \t Train loss: 0.061 took: 12.66s  Val. loss: 0.113  Val. score: 97.328%\n",
      "Epoch 8, 100% \t Train loss: 0.055 took: 13.07s  Val. loss: 0.119  Val. score: 97.317%\n",
      "Epoch 9, 100% \t Train loss: 0.046 took: 12.99s  Val. loss: 0.111  Val. score: 97.333%\n",
      "Epoch 10, 100% \t Train loss: 0.041 took: 12.58s  Val. loss: 0.113  Val. score: 97.533%\n",
      "Epoch 11, 100% \t Train loss: 0.035 took: 12.27s  Val. loss: 0.106  Val. score: 97.733%\n",
      "Epoch 12, 100% \t Train loss: 0.029 took: 12.89s  Val. loss: 0.121  Val. score: 97.411%\n",
      "Epoch 13, 100% \t Train loss: 0.030 took: 12.92s  Val. loss: 0.122  Val. score: 97.533%\n",
      "Epoch 14, 100% \t Train loss: 0.028 took: 12.58s  Val. loss: 0.126  Val. score: 97.544%\n",
      "Epoch 15, 100% \t Train loss: 0.026 took: 12.43s  Val. loss: 0.117  Val. score: 97.739%\n",
      "Training finished, took 268.065s\n",
      "\n",
      "Parameters configuration 21 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.015481261734608174\n",
      "h_sizes \t [784, 410, 215, 107, 47, 23]\n",
      "penalty \t 0.001119792400730838\n",
      "dropout \t 0.07177034193066756\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6593 +/- 0.0599\n",
      "Time for evaluation: 794.5 s\n",
      "Estimated time to finish : 10.96 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.560 took: 6.57s  Val. loss: 0.218  Val. score: 93.511%\n",
      "Epoch 2, 100% \t Train loss: 0.241 took: 6.28s  Val. loss: 0.165  Val. score: 95.150%\n",
      "Epoch 3, 100% \t Train loss: 0.180 took: 6.66s  Val. loss: 0.129  Val. score: 96.172%\n",
      "Epoch 4, 100% \t Train loss: 0.147 took: 6.45s  Val. loss: 0.124  Val. score: 96.506%\n",
      "Epoch 5, 100% \t Train loss: 0.124 took: 6.45s  Val. loss: 0.104  Val. score: 97.039%\n",
      "Epoch 6, 100% \t Train loss: 0.105 took: 6.04s  Val. loss: 0.104  Val. score: 97.078%\n",
      "Epoch 7, 100% \t Train loss: 0.087 took: 6.18s  Val. loss: 0.100  Val. score: 97.289%\n",
      "Epoch 8, 100% \t Train loss: 0.080 took: 5.96s  Val. loss: 0.093  Val. score: 97.389%\n",
      "Epoch 9, 100% \t Train loss: 0.069 took: 6.03s  Val. loss: 0.095  Val. score: 97.406%\n",
      "Epoch 10, 100% \t Train loss: 0.064 took: 6.38s  Val. loss: 0.090  Val. score: 97.500%\n",
      "Epoch 11, 100% \t Train loss: 0.058 took: 6.59s  Val. loss: 0.089  Val. score: 97.644%\n",
      "Epoch 12, 100% \t Train loss: 0.055 took: 6.49s  Val. loss: 0.091  Val. score: 97.706%\n",
      "Epoch 13, 100% \t Train loss: 0.045 took: 6.11s  Val. loss: 0.097  Val. score: 97.600%\n",
      "Epoch 14, 100% \t Train loss: 0.043 took: 6.49s  Val. loss: 0.096  Val. score: 97.733%\n",
      "Epoch 15, 100% \t Train loss: 0.039 took: 6.65s  Val. loss: 0.091  Val. score: 97.794%\n",
      "Training finished, took 154.086s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.575 took: 6.47s  Val. loss: 0.218  Val. score: 93.561%\n",
      "Epoch 2, 100% \t Train loss: 0.242 took: 6.60s  Val. loss: 0.157  Val. score: 95.344%\n",
      "Epoch 3, 100% \t Train loss: 0.178 took: 6.59s  Val. loss: 0.149  Val. score: 95.800%\n",
      "Epoch 4, 100% \t Train loss: 0.142 took: 6.65s  Val. loss: 0.118  Val. score: 96.522%\n",
      "Epoch 5, 100% \t Train loss: 0.119 took: 6.28s  Val. loss: 0.113  Val. score: 96.706%\n",
      "Epoch 6, 100% \t Train loss: 0.105 took: 6.05s  Val. loss: 0.108  Val. score: 96.883%\n",
      "Epoch 7, 100% \t Train loss: 0.086 took: 6.52s  Val. loss: 0.106  Val. score: 97.089%\n",
      "Epoch 8, 100% \t Train loss: 0.075 took: 6.32s  Val. loss: 0.109  Val. score: 97.139%\n",
      "Epoch 9, 100% \t Train loss: 0.066 took: 6.03s  Val. loss: 0.112  Val. score: 97.094%\n",
      "Epoch 10, 100% \t Train loss: 0.061 took: 6.53s  Val. loss: 0.101  Val. score: 97.400%\n",
      "Epoch 11, 100% \t Train loss: 0.054 took: 6.42s  Val. loss: 0.101  Val. score: 97.461%\n",
      "Epoch 12, 100% \t Train loss: 0.049 took: 6.18s  Val. loss: 0.101  Val. score: 97.550%\n",
      "Epoch 13, 100% \t Train loss: 0.046 took: 6.08s  Val. loss: 0.107  Val. score: 97.472%\n",
      "Epoch 14, 100% \t Train loss: 0.040 took: 6.48s  Val. loss: 0.112  Val. score: 97.506%\n",
      "Epoch 15, 100% \t Train loss: 0.037 took: 6.45s  Val. loss: 0.105  Val. score: 97.583%\n",
      "Training finished, took 155.260s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.567 took: 6.66s  Val. loss: 0.219  Val. score: 93.606%\n",
      "Epoch 2, 100% \t Train loss: 0.237 took: 6.20s  Val. loss: 0.157  Val. score: 95.450%\n",
      "Epoch 3, 100% \t Train loss: 0.181 took: 6.30s  Val. loss: 0.123  Val. score: 96.567%\n",
      "Epoch 4, 100% \t Train loss: 0.142 took: 6.15s  Val. loss: 0.114  Val. score: 96.739%\n",
      "Epoch 5, 100% \t Train loss: 0.122 took: 6.56s  Val. loss: 0.108  Val. score: 97.039%\n",
      "Epoch 6, 100% \t Train loss: 0.101 took: 6.12s  Val. loss: 0.102  Val. score: 97.333%\n",
      "Epoch 7, 100% \t Train loss: 0.090 took: 6.08s  Val. loss: 0.101  Val. score: 97.283%\n",
      "Epoch 8, 100% \t Train loss: 0.077 took: 6.08s  Val. loss: 0.099  Val. score: 97.428%\n",
      "Epoch 9, 100% \t Train loss: 0.072 took: 6.38s  Val. loss: 0.095  Val. score: 97.489%\n",
      "Epoch 10, 100% \t Train loss: 0.061 took: 6.03s  Val. loss: 0.091  Val. score: 97.611%\n",
      "Epoch 11, 100% \t Train loss: 0.060 took: 5.96s  Val. loss: 0.093  Val. score: 97.656%\n",
      "Epoch 12, 100% \t Train loss: 0.048 took: 6.15s  Val. loss: 0.096  Val. score: 97.611%\n",
      "Epoch 13, 100% \t Train loss: 0.046 took: 6.21s  Val. loss: 0.101  Val. score: 97.606%\n",
      "Epoch 14, 100% \t Train loss: 0.045 took: 5.99s  Val. loss: 0.091  Val. score: 97.772%\n",
      "Epoch 15, 100% \t Train loss: 0.039 took: 6.45s  Val. loss: 0.098  Val. score: 97.728%\n",
      "Training finished, took 152.289s\n",
      "\n",
      "Parameters configuration 22 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005872377709044323\n",
      "h_sizes \t [784, 275, 85, 27]\n",
      "penalty \t 0.004387508751456251\n",
      "dropout \t 0.19204362745606335\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.7019 +/- 0.0881\n",
      "Time for evaluation: 462.8 s\n",
      "Estimated time to finish : 10.78 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.521 took: 6.58s  Val. loss: 0.233  Val. score: 93.067%\n",
      "Epoch 2, 100% \t Train loss: 0.210 took: 6.79s  Val. loss: 0.170  Val. score: 94.928%\n",
      "Epoch 3, 100% \t Train loss: 0.148 took: 6.32s  Val. loss: 0.132  Val. score: 95.972%\n",
      "Epoch 4, 100% \t Train loss: 0.111 took: 6.64s  Val. loss: 0.114  Val. score: 96.617%\n",
      "Epoch 5, 100% \t Train loss: 0.087 took: 6.69s  Val. loss: 0.099  Val. score: 96.950%\n",
      "Epoch 6, 100% \t Train loss: 0.066 took: 6.86s  Val. loss: 0.095  Val. score: 97.089%\n",
      "Epoch 7, 100% \t Train loss: 0.053 took: 6.28s  Val. loss: 0.096  Val. score: 97.078%\n",
      "Epoch 8, 100% \t Train loss: 0.042 took: 6.48s  Val. loss: 0.088  Val. score: 97.361%\n",
      "Epoch 9, 100% \t Train loss: 0.032 took: 6.19s  Val. loss: 0.088  Val. score: 97.439%\n",
      "Epoch 10, 100% \t Train loss: 0.026 took: 6.58s  Val. loss: 0.092  Val. score: 97.417%\n",
      "Epoch 11, 100% \t Train loss: 0.019 took: 6.79s  Val. loss: 0.089  Val. score: 97.617%\n",
      "Epoch 12, 100% \t Train loss: 0.016 took: 6.23s  Val. loss: 0.088  Val. score: 97.594%\n",
      "Epoch 13, 100% \t Train loss: 0.014 took: 6.81s  Val. loss: 0.092  Val. score: 97.617%\n",
      "Epoch 14, 100% \t Train loss: 0.009 took: 6.65s  Val. loss: 0.103  Val. score: 97.483%\n",
      "Epoch 15, 100% \t Train loss: 0.009 took: 6.72s  Val. loss: 0.106  Val. score: 97.467%\n",
      "Training finished, took 158.288s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.506 took: 6.22s  Val. loss: 0.261  Val. score: 92.150%\n",
      "Epoch 2, 100% \t Train loss: 0.194 took: 6.70s  Val. loss: 0.171  Val. score: 94.811%\n",
      "Epoch 3, 100% \t Train loss: 0.130 took: 6.94s  Val. loss: 0.148  Val. score: 95.628%\n",
      "Epoch 4, 100% \t Train loss: 0.097 took: 6.69s  Val. loss: 0.124  Val. score: 96.306%\n",
      "Epoch 5, 100% \t Train loss: 0.074 took: 6.82s  Val. loss: 0.105  Val. score: 96.972%\n",
      "Epoch 6, 100% \t Train loss: 0.057 took: 6.42s  Val. loss: 0.110  Val. score: 96.861%\n",
      "Epoch 7, 100% \t Train loss: 0.046 took: 6.38s  Val. loss: 0.117  Val. score: 96.556%\n",
      "Epoch 8, 100% \t Train loss: 0.037 took: 6.67s  Val. loss: 0.102  Val. score: 97.228%\n",
      "Epoch 9, 100% \t Train loss: 0.030 took: 6.78s  Val. loss: 0.104  Val. score: 97.339%\n",
      "Epoch 10, 100% \t Train loss: 0.021 took: 6.42s  Val. loss: 0.103  Val. score: 97.233%\n",
      "Epoch 11, 100% \t Train loss: 0.016 took: 6.80s  Val. loss: 0.111  Val. score: 97.183%\n",
      "Epoch 12, 100% \t Train loss: 0.014 took: 6.98s  Val. loss: 0.098  Val. score: 97.661%\n",
      "Epoch 13, 100% \t Train loss: 0.011 took: 6.98s  Val. loss: 0.110  Val. score: 97.467%\n",
      "Epoch 14, 100% \t Train loss: 0.009 took: 6.75s  Val. loss: 0.119  Val. score: 97.211%\n",
      "Epoch 15, 100% \t Train loss: 0.006 took: 6.63s  Val. loss: 0.118  Val. score: 97.533%\n",
      "Training finished, took 160.678s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.497 took: 6.63s  Val. loss: 0.264  Val. score: 92.339%\n",
      "Epoch 2, 100% \t Train loss: 0.209 took: 6.34s  Val. loss: 0.175  Val. score: 95.022%\n",
      "Epoch 3, 100% \t Train loss: 0.142 took: 7.00s  Val. loss: 0.145  Val. score: 95.706%\n",
      "Epoch 4, 100% \t Train loss: 0.109 took: 6.76s  Val. loss: 0.119  Val. score: 96.439%\n",
      "Epoch 5, 100% \t Train loss: 0.087 took: 6.84s  Val. loss: 0.111  Val. score: 96.678%\n",
      "Epoch 6, 100% \t Train loss: 0.069 took: 7.11s  Val. loss: 0.102  Val. score: 97.000%\n",
      "Epoch 7, 100% \t Train loss: 0.055 took: 7.28s  Val. loss: 0.104  Val. score: 97.022%\n",
      "Epoch 8, 100% \t Train loss: 0.044 took: 6.45s  Val. loss: 0.095  Val. score: 97.300%\n",
      "Epoch 9, 100% \t Train loss: 0.037 took: 6.56s  Val. loss: 0.099  Val. score: 97.306%\n",
      "Epoch 10, 100% \t Train loss: 0.027 took: 6.67s  Val. loss: 0.114  Val. score: 97.039%\n",
      "Epoch 11, 100% \t Train loss: 0.022 took: 6.41s  Val. loss: 0.104  Val. score: 97.233%\n",
      "Epoch 12, 100% \t Train loss: 0.017 took: 6.90s  Val. loss: 0.111  Val. score: 97.250%\n",
      "Epoch 13, 100% \t Train loss: 0.015 took: 6.64s  Val. loss: 0.106  Val. score: 97.383%\n",
      "Epoch 14, 100% \t Train loss: 0.012 took: 6.32s  Val. loss: 0.113  Val. score: 97.250%\n",
      "Epoch 15, 100% \t Train loss: 0.010 took: 7.10s  Val. loss: 0.114  Val. score: 97.544%\n",
      "Training finished, took 161.736s\n",
      "\n",
      "Parameters configuration 23 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003687605348420281\n",
      "h_sizes \t [784, 289, 90, 26]\n",
      "penalty \t 0.0016725518176625457\n",
      "dropout \t 0.0074038631830046775\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.5148 +/- 0.0343\n",
      "Time for evaluation: 481.9 s\n",
      "Estimated time to finish : 10.63 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.628 took: 4.72s  Val. loss: 0.302  Val. score: 91.256%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.306 took: 4.90s  Val. loss: 0.224  Val. score: 93.300%\n",
      "Epoch 3, 100% \t Train loss: 0.234 took: 4.81s  Val. loss: 0.184  Val. score: 94.556%\n",
      "Epoch 4, 100% \t Train loss: 0.195 took: 4.62s  Val. loss: 0.157  Val. score: 95.306%\n",
      "Epoch 5, 100% \t Train loss: 0.166 took: 4.79s  Val. loss: 0.144  Val. score: 95.656%\n",
      "Epoch 6, 100% \t Train loss: 0.143 took: 4.41s  Val. loss: 0.127  Val. score: 96.183%\n",
      "Epoch 7, 100% \t Train loss: 0.129 took: 4.41s  Val. loss: 0.118  Val. score: 96.383%\n",
      "Epoch 8, 100% \t Train loss: 0.111 took: 4.86s  Val. loss: 0.111  Val. score: 96.656%\n",
      "Epoch 9, 100% \t Train loss: 0.104 took: 4.80s  Val. loss: 0.105  Val. score: 96.889%\n",
      "Epoch 10, 100% \t Train loss: 0.094 took: 4.78s  Val. loss: 0.104  Val. score: 96.806%\n",
      "Epoch 11, 100% \t Train loss: 0.086 took: 4.89s  Val. loss: 0.096  Val. score: 97.161%\n",
      "Epoch 12, 100% \t Train loss: 0.077 took: 4.65s  Val. loss: 0.096  Val. score: 97.239%\n",
      "Epoch 13, 100% \t Train loss: 0.072 took: 4.42s  Val. loss: 0.093  Val. score: 97.256%\n",
      "Epoch 14, 100% \t Train loss: 0.067 took: 4.79s  Val. loss: 0.092  Val. score: 97.394%\n",
      "Epoch 15, 100% \t Train loss: 0.062 took: 4.64s  Val. loss: 0.089  Val. score: 97.361%\n",
      "Training finished, took 120.756s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.625 took: 4.66s  Val. loss: 0.317  Val. score: 90.567%\n",
      "Epoch 2, 100% \t Train loss: 0.312 took: 4.81s  Val. loss: 0.243  Val. score: 92.878%\n",
      "Epoch 3, 100% \t Train loss: 0.241 took: 4.74s  Val. loss: 0.199  Val. score: 94.022%\n",
      "Epoch 4, 100% \t Train loss: 0.197 took: 4.86s  Val. loss: 0.172  Val. score: 94.900%\n",
      "Epoch 5, 100% \t Train loss: 0.169 took: 4.88s  Val. loss: 0.157  Val. score: 95.361%\n",
      "Epoch 6, 100% \t Train loss: 0.148 took: 4.54s  Val. loss: 0.141  Val. score: 95.722%\n",
      "Epoch 7, 100% \t Train loss: 0.132 took: 4.87s  Val. loss: 0.127  Val. score: 96.178%\n",
      "Epoch 8, 100% \t Train loss: 0.119 took: 4.38s  Val. loss: 0.123  Val. score: 96.317%\n",
      "Epoch 9, 100% \t Train loss: 0.107 took: 4.48s  Val. loss: 0.118  Val. score: 96.444%\n",
      "Epoch 10, 100% \t Train loss: 0.097 took: 4.81s  Val. loss: 0.110  Val. score: 96.622%\n",
      "Epoch 11, 100% \t Train loss: 0.087 took: 4.48s  Val. loss: 0.108  Val. score: 96.733%\n",
      "Epoch 12, 100% \t Train loss: 0.083 took: 4.54s  Val. loss: 0.105  Val. score: 96.839%\n",
      "Epoch 13, 100% \t Train loss: 0.075 took: 4.74s  Val. loss: 0.101  Val. score: 96.972%\n",
      "Epoch 14, 100% \t Train loss: 0.069 took: 4.56s  Val. loss: 0.101  Val. score: 97.128%\n",
      "Epoch 15, 100% \t Train loss: 0.066 took: 4.43s  Val. loss: 0.101  Val. score: 97.033%\n",
      "Training finished, took 119.691s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.657 took: 4.40s  Val. loss: 0.290  Val. score: 92.000%\n",
      "Epoch 2, 100% \t Train loss: 0.311 took: 4.60s  Val. loss: 0.213  Val. score: 93.889%\n",
      "Epoch 3, 100% \t Train loss: 0.237 took: 4.81s  Val. loss: 0.175  Val. score: 94.894%\n",
      "Epoch 4, 100% \t Train loss: 0.195 took: 4.56s  Val. loss: 0.149  Val. score: 95.483%\n",
      "Epoch 5, 100% \t Train loss: 0.163 took: 4.49s  Val. loss: 0.134  Val. score: 95.994%\n",
      "Epoch 6, 100% \t Train loss: 0.143 took: 4.79s  Val. loss: 0.117  Val. score: 96.461%\n",
      "Epoch 7, 100% \t Train loss: 0.127 took: 4.45s  Val. loss: 0.108  Val. score: 96.622%\n",
      "Epoch 8, 100% \t Train loss: 0.116 took: 4.75s  Val. loss: 0.102  Val. score: 96.833%\n",
      "Epoch 9, 100% \t Train loss: 0.104 took: 4.73s  Val. loss: 0.094  Val. score: 97.094%\n",
      "Epoch 10, 100% \t Train loss: 0.093 took: 4.46s  Val. loss: 0.091  Val. score: 97.150%\n",
      "Epoch 11, 100% \t Train loss: 0.087 took: 4.83s  Val. loss: 0.090  Val. score: 97.294%\n",
      "Epoch 12, 100% \t Train loss: 0.078 took: 4.90s  Val. loss: 0.089  Val. score: 97.278%\n",
      "Epoch 13, 100% \t Train loss: 0.074 took: 4.75s  Val. loss: 0.085  Val. score: 97.294%\n",
      "Epoch 14, 100% \t Train loss: 0.069 took: 4.45s  Val. loss: 0.082  Val. score: 97.461%\n",
      "Epoch 15, 100% \t Train loss: 0.063 took: 4.58s  Val. loss: 0.081  Val. score: 97.550%\n",
      "Training finished, took 119.265s\n",
      "\n",
      "Parameters configuration 24 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0020430674296646073\n",
      "h_sizes \t [784, 189, 45]\n",
      "penalty \t 0.00048243589313862537\n",
      "dropout \t 0.17330228520124988\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.3148 +/- 0.2135\n",
      "Time for evaluation: 360.9 s\n",
      "Estimated time to finish : 10.37 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.588 took: 8.03s  Val. loss: 0.270  Val. score: 91.956%\n",
      "Epoch 2, 100% \t Train loss: 0.236 took: 8.72s  Val. loss: 0.197  Val. score: 94.028%\n",
      "Epoch 3, 100% \t Train loss: 0.161 took: 8.69s  Val. loss: 0.141  Val. score: 96.072%\n",
      "Epoch 4, 100% \t Train loss: 0.123 took: 8.55s  Val. loss: 0.147  Val. score: 95.850%\n",
      "Epoch 5, 100% \t Train loss: 0.095 took: 8.35s  Val. loss: 0.118  Val. score: 96.750%\n",
      "Epoch 6, 100% \t Train loss: 0.077 took: 8.84s  Val. loss: 0.124  Val. score: 96.611%\n",
      "Epoch 7, 100% \t Train loss: 0.068 took: 8.59s  Val. loss: 0.110  Val. score: 97.044%\n",
      "Epoch 8, 100% \t Train loss: 0.052 took: 8.34s  Val. loss: 0.111  Val. score: 97.222%\n",
      "Epoch 9, 100% \t Train loss: 0.043 took: 8.75s  Val. loss: 0.107  Val. score: 97.267%\n",
      "Epoch 10, 100% \t Train loss: 0.036 took: 8.37s  Val. loss: 0.106  Val. score: 97.372%\n",
      "Epoch 11, 100% \t Train loss: 0.033 took: 8.87s  Val. loss: 0.101  Val. score: 97.533%\n",
      "Epoch 12, 100% \t Train loss: 0.028 took: 8.36s  Val. loss: 0.115  Val. score: 97.311%\n",
      "Epoch 13, 100% \t Train loss: 0.024 took: 8.50s  Val. loss: 0.107  Val. score: 97.583%\n",
      "Epoch 14, 100% \t Train loss: 0.021 took: 9.03s  Val. loss: 0.113  Val. score: 97.517%\n",
      "Epoch 15, 100% \t Train loss: 0.016 took: 8.63s  Val. loss: 0.114  Val. score: 97.622%\n",
      "Training finished, took 198.628s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.625 took: 7.82s  Val. loss: 0.259  Val. score: 92.583%\n",
      "Epoch 2, 100% \t Train loss: 0.232 took: 7.83s  Val. loss: 0.172  Val. score: 95.011%\n",
      "Epoch 3, 100% \t Train loss: 0.164 took: 8.56s  Val. loss: 0.134  Val. score: 96.206%\n",
      "Epoch 4, 100% \t Train loss: 0.124 took: 8.76s  Val. loss: 0.112  Val. score: 96.767%\n",
      "Epoch 5, 100% \t Train loss: 0.096 took: 8.76s  Val. loss: 0.105  Val. score: 97.078%\n",
      "Epoch 6, 100% \t Train loss: 0.078 took: 9.14s  Val. loss: 0.114  Val. score: 96.850%\n",
      "Epoch 7, 100% \t Train loss: 0.062 took: 8.88s  Val. loss: 0.100  Val. score: 97.233%\n",
      "Epoch 8, 100% \t Train loss: 0.053 took: 8.70s  Val. loss: 0.106  Val. score: 97.222%\n",
      "Epoch 9, 100% \t Train loss: 0.045 took: 8.56s  Val. loss: 0.098  Val. score: 97.533%\n",
      "Epoch 10, 100% \t Train loss: 0.036 took: 8.47s  Val. loss: 0.096  Val. score: 97.378%\n",
      "Epoch 11, 100% \t Train loss: 0.028 took: 9.00s  Val. loss: 0.107  Val. score: 97.306%\n",
      "Epoch 12, 100% \t Train loss: 0.023 took: 9.38s  Val. loss: 0.108  Val. score: 97.500%\n",
      "Epoch 13, 100% \t Train loss: 0.020 took: 8.58s  Val. loss: 0.110  Val. score: 97.428%\n",
      "Epoch 14, 100% \t Train loss: 0.018 took: 8.62s  Val. loss: 0.104  Val. score: 97.717%\n",
      "Epoch 15, 100% \t Train loss: 0.015 took: 9.09s  Val. loss: 0.111  Val. score: 97.611%\n",
      "Training finished, took 200.377s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.593 took: 7.98s  Val. loss: 0.265  Val. score: 92.050%\n",
      "Epoch 2, 100% \t Train loss: 0.238 took: 8.18s  Val. loss: 0.195  Val. score: 93.933%\n",
      "Epoch 3, 100% \t Train loss: 0.167 took: 8.45s  Val. loss: 0.137  Val. score: 95.917%\n",
      "Epoch 4, 100% \t Train loss: 0.122 took: 8.78s  Val. loss: 0.128  Val. score: 96.200%\n",
      "Epoch 5, 100% \t Train loss: 0.101 took: 8.45s  Val. loss: 0.104  Val. score: 96.928%\n",
      "Epoch 6, 100% \t Train loss: 0.080 took: 8.84s  Val. loss: 0.107  Val. score: 96.983%\n",
      "Epoch 7, 100% \t Train loss: 0.064 took: 8.79s  Val. loss: 0.102  Val. score: 97.156%\n",
      "Epoch 8, 100% \t Train loss: 0.050 took: 9.17s  Val. loss: 0.103  Val. score: 97.128%\n",
      "Epoch 9, 100% \t Train loss: 0.044 took: 8.55s  Val. loss: 0.100  Val. score: 97.233%\n",
      "Epoch 10, 100% \t Train loss: 0.038 took: 8.63s  Val. loss: 0.096  Val. score: 97.461%\n",
      "Epoch 11, 100% \t Train loss: 0.031 took: 8.93s  Val. loss: 0.098  Val. score: 97.478%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, 100% \t Train loss: 0.027 took: 8.81s  Val. loss: 0.100  Val. score: 97.511%\n",
      "Epoch 13, 100% \t Train loss: 0.023 took: 8.96s  Val. loss: 0.109  Val. score: 97.300%\n",
      "Epoch 14, 100% \t Train loss: 0.019 took: 8.66s  Val. loss: 0.100  Val. score: 97.572%\n",
      "Epoch 15, 100% \t Train loss: 0.017 took: 8.76s  Val. loss: 0.108  Val. score: 97.494%\n",
      "Training finished, took 200.325s\n",
      "\n",
      "Parameters configuration 25 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003281509558943158\n",
      "h_sizes \t [784, 329, 154, 61, 27]\n",
      "penalty \t 0.0001971321323496235\n",
      "dropout \t 0.05856873525082368\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5759 +/- 0.0578\n",
      "Time for evaluation: 600.5 s\n",
      "Estimated time to finish : 10.33 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.383 took: 6.13s  Val. loss: 0.180  Val. score: 94.700%\n",
      "Epoch 2, 100% \t Train loss: 0.156 took: 6.06s  Val. loss: 0.152  Val. score: 95.494%\n",
      "Epoch 3, 100% \t Train loss: 0.111 took: 6.55s  Val. loss: 0.113  Val. score: 96.594%\n",
      "Epoch 4, 100% \t Train loss: 0.086 took: 6.86s  Val. loss: 0.111  Val. score: 96.700%\n",
      "Epoch 5, 100% \t Train loss: 0.068 took: 7.30s  Val. loss: 0.093  Val. score: 97.250%\n",
      "Epoch 6, 100% \t Train loss: 0.054 took: 7.19s  Val. loss: 0.101  Val. score: 97.056%\n",
      "Epoch 7, 100% \t Train loss: 0.045 took: 6.86s  Val. loss: 0.090  Val. score: 97.461%\n",
      "Epoch 8, 100% \t Train loss: 0.036 took: 6.84s  Val. loss: 0.094  Val. score: 97.450%\n",
      "Epoch 9, 100% \t Train loss: 0.031 took: 6.90s  Val. loss: 0.090  Val. score: 97.644%\n",
      "Epoch 10, 100% \t Train loss: 0.027 took: 6.97s  Val. loss: 0.089  Val. score: 97.583%\n",
      "Epoch 11, 100% \t Train loss: 0.024 took: 7.43s  Val. loss: 0.099  Val. score: 97.394%\n",
      "Epoch 12, 100% \t Train loss: 0.020 took: 7.23s  Val. loss: 0.116  Val. score: 97.317%\n",
      "Epoch 13, 100% \t Train loss: 0.016 took: 7.12s  Val. loss: 0.120  Val. score: 97.456%\n",
      "Epoch 14, 100% \t Train loss: 0.018 took: 7.05s  Val. loss: 0.111  Val. score: 97.517%\n",
      "Epoch 15, 100% \t Train loss: 0.015 took: 6.70s  Val. loss: 0.115  Val. score: 97.583%\n",
      "Training finished, took 163.158s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.369 took: 5.98s  Val. loss: 0.183  Val. score: 94.539%\n",
      "Epoch 2, 100% \t Train loss: 0.144 took: 5.97s  Val. loss: 0.128  Val. score: 96.228%\n",
      "Epoch 3, 100% \t Train loss: 0.104 took: 6.58s  Val. loss: 0.110  Val. score: 96.706%\n",
      "Epoch 4, 100% \t Train loss: 0.076 took: 7.17s  Val. loss: 0.101  Val. score: 97.106%\n",
      "Epoch 5, 100% \t Train loss: 0.059 took: 6.53s  Val. loss: 0.091  Val. score: 97.406%\n",
      "Epoch 6, 100% \t Train loss: 0.049 took: 6.61s  Val. loss: 0.109  Val. score: 96.978%\n",
      "Epoch 7, 100% \t Train loss: 0.037 took: 6.82s  Val. loss: 0.106  Val. score: 97.311%\n",
      "Epoch 8, 100% \t Train loss: 0.032 took: 6.62s  Val. loss: 0.108  Val. score: 97.378%\n",
      "Epoch 9, 100% \t Train loss: 0.027 took: 6.98s  Val. loss: 0.118  Val. score: 97.283%\n",
      "Epoch 10, 100% \t Train loss: 0.025 took: 6.93s  Val. loss: 0.104  Val. score: 97.650%\n",
      "Epoch 11, 100% \t Train loss: 0.018 took: 6.73s  Val. loss: 0.110  Val. score: 97.611%\n",
      "Epoch 12, 100% \t Train loss: 0.017 took: 6.81s  Val. loss: 0.116  Val. score: 97.556%\n",
      "Epoch 13, 100% \t Train loss: 0.014 took: 6.92s  Val. loss: 0.110  Val. score: 97.750%\n",
      "Epoch 14, 100% \t Train loss: 0.014 took: 7.12s  Val. loss: 0.125  Val. score: 97.644%\n",
      "Epoch 15, 100% \t Train loss: 0.013 took: 6.83s  Val. loss: 0.114  Val. score: 97.750%\n",
      "Training finished, took 160.617s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.391 took: 6.49s  Val. loss: 0.181  Val. score: 94.611%\n",
      "Epoch 2, 100% \t Train loss: 0.152 took: 6.18s  Val. loss: 0.130  Val. score: 96.233%\n",
      "Epoch 3, 100% \t Train loss: 0.107 took: 7.06s  Val. loss: 0.110  Val. score: 96.689%\n",
      "Epoch 4, 100% \t Train loss: 0.081 took: 6.92s  Val. loss: 0.108  Val. score: 96.889%\n",
      "Epoch 5, 100% \t Train loss: 0.065 took: 7.10s  Val. loss: 0.095  Val. score: 97.300%\n",
      "Epoch 6, 100% \t Train loss: 0.050 took: 7.23s  Val. loss: 0.101  Val. score: 97.150%\n",
      "Epoch 7, 100% \t Train loss: 0.042 took: 6.85s  Val. loss: 0.108  Val. score: 97.139%\n",
      "Epoch 8, 100% \t Train loss: 0.036 took: 7.21s  Val. loss: 0.101  Val. score: 97.467%\n",
      "Epoch 9, 100% \t Train loss: 0.028 took: 7.03s  Val. loss: 0.112  Val. score: 97.300%\n",
      "Epoch 10, 100% \t Train loss: 0.026 took: 7.32s  Val. loss: 0.107  Val. score: 97.506%\n",
      "Epoch 11, 100% \t Train loss: 0.020 took: 6.91s  Val. loss: 0.113  Val. score: 97.450%\n",
      "Epoch 12, 100% \t Train loss: 0.017 took: 7.24s  Val. loss: 0.114  Val. score: 97.483%\n",
      "Epoch 13, 100% \t Train loss: 0.017 took: 6.87s  Val. loss: 0.113  Val. score: 97.711%\n",
      "Epoch 14, 100% \t Train loss: 0.013 took: 7.16s  Val. loss: 0.116  Val. score: 97.744%\n",
      "Epoch 15, 100% \t Train loss: 0.012 took: 6.83s  Val. loss: 0.120  Val. score: 97.661%\n",
      "Training finished, took 164.517s\n",
      "\n",
      "Parameters configuration 26 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.009833930049051871\n",
      "h_sizes \t [784, 269, 94, 36]\n",
      "penalty \t 0.0011941736098904498\n",
      "dropout \t 0.055327458048992334\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6648 +/- 0.0681\n",
      "Time for evaluation: 489.5 s\n",
      "Estimated time to finish : 10.18 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.400 took: 4.36s  Val. loss: 0.177  Val. score: 94.761%\n",
      "Epoch 2, 100% \t Train loss: 0.196 took: 4.40s  Val. loss: 0.136  Val. score: 95.839%\n",
      "Epoch 3, 100% \t Train loss: 0.157 took: 4.67s  Val. loss: 0.115  Val. score: 96.583%\n",
      "Epoch 4, 100% \t Train loss: 0.131 took: 4.37s  Val. loss: 0.111  Val. score: 96.839%\n",
      "Epoch 5, 100% \t Train loss: 0.111 took: 4.37s  Val. loss: 0.102  Val. score: 96.961%\n",
      "Epoch 6, 100% \t Train loss: 0.099 took: 4.28s  Val. loss: 0.100  Val. score: 97.022%\n",
      "Epoch 7, 100% \t Train loss: 0.089 took: 4.60s  Val. loss: 0.091  Val. score: 97.272%\n",
      "Epoch 8, 100% \t Train loss: 0.084 took: 4.17s  Val. loss: 0.106  Val. score: 97.089%\n",
      "Epoch 9, 100% \t Train loss: 0.075 took: 4.47s  Val. loss: 0.095  Val. score: 97.333%\n",
      "Epoch 10, 100% \t Train loss: 0.069 took: 4.21s  Val. loss: 0.088  Val. score: 97.544%\n",
      "Epoch 11, 100% \t Train loss: 0.067 took: 4.51s  Val. loss: 0.092  Val. score: 97.500%\n",
      "Epoch 12, 100% \t Train loss: 0.060 took: 4.57s  Val. loss: 0.103  Val. score: 97.333%\n",
      "Epoch 13, 100% \t Train loss: 0.058 took: 4.53s  Val. loss: 0.099  Val. score: 97.411%\n",
      "Epoch 14, 100% \t Train loss: 0.055 took: 4.50s  Val. loss: 0.099  Val. score: 97.400%\n",
      "Epoch 15, 100% \t Train loss: 0.054 took: 4.63s  Val. loss: 0.101  Val. score: 97.339%\n",
      "Training finished, took 115.855s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.405 took: 4.19s  Val. loss: 0.178  Val. score: 94.644%\n",
      "Epoch 2, 100% \t Train loss: 0.196 took: 4.37s  Val. loss: 0.151  Val. score: 95.533%\n",
      "Epoch 3, 100% \t Train loss: 0.154 took: 4.59s  Val. loss: 0.112  Val. score: 96.650%\n",
      "Epoch 4, 100% \t Train loss: 0.125 took: 4.48s  Val. loss: 0.105  Val. score: 96.933%\n",
      "Epoch 5, 100% \t Train loss: 0.107 took: 4.57s  Val. loss: 0.103  Val. score: 97.089%\n",
      "Epoch 6, 100% \t Train loss: 0.099 took: 4.58s  Val. loss: 0.102  Val. score: 97.111%\n",
      "Epoch 7, 100% \t Train loss: 0.089 took: 4.30s  Val. loss: 0.099  Val. score: 97.289%\n",
      "Epoch 8, 100% \t Train loss: 0.079 took: 4.29s  Val. loss: 0.102  Val. score: 97.383%\n",
      "Epoch 9, 100% \t Train loss: 0.074 took: 4.52s  Val. loss: 0.103  Val. score: 97.317%\n",
      "Epoch 10, 100% \t Train loss: 0.065 took: 4.52s  Val. loss: 0.103  Val. score: 97.389%\n",
      "Epoch 11, 100% \t Train loss: 0.063 took: 4.53s  Val. loss: 0.113  Val. score: 97.106%\n",
      "Epoch 12, 100% \t Train loss: 0.061 took: 4.39s  Val. loss: 0.103  Val. score: 97.333%\n",
      "Epoch 13, 100% \t Train loss: 0.052 took: 4.43s  Val. loss: 0.107  Val. score: 97.322%\n",
      "Epoch 14, 100% \t Train loss: 0.051 took: 4.43s  Val. loss: 0.105  Val. score: 97.367%\n",
      "Epoch 15, 100% \t Train loss: 0.048 took: 4.21s  Val. loss: 0.112  Val. score: 97.283%\n",
      "Training finished, took 114.967s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.383 took: 4.20s  Val. loss: 0.168  Val. score: 94.789%\n",
      "Epoch 2, 100% \t Train loss: 0.189 took: 4.24s  Val. loss: 0.139  Val. score: 95.622%\n",
      "Epoch 3, 100% \t Train loss: 0.145 took: 4.60s  Val. loss: 0.125  Val. score: 96.222%\n",
      "Epoch 4, 100% \t Train loss: 0.124 took: 4.64s  Val. loss: 0.108  Val. score: 96.956%\n",
      "Epoch 5, 100% \t Train loss: 0.106 took: 4.71s  Val. loss: 0.100  Val. score: 97.111%\n",
      "Epoch 6, 100% \t Train loss: 0.095 took: 4.57s  Val. loss: 0.101  Val. score: 97.128%\n",
      "Epoch 7, 100% \t Train loss: 0.083 took: 4.64s  Val. loss: 0.101  Val. score: 97.206%\n",
      "Epoch 8, 100% \t Train loss: 0.074 took: 4.25s  Val. loss: 0.103  Val. score: 97.322%\n",
      "Epoch 9, 100% \t Train loss: 0.072 took: 4.71s  Val. loss: 0.102  Val. score: 97.339%\n",
      "Epoch 10, 100% \t Train loss: 0.065 took: 4.59s  Val. loss: 0.103  Val. score: 97.472%\n",
      "Epoch 11, 100% \t Train loss: 0.062 took: 4.55s  Val. loss: 0.101  Val. score: 97.511%\n",
      "Epoch 12, 100% \t Train loss: 0.055 took: 4.63s  Val. loss: 0.106  Val. score: 97.383%\n",
      "Epoch 13, 100% \t Train loss: 0.052 took: 4.48s  Val. loss: 0.112  Val. score: 97.389%\n",
      "Epoch 14, 100% \t Train loss: 0.046 took: 4.35s  Val. loss: 0.108  Val. score: 97.550%\n",
      "Epoch 15, 100% \t Train loss: 0.046 took: 4.25s  Val. loss: 0.105  Val. score: 97.622%\n",
      "Training finished, took 116.604s\n",
      "\n",
      "Parameters configuration 27 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.01414588595149499\n",
      "h_sizes \t [784, 177, 40]\n",
      "penalty \t 0.00019923369612961675\n",
      "dropout \t 0.21772291278092462\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.4148 +/- 0.1484\n",
      "Time for evaluation: 348.6 s\n",
      "Estimated time to finish : 9.94 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.723 took: 9.01s  Val. loss: 0.250  Val. score: 93.222%\n",
      "Epoch 2, 100% \t Train loss: 0.254 took: 9.16s  Val. loss: 0.172  Val. score: 95.344%\n",
      "Epoch 3, 100% \t Train loss: 0.176 took: 9.41s  Val. loss: 0.149  Val. score: 95.967%\n",
      "Epoch 4, 100% \t Train loss: 0.135 took: 10.05s  Val. loss: 0.141  Val. score: 96.322%\n",
      "Epoch 5, 100% \t Train loss: 0.112 took: 9.66s  Val. loss: 0.128  Val. score: 96.644%\n",
      "Epoch 6, 100% \t Train loss: 0.093 took: 9.68s  Val. loss: 0.118  Val. score: 97.078%\n",
      "Epoch 7, 100% \t Train loss: 0.076 took: 10.19s  Val. loss: 0.123  Val. score: 97.200%\n",
      "Epoch 8, 100% \t Train loss: 0.067 took: 10.31s  Val. loss: 0.116  Val. score: 97.289%\n",
      "Epoch 9, 100% \t Train loss: 0.056 took: 10.40s  Val. loss: 0.115  Val. score: 97.356%\n",
      "Epoch 10, 100% \t Train loss: 0.051 took: 10.13s  Val. loss: 0.121  Val. score: 97.439%\n",
      "Epoch 11, 100% \t Train loss: 0.042 took: 9.66s  Val. loss: 0.126  Val. score: 97.400%\n",
      "Epoch 12, 100% \t Train loss: 0.041 took: 10.51s  Val. loss: 0.121  Val. score: 97.583%\n",
      "Epoch 13, 100% \t Train loss: 0.033 took: 9.79s  Val. loss: 0.125  Val. score: 97.517%\n",
      "Epoch 14, 100% \t Train loss: 0.030 took: 10.48s  Val. loss: 0.130  Val. score: 97.583%\n",
      "Epoch 15, 100% \t Train loss: 0.026 took: 9.74s  Val. loss: 0.128  Val. score: 97.689%\n",
      "Training finished, took 223.671s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.691 took: 9.68s  Val. loss: 0.248  Val. score: 93.122%\n",
      "Epoch 2, 100% \t Train loss: 0.244 took: 9.58s  Val. loss: 0.180  Val. score: 95.094%\n",
      "Epoch 3, 100% \t Train loss: 0.168 took: 9.85s  Val. loss: 0.147  Val. score: 95.961%\n",
      "Epoch 4, 100% \t Train loss: 0.132 took: 9.90s  Val. loss: 0.129  Val. score: 96.622%\n",
      "Epoch 5, 100% \t Train loss: 0.105 took: 9.50s  Val. loss: 0.122  Val. score: 96.828%\n",
      "Epoch 6, 100% \t Train loss: 0.089 took: 9.50s  Val. loss: 0.119  Val. score: 97.094%\n",
      "Epoch 7, 100% \t Train loss: 0.075 took: 9.94s  Val. loss: 0.120  Val. score: 97.111%\n",
      "Epoch 8, 100% \t Train loss: 0.063 took: 9.67s  Val. loss: 0.117  Val. score: 97.200%\n",
      "Epoch 9, 100% \t Train loss: 0.055 took: 9.44s  Val. loss: 0.128  Val. score: 97.200%\n",
      "Epoch 10, 100% \t Train loss: 0.044 took: 9.46s  Val. loss: 0.114  Val. score: 97.422%\n",
      "Epoch 11, 100% \t Train loss: 0.043 took: 10.37s  Val. loss: 0.132  Val. score: 97.294%\n",
      "Epoch 12, 100% \t Train loss: 0.037 took: 9.45s  Val. loss: 0.122  Val. score: 97.528%\n",
      "Epoch 13, 100% \t Train loss: 0.030 took: 9.68s  Val. loss: 0.146  Val. score: 97.294%\n",
      "Epoch 14, 100% \t Train loss: 0.030 took: 10.25s  Val. loss: 0.145  Val. score: 97.267%\n",
      "Epoch 15, 100% \t Train loss: 0.030 took: 10.05s  Val. loss: 0.136  Val. score: 97.472%\n",
      "Training finished, took 221.100s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.716 took: 9.42s  Val. loss: 0.260  Val. score: 92.350%\n",
      "Epoch 2, 100% \t Train loss: 0.271 took: 9.45s  Val. loss: 0.180  Val. score: 94.600%\n",
      "Epoch 3, 100% \t Train loss: 0.188 took: 9.32s  Val. loss: 0.143  Val. score: 95.961%\n",
      "Epoch 4, 100% \t Train loss: 0.150 took: 9.81s  Val. loss: 0.124  Val. score: 96.300%\n",
      "Epoch 5, 100% \t Train loss: 0.128 took: 10.20s  Val. loss: 0.124  Val. score: 96.622%\n",
      "Epoch 6, 100% \t Train loss: 0.102 took: 9.59s  Val. loss: 0.128  Val. score: 96.556%\n",
      "Epoch 7, 100% \t Train loss: 0.088 took: 10.19s  Val. loss: 0.111  Val. score: 97.228%\n",
      "Epoch 8, 100% \t Train loss: 0.076 took: 9.97s  Val. loss: 0.122  Val. score: 96.839%\n",
      "Epoch 9, 100% \t Train loss: 0.066 took: 10.34s  Val. loss: 0.127  Val. score: 96.933%\n",
      "Epoch 10, 100% \t Train loss: 0.058 took: 9.99s  Val. loss: 0.115  Val. score: 97.200%\n",
      "Epoch 11, 100% \t Train loss: 0.051 took: 10.31s  Val. loss: 0.112  Val. score: 97.267%\n",
      "Epoch 12, 100% \t Train loss: 0.047 took: 10.28s  Val. loss: 0.113  Val. score: 97.383%\n",
      "Epoch 13, 100% \t Train loss: 0.042 took: 9.63s  Val. loss: 0.120  Val. score: 97.372%\n",
      "Epoch 14, 100% \t Train loss: 0.035 took: 9.65s  Val. loss: 0.126  Val. score: 97.339%\n",
      "Epoch 15, 100% \t Train loss: 0.032 took: 9.91s  Val. loss: 0.120  Val. score: 97.589%\n",
      "Training finished, took 222.986s\n",
      "\n",
      "Parameters configuration 28 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005181726987083004\n",
      "h_sizes \t [784, 371, 171, 64, 34, 17]\n",
      "penalty \t 0.004622527164100379\n",
      "dropout \t 0.09180288443376405\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5833 +/- 0.0885\n",
      "Time for evaluation: 668.9 s\n",
      "Estimated time to finish : 9.93 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.595 took: 4.58s  Val. loss: 0.284  Val. score: 91.789%\n",
      "Epoch 2, 100% \t Train loss: 0.295 took: 4.87s  Val. loss: 0.207  Val. score: 93.978%\n",
      "Epoch 3, 100% \t Train loss: 0.222 took: 4.98s  Val. loss: 0.169  Val. score: 94.983%\n",
      "Epoch 4, 100% \t Train loss: 0.183 took: 4.91s  Val. loss: 0.141  Val. score: 95.739%\n",
      "Epoch 5, 100% \t Train loss: 0.156 took: 4.84s  Val. loss: 0.126  Val. score: 96.161%\n",
      "Epoch 6, 100% \t Train loss: 0.135 took: 5.32s  Val. loss: 0.115  Val. score: 96.528%\n",
      "Epoch 7, 100% \t Train loss: 0.117 took: 5.06s  Val. loss: 0.108  Val. score: 96.672%\n",
      "Epoch 8, 100% \t Train loss: 0.104 took: 4.90s  Val. loss: 0.104  Val. score: 96.778%\n",
      "Epoch 9, 100% \t Train loss: 0.097 took: 5.17s  Val. loss: 0.098  Val. score: 96.861%\n",
      "Epoch 10, 100% \t Train loss: 0.088 took: 5.15s  Val. loss: 0.095  Val. score: 97.122%\n",
      "Epoch 11, 100% \t Train loss: 0.081 took: 5.08s  Val. loss: 0.092  Val. score: 97.072%\n",
      "Epoch 12, 100% \t Train loss: 0.074 took: 5.00s  Val. loss: 0.091  Val. score: 97.167%\n",
      "Epoch 13, 100% \t Train loss: 0.068 took: 5.16s  Val. loss: 0.088  Val. score: 97.317%\n",
      "Epoch 14, 100% \t Train loss: 0.062 took: 5.25s  Val. loss: 0.087  Val. score: 97.367%\n",
      "Epoch 15, 100% \t Train loss: 0.059 took: 5.04s  Val. loss: 0.087  Val. score: 97.300%\n",
      "Training finished, took 126.960s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.603 took: 4.65s  Val. loss: 0.279  Val. score: 91.833%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.294 took: 4.97s  Val. loss: 0.216  Val. score: 93.533%\n",
      "Epoch 3, 100% \t Train loss: 0.227 took: 5.04s  Val. loss: 0.172  Val. score: 95.000%\n",
      "Epoch 4, 100% \t Train loss: 0.188 took: 4.67s  Val. loss: 0.148  Val. score: 95.644%\n",
      "Epoch 5, 100% \t Train loss: 0.157 took: 5.06s  Val. loss: 0.135  Val. score: 96.083%\n",
      "Epoch 6, 100% \t Train loss: 0.134 took: 4.99s  Val. loss: 0.123  Val. score: 96.300%\n",
      "Epoch 7, 100% \t Train loss: 0.120 took: 5.12s  Val. loss: 0.116  Val. score: 96.600%\n",
      "Epoch 8, 100% \t Train loss: 0.109 took: 5.19s  Val. loss: 0.104  Val. score: 96.961%\n",
      "Epoch 9, 100% \t Train loss: 0.099 took: 5.15s  Val. loss: 0.100  Val. score: 97.044%\n",
      "Epoch 10, 100% \t Train loss: 0.088 took: 5.18s  Val. loss: 0.099  Val. score: 97.106%\n",
      "Epoch 11, 100% \t Train loss: 0.081 took: 4.86s  Val. loss: 0.094  Val. score: 97.250%\n",
      "Epoch 12, 100% \t Train loss: 0.076 took: 4.98s  Val. loss: 0.092  Val. score: 97.306%\n",
      "Epoch 13, 100% \t Train loss: 0.069 took: 5.21s  Val. loss: 0.095  Val. score: 97.344%\n",
      "Epoch 14, 100% \t Train loss: 0.064 took: 5.13s  Val. loss: 0.094  Val. score: 97.339%\n",
      "Epoch 15, 100% \t Train loss: 0.060 took: 5.08s  Val. loss: 0.089  Val. score: 97.450%\n",
      "Training finished, took 127.183s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.594 took: 4.88s  Val. loss: 0.286  Val. score: 91.922%\n",
      "Epoch 2, 100% \t Train loss: 0.295 took: 5.12s  Val. loss: 0.208  Val. score: 93.750%\n",
      "Epoch 3, 100% \t Train loss: 0.223 took: 4.81s  Val. loss: 0.175  Val. score: 94.539%\n",
      "Epoch 4, 100% \t Train loss: 0.187 took: 5.15s  Val. loss: 0.149  Val. score: 95.239%\n",
      "Epoch 5, 100% \t Train loss: 0.161 took: 4.92s  Val. loss: 0.130  Val. score: 95.828%\n",
      "Epoch 6, 100% \t Train loss: 0.142 took: 4.92s  Val. loss: 0.117  Val. score: 96.267%\n",
      "Epoch 7, 100% \t Train loss: 0.125 took: 5.25s  Val. loss: 0.112  Val. score: 96.472%\n",
      "Epoch 8, 100% \t Train loss: 0.110 took: 4.92s  Val. loss: 0.101  Val. score: 96.806%\n",
      "Epoch 9, 100% \t Train loss: 0.104 took: 4.95s  Val. loss: 0.100  Val. score: 96.833%\n",
      "Epoch 10, 100% \t Train loss: 0.094 took: 5.26s  Val. loss: 0.095  Val. score: 97.006%\n",
      "Epoch 11, 100% \t Train loss: 0.085 took: 5.32s  Val. loss: 0.091  Val. score: 97.167%\n",
      "Epoch 12, 100% \t Train loss: 0.080 took: 4.90s  Val. loss: 0.092  Val. score: 97.161%\n",
      "Epoch 13, 100% \t Train loss: 0.074 took: 4.95s  Val. loss: 0.089  Val. score: 97.328%\n",
      "Epoch 14, 100% \t Train loss: 0.068 took: 5.26s  Val. loss: 0.085  Val. score: 97.394%\n",
      "Epoch 15, 100% \t Train loss: 0.064 took: 4.94s  Val. loss: 0.083  Val. score: 97.506%\n",
      "Training finished, took 127.560s\n",
      "\n",
      "Parameters configuration 29 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002505005023916352\n",
      "h_sizes \t [784, 190, 47]\n",
      "penalty \t 0.00011942339622755558\n",
      "dropout \t 0.20037572985486035\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4185 +/- 0.0868\n",
      "Time for evaluation: 382.9 s\n",
      "Estimated time to finish : 9.71 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.517 took: 9.65s  Val. loss: 0.236  Val. score: 93.756%\n",
      "Epoch 2, 100% \t Train loss: 0.187 took: 9.79s  Val. loss: 0.170  Val. score: 95.406%\n",
      "Epoch 3, 100% \t Train loss: 0.141 took: 9.63s  Val. loss: 0.129  Val. score: 96.728%\n",
      "Epoch 4, 100% \t Train loss: 0.104 took: 9.03s  Val. loss: 0.114  Val. score: 96.978%\n",
      "Epoch 5, 100% \t Train loss: 0.084 took: 9.47s  Val. loss: 0.136  Val. score: 96.611%\n",
      "Epoch 6, 100% \t Train loss: 0.071 took: 9.14s  Val. loss: 0.126  Val. score: 96.883%\n",
      "Epoch 7, 100% \t Train loss: 0.058 took: 9.58s  Val. loss: 0.133  Val. score: 96.933%\n",
      "Epoch 8, 100% \t Train loss: 0.049 took: 10.06s  Val. loss: 0.119  Val. score: 97.306%\n",
      "Epoch 9, 100% \t Train loss: 0.045 took: 8.95s  Val. loss: 0.131  Val. score: 97.222%\n",
      "Epoch 10, 100% \t Train loss: 0.038 took: 9.42s  Val. loss: 0.131  Val. score: 97.322%\n",
      "Epoch 11, 100% \t Train loss: 0.034 took: 9.21s  Val. loss: 0.116  Val. score: 97.350%\n",
      "Epoch 12, 100% \t Train loss: 0.028 took: 9.30s  Val. loss: 0.141  Val. score: 97.217%\n",
      "Epoch 13, 100% \t Train loss: 0.025 took: 9.42s  Val. loss: 0.168  Val. score: 97.394%\n",
      "Epoch 14, 100% \t Train loss: 0.028 took: 9.72s  Val. loss: 0.138  Val. score: 97.417%\n",
      "Epoch 15, 100% \t Train loss: 0.021 took: 9.39s  Val. loss: 0.155  Val. score: 97.250%\n",
      "Training finished, took 215.507s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.557 took: 9.62s  Val. loss: 0.214  Val. score: 94.183%\n",
      "Epoch 2, 100% \t Train loss: 0.189 took: 9.78s  Val. loss: 0.179  Val. score: 95.233%\n",
      "Epoch 3, 100% \t Train loss: 0.134 took: 9.33s  Val. loss: 0.139  Val. score: 96.150%\n",
      "Epoch 4, 100% \t Train loss: 0.111 took: 9.75s  Val. loss: 0.120  Val. score: 96.856%\n",
      "Epoch 5, 100% \t Train loss: 0.084 took: 9.49s  Val. loss: 0.126  Val. score: 96.761%\n",
      "Epoch 6, 100% \t Train loss: 0.069 took: 9.30s  Val. loss: 0.120  Val. score: 96.978%\n",
      "Epoch 7, 100% \t Train loss: 0.059 took: 9.62s  Val. loss: 0.109  Val. score: 97.150%\n",
      "Epoch 8, 100% \t Train loss: 0.053 took: 9.46s  Val. loss: 0.115  Val. score: 97.183%\n",
      "Epoch 9, 100% \t Train loss: 0.042 took: 10.10s  Val. loss: 0.117  Val. score: 97.467%\n",
      "Epoch 10, 100% \t Train loss: 0.035 took: 9.98s  Val. loss: 0.143  Val. score: 97.072%\n",
      "Epoch 11, 100% \t Train loss: 0.036 took: 9.78s  Val. loss: 0.121  Val. score: 97.494%\n",
      "Epoch 12, 100% \t Train loss: 0.028 took: 10.30s  Val. loss: 0.119  Val. score: 97.517%\n",
      "Epoch 13, 100% \t Train loss: 0.025 took: 9.98s  Val. loss: 0.129  Val. score: 97.639%\n",
      "Epoch 14, 100% \t Train loss: 0.024 took: 9.50s  Val. loss: 0.139  Val. score: 97.350%\n",
      "Epoch 15, 100% \t Train loss: 0.022 took: 9.77s  Val. loss: 0.132  Val. score: 97.400%\n",
      "Training finished, took 220.170s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.600 took: 9.80s  Val. loss: 0.224  Val. score: 93.756%\n",
      "Epoch 2, 100% \t Train loss: 0.190 took: 9.84s  Val. loss: 0.142  Val. score: 96.194%\n",
      "Epoch 3, 100% \t Train loss: 0.131 took: 9.73s  Val. loss: 0.152  Val. score: 96.206%\n",
      "Epoch 4, 100% \t Train loss: 0.105 took: 9.38s  Val. loss: 0.123  Val. score: 97.056%\n",
      "Epoch 5, 100% \t Train loss: 0.083 took: 9.89s  Val. loss: 0.161  Val. score: 96.306%\n",
      "Epoch 6, 100% \t Train loss: 0.074 took: 8.96s  Val. loss: 0.109  Val. score: 97.317%\n",
      "Epoch 7, 100% \t Train loss: 0.056 took: 9.74s  Val. loss: 0.122  Val. score: 97.183%\n",
      "Epoch 8, 100% \t Train loss: 0.048 took: 9.00s  Val. loss: 0.128  Val. score: 97.439%\n",
      "Epoch 9, 100% \t Train loss: 0.041 took: 9.85s  Val. loss: 0.118  Val. score: 97.544%\n",
      "Epoch 10, 100% \t Train loss: 0.038 took: 9.27s  Val. loss: 0.124  Val. score: 97.556%\n",
      "Epoch 11, 100% \t Train loss: 0.036 took: 8.94s  Val. loss: 0.130  Val. score: 97.550%\n",
      "Epoch 12, 100% \t Train loss: 0.031 took: 9.66s  Val. loss: 0.123  Val. score: 97.828%\n",
      "Epoch 13, 100% \t Train loss: 0.023 took: 9.58s  Val. loss: 0.142  Val. score: 97.667%\n",
      "Epoch 14, 100% \t Train loss: 0.024 took: 9.28s  Val. loss: 0.127  Val. score: 97.856%\n",
      "Epoch 15, 100% \t Train loss: 0.019 took: 10.10s  Val. loss: 0.150  Val. score: 97.622%\n",
      "Training finished, took 217.018s\n",
      "\n",
      "Parameters configuration 30 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.016591819037859452\n",
      "h_sizes \t [784, 375, 191, 88, 48, 25]\n",
      "penalty \t 0.000523814753423382\n",
      "dropout \t 0.06232699861867824\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.4241 +/- 0.1529\n",
      "Time for evaluation: 653.9 s\n",
      "Estimated time to finish : 9.68 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.733 took: 6.28s  Val. loss: 0.291  Val. score: 91.739%\n",
      "Epoch 2, 100% \t Train loss: 0.327 took: 5.93s  Val. loss: 0.206  Val. score: 94.039%\n",
      "Epoch 3, 100% \t Train loss: 0.247 took: 6.22s  Val. loss: 0.168  Val. score: 95.039%\n",
      "Epoch 4, 100% \t Train loss: 0.196 took: 6.46s  Val. loss: 0.142  Val. score: 95.900%\n",
      "Epoch 5, 100% \t Train loss: 0.162 took: 6.19s  Val. loss: 0.134  Val. score: 96.056%\n",
      "Epoch 6, 100% \t Train loss: 0.140 took: 6.22s  Val. loss: 0.122  Val. score: 96.561%\n",
      "Epoch 7, 100% \t Train loss: 0.123 took: 6.19s  Val. loss: 0.115  Val. score: 96.850%\n",
      "Epoch 8, 100% \t Train loss: 0.108 took: 6.64s  Val. loss: 0.109  Val. score: 96.917%\n",
      "Epoch 9, 100% \t Train loss: 0.096 took: 6.85s  Val. loss: 0.101  Val. score: 97.189%\n",
      "Epoch 10, 100% \t Train loss: 0.086 took: 6.32s  Val. loss: 0.100  Val. score: 97.222%\n",
      "Epoch 11, 100% \t Train loss: 0.077 took: 6.57s  Val. loss: 0.101  Val. score: 97.278%\n",
      "Epoch 12, 100% \t Train loss: 0.070 took: 6.57s  Val. loss: 0.101  Val. score: 97.272%\n",
      "Epoch 13, 100% \t Train loss: 0.063 took: 6.56s  Val. loss: 0.099  Val. score: 97.350%\n",
      "Epoch 14, 100% \t Train loss: 0.059 took: 6.61s  Val. loss: 0.095  Val. score: 97.528%\n",
      "Epoch 15, 100% \t Train loss: 0.051 took: 6.78s  Val. loss: 0.095  Val. score: 97.589%\n",
      "Training finished, took 154.751s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.718 took: 5.99s  Val. loss: 0.298  Val. score: 91.467%\n",
      "Epoch 2, 100% \t Train loss: 0.310 took: 6.38s  Val. loss: 0.205  Val. score: 93.933%\n",
      "Epoch 3, 100% \t Train loss: 0.232 took: 5.83s  Val. loss: 0.166  Val. score: 95.094%\n",
      "Epoch 4, 100% \t Train loss: 0.189 took: 6.26s  Val. loss: 0.143  Val. score: 95.689%\n",
      "Epoch 5, 100% \t Train loss: 0.156 took: 6.27s  Val. loss: 0.125  Val. score: 96.378%\n",
      "Epoch 6, 100% \t Train loss: 0.133 took: 6.18s  Val. loss: 0.119  Val. score: 96.494%\n",
      "Epoch 7, 100% \t Train loss: 0.116 took: 5.95s  Val. loss: 0.113  Val. score: 96.678%\n",
      "Epoch 8, 100% \t Train loss: 0.102 took: 6.32s  Val. loss: 0.112  Val. score: 96.856%\n",
      "Epoch 9, 100% \t Train loss: 0.090 took: 6.64s  Val. loss: 0.103  Val. score: 97.072%\n",
      "Epoch 10, 100% \t Train loss: 0.079 took: 6.37s  Val. loss: 0.108  Val. score: 96.917%\n",
      "Epoch 11, 100% \t Train loss: 0.071 took: 6.30s  Val. loss: 0.103  Val. score: 97.144%\n",
      "Epoch 12, 100% \t Train loss: 0.063 took: 6.53s  Val. loss: 0.096  Val. score: 97.289%\n",
      "Epoch 13, 100% \t Train loss: 0.060 took: 6.33s  Val. loss: 0.100  Val. score: 97.283%\n",
      "Epoch 14, 100% \t Train loss: 0.053 took: 6.59s  Val. loss: 0.096  Val. score: 97.450%\n",
      "Epoch 15, 100% \t Train loss: 0.052 took: 6.15s  Val. loss: 0.098  Val. score: 97.444%\n",
      "Training finished, took 151.857s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.804 took: 5.69s  Val. loss: 0.335  Val. score: 90.106%\n",
      "Epoch 2, 100% \t Train loss: 0.348 took: 5.80s  Val. loss: 0.217  Val. score: 93.456%\n",
      "Epoch 3, 100% \t Train loss: 0.248 took: 6.28s  Val. loss: 0.171  Val. score: 94.861%\n",
      "Epoch 4, 100% \t Train loss: 0.195 took: 5.93s  Val. loss: 0.147  Val. score: 95.533%\n",
      "Epoch 5, 100% \t Train loss: 0.161 took: 6.49s  Val. loss: 0.130  Val. score: 96.117%\n",
      "Epoch 6, 100% \t Train loss: 0.138 took: 6.30s  Val. loss: 0.126  Val. score: 96.250%\n",
      "Epoch 7, 100% \t Train loss: 0.122 took: 6.58s  Val. loss: 0.114  Val. score: 96.583%\n",
      "Epoch 8, 100% \t Train loss: 0.105 took: 6.00s  Val. loss: 0.111  Val. score: 96.728%\n",
      "Epoch 9, 100% \t Train loss: 0.097 took: 6.53s  Val. loss: 0.106  Val. score: 96.878%\n",
      "Epoch 10, 100% \t Train loss: 0.087 took: 6.48s  Val. loss: 0.101  Val. score: 97.028%\n",
      "Epoch 11, 100% \t Train loss: 0.077 took: 6.48s  Val. loss: 0.102  Val. score: 96.994%\n",
      "Epoch 12, 100% \t Train loss: 0.070 took: 6.27s  Val. loss: 0.095  Val. score: 97.189%\n",
      "Epoch 13, 100% \t Train loss: 0.066 took: 6.66s  Val. loss: 0.096  Val. score: 97.283%\n",
      "Epoch 14, 100% \t Train loss: 0.059 took: 6.46s  Val. loss: 0.099  Val. score: 97.244%\n",
      "Epoch 15, 100% \t Train loss: 0.053 took: 6.02s  Val. loss: 0.099  Val. score: 97.289%\n",
      "Training finished, took 152.174s\n",
      "\n",
      "Parameters configuration 31 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0025770385156478966\n",
      "h_sizes \t [784, 249, 77, 23]\n",
      "penalty \t 0.0010221995053274957\n",
      "dropout \t 0.15037786999979477\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4407 +/- 0.1225\n",
      "Time for evaluation: 460.0 s\n",
      "Estimated time to finish : 9.52 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.350 took: 5.01s  Val. loss: 0.179  Val. score: 94.556%\n",
      "Epoch 2, 100% \t Train loss: 0.157 took: 5.03s  Val. loss: 0.130  Val. score: 95.994%\n",
      "Epoch 3, 100% \t Train loss: 0.108 took: 5.06s  Val. loss: 0.107  Val. score: 96.861%\n",
      "Epoch 4, 100% \t Train loss: 0.083 took: 5.05s  Val. loss: 0.101  Val. score: 96.906%\n",
      "Epoch 5, 100% \t Train loss: 0.065 took: 5.06s  Val. loss: 0.090  Val. score: 97.283%\n",
      "Epoch 6, 100% \t Train loss: 0.056 took: 5.11s  Val. loss: 0.101  Val. score: 97.044%\n",
      "Epoch 7, 100% \t Train loss: 0.042 took: 4.91s  Val. loss: 0.087  Val. score: 97.428%\n",
      "Epoch 8, 100% \t Train loss: 0.035 took: 4.97s  Val. loss: 0.091  Val. score: 97.478%\n",
      "Epoch 9, 100% \t Train loss: 0.029 took: 4.98s  Val. loss: 0.090  Val. score: 97.389%\n",
      "Epoch 10, 100% \t Train loss: 0.024 took: 5.04s  Val. loss: 0.088  Val. score: 97.733%\n",
      "Epoch 11, 100% \t Train loss: 0.020 took: 5.14s  Val. loss: 0.088  Val. score: 97.806%\n",
      "Epoch 12, 100% \t Train loss: 0.017 took: 5.14s  Val. loss: 0.091  Val. score: 97.717%\n",
      "Epoch 13, 100% \t Train loss: 0.015 took: 5.36s  Val. loss: 0.094  Val. score: 97.722%\n",
      "Epoch 14, 100% \t Train loss: 0.013 took: 5.12s  Val. loss: 0.101  Val. score: 97.656%\n",
      "Epoch 15, 100% \t Train loss: 0.014 took: 5.16s  Val. loss: 0.098  Val. score: 97.778%\n",
      "Training finished, took 127.218s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.373 took: 4.76s  Val. loss: 0.190  Val. score: 94.467%\n",
      "Epoch 2, 100% \t Train loss: 0.167 took: 4.60s  Val. loss: 0.139  Val. score: 95.633%\n",
      "Epoch 3, 100% \t Train loss: 0.114 took: 5.18s  Val. loss: 0.112  Val. score: 96.667%\n",
      "Epoch 4, 100% \t Train loss: 0.088 took: 5.18s  Val. loss: 0.109  Val. score: 96.644%\n",
      "Epoch 5, 100% \t Train loss: 0.070 took: 5.00s  Val. loss: 0.097  Val. score: 97.106%\n",
      "Epoch 6, 100% \t Train loss: 0.058 took: 5.21s  Val. loss: 0.095  Val. score: 97.256%\n",
      "Epoch 7, 100% \t Train loss: 0.046 took: 4.96s  Val. loss: 0.087  Val. score: 97.500%\n",
      "Epoch 8, 100% \t Train loss: 0.039 took: 5.36s  Val. loss: 0.089  Val. score: 97.378%\n",
      "Epoch 9, 100% \t Train loss: 0.031 took: 5.08s  Val. loss: 0.089  Val. score: 97.583%\n",
      "Epoch 10, 100% \t Train loss: 0.025 took: 5.22s  Val. loss: 0.103  Val. score: 97.128%\n",
      "Epoch 11, 100% \t Train loss: 0.023 took: 5.32s  Val. loss: 0.098  Val. score: 97.472%\n",
      "Epoch 12, 100% \t Train loss: 0.020 took: 5.39s  Val. loss: 0.098  Val. score: 97.572%\n",
      "Epoch 13, 100% \t Train loss: 0.019 took: 4.99s  Val. loss: 0.095  Val. score: 97.711%\n",
      "Epoch 14, 100% \t Train loss: 0.015 took: 5.08s  Val. loss: 0.098  Val. score: 97.633%\n",
      "Epoch 15, 100% \t Train loss: 0.015 took: 5.41s  Val. loss: 0.098  Val. score: 97.589%\n",
      "Training finished, took 127.635s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.368 took: 5.02s  Val. loss: 0.201  Val. score: 93.744%\n",
      "Epoch 2, 100% \t Train loss: 0.161 took: 4.60s  Val. loss: 0.143  Val. score: 95.783%\n",
      "Epoch 3, 100% \t Train loss: 0.115 took: 5.11s  Val. loss: 0.110  Val. score: 96.717%\n",
      "Epoch 4, 100% \t Train loss: 0.085 took: 5.33s  Val. loss: 0.105  Val. score: 96.761%\n",
      "Epoch 5, 100% \t Train loss: 0.071 took: 5.54s  Val. loss: 0.096  Val. score: 97.144%\n",
      "Epoch 6, 100% \t Train loss: 0.056 took: 5.26s  Val. loss: 0.092  Val. score: 97.339%\n",
      "Epoch 7, 100% \t Train loss: 0.044 took: 5.27s  Val. loss: 0.097  Val. score: 97.217%\n",
      "Epoch 8, 100% \t Train loss: 0.036 took: 5.56s  Val. loss: 0.091  Val. score: 97.317%\n",
      "Epoch 9, 100% \t Train loss: 0.031 took: 5.58s  Val. loss: 0.091  Val. score: 97.572%\n",
      "Epoch 10, 100% \t Train loss: 0.025 took: 5.25s  Val. loss: 0.089  Val. score: 97.622%\n",
      "Epoch 11, 100% \t Train loss: 0.021 took: 5.58s  Val. loss: 0.092  Val. score: 97.639%\n",
      "Epoch 12, 100% \t Train loss: 0.018 took: 5.34s  Val. loss: 0.096  Val. score: 97.561%\n",
      "Epoch 13, 100% \t Train loss: 0.017 took: 5.47s  Val. loss: 0.097  Val. score: 97.539%\n",
      "Epoch 14, 100% \t Train loss: 0.016 took: 5.30s  Val. loss: 0.092  Val. score: 97.694%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, 100% \t Train loss: 0.012 took: 5.19s  Val. loss: 0.102  Val. score: 97.650%\n",
      "Training finished, took 131.703s\n",
      "\n",
      "Parameters configuration 32 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.007406006706032811\n",
      "h_sizes \t [784, 196, 59]\n",
      "penalty \t 0.00012689429309566718\n",
      "dropout \t 0.05279464277818349\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6722 +/- 0.0787\n",
      "Time for evaluation: 387.7 s\n",
      "Estimated time to finish : 9.32 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.392 took: 6.39s  Val. loss: 0.176  Val. score: 94.644%\n",
      "Epoch 2, 100% \t Train loss: 0.153 took: 6.12s  Val. loss: 0.122  Val. score: 96.328%\n",
      "Epoch 3, 100% \t Train loss: 0.103 took: 6.28s  Val. loss: 0.111  Val. score: 96.594%\n",
      "Epoch 4, 100% \t Train loss: 0.081 took: 6.29s  Val. loss: 0.098  Val. score: 97.178%\n",
      "Epoch 5, 100% \t Train loss: 0.060 took: 6.52s  Val. loss: 0.098  Val. score: 97.250%\n",
      "Epoch 6, 100% \t Train loss: 0.047 took: 6.07s  Val. loss: 0.100  Val. score: 97.189%\n",
      "Epoch 7, 100% \t Train loss: 0.040 took: 6.10s  Val. loss: 0.095  Val. score: 97.400%\n",
      "Epoch 8, 100% \t Train loss: 0.030 took: 6.29s  Val. loss: 0.101  Val. score: 97.433%\n",
      "Epoch 9, 100% \t Train loss: 0.026 took: 6.55s  Val. loss: 0.097  Val. score: 97.544%\n",
      "Epoch 10, 100% \t Train loss: 0.023 took: 6.23s  Val. loss: 0.102  Val. score: 97.433%\n",
      "Epoch 11, 100% \t Train loss: 0.019 took: 6.14s  Val. loss: 0.106  Val. score: 97.300%\n",
      "Epoch 12, 100% \t Train loss: 0.017 took: 6.21s  Val. loss: 0.105  Val. score: 97.622%\n",
      "Epoch 13, 100% \t Train loss: 0.013 took: 5.97s  Val. loss: 0.119  Val. score: 97.450%\n",
      "Epoch 14, 100% \t Train loss: 0.013 took: 5.97s  Val. loss: 0.116  Val. score: 97.606%\n",
      "Epoch 15, 100% \t Train loss: 0.010 took: 6.00s  Val. loss: 0.114  Val. score: 97.472%\n",
      "Training finished, took 151.678s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.401 took: 6.14s  Val. loss: 0.181  Val. score: 94.583%\n",
      "Epoch 2, 100% \t Train loss: 0.157 took: 6.43s  Val. loss: 0.132  Val. score: 96.033%\n",
      "Epoch 3, 100% \t Train loss: 0.107 took: 6.18s  Val. loss: 0.103  Val. score: 96.867%\n",
      "Epoch 4, 100% \t Train loss: 0.078 took: 6.45s  Val. loss: 0.100  Val. score: 96.961%\n",
      "Epoch 5, 100% \t Train loss: 0.060 took: 6.43s  Val. loss: 0.100  Val. score: 97.189%\n",
      "Epoch 6, 100% \t Train loss: 0.048 took: 6.10s  Val. loss: 0.109  Val. score: 97.017%\n",
      "Epoch 7, 100% \t Train loss: 0.037 took: 6.39s  Val. loss: 0.094  Val. score: 97.478%\n",
      "Epoch 8, 100% \t Train loss: 0.030 took: 6.34s  Val. loss: 0.092  Val. score: 97.656%\n",
      "Epoch 9, 100% \t Train loss: 0.026 took: 6.57s  Val. loss: 0.102  Val. score: 97.417%\n",
      "Epoch 10, 100% \t Train loss: 0.020 took: 6.42s  Val. loss: 0.100  Val. score: 97.711%\n",
      "Epoch 11, 100% \t Train loss: 0.014 took: 6.46s  Val. loss: 0.101  Val. score: 97.628%\n",
      "Epoch 12, 100% \t Train loss: 0.013 took: 6.42s  Val. loss: 0.108  Val. score: 97.639%\n",
      "Epoch 13, 100% \t Train loss: 0.014 took: 6.11s  Val. loss: 0.112  Val. score: 97.500%\n",
      "Epoch 14, 100% \t Train loss: 0.012 took: 5.98s  Val. loss: 0.106  Val. score: 97.739%\n",
      "Epoch 15, 100% \t Train loss: 0.009 took: 5.89s  Val. loss: 0.116  Val. score: 97.661%\n",
      "Training finished, took 152.695s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.394 took: 6.10s  Val. loss: 0.182  Val. score: 94.406%\n",
      "Epoch 2, 100% \t Train loss: 0.155 took: 6.32s  Val. loss: 0.156  Val. score: 95.106%\n",
      "Epoch 3, 100% \t Train loss: 0.111 took: 6.15s  Val. loss: 0.120  Val. score: 96.511%\n",
      "Epoch 4, 100% \t Train loss: 0.081 took: 6.03s  Val. loss: 0.099  Val. score: 97.022%\n",
      "Epoch 5, 100% \t Train loss: 0.062 took: 6.12s  Val. loss: 0.096  Val. score: 97.178%\n",
      "Epoch 6, 100% \t Train loss: 0.049 took: 5.97s  Val. loss: 0.094  Val. score: 97.361%\n",
      "Epoch 7, 100% \t Train loss: 0.038 took: 6.21s  Val. loss: 0.096  Val. score: 97.444%\n",
      "Epoch 8, 100% \t Train loss: 0.028 took: 6.20s  Val. loss: 0.104  Val. score: 97.394%\n",
      "Epoch 9, 100% \t Train loss: 0.026 took: 6.11s  Val. loss: 0.109  Val. score: 97.289%\n",
      "Epoch 10, 100% \t Train loss: 0.019 took: 6.61s  Val. loss: 0.104  Val. score: 97.694%\n",
      "Epoch 11, 100% \t Train loss: 0.015 took: 6.63s  Val. loss: 0.116  Val. score: 97.472%\n",
      "Epoch 12, 100% \t Train loss: 0.016 took: 6.52s  Val. loss: 0.105  Val. score: 97.628%\n",
      "Epoch 13, 100% \t Train loss: 0.013 took: 6.04s  Val. loss: 0.115  Val. score: 97.633%\n",
      "Epoch 14, 100% \t Train loss: 0.008 took: 6.51s  Val. loss: 0.116  Val. score: 97.650%\n",
      "Epoch 15, 100% \t Train loss: 0.010 took: 6.40s  Val. loss: 0.116  Val. score: 97.722%\n",
      "Training finished, took 152.805s\n",
      "\n",
      "Parameters configuration 33 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.006752107978186746\n",
      "h_sizes \t [784, 256, 100, 42]\n",
      "penalty \t 0.0015811061654509675\n",
      "dropout \t 0.03788280586520876\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.6185 +/- 0.1064\n",
      "Time for evaluation: 458.3 s\n",
      "Estimated time to finish : 9.16 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.618 took: 6.61s  Val. loss: 0.262  Val. score: 92.256%\n",
      "Epoch 2, 100% \t Train loss: 0.267 took: 6.10s  Val. loss: 0.172  Val. score: 94.772%\n",
      "Epoch 3, 100% \t Train loss: 0.196 took: 6.74s  Val. loss: 0.141  Val. score: 95.806%\n",
      "Epoch 4, 100% \t Train loss: 0.153 took: 6.79s  Val. loss: 0.120  Val. score: 96.289%\n",
      "Epoch 5, 100% \t Train loss: 0.126 took: 6.86s  Val. loss: 0.108  Val. score: 96.733%\n",
      "Epoch 6, 100% \t Train loss: 0.108 took: 6.74s  Val. loss: 0.100  Val. score: 97.094%\n",
      "Epoch 7, 100% \t Train loss: 0.096 took: 6.89s  Val. loss: 0.095  Val. score: 97.167%\n",
      "Epoch 8, 100% \t Train loss: 0.085 took: 7.03s  Val. loss: 0.093  Val. score: 97.294%\n",
      "Epoch 9, 100% \t Train loss: 0.073 took: 7.06s  Val. loss: 0.087  Val. score: 97.317%\n",
      "Epoch 10, 100% \t Train loss: 0.066 took: 6.94s  Val. loss: 0.088  Val. score: 97.500%\n",
      "Epoch 11, 100% \t Train loss: 0.060 took: 6.74s  Val. loss: 0.087  Val. score: 97.467%\n",
      "Epoch 12, 100% \t Train loss: 0.053 took: 6.74s  Val. loss: 0.088  Val. score: 97.561%\n",
      "Epoch 13, 100% \t Train loss: 0.047 took: 6.61s  Val. loss: 0.086  Val. score: 97.650%\n",
      "Epoch 14, 100% \t Train loss: 0.041 took: 6.43s  Val. loss: 0.088  Val. score: 97.578%\n",
      "Epoch 15, 100% \t Train loss: 0.038 took: 7.07s  Val. loss: 0.086  Val. score: 97.661%\n",
      "Training finished, took 161.281s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.628 took: 6.34s  Val. loss: 0.245  Val. score: 92.994%\n",
      "Epoch 2, 100% \t Train loss: 0.270 took: 6.34s  Val. loss: 0.164  Val. score: 95.378%\n",
      "Epoch 3, 100% \t Train loss: 0.194 took: 6.42s  Val. loss: 0.133  Val. score: 96.106%\n",
      "Epoch 4, 100% \t Train loss: 0.151 took: 6.55s  Val. loss: 0.117  Val. score: 96.650%\n",
      "Epoch 5, 100% \t Train loss: 0.126 took: 6.55s  Val. loss: 0.108  Val. score: 96.783%\n",
      "Epoch 6, 100% \t Train loss: 0.107 took: 6.53s  Val. loss: 0.099  Val. score: 97.206%\n",
      "Epoch 7, 100% \t Train loss: 0.089 took: 6.71s  Val. loss: 0.096  Val. score: 97.417%\n",
      "Epoch 8, 100% \t Train loss: 0.080 took: 6.79s  Val. loss: 0.092  Val. score: 97.494%\n",
      "Epoch 9, 100% \t Train loss: 0.069 took: 6.69s  Val. loss: 0.093  Val. score: 97.522%\n",
      "Epoch 10, 100% \t Train loss: 0.066 took: 6.59s  Val. loss: 0.092  Val. score: 97.589%\n",
      "Epoch 11, 100% \t Train loss: 0.054 took: 6.55s  Val. loss: 0.091  Val. score: 97.733%\n",
      "Epoch 12, 100% \t Train loss: 0.047 took: 6.34s  Val. loss: 0.088  Val. score: 97.744%\n",
      "Epoch 13, 100% \t Train loss: 0.044 took: 6.75s  Val. loss: 0.086  Val. score: 97.783%\n",
      "Epoch 14, 100% \t Train loss: 0.042 took: 6.63s  Val. loss: 0.093  Val. score: 97.700%\n",
      "Epoch 15, 100% \t Train loss: 0.035 took: 6.40s  Val. loss: 0.089  Val. score: 97.878%\n",
      "Training finished, took 157.708s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.644 took: 7.06s  Val. loss: 0.281  Val. score: 91.811%\n",
      "Epoch 2, 100% \t Train loss: 0.276 took: 6.11s  Val. loss: 0.193  Val. score: 94.200%\n",
      "Epoch 3, 100% \t Train loss: 0.203 took: 6.15s  Val. loss: 0.154  Val. score: 95.328%\n",
      "Epoch 4, 100% \t Train loss: 0.162 took: 6.34s  Val. loss: 0.142  Val. score: 95.811%\n",
      "Epoch 5, 100% \t Train loss: 0.134 took: 6.37s  Val. loss: 0.126  Val. score: 96.333%\n",
      "Epoch 6, 100% \t Train loss: 0.115 took: 6.45s  Val. loss: 0.113  Val. score: 96.661%\n",
      "Epoch 7, 100% \t Train loss: 0.095 took: 6.72s  Val. loss: 0.111  Val. score: 96.817%\n",
      "Epoch 8, 100% \t Train loss: 0.085 took: 6.33s  Val. loss: 0.110  Val. score: 96.878%\n",
      "Epoch 9, 100% \t Train loss: 0.078 took: 6.38s  Val. loss: 0.106  Val. score: 97.033%\n",
      "Epoch 10, 100% \t Train loss: 0.069 took: 6.36s  Val. loss: 0.107  Val. score: 97.167%\n",
      "Epoch 11, 100% \t Train loss: 0.060 took: 6.59s  Val. loss: 0.110  Val. score: 97.067%\n",
      "Epoch 12, 100% \t Train loss: 0.052 took: 6.32s  Val. loss: 0.107  Val. score: 97.272%\n",
      "Epoch 13, 100% \t Train loss: 0.047 took: 7.00s  Val. loss: 0.111  Val. score: 97.089%\n",
      "Epoch 14, 100% \t Train loss: 0.044 took: 6.76s  Val. loss: 0.102  Val. score: 97.417%\n",
      "Epoch 15, 100% \t Train loss: 0.041 took: 7.00s  Val. loss: 0.108  Val. score: 97.328%\n",
      "Training finished, took 158.076s\n",
      "\n",
      "Parameters configuration 34 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0035113234137754755\n",
      "h_sizes \t [784, 272, 88, 26]\n",
      "penalty \t 0.0018464191547675997\n",
      "dropout \t 0.15638398289076513\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6222 +/- 0.2262\n",
      "Time for evaluation: 478.2 s\n",
      "Estimated time to finish : 9.02 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.698 took: 9.57s  Val. loss: 0.286  Val. score: 92.656%\n",
      "Epoch 2, 100% \t Train loss: 0.275 took: 9.03s  Val. loss: 0.192  Val. score: 95.183%\n",
      "Epoch 3, 100% \t Train loss: 0.213 took: 9.20s  Val. loss: 0.153  Val. score: 95.933%\n",
      "Epoch 4, 100% \t Train loss: 0.170 took: 9.17s  Val. loss: 0.141  Val. score: 96.822%\n",
      "Epoch 5, 100% \t Train loss: 0.144 took: 9.72s  Val. loss: 0.137  Val. score: 96.567%\n",
      "Epoch 6, 100% \t Train loss: 0.126 took: 9.42s  Val. loss: 0.131  Val. score: 96.967%\n",
      "Epoch 7, 100% \t Train loss: 0.108 took: 9.25s  Val. loss: 0.122  Val. score: 97.244%\n",
      "Epoch 8, 100% \t Train loss: 0.094 took: 10.04s  Val. loss: 0.128  Val. score: 97.267%\n",
      "Epoch 9, 100% \t Train loss: 0.089 took: 9.94s  Val. loss: 0.121  Val. score: 97.378%\n",
      "Epoch 10, 100% \t Train loss: 0.082 took: 9.57s  Val. loss: 0.133  Val. score: 97.278%\n",
      "Epoch 11, 100% \t Train loss: 0.073 took: 10.02s  Val. loss: 0.120  Val. score: 97.611%\n",
      "Epoch 12, 100% \t Train loss: 0.066 took: 10.21s  Val. loss: 0.138  Val. score: 97.267%\n",
      "Epoch 13, 100% \t Train loss: 0.066 took: 9.96s  Val. loss: 0.134  Val. score: 97.178%\n",
      "Epoch 14, 100% \t Train loss: 0.063 took: 10.41s  Val. loss: 0.119  Val. score: 97.622%\n",
      "Epoch 15, 100% \t Train loss: 0.053 took: 10.44s  Val. loss: 0.129  Val. score: 97.733%\n",
      "Training finished, took 220.093s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.648 took: 9.14s  Val. loss: 0.252  Val. score: 93.378%\n",
      "Epoch 2, 100% \t Train loss: 0.266 took: 8.92s  Val. loss: 0.184  Val. score: 95.183%\n",
      "Epoch 3, 100% \t Train loss: 0.198 took: 9.61s  Val. loss: 0.138  Val. score: 96.583%\n",
      "Epoch 4, 100% \t Train loss: 0.164 took: 8.98s  Val. loss: 0.151  Val. score: 96.378%\n",
      "Epoch 5, 100% \t Train loss: 0.142 took: 9.39s  Val. loss: 0.123  Val. score: 96.933%\n",
      "Epoch 6, 100% \t Train loss: 0.126 took: 8.99s  Val. loss: 0.142  Val. score: 96.839%\n",
      "Epoch 7, 100% \t Train loss: 0.114 took: 8.86s  Val. loss: 0.131  Val. score: 97.089%\n",
      "Epoch 8, 100% \t Train loss: 0.096 took: 8.94s  Val. loss: 0.122  Val. score: 97.233%\n",
      "Epoch 9, 100% \t Train loss: 0.092 took: 9.11s  Val. loss: 0.136  Val. score: 97.156%\n",
      "Epoch 10, 100% \t Train loss: 0.081 took: 9.52s  Val. loss: 0.132  Val. score: 97.344%\n",
      "Epoch 11, 100% \t Train loss: 0.077 took: 9.03s  Val. loss: 0.125  Val. score: 97.528%\n",
      "Epoch 12, 100% \t Train loss: 0.070 took: 9.75s  Val. loss: 0.129  Val. score: 97.372%\n",
      "Epoch 13, 100% \t Train loss: 0.068 took: 10.67s  Val. loss: 0.126  Val. score: 97.528%\n",
      "Epoch 14, 100% \t Train loss: 0.063 took: 10.76s  Val. loss: 0.141  Val. score: 97.606%\n",
      "Epoch 15, 100% \t Train loss: 0.060 took: 10.55s  Val. loss: 0.120  Val. score: 97.600%\n",
      "Training finished, took 215.930s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.615 took: 9.93s  Val. loss: 0.219  Val. score: 93.950%\n",
      "Epoch 2, 100% \t Train loss: 0.257 took: 9.92s  Val. loss: 0.188  Val. score: 95.383%\n",
      "Epoch 3, 100% \t Train loss: 0.196 took: 9.61s  Val. loss: 0.156  Val. score: 96.117%\n",
      "Epoch 4, 100% \t Train loss: 0.156 took: 9.82s  Val. loss: 0.154  Val. score: 96.328%\n",
      "Epoch 5, 100% \t Train loss: 0.134 took: 9.83s  Val. loss: 0.132  Val. score: 96.739%\n",
      "Epoch 6, 100% \t Train loss: 0.113 took: 9.50s  Val. loss: 0.148  Val. score: 97.000%\n",
      "Epoch 7, 100% \t Train loss: 0.100 took: 9.72s  Val. loss: 0.133  Val. score: 97.144%\n",
      "Epoch 8, 100% \t Train loss: 0.095 took: 9.33s  Val. loss: 0.137  Val. score: 96.911%\n",
      "Epoch 9, 100% \t Train loss: 0.081 took: 9.23s  Val. loss: 0.134  Val. score: 97.217%\n",
      "Epoch 10, 100% \t Train loss: 0.076 took: 10.01s  Val. loss: 0.153  Val. score: 97.100%\n",
      "Epoch 11, 100% \t Train loss: 0.070 took: 9.64s  Val. loss: 0.128  Val. score: 97.500%\n",
      "Epoch 12, 100% \t Train loss: 0.064 took: 9.29s  Val. loss: 0.146  Val. score: 97.372%\n",
      "Epoch 13, 100% \t Train loss: 0.060 took: 9.50s  Val. loss: 0.133  Val. score: 97.311%\n",
      "Epoch 14, 100% \t Train loss: 0.058 took: 9.60s  Val. loss: 0.128  Val. score: 97.472%\n",
      "Epoch 15, 100% \t Train loss: 0.051 took: 9.88s  Val. loss: 0.131  Val. score: 97.639%\n",
      "Training finished, took 219.231s\n",
      "\n",
      "Parameters configuration 35 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.015545138195935001\n",
      "h_sizes \t [784, 373, 186, 93, 47, 21]\n",
      "penalty \t 0.002069726141627082\n",
      "dropout \t 0.1811059910810368\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.6574 +/- 0.0560\n",
      "Time for evaluation: 656.4 s\n",
      "Estimated time to finish : 8.96 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.461 took: 4.49s  Val. loss: 0.248  Val. score: 92.639%\n",
      "Epoch 2, 100% \t Train loss: 0.210 took: 4.41s  Val. loss: 0.175  Val. score: 94.661%\n",
      "Epoch 3, 100% \t Train loss: 0.155 took: 4.70s  Val. loss: 0.146  Val. score: 95.517%\n",
      "Epoch 4, 100% \t Train loss: 0.123 took: 4.42s  Val. loss: 0.127  Val. score: 96.139%\n",
      "Epoch 5, 100% \t Train loss: 0.100 took: 4.38s  Val. loss: 0.115  Val. score: 96.411%\n",
      "Epoch 6, 100% \t Train loss: 0.083 took: 4.68s  Val. loss: 0.115  Val. score: 96.450%\n",
      "Epoch 7, 100% \t Train loss: 0.074 took: 4.50s  Val. loss: 0.103  Val. score: 96.794%\n",
      "Epoch 8, 100% \t Train loss: 0.061 took: 4.73s  Val. loss: 0.095  Val. score: 97.111%\n",
      "Epoch 9, 100% \t Train loss: 0.057 took: 4.73s  Val. loss: 0.092  Val. score: 97.294%\n",
      "Epoch 10, 100% \t Train loss: 0.049 took: 4.37s  Val. loss: 0.096  Val. score: 97.200%\n",
      "Epoch 11, 100% \t Train loss: 0.042 took: 4.70s  Val. loss: 0.087  Val. score: 97.428%\n",
      "Epoch 12, 100% \t Train loss: 0.037 took: 4.67s  Val. loss: 0.088  Val. score: 97.400%\n",
      "Epoch 13, 100% \t Train loss: 0.033 took: 4.62s  Val. loss: 0.089  Val. score: 97.356%\n",
      "Epoch 14, 100% \t Train loss: 0.030 took: 4.45s  Val. loss: 0.087  Val. score: 97.439%\n",
      "Epoch 15, 100% \t Train loss: 0.027 took: 4.33s  Val. loss: 0.089  Val. score: 97.400%\n",
      "Training finished, took 117.450s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.474 took: 4.67s  Val. loss: 0.241  Val. score: 93.100%\n",
      "Epoch 2, 100% \t Train loss: 0.216 took: 4.67s  Val. loss: 0.182  Val. score: 94.533%\n",
      "Epoch 3, 100% \t Train loss: 0.159 took: 4.60s  Val. loss: 0.154  Val. score: 95.367%\n",
      "Epoch 4, 100% \t Train loss: 0.126 took: 4.70s  Val. loss: 0.125  Val. score: 96.206%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, 100% \t Train loss: 0.104 took: 4.50s  Val. loss: 0.118  Val. score: 96.472%\n",
      "Epoch 6, 100% \t Train loss: 0.086 took: 4.70s  Val. loss: 0.102  Val. score: 96.850%\n",
      "Epoch 7, 100% \t Train loss: 0.072 took: 4.63s  Val. loss: 0.100  Val. score: 96.889%\n",
      "Epoch 8, 100% \t Train loss: 0.062 took: 4.59s  Val. loss: 0.096  Val. score: 97.061%\n",
      "Epoch 9, 100% \t Train loss: 0.053 took: 4.67s  Val. loss: 0.097  Val. score: 97.028%\n",
      "Epoch 10, 100% \t Train loss: 0.048 took: 4.74s  Val. loss: 0.093  Val. score: 97.250%\n",
      "Epoch 11, 100% \t Train loss: 0.043 took: 4.44s  Val. loss: 0.092  Val. score: 97.361%\n",
      "Epoch 12, 100% \t Train loss: 0.036 took: 4.35s  Val. loss: 0.091  Val. score: 97.311%\n",
      "Epoch 13, 100% \t Train loss: 0.031 took: 4.72s  Val. loss: 0.102  Val. score: 97.106%\n",
      "Epoch 14, 100% \t Train loss: 0.030 took: 4.64s  Val. loss: 0.091  Val. score: 97.344%\n",
      "Epoch 15, 100% \t Train loss: 0.024 took: 4.75s  Val. loss: 0.091  Val. score: 97.472%\n",
      "Training finished, took 118.488s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.485 took: 4.76s  Val. loss: 0.238  Val. score: 93.144%\n",
      "Epoch 2, 100% \t Train loss: 0.235 took: 4.74s  Val. loss: 0.176  Val. score: 94.889%\n",
      "Epoch 3, 100% \t Train loss: 0.171 took: 4.76s  Val. loss: 0.143  Val. score: 95.717%\n",
      "Epoch 4, 100% \t Train loss: 0.137 took: 4.74s  Val. loss: 0.116  Val. score: 96.428%\n",
      "Epoch 5, 100% \t Train loss: 0.109 took: 4.75s  Val. loss: 0.108  Val. score: 96.739%\n",
      "Epoch 6, 100% \t Train loss: 0.094 took: 4.68s  Val. loss: 0.103  Val. score: 96.761%\n",
      "Epoch 7, 100% \t Train loss: 0.078 took: 4.84s  Val. loss: 0.100  Val. score: 97.044%\n",
      "Epoch 8, 100% \t Train loss: 0.069 took: 4.51s  Val. loss: 0.089  Val. score: 97.211%\n",
      "Epoch 9, 100% \t Train loss: 0.059 took: 4.83s  Val. loss: 0.090  Val. score: 97.439%\n",
      "Epoch 10, 100% \t Train loss: 0.052 took: 4.82s  Val. loss: 0.086  Val. score: 97.411%\n",
      "Epoch 11, 100% \t Train loss: 0.045 took: 4.72s  Val. loss: 0.084  Val. score: 97.572%\n",
      "Epoch 12, 100% \t Train loss: 0.038 took: 4.76s  Val. loss: 0.088  Val. score: 97.511%\n",
      "Epoch 13, 100% \t Train loss: 0.035 took: 5.01s  Val. loss: 0.086  Val. score: 97.650%\n",
      "Epoch 14, 100% \t Train loss: 0.032 took: 4.66s  Val. loss: 0.082  Val. score: 97.744%\n",
      "Epoch 15, 100% \t Train loss: 0.028 took: 4.85s  Val. loss: 0.081  Val. score: 97.811%\n",
      "Training finished, took 121.697s\n",
      "\n",
      "Parameters configuration 36 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0037120453380267513\n",
      "h_sizes \t [784, 178, 49]\n",
      "penalty \t 0.0001881222863357692\n",
      "dropout \t 0.07927037399245215\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.5611 +/- 0.1792\n",
      "Time for evaluation: 358.8 s\n",
      "Estimated time to finish : 8.76 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.609 took: 14.24s  Val. loss: 0.913  Val. score: 68.994%\n",
      "Epoch 2, 100% \t Train loss: 0.766 took: 13.48s  Val. loss: 0.382  Val. score: 91.372%\n",
      "Epoch 3, 100% \t Train loss: 0.490 took: 14.91s  Val. loss: 0.288  Val. score: 93.250%\n",
      "Epoch 4, 100% \t Train loss: 0.361 took: 14.55s  Val. loss: 0.235  Val. score: 94.489%\n",
      "Epoch 5, 100% \t Train loss: 0.297 took: 15.23s  Val. loss: 0.207  Val. score: 95.161%\n",
      "Epoch 6, 100% \t Train loss: 0.253 took: 15.23s  Val. loss: 0.208  Val. score: 95.622%\n",
      "Epoch 7, 100% \t Train loss: 0.231 took: 15.23s  Val. loss: 0.193  Val. score: 95.867%\n",
      "Epoch 8, 100% \t Train loss: 0.202 took: 15.37s  Val. loss: 0.186  Val. score: 96.272%\n",
      "Epoch 9, 100% \t Train loss: 0.179 took: 15.12s  Val. loss: 0.175  Val. score: 96.433%\n",
      "Epoch 10, 100% \t Train loss: 0.169 took: 14.72s  Val. loss: 0.171  Val. score: 96.744%\n",
      "Epoch 11, 100% \t Train loss: 0.158 took: 14.75s  Val. loss: 0.178  Val. score: 96.706%\n",
      "Epoch 12, 100% \t Train loss: 0.146 took: 14.65s  Val. loss: 0.176  Val. score: 96.700%\n",
      "Epoch 13, 100% \t Train loss: 0.136 took: 14.63s  Val. loss: 0.176  Val. score: 96.722%\n",
      "Epoch 14, 100% \t Train loss: 0.127 took: 15.20s  Val. loss: 0.184  Val. score: 96.772%\n",
      "Epoch 15, 100% \t Train loss: 0.120 took: 14.99s  Val. loss: 0.187  Val. score: 97.072%\n",
      "Training finished, took 319.557s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.402 took: 13.60s  Val. loss: 0.724  Val. score: 71.367%\n",
      "Epoch 2, 100% \t Train loss: 0.746 took: 13.58s  Val. loss: 0.414  Val. score: 91.072%\n",
      "Epoch 3, 100% \t Train loss: 0.535 took: 13.37s  Val. loss: 0.343  Val. score: 92.994%\n",
      "Epoch 4, 100% \t Train loss: 0.426 took: 14.54s  Val. loss: 0.282  Val. score: 94.244%\n",
      "Epoch 5, 100% \t Train loss: 0.349 took: 14.32s  Val. loss: 0.249  Val. score: 95.161%\n",
      "Epoch 6, 100% \t Train loss: 0.296 took: 14.64s  Val. loss: 0.249  Val. score: 94.450%\n",
      "Epoch 7, 100% \t Train loss: 0.253 took: 14.81s  Val. loss: 0.212  Val. score: 95.822%\n",
      "Epoch 8, 100% \t Train loss: 0.229 took: 14.82s  Val. loss: 0.204  Val. score: 96.111%\n",
      "Epoch 9, 100% \t Train loss: 0.204 took: 14.39s  Val. loss: 0.182  Val. score: 96.372%\n",
      "Epoch 10, 100% \t Train loss: 0.184 took: 14.36s  Val. loss: 0.189  Val. score: 96.600%\n",
      "Epoch 11, 100% \t Train loss: 0.166 took: 14.55s  Val. loss: 0.194  Val. score: 96.589%\n",
      "Epoch 12, 100% \t Train loss: 0.155 took: 14.70s  Val. loss: 0.197  Val. score: 96.683%\n",
      "Epoch 13, 100% \t Train loss: 0.143 took: 14.89s  Val. loss: 0.188  Val. score: 96.928%\n",
      "Epoch 14, 100% \t Train loss: 0.135 took: 15.11s  Val. loss: 0.199  Val. score: 97.033%\n",
      "Epoch 15, 100% \t Train loss: 0.127 took: 15.50s  Val. loss: 0.208  Val. score: 97.039%\n",
      "Training finished, took 313.525s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.576 took: 13.77s  Val. loss: 0.900  Val. score: 68.706%\n",
      "Epoch 2, 100% \t Train loss: 0.841 took: 14.08s  Val. loss: 0.479  Val. score: 89.578%\n",
      "Epoch 3, 100% \t Train loss: 0.563 took: 14.24s  Val. loss: 0.323  Val. score: 92.872%\n",
      "Epoch 4, 100% \t Train loss: 0.423 took: 14.49s  Val. loss: 0.263  Val. score: 94.422%\n",
      "Epoch 5, 100% \t Train loss: 0.345 took: 14.73s  Val. loss: 0.243  Val. score: 94.889%\n",
      "Epoch 6, 100% \t Train loss: 0.300 took: 13.84s  Val. loss: 0.214  Val. score: 95.522%\n",
      "Epoch 7, 100% \t Train loss: 0.263 took: 14.69s  Val. loss: 0.202  Val. score: 95.556%\n",
      "Epoch 8, 100% \t Train loss: 0.223 took: 13.73s  Val. loss: 0.193  Val. score: 96.150%\n",
      "Epoch 9, 100% \t Train loss: 0.205 took: 14.85s  Val. loss: 0.194  Val. score: 96.206%\n",
      "Epoch 10, 100% \t Train loss: 0.187 took: 14.45s  Val. loss: 0.197  Val. score: 96.356%\n",
      "Epoch 11, 100% \t Train loss: 0.167 took: 14.29s  Val. loss: 0.199  Val. score: 96.450%\n",
      "Epoch 12, 100% \t Train loss: 0.157 took: 14.71s  Val. loss: 0.194  Val. score: 96.717%\n",
      "Epoch 13, 100% \t Train loss: 0.143 took: 15.26s  Val. loss: 0.184  Val. score: 96.906%\n",
      "Epoch 14, 100% \t Train loss: 0.138 took: 14.52s  Val. loss: 0.180  Val. score: 96.967%\n",
      "Epoch 15, 100% \t Train loss: 0.125 took: 14.23s  Val. loss: 0.197  Val. score: 97.028%\n",
      "Training finished, took 310.025s\n",
      "\n",
      "Parameters configuration 37 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0028222577539235407\n",
      "h_sizes \t [784, 458, 249, 151, 82, 49, 32, 19]\n",
      "penalty \t 0.0002782470598623404\n",
      "dropout \t 0.21368914171565292\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.0463 +/- 0.0189\n",
      "Time for evaluation: 944.3 s\n",
      "Estimated time to finish : 8.84 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.379 took: 6.82s  Val. loss: 0.179  Val. score: 94.522%\n",
      "Epoch 2, 100% \t Train loss: 0.162 took: 6.68s  Val. loss: 0.116  Val. score: 96.628%\n",
      "Epoch 3, 100% \t Train loss: 0.118 took: 7.40s  Val. loss: 0.124  Val. score: 96.422%\n",
      "Epoch 4, 100% \t Train loss: 0.091 took: 7.86s  Val. loss: 0.114  Val. score: 96.939%\n",
      "Epoch 5, 100% \t Train loss: 0.076 took: 7.84s  Val. loss: 0.096  Val. score: 97.144%\n",
      "Epoch 6, 100% \t Train loss: 0.062 took: 7.93s  Val. loss: 0.101  Val. score: 97.250%\n",
      "Epoch 7, 100% \t Train loss: 0.048 took: 7.40s  Val. loss: 0.103  Val. score: 97.328%\n",
      "Epoch 8, 100% \t Train loss: 0.044 took: 7.63s  Val. loss: 0.096  Val. score: 97.644%\n",
      "Epoch 9, 100% \t Train loss: 0.038 took: 7.36s  Val. loss: 0.098  Val. score: 97.533%\n",
      "Epoch 10, 100% \t Train loss: 0.032 took: 7.30s  Val. loss: 0.112  Val. score: 97.478%\n",
      "Epoch 11, 100% \t Train loss: 0.032 took: 7.30s  Val. loss: 0.103  Val. score: 97.506%\n",
      "Epoch 12, 100% \t Train loss: 0.029 took: 7.28s  Val. loss: 0.102  Val. score: 97.561%\n",
      "Epoch 13, 100% \t Train loss: 0.025 took: 7.90s  Val. loss: 0.100  Val. score: 97.800%\n",
      "Epoch 14, 100% \t Train loss: 0.021 took: 7.56s  Val. loss: 0.113  Val. score: 97.794%\n",
      "Epoch 15, 100% \t Train loss: 0.020 took: 7.49s  Val. loss: 0.113  Val. score: 97.733%\n",
      "Training finished, took 171.848s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.382 took: 6.58s  Val. loss: 0.179  Val. score: 94.778%\n",
      "Epoch 2, 100% \t Train loss: 0.152 took: 6.60s  Val. loss: 0.143  Val. score: 95.839%\n",
      "Epoch 3, 100% \t Train loss: 0.111 took: 6.74s  Val. loss: 0.121  Val. score: 96.506%\n",
      "Epoch 4, 100% \t Train loss: 0.084 took: 6.95s  Val. loss: 0.107  Val. score: 97.083%\n",
      "Epoch 5, 100% \t Train loss: 0.067 took: 7.07s  Val. loss: 0.113  Val. score: 96.917%\n",
      "Epoch 6, 100% \t Train loss: 0.055 took: 6.89s  Val. loss: 0.103  Val. score: 97.400%\n",
      "Epoch 7, 100% \t Train loss: 0.046 took: 6.99s  Val. loss: 0.120  Val. score: 96.950%\n",
      "Epoch 8, 100% \t Train loss: 0.040 took: 7.25s  Val. loss: 0.125  Val. score: 97.228%\n",
      "Epoch 9, 100% \t Train loss: 0.035 took: 6.98s  Val. loss: 0.115  Val. score: 97.561%\n",
      "Epoch 10, 100% \t Train loss: 0.030 took: 6.88s  Val. loss: 0.118  Val. score: 97.344%\n",
      "Epoch 11, 100% \t Train loss: 0.026 took: 7.06s  Val. loss: 0.115  Val. score: 97.550%\n",
      "Epoch 12, 100% \t Train loss: 0.022 took: 6.86s  Val. loss: 0.121  Val. score: 97.489%\n",
      "Epoch 13, 100% \t Train loss: 0.021 took: 7.34s  Val. loss: 0.132  Val. score: 97.622%\n",
      "Epoch 14, 100% \t Train loss: 0.020 took: 6.98s  Val. loss: 0.128  Val. score: 97.511%\n",
      "Epoch 15, 100% \t Train loss: 0.016 took: 6.80s  Val. loss: 0.132  Val. score: 97.528%\n",
      "Training finished, took 163.206s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.388 took: 6.00s  Val. loss: 0.170  Val. score: 95.044%\n",
      "Epoch 2, 100% \t Train loss: 0.157 took: 6.13s  Val. loss: 0.152  Val. score: 95.444%\n",
      "Epoch 3, 100% \t Train loss: 0.112 took: 6.60s  Val. loss: 0.116  Val. score: 96.572%\n",
      "Epoch 4, 100% \t Train loss: 0.087 took: 6.92s  Val. loss: 0.111  Val. score: 97.017%\n",
      "Epoch 5, 100% \t Train loss: 0.073 took: 6.96s  Val. loss: 0.116  Val. score: 96.933%\n",
      "Epoch 6, 100% \t Train loss: 0.057 took: 7.11s  Val. loss: 0.105  Val. score: 97.456%\n",
      "Epoch 7, 100% \t Train loss: 0.050 took: 8.04s  Val. loss: 0.108  Val. score: 97.383%\n",
      "Epoch 8, 100% \t Train loss: 0.045 took: 8.23s  Val. loss: 0.103  Val. score: 97.367%\n",
      "Epoch 9, 100% \t Train loss: 0.036 took: 8.39s  Val. loss: 0.113  Val. score: 97.550%\n",
      "Epoch 10, 100% \t Train loss: 0.031 took: 8.28s  Val. loss: 0.124  Val. score: 97.489%\n",
      "Epoch 11, 100% \t Train loss: 0.029 took: 8.10s  Val. loss: 0.114  Val. score: 97.633%\n",
      "Epoch 12, 100% \t Train loss: 0.028 took: 7.84s  Val. loss: 0.121  Val. score: 97.606%\n",
      "Epoch 13, 100% \t Train loss: 0.023 took: 7.56s  Val. loss: 0.118  Val. score: 97.494%\n",
      "Epoch 14, 100% \t Train loss: 0.024 took: 7.69s  Val. loss: 0.126  Val. score: 97.511%\n",
      "Epoch 15, 100% \t Train loss: 0.023 took: 7.49s  Val. loss: 0.128  Val. score: 97.633%\n",
      "Training finished, took 172.714s\n",
      "\n",
      "Parameters configuration 38 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.01833598037179182\n",
      "h_sizes \t [784, 277, 100, 31]\n",
      "penalty \t 0.0001017590647857701\n",
      "dropout \t 0.06919644772687822\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6315 +/- 0.0839\n",
      "Time for evaluation: 508.9 s\n",
      "Estimated time to finish : 8.70 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.722 took: 11.86s  Val. loss: 0.266  Val. score: 92.661%\n",
      "Epoch 2, 100% \t Train loss: 0.224 took: 11.40s  Val. loss: 0.188  Val. score: 94.806%\n",
      "Epoch 3, 100% \t Train loss: 0.152 took: 12.59s  Val. loss: 0.172  Val. score: 94.983%\n",
      "Epoch 4, 100% \t Train loss: 0.117 took: 12.93s  Val. loss: 0.129  Val. score: 96.528%\n",
      "Epoch 5, 100% \t Train loss: 0.091 took: 12.45s  Val. loss: 0.129  Val. score: 96.544%\n",
      "Epoch 6, 100% \t Train loss: 0.068 took: 12.42s  Val. loss: 0.118  Val. score: 96.994%\n",
      "Epoch 7, 100% \t Train loss: 0.056 took: 12.34s  Val. loss: 0.123  Val. score: 96.872%\n",
      "Epoch 8, 100% \t Train loss: 0.042 took: 12.54s  Val. loss: 0.126  Val. score: 96.994%\n",
      "Epoch 9, 100% \t Train loss: 0.035 took: 13.27s  Val. loss: 0.117  Val. score: 97.106%\n",
      "Epoch 10, 100% \t Train loss: 0.025 took: 12.74s  Val. loss: 0.127  Val. score: 97.100%\n",
      "Epoch 11, 100% \t Train loss: 0.022 took: 12.41s  Val. loss: 0.129  Val. score: 97.200%\n",
      "Epoch 12, 100% \t Train loss: 0.021 took: 12.85s  Val. loss: 0.130  Val. score: 97.128%\n",
      "Epoch 13, 100% \t Train loss: 0.016 took: 12.41s  Val. loss: 0.117  Val. score: 97.528%\n",
      "Epoch 14, 100% \t Train loss: 0.012 took: 12.65s  Val. loss: 0.156  Val. score: 97.156%\n",
      "Epoch 15, 100% \t Train loss: 0.013 took: 13.24s  Val. loss: 0.147  Val. score: 97.106%\n",
      "Training finished, took 275.135s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.705 took: 12.27s  Val. loss: 0.293  Val. score: 91.628%\n",
      "Epoch 2, 100% \t Train loss: 0.235 took: 11.96s  Val. loss: 0.226  Val. score: 93.628%\n",
      "Epoch 3, 100% \t Train loss: 0.156 took: 12.53s  Val. loss: 0.156  Val. score: 95.694%\n",
      "Epoch 4, 100% \t Train loss: 0.111 took: 12.69s  Val. loss: 0.161  Val. score: 95.617%\n",
      "Epoch 5, 100% \t Train loss: 0.084 took: 13.26s  Val. loss: 0.121  Val. score: 96.667%\n",
      "Epoch 6, 100% \t Train loss: 0.061 took: 13.10s  Val. loss: 0.119  Val. score: 96.933%\n",
      "Epoch 7, 100% \t Train loss: 0.047 took: 13.23s  Val. loss: 0.117  Val. score: 96.828%\n",
      "Epoch 8, 100% \t Train loss: 0.035 took: 12.49s  Val. loss: 0.118  Val. score: 97.000%\n",
      "Epoch 9, 100% \t Train loss: 0.031 took: 13.17s  Val. loss: 0.119  Val. score: 97.133%\n",
      "Epoch 10, 100% \t Train loss: 0.021 took: 12.74s  Val. loss: 0.128  Val. score: 97.306%\n",
      "Epoch 11, 100% \t Train loss: 0.020 took: 12.95s  Val. loss: 0.131  Val. score: 97.244%\n",
      "Epoch 12, 100% \t Train loss: 0.013 took: 12.67s  Val. loss: 0.157  Val. score: 97.006%\n",
      "Epoch 13, 100% \t Train loss: 0.012 took: 12.58s  Val. loss: 0.150  Val. score: 97.322%\n",
      "Epoch 14, 100% \t Train loss: 0.008 took: 12.36s  Val. loss: 0.152  Val. score: 97.306%\n",
      "Epoch 15, 100% \t Train loss: 0.008 took: 12.46s  Val. loss: 0.152  Val. score: 97.450%\n",
      "Training finished, took 276.484s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.684 took: 10.84s  Val. loss: 0.309  Val. score: 91.189%\n",
      "Epoch 2, 100% \t Train loss: 0.243 took: 11.16s  Val. loss: 0.204  Val. score: 93.950%\n",
      "Epoch 3, 100% \t Train loss: 0.162 took: 11.83s  Val. loss: 0.175  Val. score: 95.100%\n",
      "Epoch 4, 100% \t Train loss: 0.119 took: 12.22s  Val. loss: 0.147  Val. score: 96.017%\n",
      "Epoch 5, 100% \t Train loss: 0.089 took: 12.96s  Val. loss: 0.134  Val. score: 96.056%\n",
      "Epoch 6, 100% \t Train loss: 0.065 took: 13.13s  Val. loss: 0.124  Val. score: 96.856%\n",
      "Epoch 7, 100% \t Train loss: 0.054 took: 12.47s  Val. loss: 0.127  Val. score: 96.817%\n",
      "Epoch 8, 100% \t Train loss: 0.043 took: 12.89s  Val. loss: 0.134  Val. score: 96.644%\n",
      "Epoch 9, 100% \t Train loss: 0.034 took: 11.94s  Val. loss: 0.127  Val. score: 97.078%\n",
      "Epoch 10, 100% \t Train loss: 0.030 took: 11.92s  Val. loss: 0.124  Val. score: 96.994%\n",
      "Epoch 11, 100% \t Train loss: 0.021 took: 13.21s  Val. loss: 0.136  Val. score: 97.194%\n",
      "Epoch 12, 100% \t Train loss: 0.016 took: 13.07s  Val. loss: 0.145  Val. score: 97.006%\n",
      "Epoch 13, 100% \t Train loss: 0.016 took: 12.87s  Val. loss: 0.149  Val. score: 97.006%\n",
      "Epoch 14, 100% \t Train loss: 0.010 took: 12.61s  Val. loss: 0.151  Val. score: 97.117%\n",
      "Epoch 15, 100% \t Train loss: 0.008 took: 11.99s  Val. loss: 0.156  Val. score: 97.400%\n",
      "Training finished, took 269.527s\n",
      "\n",
      "Parameters configuration 39 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0047514779126872735\n",
      "h_sizes \t [784, 410, 221, 121, 53, 25, 16]\n",
      "penalty \t 0.006110586067950274\n",
      "dropout \t 0.004200560732935177\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.3185 +/- 0.1520\n",
      "Time for evaluation: 822.3 s\n",
      "Estimated time to finish : 8.69 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.732 took: 11.82s  Val. loss: 0.261  Val. score: 93.156%\n",
      "Epoch 2, 100% \t Train loss: 0.247 took: 11.10s  Val. loss: 0.182  Val. score: 95.311%\n",
      "Epoch 3, 100% \t Train loss: 0.174 took: 12.49s  Val. loss: 0.181  Val. score: 95.394%\n",
      "Epoch 4, 100% \t Train loss: 0.135 took: 13.18s  Val. loss: 0.137  Val. score: 96.667%\n",
      "Epoch 5, 100% \t Train loss: 0.112 took: 13.56s  Val. loss: 0.134  Val. score: 96.878%\n",
      "Epoch 6, 100% \t Train loss: 0.098 took: 13.01s  Val. loss: 0.121  Val. score: 97.078%\n",
      "Epoch 7, 100% \t Train loss: 0.079 took: 14.02s  Val. loss: 0.131  Val. score: 97.178%\n",
      "Epoch 8, 100% \t Train loss: 0.065 took: 14.03s  Val. loss: 0.143  Val. score: 97.000%\n",
      "Epoch 9, 100% \t Train loss: 0.059 took: 13.88s  Val. loss: 0.136  Val. score: 97.189%\n",
      "Epoch 10, 100% \t Train loss: 0.056 took: 13.56s  Val. loss: 0.133  Val. score: 97.406%\n",
      "Epoch 11, 100% \t Train loss: 0.046 took: 12.98s  Val. loss: 0.153  Val. score: 97.344%\n",
      "Epoch 12, 100% \t Train loss: 0.043 took: 13.68s  Val. loss: 0.139  Val. score: 97.344%\n",
      "Epoch 13, 100% \t Train loss: 0.036 took: 13.31s  Val. loss: 0.139  Val. score: 97.633%\n",
      "Epoch 14, 100% \t Train loss: 0.036 took: 13.62s  Val. loss: 0.152  Val. score: 97.450%\n",
      "Epoch 15, 100% \t Train loss: 0.033 took: 13.67s  Val. loss: 0.145  Val. score: 97.489%\n",
      "Training finished, took 283.887s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.746 took: 11.49s  Val. loss: 0.221  Val. score: 94.267%\n",
      "Epoch 2, 100% \t Train loss: 0.235 took: 11.37s  Val. loss: 0.175  Val. score: 95.433%\n",
      "Epoch 3, 100% \t Train loss: 0.168 took: 13.39s  Val. loss: 0.143  Val. score: 96.378%\n",
      "Epoch 4, 100% \t Train loss: 0.132 took: 14.06s  Val. loss: 0.128  Val. score: 96.911%\n",
      "Epoch 5, 100% \t Train loss: 0.105 took: 13.61s  Val. loss: 0.152  Val. score: 96.739%\n",
      "Epoch 6, 100% \t Train loss: 0.092 took: 13.07s  Val. loss: 0.127  Val. score: 97.267%\n",
      "Epoch 7, 100% \t Train loss: 0.076 took: 13.46s  Val. loss: 0.128  Val. score: 97.339%\n",
      "Epoch 8, 100% \t Train loss: 0.064 took: 13.88s  Val. loss: 0.125  Val. score: 97.539%\n",
      "Epoch 9, 100% \t Train loss: 0.058 took: 13.38s  Val. loss: 0.121  Val. score: 97.256%\n",
      "Epoch 10, 100% \t Train loss: 0.050 took: 14.00s  Val. loss: 0.144  Val. score: 97.506%\n",
      "Epoch 11, 100% \t Train loss: 0.044 took: 13.79s  Val. loss: 0.155  Val. score: 97.594%\n",
      "Epoch 12, 100% \t Train loss: 0.039 took: 13.42s  Val. loss: 0.131  Val. score: 97.517%\n",
      "Epoch 13, 100% \t Train loss: 0.036 took: 13.99s  Val. loss: 0.123  Val. score: 97.878%\n",
      "Epoch 14, 100% \t Train loss: 0.032 took: 13.74s  Val. loss: 0.137  Val. score: 97.761%\n",
      "Epoch 15, 100% \t Train loss: 0.031 took: 13.46s  Val. loss: 0.139  Val. score: 97.550%\n",
      "Training finished, took 287.847s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.678 took: 12.30s  Val. loss: 0.238  Val. score: 93.628%\n",
      "Epoch 2, 100% \t Train loss: 0.246 took: 11.85s  Val. loss: 0.199  Val. score: 94.772%\n",
      "Epoch 3, 100% \t Train loss: 0.172 took: 13.45s  Val. loss: 0.146  Val. score: 96.167%\n",
      "Epoch 4, 100% \t Train loss: 0.133 took: 14.15s  Val. loss: 0.161  Val. score: 95.922%\n",
      "Epoch 5, 100% \t Train loss: 0.114 took: 13.79s  Val. loss: 0.142  Val. score: 96.617%\n",
      "Epoch 6, 100% \t Train loss: 0.094 took: 13.59s  Val. loss: 0.118  Val. score: 96.917%\n",
      "Epoch 7, 100% \t Train loss: 0.077 took: 14.14s  Val. loss: 0.126  Val. score: 96.933%\n",
      "Epoch 8, 100% \t Train loss: 0.066 took: 14.21s  Val. loss: 0.123  Val. score: 97.267%\n",
      "Epoch 9, 100% \t Train loss: 0.059 took: 14.06s  Val. loss: 0.139  Val. score: 97.233%\n",
      "Epoch 10, 100% \t Train loss: 0.053 took: 13.79s  Val. loss: 0.125  Val. score: 97.367%\n",
      "Epoch 11, 100% \t Train loss: 0.046 took: 14.27s  Val. loss: 0.123  Val. score: 97.328%\n",
      "Epoch 12, 100% \t Train loss: 0.044 took: 13.78s  Val. loss: 0.119  Val. score: 97.533%\n",
      "Epoch 13, 100% \t Train loss: 0.040 took: 13.52s  Val. loss: 0.135  Val. score: 97.261%\n",
      "Epoch 14, 100% \t Train loss: 0.034 took: 13.25s  Val. loss: 0.138  Val. score: 97.494%\n",
      "Epoch 15, 100% \t Train loss: 0.031 took: 13.15s  Val. loss: 0.135  Val. score: 97.606%\n",
      "Training finished, took 290.430s\n",
      "\n",
      "Parameters configuration 40 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.009170325296149398\n",
      "h_sizes \t [784, 427, 245, 135, 65, 38, 18]\n",
      "penalty \t 0.0009695171160236083\n",
      "dropout \t 0.09456445608021896\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5481 +/- 0.0476\n",
      "Time for evaluation: 863.4 s\n",
      "Estimated time to finish : 8.70 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.463 took: 5.84s  Val. loss: 0.192  Val. score: 94.261%\n",
      "Epoch 2, 100% \t Train loss: 0.193 took: 5.79s  Val. loss: 0.144  Val. score: 95.817%\n",
      "Epoch 3, 100% \t Train loss: 0.142 took: 6.44s  Val. loss: 0.122  Val. score: 96.489%\n",
      "Epoch 4, 100% \t Train loss: 0.114 took: 6.16s  Val. loss: 0.120  Val. score: 96.606%\n",
      "Epoch 5, 100% \t Train loss: 0.095 took: 6.23s  Val. loss: 0.111  Val. score: 96.789%\n",
      "Epoch 6, 100% \t Train loss: 0.079 took: 6.31s  Val. loss: 0.097  Val. score: 97.328%\n",
      "Epoch 7, 100% \t Train loss: 0.067 took: 5.81s  Val. loss: 0.102  Val. score: 97.361%\n",
      "Epoch 8, 100% \t Train loss: 0.061 took: 6.39s  Val. loss: 0.093  Val. score: 97.644%\n",
      "Epoch 9, 100% \t Train loss: 0.053 took: 5.78s  Val. loss: 0.096  Val. score: 97.544%\n",
      "Epoch 10, 100% \t Train loss: 0.048 took: 6.41s  Val. loss: 0.097  Val. score: 97.661%\n",
      "Epoch 11, 100% \t Train loss: 0.041 took: 5.86s  Val. loss: 0.097  Val. score: 97.517%\n",
      "Epoch 12, 100% \t Train loss: 0.038 took: 5.78s  Val. loss: 0.096  Val. score: 97.572%\n",
      "Epoch 13, 100% \t Train loss: 0.036 took: 6.30s  Val. loss: 0.100  Val. score: 97.689%\n",
      "Epoch 14, 100% \t Train loss: 0.031 took: 6.30s  Val. loss: 0.104  Val. score: 97.572%\n",
      "Epoch 15, 100% \t Train loss: 0.030 took: 5.81s  Val. loss: 0.106  Val. score: 97.767%\n",
      "Training finished, took 148.892s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.471 took: 6.33s  Val. loss: 0.221  Val. score: 93.217%\n",
      "Epoch 2, 100% \t Train loss: 0.203 took: 5.95s  Val. loss: 0.145  Val. score: 95.556%\n",
      "Epoch 3, 100% \t Train loss: 0.148 took: 6.29s  Val. loss: 0.121  Val. score: 96.383%\n",
      "Epoch 4, 100% \t Train loss: 0.118 took: 5.78s  Val. loss: 0.117  Val. score: 96.644%\n",
      "Epoch 5, 100% \t Train loss: 0.093 took: 6.13s  Val. loss: 0.104  Val. score: 97.083%\n",
      "Epoch 6, 100% \t Train loss: 0.082 took: 6.19s  Val. loss: 0.105  Val. score: 97.056%\n",
      "Epoch 7, 100% \t Train loss: 0.068 took: 5.74s  Val. loss: 0.108  Val. score: 97.033%\n",
      "Epoch 8, 100% \t Train loss: 0.062 took: 5.92s  Val. loss: 0.100  Val. score: 97.356%\n",
      "Epoch 9, 100% \t Train loss: 0.052 took: 6.37s  Val. loss: 0.099  Val. score: 97.394%\n",
      "Epoch 10, 100% \t Train loss: 0.047 took: 6.38s  Val. loss: 0.104  Val. score: 97.367%\n",
      "Epoch 11, 100% \t Train loss: 0.042 took: 6.36s  Val. loss: 0.108  Val. score: 97.261%\n",
      "Epoch 12, 100% \t Train loss: 0.038 took: 5.97s  Val. loss: 0.110  Val. score: 97.472%\n",
      "Epoch 13, 100% \t Train loss: 0.035 took: 6.54s  Val. loss: 0.102  Val. score: 97.533%\n",
      "Epoch 14, 100% \t Train loss: 0.032 took: 6.30s  Val. loss: 0.104  Val. score: 97.650%\n",
      "Epoch 15, 100% \t Train loss: 0.031 took: 6.18s  Val. loss: 0.105  Val. score: 97.617%\n",
      "Training finished, took 149.992s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.461 took: 5.89s  Val. loss: 0.176  Val. score: 94.756%\n",
      "Epoch 2, 100% \t Train loss: 0.195 took: 6.07s  Val. loss: 0.132  Val. score: 96.244%\n",
      "Epoch 3, 100% \t Train loss: 0.145 took: 5.81s  Val. loss: 0.113  Val. score: 96.689%\n",
      "Epoch 4, 100% \t Train loss: 0.114 took: 5.88s  Val. loss: 0.102  Val. score: 97.183%\n",
      "Epoch 5, 100% \t Train loss: 0.092 took: 6.45s  Val. loss: 0.111  Val. score: 97.094%\n",
      "Epoch 6, 100% \t Train loss: 0.078 took: 6.00s  Val. loss: 0.100  Val. score: 97.317%\n",
      "Epoch 7, 100% \t Train loss: 0.069 took: 5.89s  Val. loss: 0.094  Val. score: 97.433%\n",
      "Epoch 8, 100% \t Train loss: 0.059 took: 6.10s  Val. loss: 0.099  Val. score: 97.428%\n",
      "Epoch 9, 100% \t Train loss: 0.052 took: 5.99s  Val. loss: 0.106  Val. score: 97.300%\n",
      "Epoch 10, 100% \t Train loss: 0.045 took: 6.09s  Val. loss: 0.100  Val. score: 97.650%\n",
      "Epoch 11, 100% \t Train loss: 0.039 took: 5.89s  Val. loss: 0.094  Val. score: 97.683%\n",
      "Epoch 12, 100% \t Train loss: 0.042 took: 5.93s  Val. loss: 0.092  Val. score: 97.700%\n",
      "Epoch 13, 100% \t Train loss: 0.035 took: 6.18s  Val. loss: 0.103  Val. score: 97.561%\n",
      "Epoch 14, 100% \t Train loss: 0.030 took: 5.90s  Val. loss: 0.103  Val. score: 97.733%\n",
      "Epoch 15, 100% \t Train loss: 0.028 took: 6.41s  Val. loss: 0.105  Val. score: 97.594%\n",
      "Training finished, took 148.524s\n",
      "\n",
      "Parameters configuration 41 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008725959805404075\n",
      "h_sizes \t [784, 269, 79, 26]\n",
      "penalty \t 0.008162834979702554\n",
      "dropout \t 0.14902353260290122\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.6593 +/- 0.0765\n",
      "Time for evaluation: 448.6 s\n",
      "Estimated time to finish : 8.52 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.534 took: 8.61s  Val. loss: 0.218  Val. score: 93.511%\n",
      "Epoch 2, 100% \t Train loss: 0.199 took: 8.33s  Val. loss: 0.150  Val. score: 95.472%\n",
      "Epoch 3, 100% \t Train loss: 0.138 took: 8.57s  Val. loss: 0.124  Val. score: 96.322%\n",
      "Epoch 4, 100% \t Train loss: 0.106 took: 8.91s  Val. loss: 0.108  Val. score: 96.756%\n",
      "Epoch 5, 100% \t Train loss: 0.083 took: 9.06s  Val. loss: 0.100  Val. score: 97.072%\n",
      "Epoch 6, 100% \t Train loss: 0.064 took: 9.01s  Val. loss: 0.094  Val. score: 97.350%\n",
      "Epoch 7, 100% \t Train loss: 0.050 took: 9.50s  Val. loss: 0.097  Val. score: 97.350%\n",
      "Epoch 8, 100% \t Train loss: 0.040 took: 8.89s  Val. loss: 0.097  Val. score: 97.417%\n",
      "Epoch 9, 100% \t Train loss: 0.032 took: 9.12s  Val. loss: 0.097  Val. score: 97.333%\n",
      "Epoch 10, 100% \t Train loss: 0.027 took: 9.26s  Val. loss: 0.093  Val. score: 97.761%\n",
      "Epoch 11, 100% \t Train loss: 0.023 took: 9.07s  Val. loss: 0.093  Val. score: 97.783%\n",
      "Epoch 12, 100% \t Train loss: 0.018 took: 9.02s  Val. loss: 0.104  Val. score: 97.656%\n",
      "Epoch 13, 100% \t Train loss: 0.017 took: 9.15s  Val. loss: 0.102  Val. score: 97.694%\n",
      "Epoch 14, 100% \t Train loss: 0.011 took: 9.23s  Val. loss: 0.109  Val. score: 97.817%\n",
      "Epoch 15, 100% \t Train loss: 0.010 took: 9.22s  Val. loss: 0.110  Val. score: 97.761%\n",
      "Training finished, took 206.242s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.507 took: 8.54s  Val. loss: 0.223  Val. score: 93.533%\n",
      "Epoch 2, 100% \t Train loss: 0.192 took: 8.13s  Val. loss: 0.154  Val. score: 95.411%\n",
      "Epoch 3, 100% \t Train loss: 0.131 took: 8.68s  Val. loss: 0.131  Val. score: 96.228%\n",
      "Epoch 4, 100% \t Train loss: 0.097 took: 8.70s  Val. loss: 0.110  Val. score: 96.678%\n",
      "Epoch 5, 100% \t Train loss: 0.075 took: 8.99s  Val. loss: 0.103  Val. score: 96.933%\n",
      "Epoch 6, 100% \t Train loss: 0.058 took: 9.12s  Val. loss: 0.104  Val. score: 97.156%\n",
      "Epoch 7, 100% \t Train loss: 0.047 took: 9.22s  Val. loss: 0.097  Val. score: 97.289%\n",
      "Epoch 8, 100% \t Train loss: 0.036 took: 9.31s  Val. loss: 0.099  Val. score: 97.444%\n",
      "Epoch 9, 100% \t Train loss: 0.031 took: 9.19s  Val. loss: 0.094  Val. score: 97.494%\n",
      "Epoch 10, 100% \t Train loss: 0.024 took: 8.94s  Val. loss: 0.102  Val. score: 97.511%\n",
      "Epoch 11, 100% \t Train loss: 0.020 took: 8.94s  Val. loss: 0.108  Val. score: 97.394%\n",
      "Epoch 12, 100% \t Train loss: 0.017 took: 9.45s  Val. loss: 0.104  Val. score: 97.678%\n",
      "Epoch 13, 100% \t Train loss: 0.013 took: 9.09s  Val. loss: 0.106  Val. score: 97.617%\n",
      "Epoch 14, 100% \t Train loss: 0.011 took: 8.81s  Val. loss: 0.117  Val. score: 97.639%\n",
      "Epoch 15, 100% \t Train loss: 0.010 took: 8.69s  Val. loss: 0.111  Val. score: 97.744%\n",
      "Training finished, took 205.779s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.489 took: 8.63s  Val. loss: 0.233  Val. score: 93.217%\n",
      "Epoch 2, 100% \t Train loss: 0.192 took: 8.46s  Val. loss: 0.160  Val. score: 95.094%\n",
      "Epoch 3, 100% \t Train loss: 0.126 took: 8.59s  Val. loss: 0.133  Val. score: 96.156%\n",
      "Epoch 4, 100% \t Train loss: 0.099 took: 8.92s  Val. loss: 0.109  Val. score: 96.750%\n",
      "Epoch 5, 100% \t Train loss: 0.072 took: 9.55s  Val. loss: 0.101  Val. score: 97.028%\n",
      "Epoch 6, 100% \t Train loss: 0.056 took: 9.36s  Val. loss: 0.112  Val. score: 96.989%\n",
      "Epoch 7, 100% \t Train loss: 0.046 took: 9.04s  Val. loss: 0.104  Val. score: 97.156%\n",
      "Epoch 8, 100% \t Train loss: 0.038 took: 8.82s  Val. loss: 0.106  Val. score: 97.161%\n",
      "Epoch 9, 100% \t Train loss: 0.027 took: 9.13s  Val. loss: 0.107  Val. score: 97.394%\n",
      "Epoch 10, 100% \t Train loss: 0.023 took: 9.06s  Val. loss: 0.113  Val. score: 97.317%\n",
      "Epoch 11, 100% \t Train loss: 0.020 took: 8.90s  Val. loss: 0.108  Val. score: 97.406%\n",
      "Epoch 12, 100% \t Train loss: 0.017 took: 9.35s  Val. loss: 0.106  Val. score: 97.506%\n",
      "Epoch 13, 100% \t Train loss: 0.015 took: 9.00s  Val. loss: 0.116  Val. score: 97.428%\n",
      "Epoch 14, 100% \t Train loss: 0.010 took: 9.44s  Val. loss: 0.131  Val. score: 97.422%\n",
      "Epoch 15, 100% \t Train loss: 0.009 took: 9.37s  Val. loss: 0.135  Val. score: 97.461%\n",
      "Training finished, took 207.667s\n",
      "\n",
      "Parameters configuration 42 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004427617629922213\n",
      "h_sizes \t [784, 337, 146, 71, 31]\n",
      "penalty \t 0.0037981640949041177\n",
      "dropout \t 0.03778391548760354\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6556 +/- 0.1377\n",
      "Time for evaluation: 620.9 s\n",
      "Estimated time to finish : 8.42 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.424 took: 4.84s  Val. loss: 0.203  Val. score: 93.944%\n",
      "Epoch 2, 100% \t Train loss: 0.210 took: 4.77s  Val. loss: 0.161  Val. score: 95.144%\n",
      "Epoch 3, 100% \t Train loss: 0.159 took: 5.15s  Val. loss: 0.137  Val. score: 95.756%\n",
      "Epoch 4, 100% \t Train loss: 0.127 took: 5.07s  Val. loss: 0.117  Val. score: 96.467%\n",
      "Epoch 5, 100% \t Train loss: 0.106 took: 5.43s  Val. loss: 0.109  Val. score: 96.656%\n",
      "Epoch 6, 100% \t Train loss: 0.095 took: 5.02s  Val. loss: 0.103  Val. score: 96.850%\n",
      "Epoch 7, 100% \t Train loss: 0.083 took: 5.11s  Val. loss: 0.097  Val. score: 97.128%\n",
      "Epoch 8, 100% \t Train loss: 0.074 took: 5.14s  Val. loss: 0.097  Val. score: 97.072%\n",
      "Epoch 9, 100% \t Train loss: 0.066 took: 4.78s  Val. loss: 0.098  Val. score: 97.278%\n",
      "Epoch 10, 100% \t Train loss: 0.058 took: 5.04s  Val. loss: 0.091  Val. score: 97.311%\n",
      "Epoch 11, 100% \t Train loss: 0.055 took: 5.06s  Val. loss: 0.097  Val. score: 97.267%\n",
      "Epoch 12, 100% \t Train loss: 0.048 took: 4.65s  Val. loss: 0.095  Val. score: 97.367%\n",
      "Epoch 13, 100% \t Train loss: 0.045 took: 5.05s  Val. loss: 0.092  Val. score: 97.478%\n",
      "Epoch 14, 100% \t Train loss: 0.044 took: 5.01s  Val. loss: 0.097  Val. score: 97.367%\n",
      "Epoch 15, 100% \t Train loss: 0.041 took: 4.95s  Val. loss: 0.098  Val. score: 97.372%\n",
      "Training finished, took 126.160s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.455 took: 4.61s  Val. loss: 0.211  Val. score: 93.861%\n",
      "Epoch 2, 100% \t Train loss: 0.209 took: 4.55s  Val. loss: 0.154  Val. score: 95.422%\n",
      "Epoch 3, 100% \t Train loss: 0.159 took: 4.78s  Val. loss: 0.131  Val. score: 96.100%\n",
      "Epoch 4, 100% \t Train loss: 0.129 took: 4.97s  Val. loss: 0.122  Val. score: 96.389%\n",
      "Epoch 5, 100% \t Train loss: 0.107 took: 4.80s  Val. loss: 0.110  Val. score: 96.839%\n",
      "Epoch 6, 100% \t Train loss: 0.091 took: 4.88s  Val. loss: 0.105  Val. score: 96.994%\n",
      "Epoch 7, 100% \t Train loss: 0.083 took: 4.77s  Val. loss: 0.106  Val. score: 96.983%\n",
      "Epoch 8, 100% \t Train loss: 0.070 took: 4.94s  Val. loss: 0.096  Val. score: 97.272%\n",
      "Epoch 9, 100% \t Train loss: 0.065 took: 4.94s  Val. loss: 0.100  Val. score: 97.239%\n",
      "Epoch 10, 100% \t Train loss: 0.060 took: 4.88s  Val. loss: 0.098  Val. score: 97.267%\n",
      "Epoch 11, 100% \t Train loss: 0.052 took: 4.94s  Val. loss: 0.094  Val. score: 97.394%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, 100% \t Train loss: 0.048 took: 4.74s  Val. loss: 0.096  Val. score: 97.400%\n",
      "Epoch 13, 100% \t Train loss: 0.043 took: 4.62s  Val. loss: 0.099  Val. score: 97.411%\n",
      "Epoch 14, 100% \t Train loss: 0.040 took: 4.83s  Val. loss: 0.101  Val. score: 97.389%\n",
      "Epoch 15, 100% \t Train loss: 0.039 took: 4.57s  Val. loss: 0.102  Val. score: 97.533%\n",
      "Training finished, took 121.637s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.450 took: 4.59s  Val. loss: 0.197  Val. score: 94.156%\n",
      "Epoch 2, 100% \t Train loss: 0.214 took: 4.71s  Val. loss: 0.132  Val. score: 95.967%\n",
      "Epoch 3, 100% \t Train loss: 0.159 took: 4.61s  Val. loss: 0.115  Val. score: 96.433%\n",
      "Epoch 4, 100% \t Train loss: 0.131 took: 4.90s  Val. loss: 0.105  Val. score: 96.744%\n",
      "Epoch 5, 100% \t Train loss: 0.109 took: 4.96s  Val. loss: 0.098  Val. score: 96.983%\n",
      "Epoch 6, 100% \t Train loss: 0.099 took: 4.82s  Val. loss: 0.093  Val. score: 97.094%\n",
      "Epoch 7, 100% \t Train loss: 0.084 took: 4.61s  Val. loss: 0.084  Val. score: 97.433%\n",
      "Epoch 8, 100% \t Train loss: 0.074 took: 4.49s  Val. loss: 0.088  Val. score: 97.356%\n",
      "Epoch 9, 100% \t Train loss: 0.070 took: 4.93s  Val. loss: 0.087  Val. score: 97.378%\n",
      "Epoch 10, 100% \t Train loss: 0.061 took: 4.93s  Val. loss: 0.086  Val. score: 97.450%\n",
      "Epoch 11, 100% \t Train loss: 0.056 took: 4.88s  Val. loss: 0.088  Val. score: 97.522%\n",
      "Epoch 12, 100% \t Train loss: 0.051 took: 4.90s  Val. loss: 0.087  Val. score: 97.506%\n",
      "Epoch 13, 100% \t Train loss: 0.048 took: 4.96s  Val. loss: 0.084  Val. score: 97.594%\n",
      "Epoch 14, 100% \t Train loss: 0.045 took: 4.51s  Val. loss: 0.090  Val. score: 97.589%\n",
      "Epoch 15, 100% \t Train loss: 0.040 took: 4.68s  Val. loss: 0.090  Val. score: 97.611%\n",
      "Training finished, took 121.160s\n",
      "\n",
      "Parameters configuration 43 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.007084088878492843\n",
      "h_sizes \t [784, 170, 40]\n",
      "penalty \t 0.0014105081045908856\n",
      "dropout \t 0.16396063703326874\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5056 +/- 0.0995\n",
      "Time for evaluation: 370.1 s\n",
      "Estimated time to finish : 8.22 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.595 took: 4.93s  Val. loss: 0.293  Val. score: 91.389%\n",
      "Epoch 2, 100% \t Train loss: 0.281 took: 5.02s  Val. loss: 0.210  Val. score: 93.506%\n",
      "Epoch 3, 100% \t Train loss: 0.209 took: 5.01s  Val. loss: 0.169  Val. score: 94.867%\n",
      "Epoch 4, 100% \t Train loss: 0.171 took: 5.31s  Val. loss: 0.144  Val. score: 95.550%\n",
      "Epoch 5, 100% \t Train loss: 0.145 took: 5.11s  Val. loss: 0.133  Val. score: 95.950%\n",
      "Epoch 6, 100% \t Train loss: 0.121 took: 5.06s  Val. loss: 0.117  Val. score: 96.389%\n",
      "Epoch 7, 100% \t Train loss: 0.108 took: 4.91s  Val. loss: 0.111  Val. score: 96.661%\n",
      "Epoch 8, 100% \t Train loss: 0.096 took: 5.23s  Val. loss: 0.104  Val. score: 96.939%\n",
      "Epoch 9, 100% \t Train loss: 0.089 took: 5.16s  Val. loss: 0.098  Val. score: 97.000%\n",
      "Epoch 10, 100% \t Train loss: 0.080 took: 5.28s  Val. loss: 0.091  Val. score: 97.244%\n",
      "Epoch 11, 100% \t Train loss: 0.073 took: 5.47s  Val. loss: 0.091  Val. score: 97.244%\n",
      "Epoch 12, 100% \t Train loss: 0.068 took: 5.38s  Val. loss: 0.088  Val. score: 97.361%\n",
      "Epoch 13, 100% \t Train loss: 0.058 took: 5.32s  Val. loss: 0.088  Val. score: 97.372%\n",
      "Epoch 14, 100% \t Train loss: 0.056 took: 5.24s  Val. loss: 0.085  Val. score: 97.494%\n",
      "Epoch 15, 100% \t Train loss: 0.052 took: 5.15s  Val. loss: 0.086  Val. score: 97.511%\n",
      "Training finished, took 130.111s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.579 took: 4.82s  Val. loss: 0.274  Val. score: 92.028%\n",
      "Epoch 2, 100% \t Train loss: 0.281 took: 4.80s  Val. loss: 0.195  Val. score: 94.411%\n",
      "Epoch 3, 100% \t Train loss: 0.209 took: 5.35s  Val. loss: 0.166  Val. score: 95.022%\n",
      "Epoch 4, 100% \t Train loss: 0.175 took: 5.24s  Val. loss: 0.141  Val. score: 95.722%\n",
      "Epoch 5, 100% \t Train loss: 0.146 took: 5.21s  Val. loss: 0.125  Val. score: 96.289%\n",
      "Epoch 6, 100% \t Train loss: 0.127 took: 5.13s  Val. loss: 0.112  Val. score: 96.617%\n",
      "Epoch 7, 100% \t Train loss: 0.114 took: 5.20s  Val. loss: 0.105  Val. score: 96.756%\n",
      "Epoch 8, 100% \t Train loss: 0.098 took: 5.00s  Val. loss: 0.098  Val. score: 97.111%\n",
      "Epoch 9, 100% \t Train loss: 0.089 took: 5.17s  Val. loss: 0.096  Val. score: 97.000%\n",
      "Epoch 10, 100% \t Train loss: 0.080 took: 5.00s  Val. loss: 0.086  Val. score: 97.383%\n",
      "Epoch 11, 100% \t Train loss: 0.072 took: 4.99s  Val. loss: 0.087  Val. score: 97.361%\n",
      "Epoch 12, 100% \t Train loss: 0.069 took: 5.10s  Val. loss: 0.086  Val. score: 97.411%\n",
      "Epoch 13, 100% \t Train loss: 0.062 took: 5.04s  Val. loss: 0.082  Val. score: 97.383%\n",
      "Epoch 14, 100% \t Train loss: 0.059 took: 5.29s  Val. loss: 0.077  Val. score: 97.683%\n",
      "Epoch 15, 100% \t Train loss: 0.053 took: 5.23s  Val. loss: 0.078  Val. score: 97.656%\n",
      "Training finished, took 128.904s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.555 took: 4.95s  Val. loss: 0.265  Val. score: 92.256%\n",
      "Epoch 2, 100% \t Train loss: 0.263 took: 5.13s  Val. loss: 0.192  Val. score: 94.306%\n",
      "Epoch 3, 100% \t Train loss: 0.200 took: 5.20s  Val. loss: 0.166  Val. score: 95.111%\n",
      "Epoch 4, 100% \t Train loss: 0.161 took: 4.85s  Val. loss: 0.136  Val. score: 95.989%\n",
      "Epoch 5, 100% \t Train loss: 0.137 took: 5.21s  Val. loss: 0.119  Val. score: 96.461%\n",
      "Epoch 6, 100% \t Train loss: 0.119 took: 5.27s  Val. loss: 0.109  Val. score: 96.800%\n",
      "Epoch 7, 100% \t Train loss: 0.105 took: 5.24s  Val. loss: 0.103  Val. score: 96.922%\n",
      "Epoch 8, 100% \t Train loss: 0.093 took: 4.91s  Val. loss: 0.097  Val. score: 97.122%\n",
      "Epoch 9, 100% \t Train loss: 0.084 took: 5.23s  Val. loss: 0.095  Val. score: 97.161%\n",
      "Epoch 10, 100% \t Train loss: 0.075 took: 5.02s  Val. loss: 0.093  Val. score: 97.194%\n",
      "Epoch 11, 100% \t Train loss: 0.068 took: 5.19s  Val. loss: 0.095  Val. score: 97.250%\n",
      "Epoch 12, 100% \t Train loss: 0.062 took: 5.24s  Val. loss: 0.091  Val. score: 97.378%\n",
      "Epoch 13, 100% \t Train loss: 0.055 took: 5.01s  Val. loss: 0.088  Val. score: 97.339%\n",
      "Epoch 14, 100% \t Train loss: 0.052 took: 5.25s  Val. loss: 0.088  Val. score: 97.433%\n",
      "Epoch 15, 100% \t Train loss: 0.047 took: 5.02s  Val. loss: 0.087  Val. score: 97.467%\n",
      "Training finished, took 129.182s\n",
      "\n",
      "Parameters configuration 44 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002660597080053773\n",
      "h_sizes \t [784, 192, 47]\n",
      "penalty \t 0.004747205872354946\n",
      "dropout \t 0.15959281837226263\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5444 +/- 0.0806\n",
      "Time for evaluation: 389.4 s\n",
      "Estimated time to finish : 8.03 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.314 took: 10.86s  Val. loss: 0.522  Val. score: 85.672%\n",
      "Epoch 2, 100% \t Train loss: 0.646 took: 10.61s  Val. loss: 0.328  Val. score: 91.061%\n",
      "Epoch 3, 100% \t Train loss: 0.466 took: 10.89s  Val. loss: 0.248  Val. score: 93.606%\n",
      "Epoch 4, 100% \t Train loss: 0.380 took: 10.92s  Val. loss: 0.223  Val. score: 94.306%\n",
      "Epoch 5, 100% \t Train loss: 0.324 took: 10.83s  Val. loss: 0.205  Val. score: 95.006%\n",
      "Epoch 6, 100% \t Train loss: 0.282 took: 10.92s  Val. loss: 0.181  Val. score: 95.422%\n",
      "Epoch 7, 100% \t Train loss: 0.259 took: 11.01s  Val. loss: 0.176  Val. score: 95.878%\n",
      "Epoch 8, 100% \t Train loss: 0.226 took: 12.21s  Val. loss: 0.180  Val. score: 96.022%\n",
      "Epoch 9, 100% \t Train loss: 0.205 took: 11.00s  Val. loss: 0.162  Val. score: 96.317%\n",
      "Epoch 10, 100% \t Train loss: 0.189 took: 11.54s  Val. loss: 0.164  Val. score: 96.489%\n",
      "Epoch 11, 100% \t Train loss: 0.177 took: 10.93s  Val. loss: 0.163  Val. score: 96.694%\n",
      "Epoch 12, 100% \t Train loss: 0.161 took: 11.40s  Val. loss: 0.155  Val. score: 96.794%\n",
      "Epoch 13, 100% \t Train loss: 0.153 took: 11.45s  Val. loss: 0.155  Val. score: 96.978%\n",
      "Epoch 14, 100% \t Train loss: 0.149 took: 11.20s  Val. loss: 0.150  Val. score: 97.056%\n",
      "Epoch 15, 100% \t Train loss: 0.135 took: 12.09s  Val. loss: 0.151  Val. score: 97.039%\n",
      "Training finished, took 251.256s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.512 took: 11.31s  Val. loss: 0.870  Val. score: 65.794%\n",
      "Epoch 2, 100% \t Train loss: 0.930 took: 10.66s  Val. loss: 0.606  Val. score: 77.594%\n",
      "Epoch 3, 100% \t Train loss: 0.720 took: 11.76s  Val. loss: 0.472  Val. score: 88.117%\n",
      "Epoch 4, 100% \t Train loss: 0.591 took: 11.82s  Val. loss: 0.388  Val. score: 92.250%\n",
      "Epoch 5, 100% \t Train loss: 0.499 took: 11.56s  Val. loss: 0.345  Val. score: 93.406%\n",
      "Epoch 6, 100% \t Train loss: 0.429 took: 11.68s  Val. loss: 0.303  Val. score: 94.256%\n",
      "Epoch 7, 100% \t Train loss: 0.377 took: 12.24s  Val. loss: 0.270  Val. score: 94.717%\n",
      "Epoch 8, 100% \t Train loss: 0.338 took: 12.11s  Val. loss: 0.250  Val. score: 95.128%\n",
      "Epoch 9, 100% \t Train loss: 0.298 took: 11.65s  Val. loss: 0.238  Val. score: 95.617%\n",
      "Epoch 10, 100% \t Train loss: 0.267 took: 11.99s  Val. loss: 0.228  Val. score: 96.011%\n",
      "Epoch 11, 100% \t Train loss: 0.242 took: 11.95s  Val. loss: 0.217  Val. score: 95.933%\n",
      "Epoch 12, 100% \t Train loss: 0.215 took: 11.62s  Val. loss: 0.220  Val. score: 96.233%\n",
      "Epoch 13, 100% \t Train loss: 0.195 took: 12.18s  Val. loss: 0.218  Val. score: 96.067%\n",
      "Epoch 14, 100% \t Train loss: 0.186 took: 11.40s  Val. loss: 0.206  Val. score: 96.667%\n",
      "Epoch 15, 100% \t Train loss: 0.176 took: 11.77s  Val. loss: 0.208  Val. score: 96.600%\n",
      "Training finished, took 260.770s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.537 took: 11.18s  Val. loss: 0.823  Val. score: 71.517%\n",
      "Epoch 2, 100% \t Train loss: 0.821 took: 11.28s  Val. loss: 0.448  Val. score: 90.122%\n",
      "Epoch 3, 100% \t Train loss: 0.532 took: 10.87s  Val. loss: 0.266  Val. score: 93.856%\n",
      "Epoch 4, 100% \t Train loss: 0.384 took: 11.54s  Val. loss: 0.219  Val. score: 94.722%\n",
      "Epoch 5, 100% \t Train loss: 0.316 took: 11.65s  Val. loss: 0.202  Val. score: 95.294%\n",
      "Epoch 6, 100% \t Train loss: 0.274 took: 11.94s  Val. loss: 0.188  Val. score: 95.872%\n",
      "Epoch 7, 100% \t Train loss: 0.241 took: 11.28s  Val. loss: 0.175  Val. score: 96.039%\n",
      "Epoch 8, 100% \t Train loss: 0.214 took: 11.31s  Val. loss: 0.175  Val. score: 96.328%\n",
      "Epoch 9, 100% \t Train loss: 0.195 took: 11.18s  Val. loss: 0.170  Val. score: 96.506%\n",
      "Epoch 10, 100% \t Train loss: 0.178 took: 11.55s  Val. loss: 0.175  Val. score: 96.556%\n",
      "Epoch 11, 100% \t Train loss: 0.165 took: 11.34s  Val. loss: 0.160  Val. score: 96.856%\n",
      "Epoch 12, 100% \t Train loss: 0.153 took: 11.39s  Val. loss: 0.157  Val. score: 97.039%\n",
      "Epoch 13, 100% \t Train loss: 0.137 took: 12.11s  Val. loss: 0.164  Val. score: 96.989%\n",
      "Epoch 14, 100% \t Train loss: 0.133 took: 12.50s  Val. loss: 0.157  Val. score: 97.122%\n",
      "Epoch 15, 100% \t Train loss: 0.127 took: 12.55s  Val. loss: 0.157  Val. score: 97.139%\n",
      "Training finished, took 257.660s\n",
      "\n",
      "Parameters configuration 45 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0024517471771814178\n",
      "h_sizes \t [784, 397, 202, 102, 56, 27, 17]\n",
      "penalty \t 0.00544791324143448\n",
      "dropout \t 0.23620994231744216\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 96.9259 +/- 0.2341\n",
      "Time for evaluation: 770.9 s\n",
      "Estimated time to finish : 7.97 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.304 took: 4.79s  Val. loss: 0.152  Val. score: 95.378%\n",
      "Epoch 2, 100% \t Train loss: 0.136 took: 4.86s  Val. loss: 0.118  Val. score: 96.411%\n",
      "Epoch 3, 100% \t Train loss: 0.098 took: 5.10s  Val. loss: 0.114  Val. score: 96.556%\n",
      "Epoch 4, 100% \t Train loss: 0.077 took: 5.41s  Val. loss: 0.102  Val. score: 96.928%\n",
      "Epoch 5, 100% \t Train loss: 0.061 took: 5.34s  Val. loss: 0.105  Val. score: 97.028%\n",
      "Epoch 6, 100% \t Train loss: 0.050 took: 5.36s  Val. loss: 0.098  Val. score: 97.344%\n",
      "Epoch 7, 100% \t Train loss: 0.037 took: 5.33s  Val. loss: 0.102  Val. score: 97.306%\n",
      "Epoch 8, 100% \t Train loss: 0.034 took: 5.30s  Val. loss: 0.098  Val. score: 97.428%\n",
      "Epoch 9, 100% \t Train loss: 0.025 took: 5.24s  Val. loss: 0.122  Val. score: 97.061%\n",
      "Epoch 10, 100% \t Train loss: 0.022 took: 5.36s  Val. loss: 0.112  Val. score: 97.411%\n",
      "Epoch 11, 100% \t Train loss: 0.023 took: 5.29s  Val. loss: 0.114  Val. score: 97.578%\n",
      "Epoch 12, 100% \t Train loss: 0.016 took: 5.25s  Val. loss: 0.118  Val. score: 97.467%\n",
      "Epoch 13, 100% \t Train loss: 0.016 took: 5.33s  Val. loss: 0.118  Val. score: 97.422%\n",
      "Epoch 14, 100% \t Train loss: 0.013 took: 5.38s  Val. loss: 0.125  Val. score: 97.428%\n",
      "Epoch 15, 100% \t Train loss: 0.013 took: 5.20s  Val. loss: 0.124  Val. score: 97.628%\n",
      "Training finished, took 131.237s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.311 took: 4.76s  Val. loss: 0.164  Val. score: 95.083%\n",
      "Epoch 2, 100% \t Train loss: 0.133 took: 4.93s  Val. loss: 0.115  Val. score: 96.539%\n",
      "Epoch 3, 100% \t Train loss: 0.096 took: 5.24s  Val. loss: 0.118  Val. score: 96.583%\n",
      "Epoch 4, 100% \t Train loss: 0.075 took: 5.57s  Val. loss: 0.100  Val. score: 97.039%\n",
      "Epoch 5, 100% \t Train loss: 0.057 took: 5.45s  Val. loss: 0.107  Val. score: 97.017%\n",
      "Epoch 6, 100% \t Train loss: 0.046 took: 5.22s  Val. loss: 0.100  Val. score: 97.278%\n",
      "Epoch 7, 100% \t Train loss: 0.037 took: 5.67s  Val. loss: 0.116  Val. score: 96.939%\n",
      "Epoch 8, 100% \t Train loss: 0.034 took: 5.54s  Val. loss: 0.109  Val. score: 97.139%\n",
      "Epoch 9, 100% \t Train loss: 0.026 took: 5.49s  Val. loss: 0.102  Val. score: 97.472%\n",
      "Epoch 10, 100% \t Train loss: 0.023 took: 5.55s  Val. loss: 0.106  Val. score: 97.506%\n",
      "Epoch 11, 100% \t Train loss: 0.018 took: 5.58s  Val. loss: 0.113  Val. score: 97.467%\n",
      "Epoch 12, 100% \t Train loss: 0.019 took: 5.45s  Val. loss: 0.107  Val. score: 97.611%\n",
      "Epoch 13, 100% \t Train loss: 0.016 took: 5.19s  Val. loss: 0.112  Val. score: 97.572%\n",
      "Epoch 14, 100% \t Train loss: 0.015 took: 5.28s  Val. loss: 0.112  Val. score: 97.539%\n",
      "Epoch 15, 100% \t Train loss: 0.014 took: 5.42s  Val. loss: 0.111  Val. score: 97.728%\n",
      "Training finished, took 132.852s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.320 took: 4.95s  Val. loss: 0.169  Val. score: 94.833%\n",
      "Epoch 2, 100% \t Train loss: 0.141 took: 4.70s  Val. loss: 0.122  Val. score: 96.244%\n",
      "Epoch 3, 100% \t Train loss: 0.097 took: 5.11s  Val. loss: 0.108  Val. score: 96.756%\n",
      "Epoch 4, 100% \t Train loss: 0.073 took: 5.31s  Val. loss: 0.105  Val. score: 96.811%\n",
      "Epoch 5, 100% \t Train loss: 0.058 took: 5.42s  Val. loss: 0.102  Val. score: 97.100%\n",
      "Epoch 6, 100% \t Train loss: 0.046 took: 5.09s  Val. loss: 0.095  Val. score: 97.433%\n",
      "Epoch 7, 100% \t Train loss: 0.040 took: 5.41s  Val. loss: 0.101  Val. score: 97.256%\n",
      "Epoch 8, 100% \t Train loss: 0.032 took: 4.83s  Val. loss: 0.112  Val. score: 97.106%\n",
      "Epoch 9, 100% \t Train loss: 0.030 took: 5.15s  Val. loss: 0.107  Val. score: 97.311%\n",
      "Epoch 10, 100% \t Train loss: 0.025 took: 5.04s  Val. loss: 0.115  Val. score: 97.222%\n",
      "Epoch 11, 100% \t Train loss: 0.018 took: 5.18s  Val. loss: 0.105  Val. score: 97.489%\n",
      "Epoch 12, 100% \t Train loss: 0.019 took: 5.13s  Val. loss: 0.113  Val. score: 97.606%\n",
      "Epoch 13, 100% \t Train loss: 0.016 took: 5.00s  Val. loss: 0.120  Val. score: 97.450%\n",
      "Epoch 14, 100% \t Train loss: 0.017 took: 5.23s  Val. loss: 0.115  Val. score: 97.389%\n",
      "Epoch 15, 100% \t Train loss: 0.014 took: 5.18s  Val. loss: 0.120  Val. score: 97.517%\n",
      "Training finished, took 128.655s\n",
      "\n",
      "Parameters configuration 46 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.014295655103625078\n",
      "h_sizes \t [784, 180, 48]\n",
      "penalty \t 0.00013551795006647217\n",
      "dropout \t 0.043794555689653764\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6241 +/- 0.0862\n",
      "Time for evaluation: 393.9 s\n",
      "Estimated time to finish : 7.78 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.547 took: 5.81s  Val. loss: 0.264  Val. score: 92.200%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, 100% \t Train loss: 0.234 took: 5.95s  Val. loss: 0.187  Val. score: 94.722%\n",
      "Epoch 3, 100% \t Train loss: 0.167 took: 5.89s  Val. loss: 0.147  Val. score: 95.572%\n",
      "Epoch 4, 100% \t Train loss: 0.127 took: 5.96s  Val. loss: 0.123  Val. score: 96.278%\n",
      "Epoch 5, 100% \t Train loss: 0.102 took: 5.95s  Val. loss: 0.118  Val. score: 96.328%\n",
      "Epoch 6, 100% \t Train loss: 0.083 took: 5.90s  Val. loss: 0.108  Val. score: 96.678%\n",
      "Epoch 7, 100% \t Train loss: 0.067 took: 5.86s  Val. loss: 0.104  Val. score: 96.794%\n",
      "Epoch 8, 100% \t Train loss: 0.058 took: 6.13s  Val. loss: 0.095  Val. score: 97.056%\n",
      "Epoch 9, 100% \t Train loss: 0.046 took: 6.18s  Val. loss: 0.097  Val. score: 97.100%\n",
      "Epoch 10, 100% \t Train loss: 0.038 took: 5.89s  Val. loss: 0.094  Val. score: 97.233%\n",
      "Epoch 11, 100% \t Train loss: 0.032 took: 6.19s  Val. loss: 0.099  Val. score: 97.150%\n",
      "Epoch 12, 100% \t Train loss: 0.026 took: 5.90s  Val. loss: 0.101  Val. score: 97.106%\n",
      "Epoch 13, 100% \t Train loss: 0.022 took: 6.07s  Val. loss: 0.094  Val. score: 97.311%\n",
      "Epoch 14, 100% \t Train loss: 0.018 took: 6.18s  Val. loss: 0.105  Val. score: 97.183%\n",
      "Epoch 15, 100% \t Train loss: 0.017 took: 5.83s  Val. loss: 0.103  Val. score: 97.228%\n",
      "Training finished, took 148.267s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.551 took: 6.26s  Val. loss: 0.268  Val. score: 92.239%\n",
      "Epoch 2, 100% \t Train loss: 0.230 took: 6.03s  Val. loss: 0.183  Val. score: 94.711%\n",
      "Epoch 3, 100% \t Train loss: 0.163 took: 5.73s  Val. loss: 0.152  Val. score: 95.556%\n",
      "Epoch 4, 100% \t Train loss: 0.121 took: 5.71s  Val. loss: 0.126  Val. score: 96.339%\n",
      "Epoch 5, 100% \t Train loss: 0.094 took: 6.30s  Val. loss: 0.115  Val. score: 96.656%\n",
      "Epoch 6, 100% \t Train loss: 0.077 took: 6.01s  Val. loss: 0.106  Val. score: 96.883%\n",
      "Epoch 7, 100% \t Train loss: 0.064 took: 6.13s  Val. loss: 0.102  Val. score: 97.056%\n",
      "Epoch 8, 100% \t Train loss: 0.053 took: 6.07s  Val. loss: 0.110  Val. score: 97.044%\n",
      "Epoch 9, 100% \t Train loss: 0.045 took: 5.63s  Val. loss: 0.098  Val. score: 97.317%\n",
      "Epoch 10, 100% \t Train loss: 0.038 took: 5.67s  Val. loss: 0.101  Val. score: 97.239%\n",
      "Epoch 11, 100% \t Train loss: 0.031 took: 5.62s  Val. loss: 0.098  Val. score: 97.361%\n",
      "Epoch 12, 100% \t Train loss: 0.026 took: 6.02s  Val. loss: 0.099  Val. score: 97.383%\n",
      "Epoch 13, 100% \t Train loss: 0.021 took: 5.57s  Val. loss: 0.103  Val. score: 97.389%\n",
      "Epoch 14, 100% \t Train loss: 0.018 took: 6.25s  Val. loss: 0.102  Val. score: 97.506%\n",
      "Epoch 15, 100% \t Train loss: 0.016 took: 5.77s  Val. loss: 0.099  Val. score: 97.456%\n",
      "Training finished, took 145.845s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.543 took: 6.05s  Val. loss: 0.274  Val. score: 92.311%\n",
      "Epoch 2, 100% \t Train loss: 0.232 took: 5.52s  Val. loss: 0.192  Val. score: 94.444%\n",
      "Epoch 3, 100% \t Train loss: 0.164 took: 5.82s  Val. loss: 0.167  Val. score: 95.172%\n",
      "Epoch 4, 100% \t Train loss: 0.126 took: 6.01s  Val. loss: 0.135  Val. score: 95.900%\n",
      "Epoch 5, 100% \t Train loss: 0.099 took: 5.54s  Val. loss: 0.119  Val. score: 96.456%\n",
      "Epoch 6, 100% \t Train loss: 0.080 took: 5.97s  Val. loss: 0.111  Val. score: 96.639%\n",
      "Epoch 7, 100% \t Train loss: 0.068 took: 5.83s  Val. loss: 0.104  Val. score: 96.950%\n",
      "Epoch 8, 100% \t Train loss: 0.054 took: 5.90s  Val. loss: 0.103  Val. score: 96.994%\n",
      "Epoch 9, 100% \t Train loss: 0.044 took: 5.54s  Val. loss: 0.097  Val. score: 97.117%\n",
      "Epoch 10, 100% \t Train loss: 0.035 took: 6.12s  Val. loss: 0.098  Val. score: 97.222%\n",
      "Epoch 11, 100% \t Train loss: 0.030 took: 5.94s  Val. loss: 0.114  Val. score: 96.917%\n",
      "Epoch 12, 100% \t Train loss: 0.025 took: 5.90s  Val. loss: 0.102  Val. score: 97.206%\n",
      "Epoch 13, 100% \t Train loss: 0.021 took: 5.89s  Val. loss: 0.098  Val. score: 97.489%\n",
      "Epoch 14, 100% \t Train loss: 0.018 took: 6.13s  Val. loss: 0.104  Val. score: 97.350%\n",
      "Epoch 15, 100% \t Train loss: 0.015 took: 5.90s  Val. loss: 0.100  Val. score: 97.439%\n",
      "Training finished, took 145.011s\n",
      "\n",
      "Parameters configuration 47 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0027249818406783993\n",
      "h_sizes \t [784, 247, 83, 33]\n",
      "penalty \t 0.0009100398473014092\n",
      "dropout \t 0.018516942383390744\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.3741 +/- 0.1037\n",
      "Time for evaluation: 440.3 s\n",
      "Estimated time to finish : 7.61 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.567 took: 4.67s  Val. loss: 0.266  Val. score: 92.406%\n",
      "Epoch 2, 100% \t Train loss: 0.266 took: 4.38s  Val. loss: 0.193  Val. score: 94.411%\n",
      "Epoch 3, 100% \t Train loss: 0.204 took: 4.56s  Val. loss: 0.154  Val. score: 95.428%\n",
      "Epoch 4, 100% \t Train loss: 0.164 took: 4.57s  Val. loss: 0.138  Val. score: 95.889%\n",
      "Epoch 5, 100% \t Train loss: 0.140 took: 4.82s  Val. loss: 0.120  Val. score: 96.433%\n",
      "Epoch 6, 100% \t Train loss: 0.120 took: 4.98s  Val. loss: 0.111  Val. score: 96.650%\n",
      "Epoch 7, 100% \t Train loss: 0.106 took: 4.89s  Val. loss: 0.100  Val. score: 97.061%\n",
      "Epoch 8, 100% \t Train loss: 0.094 took: 4.93s  Val. loss: 0.096  Val. score: 97.194%\n",
      "Epoch 9, 100% \t Train loss: 0.081 took: 4.90s  Val. loss: 0.093  Val. score: 97.239%\n",
      "Epoch 10, 100% \t Train loss: 0.076 took: 4.98s  Val. loss: 0.089  Val. score: 97.417%\n",
      "Epoch 11, 100% \t Train loss: 0.069 took: 4.97s  Val. loss: 0.084  Val. score: 97.428%\n",
      "Epoch 12, 100% \t Train loss: 0.060 took: 4.61s  Val. loss: 0.086  Val. score: 97.400%\n",
      "Epoch 13, 100% \t Train loss: 0.055 took: 4.63s  Val. loss: 0.082  Val. score: 97.639%\n",
      "Epoch 14, 100% \t Train loss: 0.051 took: 4.85s  Val. loss: 0.085  Val. score: 97.522%\n",
      "Epoch 15, 100% \t Train loss: 0.046 took: 4.59s  Val. loss: 0.086  Val. score: 97.411%\n",
      "Training finished, took 121.438s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.517 took: 4.67s  Val. loss: 0.257  Val. score: 92.317%\n",
      "Epoch 2, 100% \t Train loss: 0.246 took: 4.47s  Val. loss: 0.190  Val. score: 94.261%\n",
      "Epoch 3, 100% \t Train loss: 0.186 took: 4.37s  Val. loss: 0.152  Val. score: 95.433%\n",
      "Epoch 4, 100% \t Train loss: 0.149 took: 4.80s  Val. loss: 0.133  Val. score: 95.844%\n",
      "Epoch 5, 100% \t Train loss: 0.126 took: 4.81s  Val. loss: 0.116  Val. score: 96.400%\n",
      "Epoch 6, 100% \t Train loss: 0.106 took: 4.49s  Val. loss: 0.112  Val. score: 96.533%\n",
      "Epoch 7, 100% \t Train loss: 0.092 took: 4.66s  Val. loss: 0.111  Val. score: 96.528%\n",
      "Epoch 8, 100% \t Train loss: 0.083 took: 4.60s  Val. loss: 0.096  Val. score: 97.044%\n",
      "Epoch 9, 100% \t Train loss: 0.071 took: 4.46s  Val. loss: 0.096  Val. score: 97.067%\n",
      "Epoch 10, 100% \t Train loss: 0.065 took: 4.54s  Val. loss: 0.092  Val. score: 97.267%\n",
      "Epoch 11, 100% \t Train loss: 0.059 took: 4.52s  Val. loss: 0.091  Val. score: 97.389%\n",
      "Epoch 12, 100% \t Train loss: 0.053 took: 4.85s  Val. loss: 0.094  Val. score: 97.267%\n",
      "Epoch 13, 100% \t Train loss: 0.047 took: 4.94s  Val. loss: 0.089  Val. score: 97.428%\n",
      "Epoch 14, 100% \t Train loss: 0.043 took: 4.91s  Val. loss: 0.090  Val. score: 97.306%\n",
      "Epoch 15, 100% \t Train loss: 0.042 took: 4.87s  Val. loss: 0.089  Val. score: 97.450%\n",
      "Training finished, took 120.221s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.542 took: 4.28s  Val. loss: 0.263  Val. score: 92.456%\n",
      "Epoch 2, 100% \t Train loss: 0.262 took: 4.68s  Val. loss: 0.186  Val. score: 94.333%\n",
      "Epoch 3, 100% \t Train loss: 0.200 took: 4.83s  Val. loss: 0.155  Val. score: 95.411%\n",
      "Epoch 4, 100% \t Train loss: 0.159 took: 4.92s  Val. loss: 0.135  Val. score: 95.833%\n",
      "Epoch 5, 100% \t Train loss: 0.138 took: 4.86s  Val. loss: 0.124  Val. score: 96.178%\n",
      "Epoch 6, 100% \t Train loss: 0.116 took: 4.87s  Val. loss: 0.110  Val. score: 96.550%\n",
      "Epoch 7, 100% \t Train loss: 0.103 took: 4.80s  Val. loss: 0.109  Val. score: 96.678%\n",
      "Epoch 8, 100% \t Train loss: 0.093 took: 4.92s  Val. loss: 0.097  Val. score: 97.078%\n",
      "Epoch 9, 100% \t Train loss: 0.082 took: 4.85s  Val. loss: 0.094  Val. score: 97.117%\n",
      "Epoch 10, 100% \t Train loss: 0.074 took: 4.52s  Val. loss: 0.090  Val. score: 97.261%\n",
      "Epoch 11, 100% \t Train loss: 0.064 took: 4.91s  Val. loss: 0.087  Val. score: 97.344%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, 100% \t Train loss: 0.061 took: 4.71s  Val. loss: 0.086  Val. score: 97.467%\n",
      "Epoch 13, 100% \t Train loss: 0.055 took: 4.79s  Val. loss: 0.084  Val. score: 97.506%\n",
      "Epoch 14, 100% \t Train loss: 0.049 took: 4.59s  Val. loss: 0.085  Val. score: 97.444%\n",
      "Epoch 15, 100% \t Train loss: 0.045 took: 4.86s  Val. loss: 0.087  Val. score: 97.578%\n",
      "Training finished, took 121.677s\n",
      "\n",
      "Parameters configuration 48 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0033666475018500957\n",
      "h_sizes \t [784, 178, 38]\n",
      "penalty \t 0.0036601726093381938\n",
      "dropout \t 0.13107226000135663\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4796 +/- 0.0712\n",
      "Time for evaluation: 364.5 s\n",
      "Estimated time to finish : 7.42 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.873 took: 9.81s  Val. loss: 0.299  Val. score: 91.911%\n",
      "Epoch 2, 100% \t Train loss: 0.354 took: 9.35s  Val. loss: 0.202  Val. score: 94.550%\n",
      "Epoch 3, 100% \t Train loss: 0.245 took: 10.15s  Val. loss: 0.169  Val. score: 95.583%\n",
      "Epoch 4, 100% \t Train loss: 0.201 took: 10.41s  Val. loss: 0.159  Val. score: 96.056%\n",
      "Epoch 5, 100% \t Train loss: 0.163 took: 10.84s  Val. loss: 0.136  Val. score: 96.600%\n",
      "Epoch 6, 100% \t Train loss: 0.141 took: 10.14s  Val. loss: 0.134  Val. score: 96.683%\n",
      "Epoch 7, 100% \t Train loss: 0.123 took: 10.08s  Val. loss: 0.139  Val. score: 96.839%\n",
      "Epoch 8, 100% \t Train loss: 0.111 took: 10.57s  Val. loss: 0.123  Val. score: 97.044%\n",
      "Epoch 9, 100% \t Train loss: 0.093 took: 10.01s  Val. loss: 0.121  Val. score: 97.189%\n",
      "Epoch 10, 100% \t Train loss: 0.086 took: 10.67s  Val. loss: 0.131  Val. score: 97.028%\n",
      "Epoch 11, 100% \t Train loss: 0.078 took: 9.99s  Val. loss: 0.126  Val. score: 97.233%\n",
      "Epoch 12, 100% \t Train loss: 0.073 took: 10.01s  Val. loss: 0.126  Val. score: 97.239%\n",
      "Epoch 13, 100% \t Train loss: 0.062 took: 10.69s  Val. loss: 0.132  Val. score: 97.283%\n",
      "Epoch 14, 100% \t Train loss: 0.060 took: 10.09s  Val. loss: 0.135  Val. score: 97.356%\n",
      "Epoch 15, 100% \t Train loss: 0.058 took: 10.80s  Val. loss: 0.136  Val. score: 97.272%\n",
      "Training finished, took 230.063s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.897 took: 9.96s  Val. loss: 0.291  Val. score: 92.189%\n",
      "Epoch 2, 100% \t Train loss: 0.331 took: 9.59s  Val. loss: 0.210  Val. score: 94.222%\n",
      "Epoch 3, 100% \t Train loss: 0.234 took: 9.75s  Val. loss: 0.158  Val. score: 95.817%\n",
      "Epoch 4, 100% \t Train loss: 0.191 took: 9.96s  Val. loss: 0.151  Val. score: 96.094%\n",
      "Epoch 5, 100% \t Train loss: 0.157 took: 10.53s  Val. loss: 0.136  Val. score: 96.467%\n",
      "Epoch 6, 100% \t Train loss: 0.139 took: 10.85s  Val. loss: 0.132  Val. score: 96.711%\n",
      "Epoch 7, 100% \t Train loss: 0.119 took: 10.57s  Val. loss: 0.127  Val. score: 96.994%\n",
      "Epoch 8, 100% \t Train loss: 0.104 took: 10.11s  Val. loss: 0.121  Val. score: 97.033%\n",
      "Epoch 9, 100% \t Train loss: 0.091 took: 10.24s  Val. loss: 0.121  Val. score: 97.189%\n",
      "Epoch 10, 100% \t Train loss: 0.081 took: 10.68s  Val. loss: 0.126  Val. score: 97.328%\n",
      "Epoch 11, 100% \t Train loss: 0.075 took: 10.53s  Val. loss: 0.120  Val. score: 97.306%\n",
      "Epoch 12, 100% \t Train loss: 0.068 took: 10.94s  Val. loss: 0.122  Val. score: 97.444%\n",
      "Epoch 13, 100% \t Train loss: 0.061 took: 10.17s  Val. loss: 0.120  Val. score: 97.422%\n",
      "Epoch 14, 100% \t Train loss: 0.054 took: 10.80s  Val. loss: 0.125  Val. score: 97.494%\n",
      "Epoch 15, 100% \t Train loss: 0.051 took: 10.33s  Val. loss: 0.120  Val. score: 97.483%\n",
      "Training finished, took 232.306s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.905 took: 10.04s  Val. loss: 0.304  Val. score: 91.611%\n",
      "Epoch 2, 100% \t Train loss: 0.341 took: 9.99s  Val. loss: 0.202  Val. score: 94.500%\n",
      "Epoch 3, 100% \t Train loss: 0.241 took: 10.08s  Val. loss: 0.171  Val. score: 95.522%\n",
      "Epoch 4, 100% \t Train loss: 0.191 took: 10.13s  Val. loss: 0.162  Val. score: 95.917%\n",
      "Epoch 5, 100% \t Train loss: 0.160 took: 10.31s  Val. loss: 0.146  Val. score: 96.267%\n",
      "Epoch 6, 100% \t Train loss: 0.133 took: 10.55s  Val. loss: 0.133  Val. score: 96.661%\n",
      "Epoch 7, 100% \t Train loss: 0.116 took: 11.12s  Val. loss: 0.127  Val. score: 97.022%\n",
      "Epoch 8, 100% \t Train loss: 0.104 took: 10.45s  Val. loss: 0.133  Val. score: 96.989%\n",
      "Epoch 9, 100% \t Train loss: 0.095 took: 10.66s  Val. loss: 0.132  Val. score: 97.044%\n",
      "Epoch 10, 100% \t Train loss: 0.080 took: 10.74s  Val. loss: 0.129  Val. score: 97.128%\n",
      "Epoch 11, 100% \t Train loss: 0.072 took: 10.73s  Val. loss: 0.130  Val. score: 97.289%\n",
      "Epoch 12, 100% \t Train loss: 0.065 took: 10.72s  Val. loss: 0.137  Val. score: 97.256%\n",
      "Epoch 13, 100% \t Train loss: 0.058 took: 10.37s  Val. loss: 0.136  Val. score: 97.344%\n",
      "Epoch 14, 100% \t Train loss: 0.054 took: 10.91s  Val. loss: 0.134  Val. score: 97.544%\n",
      "Epoch 15, 100% \t Train loss: 0.051 took: 10.62s  Val. loss: 0.146  Val. score: 97.367%\n",
      "Training finished, took 235.014s\n",
      "\n",
      "Parameters configuration 49 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0037035324424856365\n",
      "h_sizes \t [784, 375, 180, 90, 44, 19]\n",
      "penalty \t 0.002081408396368334\n",
      "dropout \t 0.1805906109347829\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.3741 +/- 0.0863\n",
      "Time for evaluation: 698.6 s\n",
      "Estimated time to finish : 7.34 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.335 took: 4.78s  Val. loss: 0.163  Val. score: 94.961%\n",
      "Epoch 2, 100% \t Train loss: 0.162 took: 4.66s  Val. loss: 0.120  Val. score: 96.300%\n",
      "Epoch 3, 100% \t Train loss: 0.120 took: 5.31s  Val. loss: 0.101  Val. score: 96.950%\n",
      "Epoch 4, 100% \t Train loss: 0.100 took: 5.50s  Val. loss: 0.093  Val. score: 97.244%\n",
      "Epoch 5, 100% \t Train loss: 0.083 took: 5.12s  Val. loss: 0.086  Val. score: 97.444%\n",
      "Epoch 6, 100% \t Train loss: 0.072 took: 5.13s  Val. loss: 0.085  Val. score: 97.567%\n",
      "Epoch 7, 100% \t Train loss: 0.063 took: 5.50s  Val. loss: 0.093  Val. score: 97.478%\n",
      "Epoch 8, 100% \t Train loss: 0.059 took: 5.60s  Val. loss: 0.086  Val. score: 97.572%\n",
      "Epoch 9, 100% \t Train loss: 0.050 took: 5.51s  Val. loss: 0.099  Val. score: 97.383%\n",
      "Epoch 10, 100% \t Train loss: 0.049 took: 5.37s  Val. loss: 0.100  Val. score: 97.306%\n",
      "Epoch 11, 100% \t Train loss: 0.044 took: 5.67s  Val. loss: 0.085  Val. score: 97.883%\n",
      "Epoch 12, 100% \t Train loss: 0.041 took: 5.68s  Val. loss: 0.088  Val. score: 97.850%\n",
      "Epoch 13, 100% \t Train loss: 0.039 took: 5.42s  Val. loss: 0.085  Val. score: 97.794%\n",
      "Epoch 14, 100% \t Train loss: 0.038 took: 5.64s  Val. loss: 0.099  Val. score: 97.750%\n",
      "Epoch 15, 100% \t Train loss: 0.033 took: 5.50s  Val. loss: 0.096  Val. score: 97.589%\n",
      "Training finished, took 132.830s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.332 took: 5.09s  Val. loss: 0.161  Val. score: 95.117%\n",
      "Epoch 2, 100% \t Train loss: 0.159 took: 5.13s  Val. loss: 0.123  Val. score: 96.244%\n",
      "Epoch 3, 100% \t Train loss: 0.121 took: 5.28s  Val. loss: 0.110  Val. score: 96.806%\n",
      "Epoch 4, 100% \t Train loss: 0.099 took: 5.49s  Val. loss: 0.101  Val. score: 97.022%\n",
      "Epoch 5, 100% \t Train loss: 0.082 took: 5.28s  Val. loss: 0.099  Val. score: 97.161%\n",
      "Epoch 6, 100% \t Train loss: 0.068 took: 5.63s  Val. loss: 0.099  Val. score: 97.294%\n",
      "Epoch 7, 100% \t Train loss: 0.062 took: 5.48s  Val. loss: 0.098  Val. score: 97.239%\n",
      "Epoch 8, 100% \t Train loss: 0.055 took: 6.24s  Val. loss: 0.099  Val. score: 97.361%\n",
      "Epoch 9, 100% \t Train loss: 0.051 took: 5.73s  Val. loss: 0.095  Val. score: 97.522%\n",
      "Epoch 10, 100% \t Train loss: 0.045 took: 5.60s  Val. loss: 0.108  Val. score: 97.189%\n",
      "Epoch 11, 100% \t Train loss: 0.043 took: 5.43s  Val. loss: 0.095  Val. score: 97.550%\n",
      "Epoch 12, 100% \t Train loss: 0.039 took: 5.41s  Val. loss: 0.100  Val. score: 97.544%\n",
      "Epoch 13, 100% \t Train loss: 0.035 took: 5.67s  Val. loss: 0.101  Val. score: 97.494%\n",
      "Epoch 14, 100% \t Train loss: 0.032 took: 5.41s  Val. loss: 0.100  Val. score: 97.594%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, 100% \t Train loss: 0.031 took: 5.58s  Val. loss: 0.104  Val. score: 97.606%\n",
      "Training finished, took 135.730s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.338 took: 5.20s  Val. loss: 0.169  Val. score: 95.167%\n",
      "Epoch 2, 100% \t Train loss: 0.163 took: 5.22s  Val. loss: 0.151  Val. score: 95.383%\n",
      "Epoch 3, 100% \t Train loss: 0.126 took: 5.20s  Val. loss: 0.123  Val. score: 96.383%\n",
      "Epoch 4, 100% \t Train loss: 0.103 took: 5.62s  Val. loss: 0.112  Val. score: 96.889%\n",
      "Epoch 5, 100% \t Train loss: 0.087 took: 5.61s  Val. loss: 0.111  Val. score: 97.022%\n",
      "Epoch 6, 100% \t Train loss: 0.072 took: 5.69s  Val. loss: 0.102  Val. score: 97.083%\n",
      "Epoch 7, 100% \t Train loss: 0.068 took: 5.59s  Val. loss: 0.101  Val. score: 97.272%\n",
      "Epoch 8, 100% \t Train loss: 0.058 took: 5.62s  Val. loss: 0.104  Val. score: 97.411%\n",
      "Epoch 9, 100% \t Train loss: 0.053 took: 5.48s  Val. loss: 0.110  Val. score: 97.261%\n",
      "Epoch 10, 100% \t Train loss: 0.051 took: 5.37s  Val. loss: 0.106  Val. score: 97.467%\n",
      "Epoch 11, 100% \t Train loss: 0.043 took: 5.36s  Val. loss: 0.107  Val. score: 97.539%\n",
      "Epoch 12, 100% \t Train loss: 0.042 took: 5.61s  Val. loss: 0.107  Val. score: 97.478%\n",
      "Epoch 13, 100% \t Train loss: 0.040 took: 5.48s  Val. loss: 0.111  Val. score: 97.517%\n",
      "Epoch 14, 100% \t Train loss: 0.039 took: 5.30s  Val. loss: 0.117  Val. score: 97.378%\n",
      "Epoch 15, 100% \t Train loss: 0.036 took: 5.20s  Val. loss: 0.115  Val. score: 97.400%\n",
      "Training finished, took 134.579s\n",
      "\n",
      "Parameters configuration 50 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.017631282700654845\n",
      "h_sizes \t [784, 195, 57]\n",
      "penalty \t 0.0002796662436471825\n",
      "dropout \t 0.15863500133922606\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5315 +/- 0.0932\n",
      "Time for evaluation: 404.3 s\n",
      "Estimated time to finish : 7.16 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.652 took: 6.21s  Val. loss: 0.254  Val. score: 92.422%\n",
      "Epoch 2, 100% \t Train loss: 0.293 took: 5.84s  Val. loss: 0.173  Val. score: 94.694%\n",
      "Epoch 3, 100% \t Train loss: 0.218 took: 6.65s  Val. loss: 0.144  Val. score: 95.756%\n",
      "Epoch 4, 100% \t Train loss: 0.179 took: 6.59s  Val. loss: 0.133  Val. score: 96.033%\n",
      "Epoch 5, 100% \t Train loss: 0.149 took: 7.05s  Val. loss: 0.121  Val. score: 96.483%\n",
      "Epoch 6, 100% \t Train loss: 0.128 took: 6.72s  Val. loss: 0.118  Val. score: 96.572%\n",
      "Epoch 7, 100% \t Train loss: 0.115 took: 6.92s  Val. loss: 0.106  Val. score: 97.039%\n",
      "Epoch 8, 100% \t Train loss: 0.103 took: 6.68s  Val. loss: 0.105  Val. score: 97.144%\n",
      "Epoch 9, 100% \t Train loss: 0.093 took: 6.81s  Val. loss: 0.111  Val. score: 97.089%\n",
      "Epoch 10, 100% \t Train loss: 0.081 took: 6.52s  Val. loss: 0.107  Val. score: 97.011%\n",
      "Epoch 11, 100% \t Train loss: 0.079 took: 6.84s  Val. loss: 0.106  Val. score: 97.122%\n",
      "Epoch 12, 100% \t Train loss: 0.070 took: 6.68s  Val. loss: 0.105  Val. score: 97.289%\n",
      "Epoch 13, 100% \t Train loss: 0.065 took: 6.73s  Val. loss: 0.104  Val. score: 97.411%\n",
      "Epoch 14, 100% \t Train loss: 0.061 took: 6.78s  Val. loss: 0.104  Val. score: 97.350%\n",
      "Epoch 15, 100% \t Train loss: 0.056 took: 6.55s  Val. loss: 0.100  Val. score: 97.539%\n",
      "Training finished, took 159.229s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.700 took: 6.28s  Val. loss: 0.269  Val. score: 92.350%\n",
      "Epoch 2, 100% \t Train loss: 0.303 took: 6.32s  Val. loss: 0.181  Val. score: 94.883%\n",
      "Epoch 3, 100% \t Train loss: 0.226 took: 6.35s  Val. loss: 0.153  Val. score: 95.489%\n",
      "Epoch 4, 100% \t Train loss: 0.181 took: 6.69s  Val. loss: 0.129  Val. score: 96.333%\n",
      "Epoch 5, 100% \t Train loss: 0.152 took: 6.61s  Val. loss: 0.123  Val. score: 96.633%\n",
      "Epoch 6, 100% \t Train loss: 0.133 took: 7.08s  Val. loss: 0.110  Val. score: 96.894%\n",
      "Epoch 7, 100% \t Train loss: 0.117 took: 6.87s  Val. loss: 0.107  Val. score: 97.106%\n",
      "Epoch 8, 100% \t Train loss: 0.100 took: 6.62s  Val. loss: 0.108  Val. score: 96.994%\n",
      "Epoch 9, 100% \t Train loss: 0.092 took: 6.77s  Val. loss: 0.105  Val. score: 97.183%\n",
      "Epoch 10, 100% \t Train loss: 0.082 took: 6.88s  Val. loss: 0.104  Val. score: 97.311%\n",
      "Epoch 11, 100% \t Train loss: 0.077 took: 6.55s  Val. loss: 0.099  Val. score: 97.322%\n",
      "Epoch 12, 100% \t Train loss: 0.073 took: 6.63s  Val. loss: 0.104  Val. score: 97.233%\n",
      "Epoch 13, 100% \t Train loss: 0.065 took: 6.62s  Val. loss: 0.101  Val. score: 97.422%\n",
      "Epoch 14, 100% \t Train loss: 0.057 took: 6.73s  Val. loss: 0.095  Val. score: 97.650%\n",
      "Epoch 15, 100% \t Train loss: 0.057 took: 6.80s  Val. loss: 0.101  Val. score: 97.439%\n",
      "Training finished, took 160.064s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.669 took: 6.41s  Val. loss: 0.256  Val. score: 92.544%\n",
      "Epoch 2, 100% \t Train loss: 0.286 took: 6.37s  Val. loss: 0.179  Val. score: 94.728%\n",
      "Epoch 3, 100% \t Train loss: 0.215 took: 6.21s  Val. loss: 0.152  Val. score: 95.517%\n",
      "Epoch 4, 100% \t Train loss: 0.174 took: 6.48s  Val. loss: 0.125  Val. score: 96.322%\n",
      "Epoch 5, 100% \t Train loss: 0.145 took: 6.86s  Val. loss: 0.112  Val. score: 96.750%\n",
      "Epoch 6, 100% \t Train loss: 0.128 took: 6.53s  Val. loss: 0.113  Val. score: 96.778%\n",
      "Epoch 7, 100% \t Train loss: 0.114 took: 6.85s  Val. loss: 0.112  Val. score: 96.878%\n",
      "Epoch 8, 100% \t Train loss: 0.099 took: 6.75s  Val. loss: 0.106  Val. score: 96.994%\n",
      "Epoch 9, 100% \t Train loss: 0.088 took: 6.72s  Val. loss: 0.098  Val. score: 97.244%\n",
      "Epoch 10, 100% \t Train loss: 0.082 took: 6.68s  Val. loss: 0.104  Val. score: 97.150%\n",
      "Epoch 11, 100% \t Train loss: 0.077 took: 6.63s  Val. loss: 0.093  Val. score: 97.500%\n",
      "Epoch 12, 100% \t Train loss: 0.069 took: 7.01s  Val. loss: 0.097  Val. score: 97.439%\n",
      "Epoch 13, 100% \t Train loss: 0.063 took: 6.58s  Val. loss: 0.095  Val. score: 97.456%\n",
      "Epoch 14, 100% \t Train loss: 0.059 took: 6.65s  Val. loss: 0.099  Val. score: 97.339%\n",
      "Epoch 15, 100% \t Train loss: 0.052 took: 6.84s  Val. loss: 0.097  Val. score: 97.500%\n",
      "Training finished, took 159.529s\n",
      "\n",
      "Parameters configuration 51 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004059616710546901\n",
      "h_sizes \t [784, 243, 77, 26]\n",
      "penalty \t 0.00023151364855912828\n",
      "dropout \t 0.21330184056198584\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4926 +/- 0.0412\n",
      "Time for evaluation: 480.0 s\n",
      "Estimated time to finish : 7.01 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.498 took: 5.21s  Val. loss: 0.240  Val. score: 93.094%\n",
      "Epoch 2, 100% \t Train loss: 0.248 took: 5.00s  Val. loss: 0.175  Val. score: 95.161%\n",
      "Epoch 3, 100% \t Train loss: 0.181 took: 5.39s  Val. loss: 0.142  Val. score: 95.806%\n",
      "Epoch 4, 100% \t Train loss: 0.146 took: 5.29s  Val. loss: 0.124  Val. score: 96.422%\n",
      "Epoch 5, 100% \t Train loss: 0.123 took: 5.45s  Val. loss: 0.120  Val. score: 96.483%\n",
      "Epoch 6, 100% \t Train loss: 0.106 took: 5.43s  Val. loss: 0.112  Val. score: 96.750%\n",
      "Epoch 7, 100% \t Train loss: 0.091 took: 5.52s  Val. loss: 0.101  Val. score: 96.933%\n",
      "Epoch 8, 100% \t Train loss: 0.085 took: 5.21s  Val. loss: 0.105  Val. score: 97.028%\n",
      "Epoch 9, 100% \t Train loss: 0.073 took: 5.06s  Val. loss: 0.103  Val. score: 97.094%\n",
      "Epoch 10, 100% \t Train loss: 0.067 took: 5.49s  Val. loss: 0.098  Val. score: 97.206%\n",
      "Epoch 11, 100% \t Train loss: 0.062 took: 5.16s  Val. loss: 0.098  Val. score: 97.272%\n",
      "Epoch 12, 100% \t Train loss: 0.059 took: 5.46s  Val. loss: 0.094  Val. score: 97.322%\n",
      "Epoch 13, 100% \t Train loss: 0.051 took: 5.37s  Val. loss: 0.095  Val. score: 97.339%\n",
      "Epoch 14, 100% \t Train loss: 0.050 took: 5.23s  Val. loss: 0.097  Val. score: 97.250%\n",
      "Epoch 15, 100% \t Train loss: 0.044 took: 5.34s  Val. loss: 0.098  Val. score: 97.378%\n",
      "Training finished, took 133.214s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.500 took: 4.75s  Val. loss: 0.244  Val. score: 92.633%\n",
      "Epoch 2, 100% \t Train loss: 0.239 took: 5.10s  Val. loss: 0.180  Val. score: 94.494%\n",
      "Epoch 3, 100% \t Train loss: 0.181 took: 5.28s  Val. loss: 0.141  Val. score: 95.756%\n",
      "Epoch 4, 100% \t Train loss: 0.144 took: 5.46s  Val. loss: 0.128  Val. score: 96.078%\n",
      "Epoch 5, 100% \t Train loss: 0.126 took: 5.19s  Val. loss: 0.110  Val. score: 96.594%\n",
      "Epoch 6, 100% \t Train loss: 0.107 took: 5.03s  Val. loss: 0.112  Val. score: 96.544%\n",
      "Epoch 7, 100% \t Train loss: 0.095 took: 5.19s  Val. loss: 0.099  Val. score: 96.978%\n",
      "Epoch 8, 100% \t Train loss: 0.086 took: 5.02s  Val. loss: 0.099  Val. score: 97.017%\n",
      "Epoch 9, 100% \t Train loss: 0.078 took: 5.41s  Val. loss: 0.092  Val. score: 97.350%\n",
      "Epoch 10, 100% \t Train loss: 0.070 took: 5.46s  Val. loss: 0.091  Val. score: 97.289%\n",
      "Epoch 11, 100% \t Train loss: 0.063 took: 5.33s  Val. loss: 0.087  Val. score: 97.422%\n",
      "Epoch 12, 100% \t Train loss: 0.060 took: 5.04s  Val. loss: 0.090  Val. score: 97.394%\n",
      "Epoch 13, 100% \t Train loss: 0.053 took: 5.45s  Val. loss: 0.089  Val. score: 97.389%\n",
      "Epoch 14, 100% \t Train loss: 0.051 took: 5.24s  Val. loss: 0.086  Val. score: 97.544%\n",
      "Epoch 15, 100% \t Train loss: 0.047 took: 5.05s  Val. loss: 0.089  Val. score: 97.506%\n",
      "Training finished, took 130.207s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.485 took: 4.72s  Val. loss: 0.221  Val. score: 93.211%\n",
      "Epoch 2, 100% \t Train loss: 0.231 took: 4.66s  Val. loss: 0.162  Val. score: 95.367%\n",
      "Epoch 3, 100% \t Train loss: 0.179 took: 5.09s  Val. loss: 0.127  Val. score: 96.028%\n",
      "Epoch 4, 100% \t Train loss: 0.141 took: 5.22s  Val. loss: 0.115  Val. score: 96.461%\n",
      "Epoch 5, 100% \t Train loss: 0.120 took: 5.17s  Val. loss: 0.102  Val. score: 96.911%\n",
      "Epoch 6, 100% \t Train loss: 0.105 took: 5.04s  Val. loss: 0.096  Val. score: 96.961%\n",
      "Epoch 7, 100% \t Train loss: 0.091 took: 4.82s  Val. loss: 0.091  Val. score: 97.194%\n",
      "Epoch 8, 100% \t Train loss: 0.084 took: 4.79s  Val. loss: 0.087  Val. score: 97.317%\n",
      "Epoch 9, 100% \t Train loss: 0.074 took: 4.89s  Val. loss: 0.088  Val. score: 97.417%\n",
      "Epoch 10, 100% \t Train loss: 0.067 took: 5.25s  Val. loss: 0.088  Val. score: 97.544%\n",
      "Epoch 11, 100% \t Train loss: 0.063 took: 5.25s  Val. loss: 0.082  Val. score: 97.589%\n",
      "Epoch 12, 100% \t Train loss: 0.058 took: 4.90s  Val. loss: 0.084  Val. score: 97.628%\n",
      "Epoch 13, 100% \t Train loss: 0.051 took: 5.17s  Val. loss: 0.084  Val. score: 97.528%\n",
      "Epoch 14, 100% \t Train loss: 0.049 took: 4.94s  Val. loss: 0.086  Val. score: 97.572%\n",
      "Epoch 15, 100% \t Train loss: 0.046 took: 4.85s  Val. loss: 0.079  Val. score: 97.744%\n",
      "Training finished, took 126.261s\n",
      "\n",
      "Parameters configuration 52 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004267334464890805\n",
      "h_sizes \t [784, 199, 51]\n",
      "penalty \t 0.00019868212127381767\n",
      "dropout \t 0.20508131040519426\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5426 +/- 0.1520\n",
      "Time for evaluation: 390.9 s\n",
      "Estimated time to finish : 6.83 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.464 took: 4.76s  Val. loss: 0.222  Val. score: 93.478%\n",
      "Epoch 2, 100% \t Train loss: 0.212 took: 4.70s  Val. loss: 0.159  Val. score: 95.283%\n",
      "Epoch 3, 100% \t Train loss: 0.156 took: 4.71s  Val. loss: 0.125  Val. score: 96.167%\n",
      "Epoch 4, 100% \t Train loss: 0.125 took: 4.99s  Val. loss: 0.113  Val. score: 96.472%\n",
      "Epoch 5, 100% \t Train loss: 0.102 took: 5.06s  Val. loss: 0.100  Val. score: 96.817%\n",
      "Epoch 6, 100% \t Train loss: 0.085 took: 5.03s  Val. loss: 0.095  Val. score: 97.161%\n",
      "Epoch 7, 100% \t Train loss: 0.074 took: 4.73s  Val. loss: 0.087  Val. score: 97.322%\n",
      "Epoch 8, 100% \t Train loss: 0.061 took: 4.98s  Val. loss: 0.092  Val. score: 97.089%\n",
      "Epoch 9, 100% \t Train loss: 0.054 took: 4.80s  Val. loss: 0.088  Val. score: 97.494%\n",
      "Epoch 10, 100% \t Train loss: 0.048 took: 4.73s  Val. loss: 0.087  Val. score: 97.444%\n",
      "Epoch 11, 100% \t Train loss: 0.043 took: 4.78s  Val. loss: 0.081  Val. score: 97.656%\n",
      "Epoch 12, 100% \t Train loss: 0.036 took: 4.66s  Val. loss: 0.086  Val. score: 97.533%\n",
      "Epoch 13, 100% \t Train loss: 0.034 took: 5.04s  Val. loss: 0.083  Val. score: 97.572%\n",
      "Epoch 14, 100% \t Train loss: 0.030 took: 5.00s  Val. loss: 0.085  Val. score: 97.617%\n",
      "Epoch 15, 100% \t Train loss: 0.027 took: 4.98s  Val. loss: 0.084  Val. score: 97.594%\n",
      "Training finished, took 122.920s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.451 took: 4.47s  Val. loss: 0.244  Val. score: 92.811%\n",
      "Epoch 2, 100% \t Train loss: 0.209 took: 4.81s  Val. loss: 0.173  Val. score: 94.917%\n",
      "Epoch 3, 100% \t Train loss: 0.152 took: 4.50s  Val. loss: 0.138  Val. score: 95.917%\n",
      "Epoch 4, 100% \t Train loss: 0.117 took: 4.99s  Val. loss: 0.125  Val. score: 96.189%\n",
      "Epoch 5, 100% \t Train loss: 0.094 took: 4.80s  Val. loss: 0.111  Val. score: 96.594%\n",
      "Epoch 6, 100% \t Train loss: 0.078 took: 4.60s  Val. loss: 0.105  Val. score: 96.822%\n",
      "Epoch 7, 100% \t Train loss: 0.066 took: 5.01s  Val. loss: 0.099  Val. score: 96.950%\n",
      "Epoch 8, 100% \t Train loss: 0.056 took: 5.06s  Val. loss: 0.097  Val. score: 97.050%\n",
      "Epoch 9, 100% \t Train loss: 0.049 took: 4.97s  Val. loss: 0.098  Val. score: 97.172%\n",
      "Epoch 10, 100% \t Train loss: 0.044 took: 4.99s  Val. loss: 0.103  Val. score: 97.050%\n",
      "Epoch 11, 100% \t Train loss: 0.038 took: 4.99s  Val. loss: 0.092  Val. score: 97.317%\n",
      "Epoch 12, 100% \t Train loss: 0.035 took: 5.04s  Val. loss: 0.095  Val. score: 97.267%\n",
      "Epoch 13, 100% \t Train loss: 0.031 took: 4.62s  Val. loss: 0.102  Val. score: 97.128%\n",
      "Epoch 14, 100% \t Train loss: 0.028 took: 5.01s  Val. loss: 0.097  Val. score: 97.289%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 4.66s  Val. loss: 0.096  Val. score: 97.439%\n",
      "Training finished, took 122.725s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.446 took: 4.66s  Val. loss: 0.220  Val. score: 93.522%\n",
      "Epoch 2, 100% \t Train loss: 0.209 took: 4.87s  Val. loss: 0.162  Val. score: 95.194%\n",
      "Epoch 3, 100% \t Train loss: 0.154 took: 4.92s  Val. loss: 0.136  Val. score: 95.867%\n",
      "Epoch 4, 100% \t Train loss: 0.120 took: 5.05s  Val. loss: 0.121  Val. score: 96.333%\n",
      "Epoch 5, 100% \t Train loss: 0.096 took: 5.00s  Val. loss: 0.104  Val. score: 96.839%\n",
      "Epoch 6, 100% \t Train loss: 0.080 took: 5.05s  Val. loss: 0.097  Val. score: 97.133%\n",
      "Epoch 7, 100% \t Train loss: 0.072 took: 4.72s  Val. loss: 0.095  Val. score: 97.189%\n",
      "Epoch 8, 100% \t Train loss: 0.061 took: 4.74s  Val. loss: 0.094  Val. score: 97.172%\n",
      "Epoch 9, 100% \t Train loss: 0.051 took: 4.95s  Val. loss: 0.086  Val. score: 97.478%\n",
      "Epoch 10, 100% \t Train loss: 0.044 took: 5.04s  Val. loss: 0.084  Val. score: 97.439%\n",
      "Epoch 11, 100% \t Train loss: 0.038 took: 5.07s  Val. loss: 0.088  Val. score: 97.483%\n",
      "Epoch 12, 100% \t Train loss: 0.036 took: 4.99s  Val. loss: 0.086  Val. score: 97.533%\n",
      "Epoch 13, 100% \t Train loss: 0.031 took: 5.03s  Val. loss: 0.082  Val. score: 97.633%\n",
      "Epoch 14, 100% \t Train loss: 0.028 took: 4.69s  Val. loss: 0.083  Val. score: 97.706%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 5.03s  Val. loss: 0.084  Val. score: 97.694%\n",
      "Training finished, took 123.928s\n",
      "\n",
      "Parameters configuration 53 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004652998886743496\n",
      "h_sizes \t [784, 188, 41]\n",
      "penalty \t 0.003212261514776027\n",
      "dropout \t 0.08871846098311928\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5759 +/- 0.1051\n",
      "Time for evaluation: 370.7 s\n",
      "Estimated time to finish : 6.66 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.709 took: 26.72s  Val. loss: 1.224  Val. score: 54.139%\n",
      "Epoch 2, 100% \t Train loss: 1.212 took: 26.77s  Val. loss: 1.043  Val. score: 60.372%\n",
      "Epoch 3, 100% \t Train loss: 1.040 took: 34.23s  Val. loss: 0.882  Val. score: 64.094%\n",
      "Epoch 4, 100% \t Train loss: 0.953 took: 37.00s  Val. loss: 0.895  Val. score: 61.628%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, 100% \t Train loss: 0.916 took: 36.33s  Val. loss: 0.882  Val. score: 67.178%\n",
      "Epoch 6, 100% \t Train loss: 0.951 took: 37.29s  Val. loss: 0.783  Val. score: 77.267%\n",
      "Epoch 7, 100% \t Train loss: 0.957 took: 35.41s  Val. loss: 0.887  Val. score: 71.406%\n",
      "Epoch 8, 100% \t Train loss: 0.919 took: 37.91s  Val. loss: 0.777  Val. score: 74.233%\n",
      "Epoch 9, 100% \t Train loss: 0.788 took: 38.75s  Val. loss: 0.708  Val. score: 73.000%\n",
      "Epoch 10, 100% \t Train loss: 0.711 took: 38.12s  Val. loss: 0.708  Val. score: 77.156%\n",
      "Epoch 11, 100% \t Train loss: 0.768 took: 36.80s  Val. loss: 0.762  Val. score: 71.928%\n",
      "Epoch 12, 100% \t Train loss: 0.779 took: 36.77s  Val. loss: 0.962  Val. score: 60.200%\n",
      "Epoch 13, 100% \t Train loss: 0.744 took: 37.35s  Val. loss: 0.783  Val. score: 75.167%\n",
      "Epoch 14, 100% \t Train loss: 0.771 took: 37.57s  Val. loss: 0.715  Val. score: 76.539%\n",
      "Epoch 15, 100% \t Train loss: 0.842 took: 36.34s  Val. loss: 1.069  Val. score: 53.128%\n",
      "Training finished, took 680.268s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.726 took: 26.26s  Val. loss: 1.111  Val. score: 59.244%\n",
      "Epoch 2, 100% \t Train loss: 1.097 took: 26.46s  Val. loss: 0.856  Val. score: 70.800%\n",
      "Epoch 3, 100% \t Train loss: 0.940 took: 35.04s  Val. loss: 0.722  Val. score: 79.206%\n",
      "Epoch 4, 100% \t Train loss: 1.003 took: 37.95s  Val. loss: 0.945  Val. score: 60.839%\n",
      "Epoch 5, 100% \t Train loss: 0.987 took: 40.16s  Val. loss: 0.857  Val. score: 70.139%\n",
      "Epoch 6, 100% \t Train loss: 0.887 took: 39.89s  Val. loss: 0.902  Val. score: 65.000%\n",
      "Epoch 7, 100% \t Train loss: 0.944 took: 39.58s  Val. loss: 0.914  Val. score: 65.172%\n",
      "Epoch 8, 100% \t Train loss: 0.930 took: 40.36s  Val. loss: 0.913  Val. score: 64.822%\n",
      "Epoch 9, 100% \t Train loss: 0.887 took: 38.67s  Val. loss: 0.951  Val. score: 58.883%\n",
      "Epoch 10, 100% \t Train loss: 0.849 took: 39.92s  Val. loss: 0.868  Val. score: 67.572%\n",
      "Epoch 11, 100% \t Train loss: 0.834 took: 42.14s  Val. loss: 0.961  Val. score: 63.478%\n",
      "Epoch 12, 100% \t Train loss: 0.806 took: 39.50s  Val. loss: 1.156  Val. score: 62.733%\n",
      "Epoch 13, 100% \t Train loss: 0.807 took: 41.61s  Val. loss: 0.930  Val. score: 61.417%\n",
      "Epoch 14, 100% \t Train loss: 0.782 took: 38.85s  Val. loss: 0.965  Val. score: 64.017%\n",
      "Epoch 15, 100% \t Train loss: 0.777 took: 42.06s  Val. loss: 0.938  Val. score: 65.289%\n",
      "Training finished, took 714.002s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.823 took: 25.02s  Val. loss: 1.352  Val. score: 46.628%\n",
      "Epoch 2, 100% \t Train loss: 1.329 took: 25.79s  Val. loss: 1.224  Val. score: 50.117%\n",
      "Epoch 3, 100% \t Train loss: 1.402 took: 34.54s  Val. loss: 1.090  Val. score: 50.911%\n",
      "Epoch 4, 100% \t Train loss: 1.269 took: 38.15s  Val. loss: 1.284  Val. score: 48.622%\n",
      "Epoch 5, 100% \t Train loss: 1.118 took: 37.17s  Val. loss: 1.013  Val. score: 55.428%\n",
      "Epoch 6, 100% \t Train loss: 0.983 took: 38.36s  Val. loss: 0.949  Val. score: 61.144%\n",
      "Epoch 7, 100% \t Train loss: 0.943 took: 37.82s  Val. loss: 0.823  Val. score: 70.856%\n",
      "Epoch 8, 100% \t Train loss: 0.902 took: 37.11s  Val. loss: 0.887  Val. score: 64.900%\n",
      "Epoch 9, 100% \t Train loss: 0.875 took: 37.59s  Val. loss: 0.791  Val. score: 72.056%\n",
      "Epoch 10, 100% \t Train loss: 0.836 took: 38.32s  Val. loss: 0.856  Val. score: 65.983%\n",
      "Epoch 11, 100% \t Train loss: 0.803 took: 37.64s  Val. loss: 0.786  Val. score: 79.094%\n",
      "Epoch 12, 100% \t Train loss: 0.793 took: 37.14s  Val. loss: 0.774  Val. score: 72.756%\n",
      "Epoch 13, 100% \t Train loss: 0.747 took: 36.64s  Val. loss: 0.676  Val. score: 77.311%\n",
      "Epoch 14, 100% \t Train loss: 0.673 took: 36.76s  Val. loss: 0.704  Val. score: 71.889%\n",
      "Epoch 15, 100% \t Train loss: 0.677 took: 36.21s  Val. loss: 0.575  Val. score: 81.111%\n",
      "Training finished, took 683.881s\n",
      "\n",
      "Parameters configuration 54 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.017265976090288824\n",
      "h_sizes \t [784, 582, 454, 351, 257, 195, 151, 120, 92, 69, 50, 36, 34, 27, 25, 20]\n",
      "penalty \t 0.0007048499838027881\n",
      "dropout \t 0.206379645320488\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 66.5093 +/- 11.4567\n",
      "Time for evaluation: 2079.3 s\n",
      "Estimated time to finish : 6.89 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.515 took: 5.00s  Val. loss: 0.245  Val. score: 92.944%\n",
      "Epoch 2, 100% \t Train loss: 0.251 took: 5.01s  Val. loss: 0.181  Val. score: 94.500%\n",
      "Epoch 3, 100% \t Train loss: 0.191 took: 4.91s  Val. loss: 0.145  Val. score: 95.417%\n",
      "Epoch 4, 100% \t Train loss: 0.158 took: 5.13s  Val. loss: 0.128  Val. score: 96.044%\n",
      "Epoch 5, 100% \t Train loss: 0.132 took: 5.15s  Val. loss: 0.117  Val. score: 96.367%\n",
      "Epoch 6, 100% \t Train loss: 0.117 took: 5.13s  Val. loss: 0.107  Val. score: 96.667%\n",
      "Epoch 7, 100% \t Train loss: 0.104 took: 5.10s  Val. loss: 0.099  Val. score: 96.850%\n",
      "Epoch 8, 100% \t Train loss: 0.090 took: 5.13s  Val. loss: 0.090  Val. score: 97.200%\n",
      "Epoch 9, 100% \t Train loss: 0.081 took: 5.01s  Val. loss: 0.086  Val. score: 97.367%\n",
      "Epoch 10, 100% \t Train loss: 0.077 took: 5.10s  Val. loss: 0.086  Val. score: 97.361%\n",
      "Epoch 11, 100% \t Train loss: 0.068 took: 5.22s  Val. loss: 0.088  Val. score: 97.333%\n",
      "Epoch 12, 100% \t Train loss: 0.063 took: 4.88s  Val. loss: 0.080  Val. score: 97.578%\n",
      "Epoch 13, 100% \t Train loss: 0.059 took: 4.99s  Val. loss: 0.083  Val. score: 97.406%\n",
      "Epoch 14, 100% \t Train loss: 0.055 took: 4.73s  Val. loss: 0.079  Val. score: 97.611%\n",
      "Epoch 15, 100% \t Train loss: 0.050 took: 4.76s  Val. loss: 0.079  Val. score: 97.639%\n",
      "Training finished, took 126.705s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.560 took: 4.98s  Val. loss: 0.262  Val. score: 92.328%\n",
      "Epoch 2, 100% \t Train loss: 0.262 took: 4.97s  Val. loss: 0.181  Val. score: 94.644%\n",
      "Epoch 3, 100% \t Train loss: 0.192 took: 4.63s  Val. loss: 0.148  Val. score: 95.617%\n",
      "Epoch 4, 100% \t Train loss: 0.157 took: 5.14s  Val. loss: 0.127  Val. score: 96.144%\n",
      "Epoch 5, 100% \t Train loss: 0.131 took: 5.16s  Val. loss: 0.112  Val. score: 96.717%\n",
      "Epoch 6, 100% \t Train loss: 0.115 took: 4.73s  Val. loss: 0.106  Val. score: 96.778%\n",
      "Epoch 7, 100% \t Train loss: 0.099 took: 5.15s  Val. loss: 0.099  Val. score: 96.983%\n",
      "Epoch 8, 100% \t Train loss: 0.090 took: 4.85s  Val. loss: 0.095  Val. score: 97.178%\n",
      "Epoch 9, 100% \t Train loss: 0.080 took: 4.88s  Val. loss: 0.092  Val. score: 97.222%\n",
      "Epoch 10, 100% \t Train loss: 0.073 took: 5.39s  Val. loss: 0.090  Val. score: 97.344%\n",
      "Epoch 11, 100% \t Train loss: 0.068 took: 4.88s  Val. loss: 0.093  Val. score: 97.283%\n",
      "Epoch 12, 100% \t Train loss: 0.062 took: 5.18s  Val. loss: 0.088  Val. score: 97.439%\n",
      "Epoch 13, 100% \t Train loss: 0.057 took: 5.15s  Val. loss: 0.088  Val. score: 97.589%\n",
      "Epoch 14, 100% \t Train loss: 0.051 took: 5.19s  Val. loss: 0.090  Val. score: 97.478%\n",
      "Epoch 15, 100% \t Train loss: 0.050 took: 5.34s  Val. loss: 0.085  Val. score: 97.606%\n",
      "Training finished, took 126.986s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.517 took: 5.02s  Val. loss: 0.253  Val. score: 92.556%\n",
      "Epoch 2, 100% \t Train loss: 0.256 took: 5.03s  Val. loss: 0.188  Val. score: 94.333%\n",
      "Epoch 3, 100% \t Train loss: 0.192 took: 4.88s  Val. loss: 0.155  Val. score: 95.356%\n",
      "Epoch 4, 100% \t Train loss: 0.154 took: 5.20s  Val. loss: 0.135  Val. score: 95.839%\n",
      "Epoch 5, 100% \t Train loss: 0.129 took: 5.23s  Val. loss: 0.117  Val. score: 96.394%\n",
      "Epoch 6, 100% \t Train loss: 0.112 took: 5.24s  Val. loss: 0.110  Val. score: 96.644%\n",
      "Epoch 7, 100% \t Train loss: 0.099 took: 5.31s  Val. loss: 0.102  Val. score: 96.900%\n",
      "Epoch 8, 100% \t Train loss: 0.086 took: 5.10s  Val. loss: 0.102  Val. score: 96.906%\n",
      "Epoch 9, 100% \t Train loss: 0.080 took: 5.27s  Val. loss: 0.095  Val. score: 97.083%\n",
      "Epoch 10, 100% \t Train loss: 0.071 took: 5.16s  Val. loss: 0.092  Val. score: 97.272%\n",
      "Epoch 11, 100% \t Train loss: 0.067 took: 5.14s  Val. loss: 0.091  Val. score: 97.333%\n",
      "Epoch 12, 100% \t Train loss: 0.059 took: 5.18s  Val. loss: 0.093  Val. score: 97.333%\n",
      "Epoch 13, 100% \t Train loss: 0.055 took: 5.22s  Val. loss: 0.089  Val. score: 97.428%\n",
      "Epoch 14, 100% \t Train loss: 0.050 took: 5.29s  Val. loss: 0.089  Val. score: 97.522%\n",
      "Epoch 15, 100% \t Train loss: 0.047 took: 5.27s  Val. loss: 0.086  Val. score: 97.544%\n",
      "Training finished, took 129.797s\n",
      "\n",
      "Parameters configuration 55 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0033531091949899144\n",
      "h_sizes \t [784, 190, 52]\n",
      "penalty \t 0.0012502629782364465\n",
      "dropout \t 0.19148207562645791\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5963 +/- 0.0391\n",
      "Time for evaluation: 384.7 s\n",
      "Estimated time to finish : 6.70 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.581 took: 4.87s  Val. loss: 0.299  Val. score: 91.600%\n",
      "Epoch 2, 100% \t Train loss: 0.275 took: 4.79s  Val. loss: 0.231  Val. score: 93.306%\n",
      "Epoch 3, 100% \t Train loss: 0.212 took: 4.89s  Val. loss: 0.191  Val. score: 94.422%\n",
      "Epoch 4, 100% \t Train loss: 0.170 took: 4.45s  Val. loss: 0.169  Val. score: 95.150%\n",
      "Epoch 5, 100% \t Train loss: 0.142 took: 4.57s  Val. loss: 0.139  Val. score: 95.889%\n",
      "Epoch 6, 100% \t Train loss: 0.120 took: 4.84s  Val. loss: 0.129  Val. score: 96.044%\n",
      "Epoch 7, 100% \t Train loss: 0.104 took: 4.91s  Val. loss: 0.117  Val. score: 96.483%\n",
      "Epoch 8, 100% \t Train loss: 0.091 took: 5.07s  Val. loss: 0.113  Val. score: 96.589%\n",
      "Epoch 9, 100% \t Train loss: 0.081 took: 4.94s  Val. loss: 0.107  Val. score: 96.683%\n",
      "Epoch 10, 100% \t Train loss: 0.074 took: 4.59s  Val. loss: 0.101  Val. score: 96.978%\n",
      "Epoch 11, 100% \t Train loss: 0.062 took: 4.63s  Val. loss: 0.099  Val. score: 96.867%\n",
      "Epoch 12, 100% \t Train loss: 0.058 took: 4.82s  Val. loss: 0.099  Val. score: 97.067%\n",
      "Epoch 13, 100% \t Train loss: 0.053 took: 4.61s  Val. loss: 0.095  Val. score: 97.094%\n",
      "Epoch 14, 100% \t Train loss: 0.048 took: 4.98s  Val. loss: 0.093  Val. score: 97.183%\n",
      "Epoch 15, 100% \t Train loss: 0.043 took: 4.59s  Val. loss: 0.094  Val. score: 97.222%\n",
      "Training finished, took 122.063s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.584 took: 4.29s  Val. loss: 0.290  Val. score: 91.644%\n",
      "Epoch 2, 100% \t Train loss: 0.268 took: 4.50s  Val. loss: 0.212  Val. score: 93.806%\n",
      "Epoch 3, 100% \t Train loss: 0.202 took: 4.80s  Val. loss: 0.170  Val. score: 95.006%\n",
      "Epoch 4, 100% \t Train loss: 0.164 took: 4.70s  Val. loss: 0.151  Val. score: 95.444%\n",
      "Epoch 5, 100% \t Train loss: 0.136 took: 4.98s  Val. loss: 0.135  Val. score: 95.856%\n",
      "Epoch 6, 100% \t Train loss: 0.119 took: 4.61s  Val. loss: 0.128  Val. score: 96.022%\n",
      "Epoch 7, 100% \t Train loss: 0.105 took: 4.60s  Val. loss: 0.116  Val. score: 96.522%\n",
      "Epoch 8, 100% \t Train loss: 0.092 took: 4.84s  Val. loss: 0.108  Val. score: 96.689%\n",
      "Epoch 9, 100% \t Train loss: 0.080 took: 4.95s  Val. loss: 0.104  Val. score: 96.917%\n",
      "Epoch 10, 100% \t Train loss: 0.075 took: 5.16s  Val. loss: 0.101  Val. score: 97.033%\n",
      "Epoch 11, 100% \t Train loss: 0.065 took: 6.59s  Val. loss: 0.098  Val. score: 97.044%\n",
      "Epoch 12, 100% \t Train loss: 0.060 took: 6.62s  Val. loss: 0.095  Val. score: 97.150%\n",
      "Epoch 13, 100% \t Train loss: 0.054 took: 6.41s  Val. loss: 0.096  Val. score: 97.100%\n",
      "Epoch 14, 100% \t Train loss: 0.048 took: 6.63s  Val. loss: 0.091  Val. score: 97.411%\n",
      "Epoch 15, 100% \t Train loss: 0.046 took: 6.41s  Val. loss: 0.091  Val. score: 97.361%\n",
      "Training finished, took 137.559s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.592 took: 6.42s  Val. loss: 0.294  Val. score: 91.456%\n",
      "Epoch 2, 100% \t Train loss: 0.282 took: 6.65s  Val. loss: 0.219  Val. score: 93.506%\n",
      "Epoch 3, 100% \t Train loss: 0.217 took: 9.22s  Val. loss: 0.181  Val. score: 94.644%\n",
      "Epoch 4, 100% \t Train loss: 0.179 took: 7.36s  Val. loss: 0.151  Val. score: 95.328%\n",
      "Epoch 5, 100% \t Train loss: 0.149 took: 6.40s  Val. loss: 0.134  Val. score: 95.761%\n",
      "Epoch 6, 100% \t Train loss: 0.126 took: 7.28s  Val. loss: 0.117  Val. score: 96.367%\n",
      "Epoch 7, 100% \t Train loss: 0.110 took: 6.81s  Val. loss: 0.110  Val. score: 96.583%\n",
      "Epoch 8, 100% \t Train loss: 0.097 took: 7.01s  Val. loss: 0.099  Val. score: 96.833%\n",
      "Epoch 9, 100% \t Train loss: 0.086 took: 6.89s  Val. loss: 0.098  Val. score: 96.933%\n",
      "Epoch 10, 100% \t Train loss: 0.076 took: 7.13s  Val. loss: 0.091  Val. score: 97.111%\n",
      "Epoch 11, 100% \t Train loss: 0.069 took: 6.14s  Val. loss: 0.097  Val. score: 97.028%\n",
      "Epoch 12, 100% \t Train loss: 0.062 took: 6.91s  Val. loss: 0.087  Val. score: 97.256%\n",
      "Epoch 13, 100% \t Train loss: 0.055 took: 6.93s  Val. loss: 0.087  Val. score: 97.306%\n",
      "Epoch 14, 100% \t Train loss: 0.051 took: 7.19s  Val. loss: 0.083  Val. score: 97.411%\n",
      "Epoch 15, 100% \t Train loss: 0.047 took: 6.77s  Val. loss: 0.084  Val. score: 97.494%\n",
      "Training finished, took 179.905s\n",
      "\n",
      "Parameters configuration 56 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.002227005787023503\n",
      "h_sizes \t [784, 176, 45]\n",
      "penalty \t 0.0006736571039832936\n",
      "dropout \t 0.06569049949560204\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.3593 +/- 0.1111\n",
      "Time for evaluation: 440.7 s\n",
      "Estimated time to finish : 6.53 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.410 took: 7.38s  Val. loss: 0.185  Val. score: 94.406%\n",
      "Epoch 2, 100% \t Train loss: 0.195 took: 7.27s  Val. loss: 0.151  Val. score: 95.433%\n",
      "Epoch 3, 100% \t Train loss: 0.148 took: 7.06s  Val. loss: 0.123  Val. score: 96.289%\n",
      "Epoch 4, 100% \t Train loss: 0.120 took: 7.22s  Val. loss: 0.110  Val. score: 96.711%\n",
      "Epoch 5, 100% \t Train loss: 0.100 took: 7.97s  Val. loss: 0.104  Val. score: 96.900%\n",
      "Epoch 6, 100% \t Train loss: 0.085 took: 7.32s  Val. loss: 0.101  Val. score: 97.139%\n",
      "Epoch 7, 100% \t Train loss: 0.076 took: 8.50s  Val. loss: 0.093  Val. score: 97.250%\n",
      "Epoch 8, 100% \t Train loss: 0.067 took: 7.41s  Val. loss: 0.090  Val. score: 97.422%\n",
      "Epoch 9, 100% \t Train loss: 0.058 took: 7.46s  Val. loss: 0.092  Val. score: 97.417%\n",
      "Epoch 10, 100% \t Train loss: 0.056 took: 7.53s  Val. loss: 0.097  Val. score: 97.428%\n",
      "Epoch 11, 100% \t Train loss: 0.050 took: 5.08s  Val. loss: 0.093  Val. score: 97.483%\n",
      "Epoch 12, 100% \t Train loss: 0.045 took: 5.35s  Val. loss: 0.090  Val. score: 97.639%\n",
      "Epoch 13, 100% \t Train loss: 0.041 took: 5.23s  Val. loss: 0.095  Val. score: 97.589%\n",
      "Epoch 14, 100% \t Train loss: 0.039 took: 5.20s  Val. loss: 0.097  Val. score: 97.550%\n",
      "Epoch 15, 100% \t Train loss: 0.037 took: 5.36s  Val. loss: 0.090  Val. score: 97.639%\n",
      "Training finished, took 172.604s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.447 took: 4.88s  Val. loss: 0.196  Val. score: 93.961%\n",
      "Epoch 2, 100% \t Train loss: 0.216 took: 7.38s  Val. loss: 0.145  Val. score: 95.528%\n",
      "Epoch 3, 100% \t Train loss: 0.162 took: 5.85s  Val. loss: 0.118  Val. score: 96.339%\n",
      "Epoch 4, 100% \t Train loss: 0.132 took: 5.44s  Val. loss: 0.111  Val. score: 96.617%\n",
      "Epoch 5, 100% \t Train loss: 0.116 took: 5.46s  Val. loss: 0.096  Val. score: 97.133%\n",
      "Epoch 6, 100% \t Train loss: 0.100 took: 5.34s  Val. loss: 0.098  Val. score: 97.178%\n",
      "Epoch 7, 100% \t Train loss: 0.088 took: 5.24s  Val. loss: 0.091  Val. score: 97.428%\n",
      "Epoch 8, 100% \t Train loss: 0.078 took: 5.51s  Val. loss: 0.098  Val. score: 97.189%\n",
      "Epoch 9, 100% \t Train loss: 0.071 took: 5.28s  Val. loss: 0.091  Val. score: 97.400%\n",
      "Epoch 10, 100% \t Train loss: 0.067 took: 5.42s  Val. loss: 0.083  Val. score: 97.639%\n",
      "Epoch 11, 100% \t Train loss: 0.061 took: 7.16s  Val. loss: 0.086  Val. score: 97.644%\n",
      "Epoch 12, 100% \t Train loss: 0.054 took: 6.90s  Val. loss: 0.086  Val. score: 97.700%\n",
      "Epoch 13, 100% \t Train loss: 0.050 took: 8.52s  Val. loss: 0.086  Val. score: 97.672%\n",
      "Epoch 14, 100% \t Train loss: 0.047 took: 5.60s  Val. loss: 0.091  Val. score: 97.700%\n",
      "Epoch 15, 100% \t Train loss: 0.045 took: 5.24s  Val. loss: 0.092  Val. score: 97.733%\n",
      "Training finished, took 149.175s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 100% \t Train loss: 0.431 took: 4.68s  Val. loss: 0.187  Val. score: 94.222%\n",
      "Epoch 2, 100% \t Train loss: 0.206 took: 4.73s  Val. loss: 0.142  Val. score: 95.683%\n",
      "Epoch 3, 100% \t Train loss: 0.158 took: 5.24s  Val. loss: 0.120  Val. score: 96.311%\n",
      "Epoch 4, 100% \t Train loss: 0.129 took: 5.28s  Val. loss: 0.113  Val. score: 96.489%\n",
      "Epoch 5, 100% \t Train loss: 0.108 took: 5.21s  Val. loss: 0.100  Val. score: 96.972%\n",
      "Epoch 6, 100% \t Train loss: 0.094 took: 5.23s  Val. loss: 0.096  Val. score: 97.111%\n",
      "Epoch 7, 100% \t Train loss: 0.081 took: 5.38s  Val. loss: 0.098  Val. score: 97.067%\n",
      "Epoch 8, 100% \t Train loss: 0.075 took: 4.88s  Val. loss: 0.090  Val. score: 97.328%\n",
      "Epoch 9, 100% \t Train loss: 0.071 took: 5.19s  Val. loss: 0.089  Val. score: 97.494%\n",
      "Epoch 10, 100% \t Train loss: 0.059 took: 5.00s  Val. loss: 0.092  Val. score: 97.383%\n",
      "Epoch 11, 100% \t Train loss: 0.058 took: 5.37s  Val. loss: 0.095  Val. score: 97.350%\n",
      "Epoch 12, 100% \t Train loss: 0.053 took: 5.78s  Val. loss: 0.090  Val. score: 97.506%\n",
      "Epoch 13, 100% \t Train loss: 0.049 took: 5.24s  Val. loss: 0.093  Val. score: 97.400%\n",
      "Epoch 14, 100% \t Train loss: 0.045 took: 5.35s  Val. loss: 0.094  Val. score: 97.567%\n",
      "Epoch 15, 100% \t Train loss: 0.043 took: 4.98s  Val. loss: 0.094  Val. score: 97.678%\n",
      "Training finished, took 128.569s\n",
      "\n",
      "Parameters configuration 57 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008249523303740786\n",
      "h_sizes \t [784, 192, 42]\n",
      "penalty \t 0.00517351748939074\n",
      "dropout \t 0.19768748736286157\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6833 +/- 0.0388\n",
      "Time for evaluation: 451.6 s\n",
      "Estimated time to finish : 6.36 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.726 took: 6.40s  Val. loss: 0.270  Val. score: 92.050%\n",
      "Epoch 2, 100% \t Train loss: 0.298 took: 5.87s  Val. loss: 0.190  Val. score: 94.406%\n",
      "Epoch 3, 100% \t Train loss: 0.220 took: 5.79s  Val. loss: 0.157  Val. score: 95.506%\n",
      "Epoch 4, 100% \t Train loss: 0.184 took: 5.83s  Val. loss: 0.138  Val. score: 95.850%\n",
      "Epoch 5, 100% \t Train loss: 0.154 took: 5.93s  Val. loss: 0.127  Val. score: 96.128%\n",
      "Epoch 6, 100% \t Train loss: 0.133 took: 6.45s  Val. loss: 0.116  Val. score: 96.533%\n",
      "Epoch 7, 100% \t Train loss: 0.118 took: 6.19s  Val. loss: 0.111  Val. score: 96.728%\n",
      "Epoch 8, 100% \t Train loss: 0.103 took: 5.87s  Val. loss: 0.112  Val. score: 96.883%\n",
      "Epoch 9, 100% \t Train loss: 0.094 took: 6.26s  Val. loss: 0.105  Val. score: 97.028%\n",
      "Epoch 10, 100% \t Train loss: 0.087 took: 6.48s  Val. loss: 0.098  Val. score: 97.244%\n",
      "Epoch 11, 100% \t Train loss: 0.077 took: 6.35s  Val. loss: 0.098  Val. score: 97.322%\n",
      "Epoch 12, 100% \t Train loss: 0.071 took: 6.24s  Val. loss: 0.101  Val. score: 97.250%\n",
      "Epoch 13, 100% \t Train loss: 0.067 took: 5.93s  Val. loss: 0.098  Val. score: 97.306%\n",
      "Epoch 14, 100% \t Train loss: 0.059 took: 6.03s  Val. loss: 0.096  Val. score: 97.411%\n",
      "Epoch 15, 100% \t Train loss: 0.057 took: 6.11s  Val. loss: 0.097  Val. score: 97.378%\n",
      "Training finished, took 150.680s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.740 took: 6.13s  Val. loss: 0.275  Val. score: 92.156%\n",
      "Epoch 2, 100% \t Train loss: 0.322 took: 6.08s  Val. loss: 0.191  Val. score: 94.478%\n",
      "Epoch 3, 100% \t Train loss: 0.241 took: 6.37s  Val. loss: 0.157  Val. score: 95.417%\n",
      "Epoch 4, 100% \t Train loss: 0.193 took: 6.26s  Val. loss: 0.147  Val. score: 95.817%\n",
      "Epoch 5, 100% \t Train loss: 0.162 took: 6.69s  Val. loss: 0.122  Val. score: 96.583%\n",
      "Epoch 6, 100% \t Train loss: 0.141 took: 6.23s  Val. loss: 0.117  Val. score: 96.589%\n",
      "Epoch 7, 100% \t Train loss: 0.127 took: 6.47s  Val. loss: 0.106  Val. score: 97.050%\n",
      "Epoch 8, 100% \t Train loss: 0.112 took: 6.55s  Val. loss: 0.104  Val. score: 97.139%\n",
      "Epoch 9, 100% \t Train loss: 0.101 took: 6.39s  Val. loss: 0.105  Val. score: 97.172%\n",
      "Epoch 10, 100% \t Train loss: 0.091 took: 6.89s  Val. loss: 0.106  Val. score: 97.194%\n",
      "Epoch 11, 100% \t Train loss: 0.083 took: 6.61s  Val. loss: 0.095  Val. score: 97.489%\n",
      "Epoch 12, 100% \t Train loss: 0.076 took: 6.12s  Val. loss: 0.097  Val. score: 97.378%\n",
      "Epoch 13, 100% \t Train loss: 0.070 took: 6.25s  Val. loss: 0.100  Val. score: 97.317%\n",
      "Epoch 14, 100% \t Train loss: 0.067 took: 6.47s  Val. loss: 0.097  Val. score: 97.578%\n",
      "Epoch 15, 100% \t Train loss: 0.061 took: 6.43s  Val. loss: 0.098  Val. score: 97.506%\n",
      "Training finished, took 155.927s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.714 took: 6.51s  Val. loss: 0.270  Val. score: 92.161%\n",
      "Epoch 2, 100% \t Train loss: 0.323 took: 6.60s  Val. loss: 0.185  Val. score: 94.650%\n",
      "Epoch 3, 100% \t Train loss: 0.233 took: 6.06s  Val. loss: 0.150  Val. score: 95.606%\n",
      "Epoch 4, 100% \t Train loss: 0.192 took: 6.56s  Val. loss: 0.134  Val. score: 96.128%\n",
      "Epoch 5, 100% \t Train loss: 0.159 took: 6.10s  Val. loss: 0.121  Val. score: 96.594%\n",
      "Epoch 6, 100% \t Train loss: 0.142 took: 6.33s  Val. loss: 0.115  Val. score: 96.861%\n",
      "Epoch 7, 100% \t Train loss: 0.124 took: 6.31s  Val. loss: 0.109  Val. score: 97.006%\n",
      "Epoch 8, 100% \t Train loss: 0.111 took: 6.21s  Val. loss: 0.102  Val. score: 97.300%\n",
      "Epoch 9, 100% \t Train loss: 0.098 took: 6.25s  Val. loss: 0.101  Val. score: 97.317%\n",
      "Epoch 10, 100% \t Train loss: 0.091 took: 6.25s  Val. loss: 0.101  Val. score: 97.367%\n",
      "Epoch 11, 100% \t Train loss: 0.083 took: 6.16s  Val. loss: 0.100  Val. score: 97.422%\n",
      "Epoch 12, 100% \t Train loss: 0.076 took: 6.44s  Val. loss: 0.097  Val. score: 97.578%\n",
      "Epoch 13, 100% \t Train loss: 0.070 took: 6.08s  Val. loss: 0.094  Val. score: 97.539%\n",
      "Epoch 14, 100% \t Train loss: 0.063 took: 6.06s  Val. loss: 0.100  Val. score: 97.506%\n",
      "Epoch 15, 100% \t Train loss: 0.059 took: 6.26s  Val. loss: 0.099  Val. score: 97.639%\n",
      "Training finished, took 153.914s\n",
      "\n",
      "Parameters configuration 58 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0032469236985254225\n",
      "h_sizes \t [784, 268, 80, 25]\n",
      "penalty \t 0.00048641540439475165\n",
      "dropout \t 0.22363118687779257\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.5074 +/- 0.1066\n",
      "Time for evaluation: 461.7 s\n",
      "Estimated time to finish : 6.20 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.561 took: 5.03s  Val. loss: 0.265  Val. score: 92.156%\n",
      "Epoch 2, 100% \t Train loss: 0.270 took: 5.10s  Val. loss: 0.192  Val. score: 94.417%\n",
      "Epoch 3, 100% \t Train loss: 0.205 took: 4.86s  Val. loss: 0.156  Val. score: 95.356%\n",
      "Epoch 4, 100% \t Train loss: 0.167 took: 5.12s  Val. loss: 0.136  Val. score: 95.967%\n",
      "Epoch 5, 100% \t Train loss: 0.141 took: 5.17s  Val. loss: 0.122  Val. score: 96.350%\n",
      "Epoch 6, 100% \t Train loss: 0.123 took: 5.22s  Val. loss: 0.110  Val. score: 96.706%\n",
      "Epoch 7, 100% \t Train loss: 0.105 took: 5.25s  Val. loss: 0.104  Val. score: 96.939%\n",
      "Epoch 8, 100% \t Train loss: 0.097 took: 5.25s  Val. loss: 0.097  Val. score: 97.050%\n",
      "Epoch 9, 100% \t Train loss: 0.087 took: 5.02s  Val. loss: 0.097  Val. score: 97.106%\n",
      "Epoch 10, 100% \t Train loss: 0.078 took: 5.22s  Val. loss: 0.090  Val. score: 97.228%\n",
      "Epoch 11, 100% \t Train loss: 0.072 took: 5.32s  Val. loss: 0.090  Val. score: 97.267%\n",
      "Epoch 12, 100% \t Train loss: 0.067 took: 4.99s  Val. loss: 0.085  Val. score: 97.467%\n",
      "Epoch 13, 100% \t Train loss: 0.061 took: 5.27s  Val. loss: 0.084  Val. score: 97.444%\n",
      "Epoch 14, 100% \t Train loss: 0.057 took: 5.29s  Val. loss: 0.087  Val. score: 97.450%\n",
      "Epoch 15, 100% \t Train loss: 0.054 took: 4.97s  Val. loss: 0.084  Val. score: 97.506%\n",
      "Training finished, took 129.581s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.570 took: 5.05s  Val. loss: 0.269  Val. score: 92.167%\n",
      "Epoch 2, 100% \t Train loss: 0.284 took: 4.97s  Val. loss: 0.197  Val. score: 94.089%\n",
      "Epoch 3, 100% \t Train loss: 0.212 took: 5.01s  Val. loss: 0.161  Val. score: 95.061%\n",
      "Epoch 4, 100% \t Train loss: 0.175 took: 5.16s  Val. loss: 0.136  Val. score: 95.839%\n",
      "Epoch 5, 100% \t Train loss: 0.148 took: 5.85s  Val. loss: 0.120  Val. score: 96.356%\n",
      "Epoch 6, 100% \t Train loss: 0.127 took: 5.40s  Val. loss: 0.109  Val. score: 96.728%\n",
      "Epoch 7, 100% \t Train loss: 0.112 took: 5.05s  Val. loss: 0.105  Val. score: 96.856%\n",
      "Epoch 8, 100% \t Train loss: 0.094 took: 5.13s  Val. loss: 0.096  Val. score: 97.156%\n",
      "Epoch 9, 100% \t Train loss: 0.090 took: 5.25s  Val. loss: 0.093  Val. score: 97.206%\n",
      "Epoch 10, 100% \t Train loss: 0.083 took: 4.98s  Val. loss: 0.089  Val. score: 97.328%\n",
      "Epoch 11, 100% \t Train loss: 0.075 took: 5.00s  Val. loss: 0.090  Val. score: 97.378%\n",
      "Epoch 12, 100% \t Train loss: 0.068 took: 5.06s  Val. loss: 0.091  Val. score: 97.294%\n",
      "Epoch 13, 100% \t Train loss: 0.063 took: 5.24s  Val. loss: 0.084  Val. score: 97.500%\n",
      "Epoch 14, 100% \t Train loss: 0.059 took: 5.38s  Val. loss: 0.085  Val. score: 97.611%\n",
      "Epoch 15, 100% \t Train loss: 0.055 took: 5.30s  Val. loss: 0.085  Val. score: 97.567%\n",
      "Training finished, took 130.644s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.557 took: 5.11s  Val. loss: 0.272  Val. score: 92.200%\n",
      "Epoch 2, 100% \t Train loss: 0.265 took: 4.98s  Val. loss: 0.194  Val. score: 94.356%\n",
      "Epoch 3, 100% \t Train loss: 0.202 took: 5.04s  Val. loss: 0.163  Val. score: 95.089%\n",
      "Epoch 4, 100% \t Train loss: 0.165 took: 5.04s  Val. loss: 0.149  Val. score: 95.378%\n",
      "Epoch 5, 100% \t Train loss: 0.140 took: 4.95s  Val. loss: 0.124  Val. score: 96.194%\n",
      "Epoch 6, 100% \t Train loss: 0.119 took: 5.04s  Val. loss: 0.120  Val. score: 96.278%\n",
      "Epoch 7, 100% \t Train loss: 0.107 took: 5.09s  Val. loss: 0.110  Val. score: 96.522%\n",
      "Epoch 8, 100% \t Train loss: 0.095 took: 4.93s  Val. loss: 0.103  Val. score: 96.844%\n",
      "Epoch 9, 100% \t Train loss: 0.085 took: 5.23s  Val. loss: 0.100  Val. score: 96.972%\n",
      "Epoch 10, 100% \t Train loss: 0.075 took: 5.19s  Val. loss: 0.094  Val. score: 97.094%\n",
      "Epoch 11, 100% \t Train loss: 0.069 took: 5.06s  Val. loss: 0.099  Val. score: 97.039%\n",
      "Epoch 12, 100% \t Train loss: 0.062 took: 5.32s  Val. loss: 0.092  Val. score: 97.183%\n",
      "Epoch 13, 100% \t Train loss: 0.058 took: 5.16s  Val. loss: 0.090  Val. score: 97.217%\n",
      "Epoch 14, 100% \t Train loss: 0.055 took: 5.22s  Val. loss: 0.088  Val. score: 97.267%\n",
      "Epoch 15, 100% \t Train loss: 0.051 took: 5.27s  Val. loss: 0.089  Val. score: 97.383%\n",
      "Training finished, took 129.890s\n",
      "\n",
      "Parameters configuration 59 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0030584838248822067\n",
      "h_sizes \t [784, 187, 42]\n",
      "penalty \t 0.0001867424712621452\n",
      "dropout \t 0.17013854999580497\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4852 +/- 0.0762\n",
      "Time for evaluation: 391.3 s\n",
      "Estimated time to finish : 6.03 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.786 took: 11.65s  Val. loss: 0.279  Val. score: 92.517%\n",
      "Epoch 2, 100% \t Train loss: 0.234 took: 11.90s  Val. loss: 0.202  Val. score: 95.067%\n",
      "Epoch 3, 100% \t Train loss: 0.166 took: 13.87s  Val. loss: 0.151  Val. score: 96.183%\n",
      "Epoch 4, 100% \t Train loss: 0.133 took: 14.41s  Val. loss: 0.159  Val. score: 96.089%\n",
      "Epoch 5, 100% \t Train loss: 0.104 took: 14.66s  Val. loss: 0.152  Val. score: 96.433%\n",
      "Epoch 6, 100% \t Train loss: 0.089 took: 14.51s  Val. loss: 0.139  Val. score: 96.711%\n",
      "Epoch 7, 100% \t Train loss: 0.070 took: 14.54s  Val. loss: 0.145  Val. score: 96.828%\n",
      "Epoch 8, 100% \t Train loss: 0.060 took: 15.03s  Val. loss: 0.129  Val. score: 96.939%\n",
      "Epoch 9, 100% \t Train loss: 0.053 took: 14.38s  Val. loss: 0.134  Val. score: 97.244%\n",
      "Epoch 10, 100% \t Train loss: 0.046 took: 15.27s  Val. loss: 0.119  Val. score: 97.539%\n",
      "Epoch 11, 100% \t Train loss: 0.039 took: 14.64s  Val. loss: 0.147  Val. score: 97.389%\n",
      "Epoch 12, 100% \t Train loss: 0.034 took: 15.29s  Val. loss: 0.153  Val. score: 97.389%\n",
      "Epoch 13, 100% \t Train loss: 0.032 took: 15.29s  Val. loss: 0.121  Val. score: 97.400%\n",
      "Epoch 14, 100% \t Train loss: 0.027 took: 15.06s  Val. loss: 0.133  Val. score: 97.644%\n",
      "Epoch 15, 100% \t Train loss: 0.030 took: 15.78s  Val. loss: 0.159  Val. score: 97.333%\n",
      "Training finished, took 305.318s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.645 took: 11.73s  Val. loss: 0.303  Val. score: 91.650%\n",
      "Epoch 2, 100% \t Train loss: 0.208 took: 11.80s  Val. loss: 0.187  Val. score: 95.272%\n",
      "Epoch 3, 100% \t Train loss: 0.146 took: 13.47s  Val. loss: 0.150  Val. score: 95.972%\n",
      "Epoch 4, 100% \t Train loss: 0.110 took: 14.19s  Val. loss: 0.137  Val. score: 96.639%\n",
      "Epoch 5, 100% \t Train loss: 0.086 took: 14.19s  Val. loss: 0.135  Val. score: 96.689%\n",
      "Epoch 6, 100% \t Train loss: 0.070 took: 14.80s  Val. loss: 0.140  Val. score: 96.883%\n",
      "Epoch 7, 100% \t Train loss: 0.059 took: 14.15s  Val. loss: 0.133  Val. score: 96.772%\n",
      "Epoch 8, 100% \t Train loss: 0.054 took: 14.63s  Val. loss: 0.133  Val. score: 97.078%\n",
      "Epoch 9, 100% \t Train loss: 0.044 took: 14.45s  Val. loss: 0.140  Val. score: 97.011%\n",
      "Epoch 10, 100% \t Train loss: 0.036 took: 14.00s  Val. loss: 0.127  Val. score: 97.389%\n",
      "Epoch 11, 100% \t Train loss: 0.035 took: 14.15s  Val. loss: 0.129  Val. score: 97.339%\n",
      "Epoch 12, 100% \t Train loss: 0.029 took: 14.80s  Val. loss: 0.143  Val. score: 97.372%\n",
      "Epoch 13, 100% \t Train loss: 0.028 took: 14.23s  Val. loss: 0.159  Val. score: 97.289%\n",
      "Epoch 14, 100% \t Train loss: 0.025 took: 14.69s  Val. loss: 0.129  Val. score: 97.550%\n",
      "Epoch 15, 100% \t Train loss: 0.019 took: 14.34s  Val. loss: 0.158  Val. score: 97.428%\n",
      "Training finished, took 298.580s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.765 took: 12.17s  Val. loss: 0.280  Val. score: 92.656%\n",
      "Epoch 2, 100% \t Train loss: 0.230 took: 11.80s  Val. loss: 0.181  Val. score: 95.361%\n",
      "Epoch 3, 100% \t Train loss: 0.153 took: 14.06s  Val. loss: 0.170  Val. score: 95.689%\n",
      "Epoch 4, 100% \t Train loss: 0.122 took: 14.23s  Val. loss: 0.137  Val. score: 96.472%\n",
      "Epoch 5, 100% \t Train loss: 0.095 took: 14.02s  Val. loss: 0.128  Val. score: 96.678%\n",
      "Epoch 6, 100% \t Train loss: 0.073 took: 13.92s  Val. loss: 0.121  Val. score: 97.133%\n",
      "Epoch 7, 100% \t Train loss: 0.060 took: 14.42s  Val. loss: 0.124  Val. score: 97.294%\n",
      "Epoch 8, 100% \t Train loss: 0.055 took: 14.21s  Val. loss: 0.148  Val. score: 96.739%\n",
      "Epoch 9, 100% \t Train loss: 0.047 took: 14.11s  Val. loss: 0.122  Val. score: 97.356%\n",
      "Epoch 10, 100% \t Train loss: 0.041 took: 14.57s  Val. loss: 0.129  Val. score: 97.328%\n",
      "Epoch 11, 100% \t Train loss: 0.033 took: 14.67s  Val. loss: 0.128  Val. score: 97.572%\n",
      "Epoch 12, 100% \t Train loss: 0.035 took: 14.38s  Val. loss: 0.125  Val. score: 97.594%\n",
      "Epoch 13, 100% \t Train loss: 0.026 took: 14.77s  Val. loss: 0.133  Val. score: 97.428%\n",
      "Epoch 14, 100% \t Train loss: 0.024 took: 13.86s  Val. loss: 0.145  Val. score: 97.678%\n",
      "Epoch 15, 100% \t Train loss: 0.019 took: 14.07s  Val. loss: 0.143  Val. score: 97.667%\n",
      "Training finished, took 296.973s\n",
      "\n",
      "Parameters configuration 60 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.014696218671370463\n",
      "h_sizes \t [784, 431, 224, 123, 69, 40, 21]\n",
      "penalty \t 0.000940110672788446\n",
      "dropout \t 0.04132485098406263\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4759 +/- 0.1403\n",
      "Time for evaluation: 902.1 s\n",
      "Estimated time to finish : 5.95 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.356 took: 4.63s  Val. loss: 0.191  Val. score: 94.367%\n",
      "Epoch 2, 100% \t Train loss: 0.148 took: 4.65s  Val. loss: 0.142  Val. score: 95.700%\n",
      "Epoch 3, 100% \t Train loss: 0.102 took: 4.82s  Val. loss: 0.133  Val. score: 96.094%\n",
      "Epoch 4, 100% \t Train loss: 0.078 took: 4.68s  Val. loss: 0.114  Val. score: 96.589%\n",
      "Epoch 5, 100% \t Train loss: 0.061 took: 5.01s  Val. loss: 0.118  Val. score: 96.456%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, 100% \t Train loss: 0.046 took: 4.83s  Val. loss: 0.104  Val. score: 97.006%\n",
      "Epoch 7, 100% \t Train loss: 0.036 took: 5.10s  Val. loss: 0.116  Val. score: 96.833%\n",
      "Epoch 8, 100% \t Train loss: 0.027 took: 4.97s  Val. loss: 0.106  Val. score: 97.061%\n",
      "Epoch 9, 100% \t Train loss: 0.020 took: 4.97s  Val. loss: 0.111  Val. score: 97.267%\n",
      "Epoch 10, 100% \t Train loss: 0.019 took: 4.75s  Val. loss: 0.117  Val. score: 97.144%\n",
      "Epoch 11, 100% \t Train loss: 0.013 took: 4.95s  Val. loss: 0.120  Val. score: 97.189%\n",
      "Epoch 12, 100% \t Train loss: 0.012 took: 5.16s  Val. loss: 0.117  Val. score: 97.289%\n",
      "Epoch 13, 100% \t Train loss: 0.009 took: 5.07s  Val. loss: 0.133  Val. score: 97.261%\n",
      "Epoch 14, 100% \t Train loss: 0.009 took: 4.94s  Val. loss: 0.134  Val. score: 97.322%\n",
      "Epoch 15, 100% \t Train loss: 0.007 took: 5.13s  Val. loss: 0.138  Val. score: 97.294%\n",
      "Training finished, took 124.086s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.345 took: 4.72s  Val. loss: 0.187  Val. score: 94.372%\n",
      "Epoch 2, 100% \t Train loss: 0.141 took: 4.74s  Val. loss: 0.131  Val. score: 96.089%\n",
      "Epoch 3, 100% \t Train loss: 0.096 took: 4.63s  Val. loss: 0.113  Val. score: 96.600%\n",
      "Epoch 4, 100% \t Train loss: 0.072 took: 5.05s  Val. loss: 0.101  Val. score: 96.894%\n",
      "Epoch 5, 100% \t Train loss: 0.055 took: 5.08s  Val. loss: 0.106  Val. score: 96.856%\n",
      "Epoch 6, 100% \t Train loss: 0.042 took: 4.86s  Val. loss: 0.099  Val. score: 97.200%\n",
      "Epoch 7, 100% \t Train loss: 0.031 took: 4.88s  Val. loss: 0.097  Val. score: 97.350%\n",
      "Epoch 8, 100% \t Train loss: 0.025 took: 5.05s  Val. loss: 0.097  Val. score: 97.256%\n",
      "Epoch 9, 100% \t Train loss: 0.018 took: 5.10s  Val. loss: 0.103  Val. score: 97.367%\n",
      "Epoch 10, 100% \t Train loss: 0.013 took: 5.07s  Val. loss: 0.103  Val. score: 97.617%\n",
      "Epoch 11, 100% \t Train loss: 0.010 took: 4.84s  Val. loss: 0.116  Val. score: 97.267%\n",
      "Epoch 12, 100% \t Train loss: 0.009 took: 5.02s  Val. loss: 0.115  Val. score: 97.439%\n",
      "Epoch 13, 100% \t Train loss: 0.008 took: 5.21s  Val. loss: 0.108  Val. score: 97.656%\n",
      "Epoch 14, 100% \t Train loss: 0.006 took: 5.14s  Val. loss: 0.111  Val. score: 97.572%\n",
      "Epoch 15, 100% \t Train loss: 0.005 took: 5.07s  Val. loss: 0.115  Val. score: 97.572%\n",
      "Training finished, took 125.853s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.337 took: 4.58s  Val. loss: 0.187  Val. score: 94.494%\n",
      "Epoch 2, 100% \t Train loss: 0.144 took: 4.84s  Val. loss: 0.132  Val. score: 95.933%\n",
      "Epoch 3, 100% \t Train loss: 0.097 took: 4.78s  Val. loss: 0.108  Val. score: 96.828%\n",
      "Epoch 4, 100% \t Train loss: 0.072 took: 5.03s  Val. loss: 0.105  Val. score: 96.800%\n",
      "Epoch 5, 100% \t Train loss: 0.054 took: 4.92s  Val. loss: 0.114  Val. score: 96.756%\n",
      "Epoch 6, 100% \t Train loss: 0.043 took: 5.30s  Val. loss: 0.097  Val. score: 97.350%\n",
      "Epoch 7, 100% \t Train loss: 0.029 took: 5.09s  Val. loss: 0.102  Val. score: 97.317%\n",
      "Epoch 8, 100% \t Train loss: 0.025 took: 5.05s  Val. loss: 0.097  Val. score: 97.539%\n",
      "Epoch 9, 100% \t Train loss: 0.018 took: 4.79s  Val. loss: 0.109  Val. score: 97.283%\n",
      "Epoch 10, 100% \t Train loss: 0.016 took: 4.89s  Val. loss: 0.098  Val. score: 97.656%\n",
      "Epoch 11, 100% \t Train loss: 0.012 took: 4.94s  Val. loss: 0.125  Val. score: 97.117%\n",
      "Epoch 12, 100% \t Train loss: 0.011 took: 4.94s  Val. loss: 0.115  Val. score: 97.400%\n",
      "Epoch 13, 100% \t Train loss: 0.008 took: 5.06s  Val. loss: 0.111  Val. score: 97.561%\n",
      "Epoch 14, 100% \t Train loss: 0.006 took: 4.96s  Val. loss: 0.115  Val. score: 97.694%\n",
      "Epoch 15, 100% \t Train loss: 0.006 took: 5.22s  Val. loss: 0.110  Val. score: 97.767%\n",
      "Training finished, took 126.555s\n",
      "\n",
      "Parameters configuration 61 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.012079612733427109\n",
      "h_sizes \t [784, 171, 32]\n",
      "penalty \t 0.0007922629325822313\n",
      "dropout \t 0.001652816978295918\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5444 +/- 0.1938\n",
      "Time for evaluation: 377.7 s\n",
      "Estimated time to finish : 5.77 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.336 took: 7.03s  Val. loss: 0.168  Val. score: 94.928%\n",
      "Epoch 2, 100% \t Train loss: 0.127 took: 6.95s  Val. loss: 0.127  Val. score: 96.272%\n",
      "Epoch 3, 100% \t Train loss: 0.082 took: 7.26s  Val. loss: 0.110  Val. score: 96.661%\n",
      "Epoch 4, 100% \t Train loss: 0.060 took: 8.04s  Val. loss: 0.112  Val. score: 96.844%\n",
      "Epoch 5, 100% \t Train loss: 0.042 took: 7.93s  Val. loss: 0.118  Val. score: 96.761%\n",
      "Epoch 6, 100% \t Train loss: 0.035 took: 7.67s  Val. loss: 0.108  Val. score: 97.272%\n",
      "Epoch 7, 100% \t Train loss: 0.027 took: 7.31s  Val. loss: 0.106  Val. score: 97.383%\n",
      "Epoch 8, 100% \t Train loss: 0.021 took: 7.59s  Val. loss: 0.113  Val. score: 97.261%\n",
      "Epoch 9, 100% \t Train loss: 0.017 took: 7.54s  Val. loss: 0.117  Val. score: 97.322%\n",
      "Epoch 10, 100% \t Train loss: 0.014 took: 7.37s  Val. loss: 0.130  Val. score: 97.333%\n",
      "Epoch 11, 100% \t Train loss: 0.010 took: 7.58s  Val. loss: 0.143  Val. score: 97.183%\n",
      "Epoch 12, 100% \t Train loss: 0.009 took: 7.86s  Val. loss: 0.142  Val. score: 97.206%\n",
      "Epoch 13, 100% \t Train loss: 0.010 took: 7.46s  Val. loss: 0.137  Val. score: 97.350%\n",
      "Epoch 14, 100% \t Train loss: 0.008 took: 7.98s  Val. loss: 0.137  Val. score: 97.578%\n",
      "Epoch 15, 100% \t Train loss: 0.007 took: 7.52s  Val. loss: 0.146  Val. score: 97.372%\n",
      "Training finished, took 175.618s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.326 took: 6.62s  Val. loss: 0.160  Val. score: 95.289%\n",
      "Epoch 2, 100% \t Train loss: 0.123 took: 6.98s  Val. loss: 0.121  Val. score: 96.444%\n",
      "Epoch 3, 100% \t Train loss: 0.082 took: 7.38s  Val. loss: 0.121  Val. score: 96.600%\n",
      "Epoch 4, 100% \t Train loss: 0.064 took: 8.12s  Val. loss: 0.105  Val. score: 97.039%\n",
      "Epoch 5, 100% \t Train loss: 0.052 took: 7.54s  Val. loss: 0.120  Val. score: 96.717%\n",
      "Epoch 6, 100% \t Train loss: 0.037 took: 7.66s  Val. loss: 0.116  Val. score: 97.083%\n",
      "Epoch 7, 100% \t Train loss: 0.028 took: 7.83s  Val. loss: 0.122  Val. score: 97.144%\n",
      "Epoch 8, 100% \t Train loss: 0.025 took: 7.57s  Val. loss: 0.124  Val. score: 97.161%\n",
      "Epoch 9, 100% \t Train loss: 0.016 took: 7.72s  Val. loss: 0.137  Val. score: 97.161%\n",
      "Epoch 10, 100% \t Train loss: 0.017 took: 8.37s  Val. loss: 0.138  Val. score: 97.139%\n",
      "Epoch 11, 100% \t Train loss: 0.015 took: 7.76s  Val. loss: 0.129  Val. score: 97.411%\n",
      "Epoch 12, 100% \t Train loss: 0.011 took: 7.66s  Val. loss: 0.133  Val. score: 97.556%\n",
      "Epoch 13, 100% \t Train loss: 0.010 took: 7.72s  Val. loss: 0.149  Val. score: 97.378%\n",
      "Epoch 14, 100% \t Train loss: 0.010 took: 7.58s  Val. loss: 0.136  Val. score: 97.550%\n",
      "Epoch 15, 100% \t Train loss: 0.009 took: 7.55s  Val. loss: 0.156  Val. score: 97.489%\n",
      "Training finished, took 176.602s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.324 took: 6.57s  Val. loss: 0.171  Val. score: 94.994%\n",
      "Epoch 2, 100% \t Train loss: 0.123 took: 6.85s  Val. loss: 0.121  Val. score: 96.239%\n",
      "Epoch 3, 100% \t Train loss: 0.085 took: 7.35s  Val. loss: 0.128  Val. score: 95.956%\n",
      "Epoch 4, 100% \t Train loss: 0.062 took: 7.84s  Val. loss: 0.117  Val. score: 96.567%\n",
      "Epoch 5, 100% \t Train loss: 0.045 took: 7.50s  Val. loss: 0.105  Val. score: 97.056%\n",
      "Epoch 6, 100% \t Train loss: 0.041 took: 7.52s  Val. loss: 0.102  Val. score: 97.250%\n",
      "Epoch 7, 100% \t Train loss: 0.027 took: 7.81s  Val. loss: 0.109  Val. score: 97.256%\n",
      "Epoch 8, 100% \t Train loss: 0.022 took: 7.74s  Val. loss: 0.112  Val. score: 97.311%\n",
      "Epoch 9, 100% \t Train loss: 0.021 took: 7.73s  Val. loss: 0.126  Val. score: 97.094%\n",
      "Epoch 10, 100% \t Train loss: 0.017 took: 7.61s  Val. loss: 0.112  Val. score: 97.567%\n",
      "Epoch 11, 100% \t Train loss: 0.010 took: 7.60s  Val. loss: 0.128  Val. score: 97.372%\n",
      "Epoch 12, 100% \t Train loss: 0.012 took: 7.80s  Val. loss: 0.120  Val. score: 97.572%\n",
      "Epoch 13, 100% \t Train loss: 0.008 took: 7.66s  Val. loss: 0.137  Val. score: 97.361%\n",
      "Epoch 14, 100% \t Train loss: 0.006 took: 7.74s  Val. loss: 0.156  Val. score: 97.317%\n",
      "Epoch 15, 100% \t Train loss: 0.009 took: 7.62s  Val. loss: 0.138  Val. score: 97.461%\n",
      "Training finished, took 175.259s\n",
      "\n",
      "Parameters configuration 62 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.015389540724715416\n",
      "h_sizes \t [784, 276, 104, 30]\n",
      "penalty \t 0.0006799702539408856\n",
      "dropout \t 0.004042950171734394\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4407 +/- 0.0498\n",
      "Time for evaluation: 528.7 s\n",
      "Estimated time to finish : 5.62 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.624 took: 4.86s  Val. loss: 0.282  Val. score: 91.933%\n",
      "Epoch 2, 100% \t Train loss: 0.299 took: 5.04s  Val. loss: 0.211  Val. score: 93.767%\n",
      "Epoch 3, 100% \t Train loss: 0.228 took: 5.05s  Val. loss: 0.166  Val. score: 95.178%\n",
      "Epoch 4, 100% \t Train loss: 0.185 took: 5.31s  Val. loss: 0.142  Val. score: 95.678%\n",
      "Epoch 5, 100% \t Train loss: 0.157 took: 5.18s  Val. loss: 0.124  Val. score: 96.189%\n",
      "Epoch 6, 100% \t Train loss: 0.138 took: 5.43s  Val. loss: 0.113  Val. score: 96.511%\n",
      "Epoch 7, 100% \t Train loss: 0.120 took: 5.64s  Val. loss: 0.103  Val. score: 96.828%\n",
      "Epoch 8, 100% \t Train loss: 0.109 took: 5.49s  Val. loss: 0.099  Val. score: 96.978%\n",
      "Epoch 9, 100% \t Train loss: 0.098 took: 5.54s  Val. loss: 0.095  Val. score: 97.078%\n",
      "Epoch 10, 100% \t Train loss: 0.087 took: 5.55s  Val. loss: 0.086  Val. score: 97.389%\n",
      "Epoch 11, 100% \t Train loss: 0.081 took: 5.46s  Val. loss: 0.086  Val. score: 97.383%\n",
      "Epoch 12, 100% \t Train loss: 0.073 took: 5.36s  Val. loss: 0.087  Val. score: 97.322%\n",
      "Epoch 13, 100% \t Train loss: 0.066 took: 5.37s  Val. loss: 0.082  Val. score: 97.467%\n",
      "Epoch 14, 100% \t Train loss: 0.062 took: 5.40s  Val. loss: 0.082  Val. score: 97.522%\n",
      "Epoch 15, 100% \t Train loss: 0.059 took: 5.31s  Val. loss: 0.078  Val. score: 97.611%\n",
      "Training finished, took 134.645s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.598 took: 5.40s  Val. loss: 0.285  Val. score: 91.656%\n",
      "Epoch 2, 100% \t Train loss: 0.288 took: 5.50s  Val. loss: 0.209  Val. score: 93.822%\n",
      "Epoch 3, 100% \t Train loss: 0.225 took: 5.63s  Val. loss: 0.171  Val. score: 94.844%\n",
      "Epoch 4, 100% \t Train loss: 0.183 took: 5.47s  Val. loss: 0.147  Val. score: 95.528%\n",
      "Epoch 5, 100% \t Train loss: 0.157 took: 5.50s  Val. loss: 0.135  Val. score: 95.850%\n",
      "Epoch 6, 100% \t Train loss: 0.132 took: 5.98s  Val. loss: 0.123  Val. score: 96.200%\n",
      "Epoch 7, 100% \t Train loss: 0.120 took: 5.79s  Val. loss: 0.115  Val. score: 96.589%\n",
      "Epoch 8, 100% \t Train loss: 0.105 took: 5.45s  Val. loss: 0.107  Val. score: 96.717%\n",
      "Epoch 9, 100% \t Train loss: 0.094 took: 5.45s  Val. loss: 0.100  Val. score: 96.889%\n",
      "Epoch 10, 100% \t Train loss: 0.086 took: 5.71s  Val. loss: 0.098  Val. score: 96.989%\n",
      "Epoch 11, 100% \t Train loss: 0.081 took: 5.73s  Val. loss: 0.096  Val. score: 97.128%\n",
      "Epoch 12, 100% \t Train loss: 0.072 took: 5.50s  Val. loss: 0.094  Val. score: 97.122%\n",
      "Epoch 13, 100% \t Train loss: 0.068 took: 5.77s  Val. loss: 0.092  Val. score: 97.222%\n",
      "Epoch 14, 100% \t Train loss: 0.061 took: 5.44s  Val. loss: 0.089  Val. score: 97.367%\n",
      "Epoch 15, 100% \t Train loss: 0.061 took: 5.67s  Val. loss: 0.088  Val. score: 97.372%\n",
      "Training finished, took 139.377s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.592 took: 5.27s  Val. loss: 0.278  Val. score: 92.039%\n",
      "Epoch 2, 100% \t Train loss: 0.278 took: 5.22s  Val. loss: 0.207  Val. score: 94.161%\n",
      "Epoch 3, 100% \t Train loss: 0.214 took: 5.30s  Val. loss: 0.172  Val. score: 94.961%\n",
      "Epoch 4, 100% \t Train loss: 0.173 took: 5.31s  Val. loss: 0.148  Val. score: 95.694%\n",
      "Epoch 5, 100% \t Train loss: 0.147 took: 5.18s  Val. loss: 0.136  Val. score: 95.994%\n",
      "Epoch 6, 100% \t Train loss: 0.129 took: 5.40s  Val. loss: 0.125  Val. score: 96.350%\n",
      "Epoch 7, 100% \t Train loss: 0.114 took: 5.50s  Val. loss: 0.114  Val. score: 96.589%\n",
      "Epoch 8, 100% \t Train loss: 0.102 took: 5.53s  Val. loss: 0.110  Val. score: 96.839%\n",
      "Epoch 9, 100% \t Train loss: 0.093 took: 5.68s  Val. loss: 0.103  Val. score: 97.078%\n",
      "Epoch 10, 100% \t Train loss: 0.086 took: 5.39s  Val. loss: 0.102  Val. score: 97.106%\n",
      "Epoch 11, 100% \t Train loss: 0.078 took: 5.55s  Val. loss: 0.099  Val. score: 97.161%\n",
      "Epoch 12, 100% \t Train loss: 0.071 took: 5.19s  Val. loss: 0.100  Val. score: 97.261%\n",
      "Epoch 13, 100% \t Train loss: 0.064 took: 5.35s  Val. loss: 0.097  Val. score: 97.233%\n",
      "Epoch 14, 100% \t Train loss: 0.060 took: 5.52s  Val. loss: 0.093  Val. score: 97.400%\n",
      "Epoch 15, 100% \t Train loss: 0.057 took: 5.14s  Val. loss: 0.094  Val. score: 97.378%\n",
      "Training finished, took 134.672s\n",
      "\n",
      "Parameters configuration 63 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0024735655099754287\n",
      "h_sizes \t [784, 203, 44]\n",
      "penalty \t 0.001556507293493741\n",
      "dropout \t 0.18549367920735485\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4537 +/- 0.1113\n",
      "Time for evaluation: 409.9 s\n",
      "Estimated time to finish : 5.46 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.483 took: 5.04s  Val. loss: 0.203  Val. score: 93.850%\n",
      "Epoch 2, 100% \t Train loss: 0.229 took: 5.02s  Val. loss: 0.152  Val. score: 95.267%\n",
      "Epoch 3, 100% \t Train loss: 0.176 took: 4.91s  Val. loss: 0.128  Val. score: 96.122%\n",
      "Epoch 4, 100% \t Train loss: 0.138 took: 5.36s  Val. loss: 0.117  Val. score: 96.422%\n",
      "Epoch 5, 100% \t Train loss: 0.119 took: 5.33s  Val. loss: 0.102  Val. score: 96.900%\n",
      "Epoch 6, 100% \t Train loss: 0.107 took: 5.24s  Val. loss: 0.098  Val. score: 97.033%\n",
      "Epoch 7, 100% \t Train loss: 0.093 took: 5.23s  Val. loss: 0.097  Val. score: 97.178%\n",
      "Epoch 8, 100% \t Train loss: 0.087 took: 5.06s  Val. loss: 0.092  Val. score: 97.233%\n",
      "Epoch 9, 100% \t Train loss: 0.077 took: 5.42s  Val. loss: 0.091  Val. score: 97.428%\n",
      "Epoch 10, 100% \t Train loss: 0.070 took: 5.10s  Val. loss: 0.085  Val. score: 97.633%\n",
      "Epoch 11, 100% \t Train loss: 0.068 took: 5.22s  Val. loss: 0.088  Val. score: 97.350%\n",
      "Epoch 12, 100% \t Train loss: 0.059 took: 5.45s  Val. loss: 0.093  Val. score: 97.372%\n",
      "Epoch 13, 100% \t Train loss: 0.056 took: 5.45s  Val. loss: 0.088  Val. score: 97.594%\n",
      "Epoch 14, 100% \t Train loss: 0.051 took: 5.28s  Val. loss: 0.091  Val. score: 97.533%\n",
      "Epoch 15, 100% \t Train loss: 0.052 took: 5.47s  Val. loss: 0.085  Val. score: 97.706%\n",
      "Training finished, took 130.577s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.474 took: 5.19s  Val. loss: 0.208  Val. score: 94.000%\n",
      "Epoch 2, 100% \t Train loss: 0.228 took: 5.00s  Val. loss: 0.157  Val. score: 95.283%\n",
      "Epoch 3, 100% \t Train loss: 0.174 took: 5.06s  Val. loss: 0.128  Val. score: 96.144%\n",
      "Epoch 4, 100% \t Train loss: 0.146 took: 5.46s  Val. loss: 0.116  Val. score: 96.539%\n",
      "Epoch 5, 100% \t Train loss: 0.119 took: 5.24s  Val. loss: 0.106  Val. score: 96.761%\n",
      "Epoch 6, 100% \t Train loss: 0.104 took: 5.49s  Val. loss: 0.102  Val. score: 97.039%\n",
      "Epoch 7, 100% \t Train loss: 0.093 took: 5.32s  Val. loss: 0.102  Val. score: 96.967%\n",
      "Epoch 8, 100% \t Train loss: 0.081 took: 5.33s  Val. loss: 0.095  Val. score: 97.156%\n",
      "Epoch 9, 100% \t Train loss: 0.077 took: 5.50s  Val. loss: 0.096  Val. score: 97.356%\n",
      "Epoch 10, 100% \t Train loss: 0.072 took: 5.35s  Val. loss: 0.094  Val. score: 97.433%\n",
      "Epoch 11, 100% \t Train loss: 0.065 took: 5.16s  Val. loss: 0.092  Val. score: 97.383%\n",
      "Epoch 12, 100% \t Train loss: 0.058 took: 5.40s  Val. loss: 0.099  Val. score: 97.339%\n",
      "Epoch 13, 100% \t Train loss: 0.058 took: 5.37s  Val. loss: 0.092  Val. score: 97.578%\n",
      "Epoch 14, 100% \t Train loss: 0.050 took: 5.60s  Val. loss: 0.094  Val. score: 97.467%\n",
      "Epoch 15, 100% \t Train loss: 0.044 took: 5.59s  Val. loss: 0.094  Val. score: 97.561%\n",
      "Training finished, took 133.265s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.459 took: 5.19s  Val. loss: 0.222  Val. score: 93.289%\n",
      "Epoch 2, 100% \t Train loss: 0.226 took: 5.11s  Val. loss: 0.156  Val. score: 95.378%\n",
      "Epoch 3, 100% \t Train loss: 0.171 took: 5.40s  Val. loss: 0.131  Val. score: 96.028%\n",
      "Epoch 4, 100% \t Train loss: 0.143 took: 5.66s  Val. loss: 0.114  Val. score: 96.622%\n",
      "Epoch 5, 100% \t Train loss: 0.121 took: 5.53s  Val. loss: 0.108  Val. score: 96.661%\n",
      "Epoch 6, 100% \t Train loss: 0.106 took: 5.55s  Val. loss: 0.104  Val. score: 96.878%\n",
      "Epoch 7, 100% \t Train loss: 0.093 took: 5.54s  Val. loss: 0.097  Val. score: 97.256%\n",
      "Epoch 8, 100% \t Train loss: 0.084 took: 5.72s  Val. loss: 0.092  Val. score: 97.367%\n",
      "Epoch 9, 100% \t Train loss: 0.077 took: 5.43s  Val. loss: 0.091  Val. score: 97.394%\n",
      "Epoch 10, 100% \t Train loss: 0.070 took: 5.76s  Val. loss: 0.091  Val. score: 97.433%\n",
      "Epoch 11, 100% \t Train loss: 0.065 took: 5.57s  Val. loss: 0.088  Val. score: 97.561%\n",
      "Epoch 12, 100% \t Train loss: 0.059 took: 5.47s  Val. loss: 0.093  Val. score: 97.433%\n",
      "Epoch 13, 100% \t Train loss: 0.056 took: 5.23s  Val. loss: 0.090  Val. score: 97.594%\n",
      "Epoch 14, 100% \t Train loss: 0.052 took: 5.22s  Val. loss: 0.096  Val. score: 97.478%\n",
      "Epoch 15, 100% \t Train loss: 0.048 took: 5.56s  Val. loss: 0.092  Val. score: 97.656%\n",
      "Training finished, took 135.987s\n",
      "\n",
      "Parameters configuration 64 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.006246113586783729\n",
      "h_sizes \t [784, 187, 48]\n",
      "penalty \t 0.0021836989752139447\n",
      "dropout \t 0.23167648243336392\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6407 +/- 0.0599\n",
      "Time for evaluation: 401.0 s\n",
      "Estimated time to finish : 5.29 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.431 took: 4.77s  Val. loss: 0.183  Val. score: 94.617%\n",
      "Epoch 2, 100% \t Train loss: 0.219 took: 4.53s  Val. loss: 0.139  Val. score: 95.783%\n",
      "Epoch 3, 100% \t Train loss: 0.173 took: 4.65s  Val. loss: 0.121  Val. score: 96.439%\n",
      "Epoch 4, 100% \t Train loss: 0.143 took: 4.53s  Val. loss: 0.111  Val. score: 96.783%\n",
      "Epoch 5, 100% \t Train loss: 0.125 took: 4.84s  Val. loss: 0.106  Val. score: 96.967%\n",
      "Epoch 6, 100% \t Train loss: 0.113 took: 4.69s  Val. loss: 0.105  Val. score: 97.017%\n",
      "Epoch 7, 100% \t Train loss: 0.100 took: 4.76s  Val. loss: 0.112  Val. score: 96.772%\n",
      "Epoch 8, 100% \t Train loss: 0.092 took: 4.89s  Val. loss: 0.101  Val. score: 97.244%\n",
      "Epoch 9, 100% \t Train loss: 0.085 took: 4.73s  Val. loss: 0.104  Val. score: 97.106%\n",
      "Epoch 10, 100% \t Train loss: 0.076 took: 4.71s  Val. loss: 0.100  Val. score: 97.278%\n",
      "Epoch 11, 100% \t Train loss: 0.074 took: 4.81s  Val. loss: 0.098  Val. score: 97.350%\n",
      "Epoch 12, 100% \t Train loss: 0.065 took: 4.89s  Val. loss: 0.103  Val. score: 97.333%\n",
      "Epoch 13, 100% \t Train loss: 0.063 took: 4.88s  Val. loss: 0.098  Val. score: 97.522%\n",
      "Epoch 14, 100% \t Train loss: 0.056 took: 4.86s  Val. loss: 0.100  Val. score: 97.528%\n",
      "Epoch 15, 100% \t Train loss: 0.054 took: 5.15s  Val. loss: 0.125  Val. score: 97.156%\n",
      "Training finished, took 123.884s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.415 took: 4.90s  Val. loss: 0.178  Val. score: 94.689%\n",
      "Epoch 2, 100% \t Train loss: 0.203 took: 5.39s  Val. loss: 0.146  Val. score: 95.622%\n",
      "Epoch 3, 100% \t Train loss: 0.160 took: 5.01s  Val. loss: 0.125  Val. score: 96.333%\n",
      "Epoch 4, 100% \t Train loss: 0.132 took: 5.16s  Val. loss: 0.113  Val. score: 96.639%\n",
      "Epoch 5, 100% \t Train loss: 0.115 took: 5.29s  Val. loss: 0.129  Val. score: 96.417%\n",
      "Epoch 6, 100% \t Train loss: 0.107 took: 5.16s  Val. loss: 0.112  Val. score: 97.067%\n",
      "Epoch 7, 100% \t Train loss: 0.093 took: 5.05s  Val. loss: 0.108  Val. score: 97.122%\n",
      "Epoch 8, 100% \t Train loss: 0.084 took: 5.26s  Val. loss: 0.114  Val. score: 96.967%\n",
      "Epoch 9, 100% \t Train loss: 0.076 took: 5.23s  Val. loss: 0.104  Val. score: 97.233%\n",
      "Epoch 10, 100% \t Train loss: 0.073 took: 4.97s  Val. loss: 0.100  Val. score: 97.411%\n",
      "Epoch 11, 100% \t Train loss: 0.068 took: 5.05s  Val. loss: 0.104  Val. score: 97.267%\n",
      "Epoch 12, 100% \t Train loss: 0.061 took: 4.94s  Val. loss: 0.109  Val. score: 97.283%\n",
      "Epoch 13, 100% \t Train loss: 0.056 took: 4.97s  Val. loss: 0.110  Val. score: 97.317%\n",
      "Epoch 14, 100% \t Train loss: 0.053 took: 4.98s  Val. loss: 0.116  Val. score: 97.233%\n",
      "Epoch 15, 100% \t Train loss: 0.051 took: 4.88s  Val. loss: 0.109  Val. score: 97.433%\n",
      "Training finished, took 131.426s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.411 took: 5.27s  Val. loss: 0.168  Val. score: 94.950%\n",
      "Epoch 2, 100% \t Train loss: 0.205 took: 4.96s  Val. loss: 0.134  Val. score: 96.050%\n",
      "Epoch 3, 100% \t Train loss: 0.159 took: 4.97s  Val. loss: 0.118  Val. score: 96.633%\n",
      "Epoch 4, 100% \t Train loss: 0.137 took: 4.96s  Val. loss: 0.109  Val. score: 96.917%\n",
      "Epoch 5, 100% \t Train loss: 0.120 took: 5.21s  Val. loss: 0.101  Val. score: 97.211%\n",
      "Epoch 6, 100% \t Train loss: 0.108 took: 5.04s  Val. loss: 0.105  Val. score: 97.206%\n",
      "Epoch 7, 100% \t Train loss: 0.096 took: 5.08s  Val. loss: 0.099  Val. score: 97.394%\n",
      "Epoch 8, 100% \t Train loss: 0.088 took: 5.00s  Val. loss: 0.104  Val. score: 97.183%\n",
      "Epoch 9, 100% \t Train loss: 0.078 took: 5.03s  Val. loss: 0.102  Val. score: 97.406%\n",
      "Epoch 10, 100% \t Train loss: 0.074 took: 4.91s  Val. loss: 0.103  Val. score: 97.411%\n",
      "Epoch 11, 100% \t Train loss: 0.071 took: 5.18s  Val. loss: 0.103  Val. score: 97.428%\n",
      "Epoch 12, 100% \t Train loss: 0.068 took: 4.85s  Val. loss: 0.108  Val. score: 97.372%\n",
      "Epoch 13, 100% \t Train loss: 0.062 took: 4.81s  Val. loss: 0.100  Val. score: 97.567%\n",
      "Epoch 14, 100% \t Train loss: 0.061 took: 4.86s  Val. loss: 0.108  Val. score: 97.428%\n",
      "Epoch 15, 100% \t Train loss: 0.054 took: 5.20s  Val. loss: 0.111  Val. score: 97.478%\n",
      "Training finished, took 129.526s\n",
      "\n",
      "Parameters configuration 65 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.014469070002168016\n",
      "h_sizes \t [784, 174, 29]\n",
      "penalty \t 0.003371452354480753\n",
      "dropout \t 0.21974732157771126\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.3556 +/- 0.1426\n",
      "Time for evaluation: 386.0 s\n",
      "Estimated time to finish : 5.12 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.811 took: 15.35s  Val. loss: 0.328  Val. score: 91.350%\n",
      "Epoch 2, 100% \t Train loss: 0.310 took: 15.21s  Val. loss: 0.196  Val. score: 94.944%\n",
      "Epoch 3, 100% \t Train loss: 0.213 took: 16.59s  Val. loss: 0.172  Val. score: 95.933%\n",
      "Epoch 4, 100% \t Train loss: 0.170 took: 17.24s  Val. loss: 0.153  Val. score: 96.406%\n",
      "Epoch 5, 100% \t Train loss: 0.133 took: 17.00s  Val. loss: 0.149  Val. score: 96.422%\n",
      "Epoch 6, 100% \t Train loss: 0.112 took: 16.94s  Val. loss: 0.144  Val. score: 96.839%\n",
      "Epoch 7, 100% \t Train loss: 0.096 took: 16.74s  Val. loss: 0.137  Val. score: 96.889%\n",
      "Epoch 8, 100% \t Train loss: 0.078 took: 16.48s  Val. loss: 0.130  Val. score: 97.078%\n",
      "Epoch 9, 100% \t Train loss: 0.071 took: 16.29s  Val. loss: 0.128  Val. score: 97.383%\n",
      "Epoch 10, 100% \t Train loss: 0.061 took: 16.29s  Val. loss: 0.162  Val. score: 97.078%\n",
      "Epoch 11, 100% \t Train loss: 0.055 took: 16.22s  Val. loss: 0.136  Val. score: 97.450%\n",
      "Epoch 12, 100% \t Train loss: 0.049 took: 15.55s  Val. loss: 0.145  Val. score: 97.150%\n",
      "Epoch 13, 100% \t Train loss: 0.046 took: 15.46s  Val. loss: 0.154  Val. score: 97.344%\n",
      "Epoch 14, 100% \t Train loss: 0.042 took: 15.16s  Val. loss: 0.158  Val. score: 97.328%\n",
      "Epoch 15, 100% \t Train loss: 0.035 took: 15.26s  Val. loss: 0.150  Val. score: 97.556%\n",
      "Training finished, took 344.714s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.899 took: 14.14s  Val. loss: 0.319  Val. score: 91.461%\n",
      "Epoch 2, 100% \t Train loss: 0.333 took: 14.69s  Val. loss: 0.246  Val. score: 93.622%\n",
      "Epoch 3, 100% \t Train loss: 0.235 took: 15.18s  Val. loss: 0.200  Val. score: 95.167%\n",
      "Epoch 4, 100% \t Train loss: 0.183 took: 15.23s  Val. loss: 0.174  Val. score: 95.883%\n",
      "Epoch 5, 100% \t Train loss: 0.147 took: 15.00s  Val. loss: 0.165  Val. score: 96.211%\n",
      "Epoch 6, 100% \t Train loss: 0.126 took: 15.30s  Val. loss: 0.159  Val. score: 96.350%\n",
      "Epoch 7, 100% \t Train loss: 0.100 took: 15.20s  Val. loss: 0.148  Val. score: 96.706%\n",
      "Epoch 8, 100% \t Train loss: 0.089 took: 15.33s  Val. loss: 0.148  Val. score: 96.861%\n",
      "Epoch 9, 100% \t Train loss: 0.076 took: 14.82s  Val. loss: 0.151  Val. score: 96.933%\n",
      "Epoch 10, 100% \t Train loss: 0.064 took: 15.37s  Val. loss: 0.138  Val. score: 97.067%\n",
      "Epoch 11, 100% \t Train loss: 0.060 took: 15.55s  Val. loss: 0.146  Val. score: 97.133%\n",
      "Epoch 12, 100% \t Train loss: 0.053 took: 15.49s  Val. loss: 0.139  Val. score: 97.317%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, 100% \t Train loss: 0.044 took: 15.17s  Val. loss: 0.157  Val. score: 97.261%\n",
      "Epoch 14, 100% \t Train loss: 0.041 took: 15.09s  Val. loss: 0.150  Val. score: 97.450%\n",
      "Epoch 15, 100% \t Train loss: 0.037 took: 15.44s  Val. loss: 0.149  Val. score: 97.444%\n",
      "Training finished, took 323.776s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.959 took: 13.89s  Val. loss: 0.378  Val. score: 90.250%\n",
      "Epoch 2, 100% \t Train loss: 0.342 took: 13.88s  Val. loss: 0.222  Val. score: 94.417%\n",
      "Epoch 3, 100% \t Train loss: 0.226 took: 15.01s  Val. loss: 0.195  Val. score: 95.289%\n",
      "Epoch 4, 100% \t Train loss: 0.174 took: 14.56s  Val. loss: 0.167  Val. score: 96.033%\n",
      "Epoch 5, 100% \t Train loss: 0.140 took: 15.75s  Val. loss: 0.167  Val. score: 96.094%\n",
      "Epoch 6, 100% \t Train loss: 0.120 took: 14.93s  Val. loss: 0.157  Val. score: 96.411%\n",
      "Epoch 7, 100% \t Train loss: 0.097 took: 15.32s  Val. loss: 0.146  Val. score: 96.872%\n",
      "Epoch 8, 100% \t Train loss: 0.082 took: 15.48s  Val. loss: 0.143  Val. score: 97.017%\n",
      "Epoch 9, 100% \t Train loss: 0.071 took: 15.14s  Val. loss: 0.144  Val. score: 97.083%\n",
      "Epoch 10, 100% \t Train loss: 0.066 took: 15.45s  Val. loss: 0.143  Val. score: 97.211%\n",
      "Epoch 11, 100% \t Train loss: 0.054 took: 15.31s  Val. loss: 0.159  Val. score: 97.172%\n",
      "Epoch 12, 100% \t Train loss: 0.051 took: 14.95s  Val. loss: 0.158  Val. score: 97.339%\n",
      "Epoch 13, 100% \t Train loss: 0.043 took: 15.32s  Val. loss: 0.171  Val. score: 97.200%\n",
      "Epoch 14, 100% \t Train loss: 0.040 took: 14.84s  Val. loss: 0.165  Val. score: 97.461%\n",
      "Epoch 15, 100% \t Train loss: 0.035 took: 14.89s  Val. loss: 0.160  Val. score: 97.417%\n",
      "Training finished, took 319.957s\n",
      "\n",
      "Parameters configuration 66 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005352413450006965\n",
      "h_sizes \t [784, 454, 253, 144, 90, 55, 31, 16]\n",
      "penalty \t 0.0002164070392617981\n",
      "dropout \t 0.0894324025959558\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4722 +/- 0.0600\n",
      "Time for evaluation: 989.6 s\n",
      "Estimated time to finish : 5.04 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.412 took: 8.21s  Val. loss: 0.182  Val. score: 94.661%\n",
      "Epoch 2, 100% \t Train loss: 0.155 took: 8.26s  Val. loss: 0.153  Val. score: 95.472%\n",
      "Epoch 3, 100% \t Train loss: 0.111 took: 8.91s  Val. loss: 0.131  Val. score: 96.133%\n",
      "Epoch 4, 100% \t Train loss: 0.087 took: 8.83s  Val. loss: 0.120  Val. score: 96.494%\n",
      "Epoch 5, 100% \t Train loss: 0.065 took: 9.20s  Val. loss: 0.119  Val. score: 96.939%\n",
      "Epoch 6, 100% \t Train loss: 0.054 took: 9.26s  Val. loss: 0.107  Val. score: 97.283%\n",
      "Epoch 7, 100% \t Train loss: 0.045 took: 9.21s  Val. loss: 0.114  Val. score: 97.206%\n",
      "Epoch 8, 100% \t Train loss: 0.041 took: 8.86s  Val. loss: 0.117  Val. score: 97.222%\n",
      "Epoch 9, 100% \t Train loss: 0.035 took: 8.67s  Val. loss: 0.113  Val. score: 97.322%\n",
      "Epoch 10, 100% \t Train loss: 0.028 took: 9.10s  Val. loss: 0.108  Val. score: 97.494%\n",
      "Epoch 11, 100% \t Train loss: 0.022 took: 9.52s  Val. loss: 0.129  Val. score: 97.228%\n",
      "Epoch 12, 100% \t Train loss: 0.016 took: 9.47s  Val. loss: 0.125  Val. score: 97.656%\n",
      "Epoch 13, 100% \t Train loss: 0.021 took: 9.02s  Val. loss: 0.142  Val. score: 97.306%\n",
      "Epoch 14, 100% \t Train loss: 0.018 took: 8.89s  Val. loss: 0.129  Val. score: 97.589%\n",
      "Epoch 15, 100% \t Train loss: 0.015 took: 8.81s  Val. loss: 0.132  Val. score: 97.589%\n",
      "Training finished, took 203.080s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.426 took: 7.99s  Val. loss: 0.160  Val. score: 95.550%\n",
      "Epoch 2, 100% \t Train loss: 0.153 took: 7.57s  Val. loss: 0.143  Val. score: 96.033%\n",
      "Epoch 3, 100% \t Train loss: 0.107 took: 9.05s  Val. loss: 0.124  Val. score: 96.767%\n",
      "Epoch 4, 100% \t Train loss: 0.082 took: 8.96s  Val. loss: 0.125  Val. score: 96.744%\n",
      "Epoch 5, 100% \t Train loss: 0.063 took: 8.99s  Val. loss: 0.121  Val. score: 96.989%\n",
      "Epoch 6, 100% \t Train loss: 0.052 took: 9.02s  Val. loss: 0.124  Val. score: 96.994%\n",
      "Epoch 7, 100% \t Train loss: 0.041 took: 8.80s  Val. loss: 0.135  Val. score: 96.989%\n",
      "Epoch 8, 100% \t Train loss: 0.036 took: 9.27s  Val. loss: 0.138  Val. score: 97.144%\n",
      "Epoch 9, 100% \t Train loss: 0.030 took: 8.75s  Val. loss: 0.131  Val. score: 97.428%\n",
      "Epoch 10, 100% \t Train loss: 0.030 took: 8.99s  Val. loss: 0.127  Val. score: 97.372%\n",
      "Epoch 11, 100% \t Train loss: 0.022 took: 8.92s  Val. loss: 0.162  Val. score: 97.150%\n",
      "Epoch 12, 100% \t Train loss: 0.019 took: 9.63s  Val. loss: 0.143  Val. score: 97.539%\n",
      "Epoch 13, 100% \t Train loss: 0.017 took: 9.29s  Val. loss: 0.150  Val. score: 97.483%\n",
      "Epoch 14, 100% \t Train loss: 0.014 took: 9.25s  Val. loss: 0.156  Val. score: 97.500%\n",
      "Epoch 15, 100% \t Train loss: 0.013 took: 9.18s  Val. loss: 0.153  Val. score: 97.628%\n",
      "Training finished, took 201.827s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.469 took: 7.67s  Val. loss: 0.198  Val. score: 94.083%\n",
      "Epoch 2, 100% \t Train loss: 0.159 took: 7.84s  Val. loss: 0.149  Val. score: 95.933%\n",
      "Epoch 3, 100% \t Train loss: 0.118 took: 8.52s  Val. loss: 0.122  Val. score: 96.339%\n",
      "Epoch 4, 100% \t Train loss: 0.089 took: 9.11s  Val. loss: 0.112  Val. score: 97.022%\n",
      "Epoch 5, 100% \t Train loss: 0.069 took: 9.02s  Val. loss: 0.108  Val. score: 97.017%\n",
      "Epoch 6, 100% \t Train loss: 0.055 took: 9.06s  Val. loss: 0.111  Val. score: 97.333%\n",
      "Epoch 7, 100% \t Train loss: 0.043 took: 9.10s  Val. loss: 0.114  Val. score: 97.261%\n",
      "Epoch 8, 100% \t Train loss: 0.040 took: 9.11s  Val. loss: 0.115  Val. score: 97.506%\n",
      "Epoch 9, 100% \t Train loss: 0.033 took: 9.10s  Val. loss: 0.108  Val. score: 97.594%\n",
      "Epoch 10, 100% \t Train loss: 0.026 took: 9.21s  Val. loss: 0.116  Val. score: 97.483%\n",
      "Epoch 11, 100% \t Train loss: 0.025 took: 9.22s  Val. loss: 0.112  Val. score: 97.611%\n",
      "Epoch 12, 100% \t Train loss: 0.024 took: 9.15s  Val. loss: 0.124  Val. score: 97.650%\n",
      "Epoch 13, 100% \t Train loss: 0.020 took: 8.95s  Val. loss: 0.123  Val. score: 97.517%\n",
      "Epoch 14, 100% \t Train loss: 0.018 took: 9.08s  Val. loss: 0.116  Val. score: 97.789%\n",
      "Epoch 15, 100% \t Train loss: 0.015 took: 8.90s  Val. loss: 0.134  Val. score: 97.667%\n",
      "Training finished, took 201.664s\n",
      "\n",
      "Parameters configuration 67 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.017409252827701914\n",
      "h_sizes \t [784, 335, 124, 48, 22]\n",
      "penalty \t 0.00022599498781326996\n",
      "dropout \t 0.031551726063454716\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6278 +/- 0.0318\n",
      "Time for evaluation: 607.7 s\n",
      "Estimated time to finish : 4.90 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.441 took: 4.32s  Val. loss: 0.240  Val. score: 93.139%\n",
      "Epoch 2, 100% \t Train loss: 0.213 took: 4.40s  Val. loss: 0.169  Val. score: 94.917%\n",
      "Epoch 3, 100% \t Train loss: 0.154 took: 4.61s  Val. loss: 0.138  Val. score: 95.889%\n",
      "Epoch 4, 100% \t Train loss: 0.119 took: 4.40s  Val. loss: 0.123  Val. score: 96.311%\n",
      "Epoch 5, 100% \t Train loss: 0.095 took: 4.69s  Val. loss: 0.117  Val. score: 96.533%\n",
      "Epoch 6, 100% \t Train loss: 0.077 took: 4.49s  Val. loss: 0.108  Val. score: 96.800%\n",
      "Epoch 7, 100% \t Train loss: 0.064 took: 4.50s  Val. loss: 0.098  Val. score: 97.033%\n",
      "Epoch 8, 100% \t Train loss: 0.054 took: 4.73s  Val. loss: 0.097  Val. score: 97.200%\n",
      "Epoch 9, 100% \t Train loss: 0.044 took: 4.41s  Val. loss: 0.094  Val. score: 97.306%\n",
      "Epoch 10, 100% \t Train loss: 0.038 took: 4.72s  Val. loss: 0.092  Val. score: 97.361%\n",
      "Epoch 11, 100% \t Train loss: 0.032 took: 4.68s  Val. loss: 0.092  Val. score: 97.472%\n",
      "Epoch 12, 100% \t Train loss: 0.027 took: 4.41s  Val. loss: 0.093  Val. score: 97.461%\n",
      "Epoch 13, 100% \t Train loss: 0.023 took: 4.48s  Val. loss: 0.090  Val. score: 97.583%\n",
      "Epoch 14, 100% \t Train loss: 0.020 took: 4.71s  Val. loss: 0.092  Val. score: 97.561%\n",
      "Epoch 15, 100% \t Train loss: 0.018 took: 4.78s  Val. loss: 0.094  Val. score: 97.472%\n",
      "Training finished, took 118.030s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 100% \t Train loss: 0.462 took: 4.32s  Val. loss: 0.235  Val. score: 93.106%\n",
      "Epoch 2, 100% \t Train loss: 0.200 took: 4.31s  Val. loss: 0.188  Val. score: 94.328%\n",
      "Epoch 3, 100% \t Train loss: 0.147 took: 4.31s  Val. loss: 0.146  Val. score: 95.639%\n",
      "Epoch 4, 100% \t Train loss: 0.115 took: 4.71s  Val. loss: 0.116  Val. score: 96.533%\n",
      "Epoch 5, 100% \t Train loss: 0.094 took: 4.26s  Val. loss: 0.103  Val. score: 96.767%\n",
      "Epoch 6, 100% \t Train loss: 0.079 took: 4.35s  Val. loss: 0.095  Val. score: 97.200%\n",
      "Epoch 7, 100% \t Train loss: 0.063 took: 4.61s  Val. loss: 0.087  Val. score: 97.328%\n",
      "Epoch 8, 100% \t Train loss: 0.054 took: 4.37s  Val. loss: 0.087  Val. score: 97.378%\n",
      "Epoch 9, 100% \t Train loss: 0.044 took: 4.35s  Val. loss: 0.093  Val. score: 97.200%\n",
      "Epoch 10, 100% \t Train loss: 0.039 took: 4.88s  Val. loss: 0.090  Val. score: 97.222%\n",
      "Epoch 11, 100% \t Train loss: 0.033 took: 4.57s  Val. loss: 0.088  Val. score: 97.428%\n",
      "Epoch 12, 100% \t Train loss: 0.029 took: 4.55s  Val. loss: 0.084  Val. score: 97.467%\n",
      "Epoch 13, 100% \t Train loss: 0.024 took: 4.62s  Val. loss: 0.081  Val. score: 97.672%\n",
      "Epoch 14, 100% \t Train loss: 0.021 took: 4.64s  Val. loss: 0.096  Val. score: 97.367%\n",
      "Epoch 15, 100% \t Train loss: 0.021 took: 4.29s  Val. loss: 0.091  Val. score: 97.472%\n",
      "Training finished, took 117.236s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.446 took: 4.45s  Val. loss: 0.266  Val. score: 92.428%\n",
      "Epoch 2, 100% \t Train loss: 0.217 took: 4.72s  Val. loss: 0.199  Val. score: 94.072%\n",
      "Epoch 3, 100% \t Train loss: 0.154 took: 4.29s  Val. loss: 0.145  Val. score: 95.511%\n",
      "Epoch 4, 100% \t Train loss: 0.123 took: 4.63s  Val. loss: 0.130  Val. score: 95.906%\n",
      "Epoch 5, 100% \t Train loss: 0.098 took: 4.64s  Val. loss: 0.118  Val. score: 96.489%\n",
      "Epoch 6, 100% \t Train loss: 0.080 took: 4.31s  Val. loss: 0.115  Val. score: 96.394%\n",
      "Epoch 7, 100% \t Train loss: 0.069 took: 4.57s  Val. loss: 0.104  Val. score: 96.878%\n",
      "Epoch 8, 100% \t Train loss: 0.057 took: 4.36s  Val. loss: 0.103  Val. score: 96.783%\n",
      "Epoch 9, 100% \t Train loss: 0.050 took: 4.62s  Val. loss: 0.104  Val. score: 96.928%\n",
      "Epoch 10, 100% \t Train loss: 0.042 took: 4.27s  Val. loss: 0.099  Val. score: 97.111%\n",
      "Epoch 11, 100% \t Train loss: 0.037 took: 4.68s  Val. loss: 0.098  Val. score: 97.061%\n",
      "Epoch 12, 100% \t Train loss: 0.031 took: 4.69s  Val. loss: 0.099  Val. score: 97.156%\n",
      "Epoch 13, 100% \t Train loss: 0.027 took: 4.64s  Val. loss: 0.101  Val. score: 97.083%\n",
      "Epoch 14, 100% \t Train loss: 0.023 took: 4.63s  Val. loss: 0.095  Val. score: 97.350%\n",
      "Epoch 15, 100% \t Train loss: 0.019 took: 4.59s  Val. loss: 0.108  Val. score: 97.056%\n",
      "Training finished, took 117.835s\n",
      "\n",
      "Parameters configuration 68 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004192838925781067\n",
      "h_sizes \t [784, 173, 48]\n",
      "penalty \t 0.003185094421274093\n",
      "dropout \t 0.02805778770430714\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.3333 +/- 0.1964\n",
      "Time for evaluation: 354.3 s\n",
      "Estimated time to finish : 4.73 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.533 took: 8.77s  Val. loss: 0.202  Val. score: 94.350%\n",
      "Epoch 2, 100% \t Train loss: 0.189 took: 8.41s  Val. loss: 0.168  Val. score: 95.328%\n",
      "Epoch 3, 100% \t Train loss: 0.140 took: 9.05s  Val. loss: 0.144  Val. score: 96.111%\n",
      "Epoch 4, 100% \t Train loss: 0.104 took: 9.90s  Val. loss: 0.136  Val. score: 96.522%\n",
      "Epoch 5, 100% \t Train loss: 0.088 took: 9.71s  Val. loss: 0.115  Val. score: 97.067%\n",
      "Epoch 6, 100% \t Train loss: 0.068 took: 9.41s  Val. loss: 0.124  Val. score: 97.083%\n",
      "Epoch 7, 100% \t Train loss: 0.060 took: 9.52s  Val. loss: 0.110  Val. score: 97.200%\n",
      "Epoch 8, 100% \t Train loss: 0.050 took: 9.80s  Val. loss: 0.121  Val. score: 97.294%\n",
      "Epoch 9, 100% \t Train loss: 0.043 took: 9.11s  Val. loss: 0.123  Val. score: 97.433%\n",
      "Epoch 10, 100% \t Train loss: 0.036 took: 9.58s  Val. loss: 0.123  Val. score: 97.383%\n",
      "Epoch 11, 100% \t Train loss: 0.032 took: 10.03s  Val. loss: 0.120  Val. score: 97.694%\n",
      "Epoch 12, 100% \t Train loss: 0.027 took: 9.35s  Val. loss: 0.129  Val. score: 97.572%\n",
      "Epoch 13, 100% \t Train loss: 0.026 took: 9.12s  Val. loss: 0.135  Val. score: 97.333%\n",
      "Epoch 14, 100% \t Train loss: 0.023 took: 9.54s  Val. loss: 0.126  Val. score: 97.700%\n",
      "Epoch 15, 100% \t Train loss: 0.021 took: 9.16s  Val. loss: 0.140  Val. score: 97.556%\n",
      "Training finished, took 212.138s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.528 took: 8.80s  Val. loss: 0.209  Val. score: 93.789%\n",
      "Epoch 2, 100% \t Train loss: 0.201 took: 8.25s  Val. loss: 0.152  Val. score: 95.561%\n",
      "Epoch 3, 100% \t Train loss: 0.144 took: 9.88s  Val. loss: 0.142  Val. score: 95.944%\n",
      "Epoch 4, 100% \t Train loss: 0.113 took: 9.77s  Val. loss: 0.113  Val. score: 96.933%\n",
      "Epoch 5, 100% \t Train loss: 0.088 took: 9.47s  Val. loss: 0.103  Val. score: 97.283%\n",
      "Epoch 6, 100% \t Train loss: 0.072 took: 9.88s  Val. loss: 0.119  Val. score: 97.011%\n",
      "Epoch 7, 100% \t Train loss: 0.063 took: 9.54s  Val. loss: 0.110  Val. score: 97.239%\n",
      "Epoch 8, 100% \t Train loss: 0.052 took: 9.55s  Val. loss: 0.113  Val. score: 97.428%\n",
      "Epoch 9, 100% \t Train loss: 0.040 took: 9.34s  Val. loss: 0.114  Val. score: 97.450%\n",
      "Epoch 10, 100% \t Train loss: 0.036 took: 9.36s  Val. loss: 0.117  Val. score: 97.594%\n",
      "Epoch 11, 100% \t Train loss: 0.032 took: 9.39s  Val. loss: 0.110  Val. score: 97.567%\n",
      "Epoch 12, 100% \t Train loss: 0.028 took: 9.69s  Val. loss: 0.115  Val. score: 97.700%\n",
      "Epoch 13, 100% \t Train loss: 0.026 took: 10.18s  Val. loss: 0.124  Val. score: 97.600%\n",
      "Epoch 14, 100% \t Train loss: 0.021 took: 9.35s  Val. loss: 0.123  Val. score: 97.733%\n",
      "Epoch 15, 100% \t Train loss: 0.020 took: 9.35s  Val. loss: 0.141  Val. score: 97.422%\n",
      "Training finished, took 213.906s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.531 took: 8.51s  Val. loss: 0.205  Val. score: 94.272%\n",
      "Epoch 2, 100% \t Train loss: 0.190 took: 8.29s  Val. loss: 0.160  Val. score: 95.583%\n",
      "Epoch 3, 100% \t Train loss: 0.134 took: 9.16s  Val. loss: 0.137  Val. score: 96.272%\n",
      "Epoch 4, 100% \t Train loss: 0.101 took: 9.96s  Val. loss: 0.125  Val. score: 96.833%\n",
      "Epoch 5, 100% \t Train loss: 0.080 took: 9.34s  Val. loss: 0.117  Val. score: 96.883%\n",
      "Epoch 6, 100% \t Train loss: 0.069 took: 9.42s  Val. loss: 0.113  Val. score: 97.339%\n",
      "Epoch 7, 100% \t Train loss: 0.052 took: 9.55s  Val. loss: 0.136  Val. score: 97.022%\n",
      "Epoch 8, 100% \t Train loss: 0.046 took: 9.75s  Val. loss: 0.115  Val. score: 97.489%\n",
      "Epoch 9, 100% \t Train loss: 0.042 took: 9.52s  Val. loss: 0.116  Val. score: 97.439%\n",
      "Epoch 10, 100% \t Train loss: 0.034 took: 10.03s  Val. loss: 0.111  Val. score: 97.656%\n",
      "Epoch 11, 100% \t Train loss: 0.031 took: 9.78s  Val. loss: 0.115  Val. score: 97.561%\n",
      "Epoch 12, 100% \t Train loss: 0.026 took: 10.01s  Val. loss: 0.125  Val. score: 97.522%\n",
      "Epoch 13, 100% \t Train loss: 0.027 took: 10.01s  Val. loss: 0.132  Val. score: 97.528%\n",
      "Epoch 14, 100% \t Train loss: 0.017 took: 9.75s  Val. loss: 0.122  Val. score: 97.761%\n",
      "Epoch 15, 100% \t Train loss: 0.018 took: 9.75s  Val. loss: 0.138  Val. score: 97.767%\n",
      "Training finished, took 215.544s\n",
      "\n",
      "Parameters configuration 69 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00900478238752776\n",
      "h_sizes \t [784, 363, 156, 62, 16]\n",
      "penalty \t 0.008494306474535444\n",
      "dropout \t 0.07470528457387518\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5815 +/- 0.1418\n",
      "Time for evaluation: 642.8 s\n",
      "Estimated time to finish : 4.60 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.615 took: 6.48s  Val. loss: 0.263  Val. score: 92.256%\n",
      "Epoch 2, 100% \t Train loss: 0.257 took: 6.29s  Val. loss: 0.183  Val. score: 94.817%\n",
      "Epoch 3, 100% \t Train loss: 0.190 took: 6.39s  Val. loss: 0.145  Val. score: 95.533%\n",
      "Epoch 4, 100% \t Train loss: 0.147 took: 6.67s  Val. loss: 0.127  Val. score: 96.228%\n",
      "Epoch 5, 100% \t Train loss: 0.119 took: 7.00s  Val. loss: 0.110  Val. score: 96.583%\n",
      "Epoch 6, 100% \t Train loss: 0.101 took: 6.33s  Val. loss: 0.103  Val. score: 96.789%\n",
      "Epoch 7, 100% \t Train loss: 0.084 took: 6.67s  Val. loss: 0.096  Val. score: 97.144%\n",
      "Epoch 8, 100% \t Train loss: 0.071 took: 6.65s  Val. loss: 0.094  Val. score: 97.311%\n",
      "Epoch 9, 100% \t Train loss: 0.061 took: 6.37s  Val. loss: 0.085  Val. score: 97.461%\n",
      "Epoch 10, 100% \t Train loss: 0.051 took: 6.36s  Val. loss: 0.088  Val. score: 97.428%\n",
      "Epoch 11, 100% \t Train loss: 0.046 took: 6.77s  Val. loss: 0.086  Val. score: 97.433%\n",
      "Epoch 12, 100% \t Train loss: 0.040 took: 6.60s  Val. loss: 0.090  Val. score: 97.489%\n",
      "Epoch 13, 100% \t Train loss: 0.033 took: 6.55s  Val. loss: 0.088  Val. score: 97.561%\n",
      "Epoch 14, 100% \t Train loss: 0.031 took: 6.72s  Val. loss: 0.084  Val. score: 97.761%\n",
      "Epoch 15, 100% \t Train loss: 0.027 took: 6.94s  Val. loss: 0.089  Val. score: 97.667%\n",
      "Training finished, took 159.736s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.617 took: 6.35s  Val. loss: 0.273  Val. score: 91.856%\n",
      "Epoch 2, 100% \t Train loss: 0.264 took: 6.79s  Val. loss: 0.194  Val. score: 94.433%\n",
      "Epoch 3, 100% \t Train loss: 0.194 took: 6.78s  Val. loss: 0.156  Val. score: 95.333%\n",
      "Epoch 4, 100% \t Train loss: 0.152 took: 6.93s  Val. loss: 0.131  Val. score: 95.939%\n",
      "Epoch 5, 100% \t Train loss: 0.124 took: 6.56s  Val. loss: 0.120  Val. score: 96.306%\n",
      "Epoch 6, 100% \t Train loss: 0.101 took: 6.36s  Val. loss: 0.109  Val. score: 96.672%\n",
      "Epoch 7, 100% \t Train loss: 0.085 took: 6.29s  Val. loss: 0.103  Val. score: 96.844%\n",
      "Epoch 8, 100% \t Train loss: 0.072 took: 6.71s  Val. loss: 0.098  Val. score: 97.156%\n",
      "Epoch 9, 100% \t Train loss: 0.063 took: 6.21s  Val. loss: 0.097  Val. score: 97.144%\n",
      "Epoch 10, 100% \t Train loss: 0.053 took: 6.22s  Val. loss: 0.097  Val. score: 97.222%\n",
      "Epoch 11, 100% \t Train loss: 0.045 took: 6.55s  Val. loss: 0.088  Val. score: 97.489%\n",
      "Epoch 12, 100% \t Train loss: 0.041 took: 6.33s  Val. loss: 0.088  Val. score: 97.567%\n",
      "Epoch 13, 100% \t Train loss: 0.034 took: 6.21s  Val. loss: 0.097  Val. score: 97.450%\n",
      "Epoch 14, 100% \t Train loss: 0.032 took: 6.38s  Val. loss: 0.091  Val. score: 97.611%\n",
      "Epoch 15, 100% \t Train loss: 0.028 took: 6.66s  Val. loss: 0.092  Val. score: 97.650%\n",
      "Training finished, took 158.401s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.708 took: 6.35s  Val. loss: 0.306  Val. score: 91.222%\n",
      "Epoch 2, 100% \t Train loss: 0.282 took: 6.66s  Val. loss: 0.220  Val. score: 93.522%\n",
      "Epoch 3, 100% \t Train loss: 0.202 took: 6.77s  Val. loss: 0.176  Val. score: 94.739%\n",
      "Epoch 4, 100% \t Train loss: 0.156 took: 6.29s  Val. loss: 0.144  Val. score: 95.739%\n",
      "Epoch 5, 100% \t Train loss: 0.126 took: 6.68s  Val. loss: 0.137  Val. score: 95.828%\n",
      "Epoch 6, 100% \t Train loss: 0.105 took: 7.02s  Val. loss: 0.122  Val. score: 96.333%\n",
      "Epoch 7, 100% \t Train loss: 0.088 took: 6.51s  Val. loss: 0.111  Val. score: 96.678%\n",
      "Epoch 8, 100% \t Train loss: 0.077 took: 6.86s  Val. loss: 0.110  Val. score: 96.700%\n",
      "Epoch 9, 100% \t Train loss: 0.066 took: 6.33s  Val. loss: 0.106  Val. score: 97.022%\n",
      "Epoch 10, 100% \t Train loss: 0.058 took: 6.74s  Val. loss: 0.105  Val. score: 97.061%\n",
      "Epoch 11, 100% \t Train loss: 0.048 took: 6.64s  Val. loss: 0.109  Val. score: 97.000%\n",
      "Epoch 12, 100% \t Train loss: 0.042 took: 6.40s  Val. loss: 0.100  Val. score: 97.161%\n",
      "Epoch 13, 100% \t Train loss: 0.040 took: 6.22s  Val. loss: 0.103  Val. score: 97.278%\n",
      "Epoch 14, 100% \t Train loss: 0.033 took: 6.26s  Val. loss: 0.102  Val. score: 97.328%\n",
      "Epoch 15, 100% \t Train loss: 0.029 took: 6.48s  Val. loss: 0.097  Val. score: 97.467%\n",
      "Training finished, took 159.024s\n",
      "\n",
      "Parameters configuration 70 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0023339755264640957\n",
      "h_sizes \t [784, 273, 104, 28]\n",
      "penalty \t 0.002391632438242522\n",
      "dropout \t 0.07128884721140097\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.5944 +/- 0.0906\n",
      "Time for evaluation: 478.3 s\n",
      "Estimated time to finish : 4.44 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.416 took: 6.91s  Val. loss: 0.160  Val. score: 95.317%\n",
      "Epoch 2, 100% \t Train loss: 0.179 took: 6.31s  Val. loss: 0.124  Val. score: 96.300%\n",
      "Epoch 3, 100% \t Train loss: 0.136 took: 6.83s  Val. loss: 0.106  Val. score: 96.828%\n",
      "Epoch 4, 100% \t Train loss: 0.111 took: 7.43s  Val. loss: 0.102  Val. score: 97.100%\n",
      "Epoch 5, 100% \t Train loss: 0.090 took: 7.15s  Val. loss: 0.093  Val. score: 97.272%\n",
      "Epoch 6, 100% \t Train loss: 0.079 took: 7.13s  Val. loss: 0.088  Val. score: 97.556%\n",
      "Epoch 7, 100% \t Train loss: 0.069 took: 7.17s  Val. loss: 0.095  Val. score: 97.394%\n",
      "Epoch 8, 100% \t Train loss: 0.060 took: 7.35s  Val. loss: 0.092  Val. score: 97.656%\n",
      "Epoch 9, 100% \t Train loss: 0.053 took: 7.45s  Val. loss: 0.087  Val. score: 97.733%\n",
      "Epoch 10, 100% \t Train loss: 0.050 took: 7.10s  Val. loss: 0.088  Val. score: 97.750%\n",
      "Epoch 11, 100% \t Train loss: 0.042 took: 7.03s  Val. loss: 0.084  Val. score: 97.944%\n",
      "Epoch 12, 100% \t Train loss: 0.038 took: 7.20s  Val. loss: 0.095  Val. score: 97.722%\n",
      "Epoch 13, 100% \t Train loss: 0.038 took: 7.43s  Val. loss: 0.091  Val. score: 97.872%\n",
      "Epoch 14, 100% \t Train loss: 0.030 took: 7.17s  Val. loss: 0.097  Val. score: 97.906%\n",
      "Epoch 15, 100% \t Train loss: 0.034 took: 7.38s  Val. loss: 0.097  Val. score: 97.783%\n",
      "Training finished, took 168.487s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.451 took: 6.70s  Val. loss: 0.181  Val. score: 94.722%\n",
      "Epoch 2, 100% \t Train loss: 0.190 took: 6.49s  Val. loss: 0.137  Val. score: 95.911%\n",
      "Epoch 3, 100% \t Train loss: 0.141 took: 6.94s  Val. loss: 0.116  Val. score: 96.744%\n",
      "Epoch 4, 100% \t Train loss: 0.110 took: 7.54s  Val. loss: 0.109  Val. score: 96.900%\n",
      "Epoch 5, 100% \t Train loss: 0.095 took: 7.76s  Val. loss: 0.107  Val. score: 97.022%\n",
      "Epoch 6, 100% \t Train loss: 0.078 took: 7.35s  Val. loss: 0.103  Val. score: 97.256%\n",
      "Epoch 7, 100% \t Train loss: 0.070 took: 7.68s  Val. loss: 0.099  Val. score: 97.394%\n",
      "Epoch 8, 100% \t Train loss: 0.062 took: 7.29s  Val. loss: 0.107  Val. score: 97.222%\n",
      "Epoch 9, 100% \t Train loss: 0.054 took: 7.74s  Val. loss: 0.105  Val. score: 97.506%\n",
      "Epoch 10, 100% \t Train loss: 0.049 took: 7.55s  Val. loss: 0.100  Val. score: 97.528%\n",
      "Epoch 11, 100% \t Train loss: 0.043 took: 7.28s  Val. loss: 0.119  Val. score: 97.283%\n",
      "Epoch 12, 100% \t Train loss: 0.042 took: 7.40s  Val. loss: 0.109  Val. score: 97.483%\n",
      "Epoch 13, 100% \t Train loss: 0.040 took: 7.86s  Val. loss: 0.124  Val. score: 97.294%\n",
      "Epoch 14, 100% \t Train loss: 0.035 took: 7.92s  Val. loss: 0.108  Val. score: 97.561%\n",
      "Epoch 15, 100% \t Train loss: 0.033 took: 7.59s  Val. loss: 0.100  Val. score: 97.678%\n",
      "Training finished, took 172.822s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.429 took: 6.63s  Val. loss: 0.194  Val. score: 94.378%\n",
      "Epoch 2, 100% \t Train loss: 0.183 took: 6.66s  Val. loss: 0.127  Val. score: 96.406%\n",
      "Epoch 3, 100% \t Train loss: 0.132 took: 6.97s  Val. loss: 0.147  Val. score: 95.939%\n",
      "Epoch 4, 100% \t Train loss: 0.108 took: 7.40s  Val. loss: 0.111  Val. score: 96.900%\n",
      "Epoch 5, 100% \t Train loss: 0.092 took: 7.65s  Val. loss: 0.109  Val. score: 97.178%\n",
      "Epoch 6, 100% \t Train loss: 0.077 took: 7.20s  Val. loss: 0.112  Val. score: 97.033%\n",
      "Epoch 7, 100% \t Train loss: 0.070 took: 7.18s  Val. loss: 0.101  Val. score: 97.356%\n",
      "Epoch 8, 100% \t Train loss: 0.062 took: 7.22s  Val. loss: 0.097  Val. score: 97.644%\n",
      "Epoch 9, 100% \t Train loss: 0.054 took: 7.34s  Val. loss: 0.097  Val. score: 97.544%\n",
      "Epoch 10, 100% \t Train loss: 0.048 took: 7.35s  Val. loss: 0.102  Val. score: 97.550%\n",
      "Epoch 11, 100% \t Train loss: 0.046 took: 7.27s  Val. loss: 0.098  Val. score: 97.617%\n",
      "Epoch 12, 100% \t Train loss: 0.037 took: 7.42s  Val. loss: 0.112  Val. score: 97.378%\n",
      "Epoch 13, 100% \t Train loss: 0.036 took: 7.52s  Val. loss: 0.098  Val. score: 97.828%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, 100% \t Train loss: 0.033 took: 7.40s  Val. loss: 0.107  Val. score: 97.628%\n",
      "Epoch 15, 100% \t Train loss: 0.032 took: 7.83s  Val. loss: 0.109  Val. score: 97.511%\n",
      "Training finished, took 171.052s\n",
      "\n",
      "Parameters configuration 71 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.011566193764914997\n",
      "h_sizes \t [784, 281, 101, 36]\n",
      "penalty \t 0.00016082339144314823\n",
      "dropout \t 0.1773556365217188\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6574 +/- 0.1121\n",
      "Time for evaluation: 513.6 s\n",
      "Estimated time to finish : 4.29 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.628 took: 4.53s  Val. loss: 0.306  Val. score: 91.406%\n",
      "Epoch 2, 100% \t Train loss: 0.311 took: 4.59s  Val. loss: 0.229  Val. score: 93.106%\n",
      "Epoch 3, 100% \t Train loss: 0.242 took: 4.31s  Val. loss: 0.191  Val. score: 94.400%\n",
      "Epoch 4, 100% \t Train loss: 0.200 took: 4.49s  Val. loss: 0.164  Val. score: 94.972%\n",
      "Epoch 5, 100% \t Train loss: 0.173 took: 4.35s  Val. loss: 0.145  Val. score: 95.539%\n",
      "Epoch 6, 100% \t Train loss: 0.151 took: 4.61s  Val. loss: 0.131  Val. score: 96.022%\n",
      "Epoch 7, 100% \t Train loss: 0.136 took: 4.41s  Val. loss: 0.125  Val. score: 96.217%\n",
      "Epoch 8, 100% \t Train loss: 0.120 took: 4.73s  Val. loss: 0.119  Val. score: 96.456%\n",
      "Epoch 9, 100% \t Train loss: 0.110 took: 4.61s  Val. loss: 0.115  Val. score: 96.556%\n",
      "Epoch 10, 100% \t Train loss: 0.101 took: 4.81s  Val. loss: 0.113  Val. score: 96.761%\n",
      "Epoch 11, 100% \t Train loss: 0.096 took: 4.72s  Val. loss: 0.107  Val. score: 96.850%\n",
      "Epoch 12, 100% \t Train loss: 0.086 took: 4.30s  Val. loss: 0.104  Val. score: 96.972%\n",
      "Epoch 13, 100% \t Train loss: 0.081 took: 4.34s  Val. loss: 0.103  Val. score: 96.956%\n",
      "Epoch 14, 100% \t Train loss: 0.076 took: 4.31s  Val. loss: 0.099  Val. score: 97.100%\n",
      "Epoch 15, 100% \t Train loss: 0.072 took: 4.73s  Val. loss: 0.100  Val. score: 97.189%\n",
      "Training finished, took 117.477s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.657 took: 4.59s  Val. loss: 0.292  Val. score: 91.333%\n",
      "Epoch 2, 100% \t Train loss: 0.326 took: 4.65s  Val. loss: 0.219  Val. score: 93.583%\n",
      "Epoch 3, 100% \t Train loss: 0.255 took: 4.72s  Val. loss: 0.174  Val. score: 94.767%\n",
      "Epoch 4, 100% \t Train loss: 0.212 took: 4.43s  Val. loss: 0.146  Val. score: 95.817%\n",
      "Epoch 5, 100% \t Train loss: 0.181 took: 4.29s  Val. loss: 0.131  Val. score: 96.089%\n",
      "Epoch 6, 100% \t Train loss: 0.159 took: 4.23s  Val. loss: 0.121  Val. score: 96.372%\n",
      "Epoch 7, 100% \t Train loss: 0.144 took: 4.65s  Val. loss: 0.110  Val. score: 96.767%\n",
      "Epoch 8, 100% \t Train loss: 0.129 took: 4.62s  Val. loss: 0.108  Val. score: 96.783%\n",
      "Epoch 9, 100% \t Train loss: 0.119 took: 4.68s  Val. loss: 0.099  Val. score: 97.000%\n",
      "Epoch 10, 100% \t Train loss: 0.112 took: 4.71s  Val. loss: 0.094  Val. score: 97.244%\n",
      "Epoch 11, 100% \t Train loss: 0.102 took: 4.68s  Val. loss: 0.090  Val. score: 97.378%\n",
      "Epoch 12, 100% \t Train loss: 0.092 took: 4.64s  Val. loss: 0.095  Val. score: 97.172%\n",
      "Epoch 13, 100% \t Train loss: 0.089 took: 4.44s  Val. loss: 0.088  Val. score: 97.400%\n",
      "Epoch 14, 100% \t Train loss: 0.082 took: 4.62s  Val. loss: 0.088  Val. score: 97.406%\n",
      "Epoch 15, 100% \t Train loss: 0.077 took: 4.75s  Val. loss: 0.083  Val. score: 97.578%\n",
      "Training finished, took 118.282s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.641 took: 4.53s  Val. loss: 0.281  Val. score: 91.756%\n",
      "Epoch 2, 100% \t Train loss: 0.310 took: 4.69s  Val. loss: 0.214  Val. score: 93.550%\n",
      "Epoch 3, 100% \t Train loss: 0.242 took: 4.70s  Val. loss: 0.175  Val. score: 94.706%\n",
      "Epoch 4, 100% \t Train loss: 0.204 took: 4.43s  Val. loss: 0.152  Val. score: 95.317%\n",
      "Epoch 5, 100% \t Train loss: 0.176 took: 4.52s  Val. loss: 0.139  Val. score: 95.644%\n",
      "Epoch 6, 100% \t Train loss: 0.156 took: 4.37s  Val. loss: 0.125  Val. score: 96.156%\n",
      "Epoch 7, 100% \t Train loss: 0.137 took: 4.37s  Val. loss: 0.118  Val. score: 96.417%\n",
      "Epoch 8, 100% \t Train loss: 0.126 took: 4.30s  Val. loss: 0.107  Val. score: 96.717%\n",
      "Epoch 9, 100% \t Train loss: 0.112 took: 4.73s  Val. loss: 0.104  Val. score: 96.839%\n",
      "Epoch 10, 100% \t Train loss: 0.105 took: 4.47s  Val. loss: 0.099  Val. score: 97.028%\n",
      "Epoch 11, 100% \t Train loss: 0.098 took: 4.59s  Val. loss: 0.095  Val. score: 97.039%\n",
      "Epoch 12, 100% \t Train loss: 0.095 took: 4.74s  Val. loss: 0.092  Val. score: 97.156%\n",
      "Epoch 13, 100% \t Train loss: 0.084 took: 4.71s  Val. loss: 0.091  Val. score: 97.311%\n",
      "Epoch 14, 100% \t Train loss: 0.080 took: 4.70s  Val. loss: 0.088  Val. score: 97.317%\n",
      "Epoch 15, 100% \t Train loss: 0.075 took: 4.49s  Val. loss: 0.090  Val. score: 97.328%\n",
      "Training finished, took 118.186s\n",
      "\n",
      "Parameters configuration 72 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00244492967648772\n",
      "h_sizes \t [784, 182, 41]\n",
      "penalty \t 0.0001231265576684176\n",
      "dropout \t 0.22580161159598486\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.3648 +/- 0.1609\n",
      "Time for evaluation: 355.1 s\n",
      "Estimated time to finish : 4.12 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.473 took: 6.05s  Val. loss: 0.195  Val. score: 94.139%\n",
      "Epoch 2, 100% \t Train loss: 0.219 took: 6.31s  Val. loss: 0.138  Val. score: 95.811%\n",
      "Epoch 3, 100% \t Train loss: 0.167 took: 6.59s  Val. loss: 0.120  Val. score: 96.461%\n",
      "Epoch 4, 100% \t Train loss: 0.140 took: 6.88s  Val. loss: 0.109  Val. score: 96.839%\n",
      "Epoch 5, 100% \t Train loss: 0.117 took: 6.75s  Val. loss: 0.110  Val. score: 96.989%\n",
      "Epoch 6, 100% \t Train loss: 0.104 took: 7.88s  Val. loss: 0.102  Val. score: 97.261%\n",
      "Epoch 7, 100% \t Train loss: 0.094 took: 6.90s  Val. loss: 0.101  Val. score: 97.233%\n",
      "Epoch 8, 100% \t Train loss: 0.082 took: 7.33s  Val. loss: 0.094  Val. score: 97.422%\n",
      "Epoch 9, 100% \t Train loss: 0.074 took: 7.10s  Val. loss: 0.102  Val. score: 97.361%\n",
      "Epoch 10, 100% \t Train loss: 0.070 took: 6.82s  Val. loss: 0.105  Val. score: 97.417%\n",
      "Epoch 11, 100% \t Train loss: 0.062 took: 6.76s  Val. loss: 0.091  Val. score: 97.706%\n",
      "Epoch 12, 100% \t Train loss: 0.059 took: 7.34s  Val. loss: 0.098  Val. score: 97.778%\n",
      "Epoch 13, 100% \t Train loss: 0.051 took: 7.25s  Val. loss: 0.099  Val. score: 97.594%\n",
      "Epoch 14, 100% \t Train loss: 0.052 took: 6.71s  Val. loss: 0.102  Val. score: 97.783%\n",
      "Epoch 15, 100% \t Train loss: 0.046 took: 6.94s  Val. loss: 0.098  Val. score: 97.656%\n",
      "Training finished, took 164.220s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.521 took: 6.15s  Val. loss: 0.199  Val. score: 94.161%\n",
      "Epoch 2, 100% \t Train loss: 0.221 took: 6.11s  Val. loss: 0.156  Val. score: 95.467%\n",
      "Epoch 3, 100% \t Train loss: 0.174 took: 6.74s  Val. loss: 0.129  Val. score: 96.222%\n",
      "Epoch 4, 100% \t Train loss: 0.137 took: 7.40s  Val. loss: 0.122  Val. score: 96.567%\n",
      "Epoch 5, 100% \t Train loss: 0.120 took: 6.87s  Val. loss: 0.116  Val. score: 96.767%\n",
      "Epoch 6, 100% \t Train loss: 0.106 took: 6.94s  Val. loss: 0.116  Val. score: 96.833%\n",
      "Epoch 7, 100% \t Train loss: 0.096 took: 7.58s  Val. loss: 0.108  Val. score: 97.189%\n",
      "Epoch 8, 100% \t Train loss: 0.083 took: 8.02s  Val. loss: 0.110  Val. score: 97.167%\n",
      "Epoch 9, 100% \t Train loss: 0.078 took: 7.80s  Val. loss: 0.106  Val. score: 97.406%\n",
      "Epoch 10, 100% \t Train loss: 0.071 took: 8.29s  Val. loss: 0.104  Val. score: 97.483%\n",
      "Epoch 11, 100% \t Train loss: 0.067 took: 8.43s  Val. loss: 0.099  Val. score: 97.478%\n",
      "Epoch 12, 100% \t Train loss: 0.059 took: 7.92s  Val. loss: 0.108  Val. score: 97.322%\n",
      "Epoch 13, 100% \t Train loss: 0.056 took: 8.26s  Val. loss: 0.107  Val. score: 97.567%\n",
      "Epoch 14, 100% \t Train loss: 0.054 took: 8.38s  Val. loss: 0.103  Val. score: 97.594%\n",
      "Epoch 15, 100% \t Train loss: 0.047 took: 8.31s  Val. loss: 0.105  Val. score: 97.500%\n",
      "Training finished, took 178.756s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.481 took: 7.42s  Val. loss: 0.188  Val. score: 94.522%\n",
      "Epoch 2, 100% \t Train loss: 0.221 took: 7.43s  Val. loss: 0.140  Val. score: 95.950%\n",
      "Epoch 3, 100% \t Train loss: 0.167 took: 8.21s  Val. loss: 0.128  Val. score: 96.439%\n",
      "Epoch 4, 100% \t Train loss: 0.138 took: 8.09s  Val. loss: 0.116  Val. score: 96.856%\n",
      "Epoch 5, 100% \t Train loss: 0.117 took: 8.14s  Val. loss: 0.113  Val. score: 96.967%\n",
      "Epoch 6, 100% \t Train loss: 0.104 took: 8.32s  Val. loss: 0.113  Val. score: 96.983%\n",
      "Epoch 7, 100% \t Train loss: 0.092 took: 6.94s  Val. loss: 0.103  Val. score: 97.289%\n",
      "Epoch 8, 100% \t Train loss: 0.081 took: 8.20s  Val. loss: 0.104  Val. score: 97.311%\n",
      "Epoch 9, 100% \t Train loss: 0.070 took: 8.17s  Val. loss: 0.108  Val. score: 97.267%\n",
      "Epoch 10, 100% \t Train loss: 0.064 took: 7.95s  Val. loss: 0.108  Val. score: 97.472%\n",
      "Epoch 11, 100% \t Train loss: 0.066 took: 7.97s  Val. loss: 0.103  Val. score: 97.539%\n",
      "Epoch 12, 100% \t Train loss: 0.059 took: 7.96s  Val. loss: 0.103  Val. score: 97.578%\n",
      "Epoch 13, 100% \t Train loss: 0.053 took: 8.26s  Val. loss: 0.107  Val. score: 97.456%\n",
      "Epoch 14, 100% \t Train loss: 0.048 took: 7.44s  Val. loss: 0.109  Val. score: 97.511%\n",
      "Epoch 15, 100% \t Train loss: 0.048 took: 7.20s  Val. loss: 0.107  Val. score: 97.622%\n",
      "Training finished, took 186.648s\n",
      "\n",
      "Parameters configuration 73 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.010849257775159157\n",
      "h_sizes \t [784, 244, 89, 32]\n",
      "penalty \t 0.001891800826918899\n",
      "dropout \t 0.21884735098848143\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5926 +/- 0.0669\n",
      "Time for evaluation: 530.8 s\n",
      "Estimated time to finish : 3.98 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.351 took: 4.28s  Val. loss: 0.159  Val. score: 95.322%\n",
      "Epoch 2, 100% \t Train loss: 0.163 took: 4.13s  Val. loss: 0.122  Val. score: 96.433%\n",
      "Epoch 3, 100% \t Train loss: 0.121 took: 4.30s  Val. loss: 0.110  Val. score: 96.683%\n",
      "Epoch 4, 100% \t Train loss: 0.097 took: 4.74s  Val. loss: 0.108  Val. score: 96.806%\n",
      "Epoch 5, 100% \t Train loss: 0.080 took: 4.40s  Val. loss: 0.111  Val. score: 96.789%\n",
      "Epoch 6, 100% \t Train loss: 0.072 took: 4.41s  Val. loss: 0.102  Val. score: 97.133%\n",
      "Epoch 7, 100% \t Train loss: 0.060 took: 4.78s  Val. loss: 0.104  Val. score: 97.183%\n",
      "Epoch 8, 100% \t Train loss: 0.054 took: 4.87s  Val. loss: 0.104  Val. score: 97.172%\n",
      "Epoch 9, 100% \t Train loss: 0.050 took: 4.90s  Val. loss: 0.102  Val. score: 97.361%\n",
      "Epoch 10, 100% \t Train loss: 0.042 took: 4.82s  Val. loss: 0.108  Val. score: 97.278%\n",
      "Epoch 11, 100% \t Train loss: 0.040 took: 4.82s  Val. loss: 0.105  Val. score: 97.356%\n",
      "Epoch 12, 100% \t Train loss: 0.034 took: 4.43s  Val. loss: 0.110  Val. score: 97.467%\n",
      "Epoch 13, 100% \t Train loss: 0.031 took: 4.84s  Val. loss: 0.109  Val. score: 97.411%\n",
      "Epoch 14, 100% \t Train loss: 0.028 took: 4.86s  Val. loss: 0.116  Val. score: 97.339%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 4.70s  Val. loss: 0.134  Val. score: 97.311%\n",
      "Training finished, took 117.218s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.358 took: 4.53s  Val. loss: 0.192  Val. score: 94.094%\n",
      "Epoch 2, 100% \t Train loss: 0.160 took: 4.51s  Val. loss: 0.141  Val. score: 95.800%\n",
      "Epoch 3, 100% \t Train loss: 0.121 took: 4.75s  Val. loss: 0.116  Val. score: 96.622%\n",
      "Epoch 4, 100% \t Train loss: 0.095 took: 4.77s  Val. loss: 0.111  Val. score: 96.833%\n",
      "Epoch 5, 100% \t Train loss: 0.081 took: 4.56s  Val. loss: 0.108  Val. score: 96.950%\n",
      "Epoch 6, 100% \t Train loss: 0.070 took: 4.93s  Val. loss: 0.108  Val. score: 97.094%\n",
      "Epoch 7, 100% \t Train loss: 0.062 took: 4.85s  Val. loss: 0.109  Val. score: 97.094%\n",
      "Epoch 8, 100% \t Train loss: 0.053 took: 4.86s  Val. loss: 0.107  Val. score: 97.156%\n",
      "Epoch 9, 100% \t Train loss: 0.050 took: 4.79s  Val. loss: 0.103  Val. score: 97.417%\n",
      "Epoch 10, 100% \t Train loss: 0.043 took: 4.58s  Val. loss: 0.106  Val. score: 97.444%\n",
      "Epoch 11, 100% \t Train loss: 0.041 took: 4.66s  Val. loss: 0.114  Val. score: 97.222%\n",
      "Epoch 12, 100% \t Train loss: 0.037 took: 4.44s  Val. loss: 0.107  Val. score: 97.500%\n",
      "Epoch 13, 100% \t Train loss: 0.032 took: 4.80s  Val. loss: 0.131  Val. score: 97.006%\n",
      "Epoch 14, 100% \t Train loss: 0.034 took: 4.43s  Val. loss: 0.110  Val. score: 97.522%\n",
      "Epoch 15, 100% \t Train loss: 0.030 took: 4.71s  Val. loss: 0.121  Val. score: 97.428%\n",
      "Training finished, took 118.016s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.358 took: 4.33s  Val. loss: 0.168  Val. score: 94.822%\n",
      "Epoch 2, 100% \t Train loss: 0.167 took: 4.49s  Val. loss: 0.137  Val. score: 95.978%\n",
      "Epoch 3, 100% \t Train loss: 0.124 took: 4.78s  Val. loss: 0.109  Val. score: 96.867%\n",
      "Epoch 4, 100% \t Train loss: 0.100 took: 4.87s  Val. loss: 0.115  Val. score: 96.811%\n",
      "Epoch 5, 100% \t Train loss: 0.085 took: 4.92s  Val. loss: 0.105  Val. score: 96.811%\n",
      "Epoch 6, 100% \t Train loss: 0.072 took: 5.03s  Val. loss: 0.100  Val. score: 97.306%\n",
      "Epoch 7, 100% \t Train loss: 0.065 took: 4.98s  Val. loss: 0.096  Val. score: 97.411%\n",
      "Epoch 8, 100% \t Train loss: 0.055 took: 5.02s  Val. loss: 0.097  Val. score: 97.328%\n",
      "Epoch 9, 100% \t Train loss: 0.050 took: 5.10s  Val. loss: 0.106  Val. score: 97.311%\n",
      "Epoch 10, 100% \t Train loss: 0.047 took: 5.07s  Val. loss: 0.096  Val. score: 97.600%\n",
      "Epoch 11, 100% \t Train loss: 0.042 took: 5.04s  Val. loss: 0.100  Val. score: 97.422%\n",
      "Epoch 12, 100% \t Train loss: 0.036 took: 5.01s  Val. loss: 0.099  Val. score: 97.633%\n",
      "Epoch 13, 100% \t Train loss: 0.035 took: 5.03s  Val. loss: 0.105  Val. score: 97.600%\n",
      "Epoch 14, 100% \t Train loss: 0.031 took: 4.66s  Val. loss: 0.111  Val. score: 97.517%\n",
      "Epoch 15, 100% \t Train loss: 0.030 took: 4.99s  Val. loss: 0.110  Val. score: 97.561%\n",
      "Training finished, took 121.198s\n",
      "\n",
      "Parameters configuration 74 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.014905145100167234\n",
      "h_sizes \t [784, 180, 40]\n",
      "penalty \t 0.005909636679506393\n",
      "dropout \t 0.12621349618380256\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4333 +/- 0.1021\n",
      "Time for evaluation: 357.6 s\n",
      "Estimated time to finish : 3.81 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.439 took: 4.87s  Val. loss: 0.224  Val. score: 93.250%\n",
      "Epoch 2, 100% \t Train loss: 0.209 took: 4.42s  Val. loss: 0.153  Val. score: 95.389%\n",
      "Epoch 3, 100% \t Train loss: 0.154 took: 4.50s  Val. loss: 0.125  Val. score: 96.261%\n",
      "Epoch 4, 100% \t Train loss: 0.124 took: 4.99s  Val. loss: 0.107  Val. score: 96.794%\n",
      "Epoch 5, 100% \t Train loss: 0.107 took: 4.59s  Val. loss: 0.102  Val. score: 97.006%\n",
      "Epoch 6, 100% \t Train loss: 0.087 took: 4.59s  Val. loss: 0.097  Val. score: 97.067%\n",
      "Epoch 7, 100% \t Train loss: 0.076 took: 4.85s  Val. loss: 0.097  Val. score: 97.206%\n",
      "Epoch 8, 100% \t Train loss: 0.068 took: 5.03s  Val. loss: 0.094  Val. score: 97.333%\n",
      "Epoch 9, 100% \t Train loss: 0.060 took: 5.04s  Val. loss: 0.101  Val. score: 97.111%\n",
      "Epoch 10, 100% \t Train loss: 0.053 took: 4.70s  Val. loss: 0.089  Val. score: 97.461%\n",
      "Epoch 11, 100% \t Train loss: 0.048 took: 4.65s  Val. loss: 0.091  Val. score: 97.494%\n",
      "Epoch 12, 100% \t Train loss: 0.043 took: 4.60s  Val. loss: 0.090  Val. score: 97.489%\n",
      "Epoch 13, 100% \t Train loss: 0.039 took: 4.73s  Val. loss: 0.092  Val. score: 97.589%\n",
      "Epoch 14, 100% \t Train loss: 0.036 took: 5.05s  Val. loss: 0.091  Val. score: 97.589%\n",
      "Epoch 15, 100% \t Train loss: 0.033 took: 5.00s  Val. loss: 0.091  Val. score: 97.628%\n",
      "Training finished, took 121.410s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.457 took: 4.84s  Val. loss: 0.213  Val. score: 93.617%\n",
      "Epoch 2, 100% \t Train loss: 0.211 took: 4.46s  Val. loss: 0.158  Val. score: 95.122%\n",
      "Epoch 3, 100% \t Train loss: 0.159 took: 4.95s  Val. loss: 0.132  Val. score: 96.061%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, 100% \t Train loss: 0.125 took: 4.91s  Val. loss: 0.122  Val. score: 96.356%\n",
      "Epoch 5, 100% \t Train loss: 0.108 took: 5.05s  Val. loss: 0.106  Val. score: 96.950%\n",
      "Epoch 6, 100% \t Train loss: 0.092 took: 4.70s  Val. loss: 0.099  Val. score: 97.022%\n",
      "Epoch 7, 100% \t Train loss: 0.080 took: 4.71s  Val. loss: 0.096  Val. score: 97.194%\n",
      "Epoch 8, 100% \t Train loss: 0.069 took: 4.70s  Val. loss: 0.093  Val. score: 97.328%\n",
      "Epoch 9, 100% \t Train loss: 0.063 took: 5.03s  Val. loss: 0.098  Val. score: 97.211%\n",
      "Epoch 10, 100% \t Train loss: 0.057 took: 5.18s  Val. loss: 0.093  Val. score: 97.394%\n",
      "Epoch 11, 100% \t Train loss: 0.051 took: 4.72s  Val. loss: 0.088  Val. score: 97.550%\n",
      "Epoch 12, 100% \t Train loss: 0.045 took: 4.69s  Val. loss: 0.094  Val. score: 97.489%\n",
      "Epoch 13, 100% \t Train loss: 0.042 took: 5.00s  Val. loss: 0.091  Val. score: 97.489%\n",
      "Epoch 14, 100% \t Train loss: 0.039 took: 5.09s  Val. loss: 0.098  Val. score: 97.417%\n",
      "Epoch 15, 100% \t Train loss: 0.036 took: 4.85s  Val. loss: 0.095  Val. score: 97.550%\n",
      "Training finished, took 122.488s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.442 took: 4.64s  Val. loss: 0.202  Val. score: 93.722%\n",
      "Epoch 2, 100% \t Train loss: 0.208 took: 4.64s  Val. loss: 0.151  Val. score: 95.317%\n",
      "Epoch 3, 100% \t Train loss: 0.156 took: 4.79s  Val. loss: 0.119  Val. score: 96.244%\n",
      "Epoch 4, 100% \t Train loss: 0.126 took: 5.05s  Val. loss: 0.109  Val. score: 96.722%\n",
      "Epoch 5, 100% \t Train loss: 0.105 took: 5.01s  Val. loss: 0.104  Val. score: 96.928%\n",
      "Epoch 6, 100% \t Train loss: 0.089 took: 5.10s  Val. loss: 0.095  Val. score: 97.078%\n",
      "Epoch 7, 100% \t Train loss: 0.079 took: 5.03s  Val. loss: 0.090  Val. score: 97.306%\n",
      "Epoch 8, 100% \t Train loss: 0.072 took: 4.64s  Val. loss: 0.089  Val. score: 97.406%\n",
      "Epoch 9, 100% \t Train loss: 0.063 took: 5.01s  Val. loss: 0.090  Val. score: 97.428%\n",
      "Epoch 10, 100% \t Train loss: 0.057 took: 5.22s  Val. loss: 0.087  Val. score: 97.561%\n",
      "Epoch 11, 100% \t Train loss: 0.050 took: 5.09s  Val. loss: 0.085  Val. score: 97.528%\n",
      "Epoch 12, 100% \t Train loss: 0.045 took: 4.66s  Val. loss: 0.087  Val. score: 97.494%\n",
      "Epoch 13, 100% \t Train loss: 0.045 took: 4.66s  Val. loss: 0.088  Val. score: 97.500%\n",
      "Epoch 14, 100% \t Train loss: 0.041 took: 5.13s  Val. loss: 0.089  Val. score: 97.572%\n",
      "Epoch 15, 100% \t Train loss: 0.036 took: 4.65s  Val. loss: 0.088  Val. score: 97.667%\n",
      "Training finished, took 122.556s\n",
      "\n",
      "Parameters configuration 75 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005806526806521204\n",
      "h_sizes \t [784, 190, 52]\n",
      "penalty \t 0.008738796712367566\n",
      "dropout \t 0.17153043626351422\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6148 +/- 0.0485\n",
      "Time for evaluation: 367.6 s\n",
      "Estimated time to finish : 3.65 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.530 took: 4.21s  Val. loss: 0.293  Val. score: 91.733%\n",
      "Epoch 2, 100% \t Train loss: 0.255 took: 4.37s  Val. loss: 0.214  Val. score: 93.961%\n",
      "Epoch 3, 100% \t Train loss: 0.192 took: 4.38s  Val. loss: 0.176  Val. score: 94.900%\n",
      "Epoch 4, 100% \t Train loss: 0.151 took: 4.28s  Val. loss: 0.148  Val. score: 95.706%\n",
      "Epoch 5, 100% \t Train loss: 0.123 took: 4.35s  Val. loss: 0.132  Val. score: 96.122%\n",
      "Epoch 6, 100% \t Train loss: 0.104 took: 4.41s  Val. loss: 0.122  Val. score: 96.428%\n",
      "Epoch 7, 100% \t Train loss: 0.088 took: 4.31s  Val. loss: 0.113  Val. score: 96.389%\n",
      "Epoch 8, 100% \t Train loss: 0.076 took: 4.37s  Val. loss: 0.107  Val. score: 96.778%\n",
      "Epoch 9, 100% \t Train loss: 0.064 took: 4.36s  Val. loss: 0.099  Val. score: 96.972%\n",
      "Epoch 10, 100% \t Train loss: 0.057 took: 4.43s  Val. loss: 0.097  Val. score: 97.089%\n",
      "Epoch 11, 100% \t Train loss: 0.050 took: 4.16s  Val. loss: 0.096  Val. score: 97.128%\n",
      "Epoch 12, 100% \t Train loss: 0.042 took: 4.33s  Val. loss: 0.092  Val. score: 97.239%\n",
      "Epoch 13, 100% \t Train loss: 0.038 took: 4.39s  Val. loss: 0.093  Val. score: 97.300%\n",
      "Epoch 14, 100% \t Train loss: 0.034 took: 4.32s  Val. loss: 0.094  Val. score: 97.289%\n",
      "Epoch 15, 100% \t Train loss: 0.030 took: 4.02s  Val. loss: 0.093  Val. score: 97.417%\n",
      "Training finished, took 111.619s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.554 took: 4.33s  Val. loss: 0.288  Val. score: 91.683%\n",
      "Epoch 2, 100% \t Train loss: 0.273 took: 4.22s  Val. loss: 0.219  Val. score: 93.794%\n",
      "Epoch 3, 100% \t Train loss: 0.210 took: 4.38s  Val. loss: 0.191  Val. score: 94.428%\n",
      "Epoch 4, 100% \t Train loss: 0.173 took: 4.32s  Val. loss: 0.165  Val. score: 95.244%\n",
      "Epoch 5, 100% \t Train loss: 0.145 took: 4.25s  Val. loss: 0.151  Val. score: 95.583%\n",
      "Epoch 6, 100% \t Train loss: 0.122 took: 4.31s  Val. loss: 0.127  Val. score: 96.156%\n",
      "Epoch 7, 100% \t Train loss: 0.104 took: 4.31s  Val. loss: 0.123  Val. score: 96.522%\n",
      "Epoch 8, 100% \t Train loss: 0.090 took: 4.37s  Val. loss: 0.114  Val. score: 96.711%\n",
      "Epoch 9, 100% \t Train loss: 0.080 took: 4.42s  Val. loss: 0.102  Val. score: 96.978%\n",
      "Epoch 10, 100% \t Train loss: 0.070 took: 4.39s  Val. loss: 0.098  Val. score: 97.100%\n",
      "Epoch 11, 100% \t Train loss: 0.060 took: 4.17s  Val. loss: 0.095  Val. score: 97.239%\n",
      "Epoch 12, 100% \t Train loss: 0.055 took: 4.37s  Val. loss: 0.096  Val. score: 97.156%\n",
      "Epoch 13, 100% \t Train loss: 0.047 took: 4.41s  Val. loss: 0.090  Val. score: 97.456%\n",
      "Epoch 14, 100% \t Train loss: 0.042 took: 4.17s  Val. loss: 0.094  Val. score: 97.317%\n",
      "Epoch 15, 100% \t Train loss: 0.039 took: 4.01s  Val. loss: 0.092  Val. score: 97.378%\n",
      "Training finished, took 111.226s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.546 took: 4.11s  Val. loss: 0.291  Val. score: 91.506%\n",
      "Epoch 2, 100% \t Train loss: 0.256 took: 4.35s  Val. loss: 0.216  Val. score: 93.767%\n",
      "Epoch 3, 100% \t Train loss: 0.191 took: 4.09s  Val. loss: 0.177  Val. score: 94.617%\n",
      "Epoch 4, 100% \t Train loss: 0.152 took: 3.96s  Val. loss: 0.159  Val. score: 95.094%\n",
      "Epoch 5, 100% \t Train loss: 0.128 took: 4.40s  Val. loss: 0.134  Val. score: 95.872%\n",
      "Epoch 6, 100% \t Train loss: 0.106 took: 4.27s  Val. loss: 0.118  Val. score: 96.256%\n",
      "Epoch 7, 100% \t Train loss: 0.092 took: 4.41s  Val. loss: 0.109  Val. score: 96.611%\n",
      "Epoch 8, 100% \t Train loss: 0.078 took: 4.43s  Val. loss: 0.104  Val. score: 96.794%\n",
      "Epoch 9, 100% \t Train loss: 0.069 took: 4.19s  Val. loss: 0.102  Val. score: 96.872%\n",
      "Epoch 10, 100% \t Train loss: 0.062 took: 4.34s  Val. loss: 0.098  Val. score: 96.994%\n",
      "Epoch 11, 100% \t Train loss: 0.054 took: 4.23s  Val. loss: 0.099  Val. score: 97.017%\n",
      "Epoch 12, 100% \t Train loss: 0.048 took: 4.39s  Val. loss: 0.091  Val. score: 97.178%\n",
      "Epoch 13, 100% \t Train loss: 0.042 took: 4.14s  Val. loss: 0.089  Val. score: 97.344%\n",
      "Epoch 14, 100% \t Train loss: 0.035 took: 4.02s  Val. loss: 0.090  Val. score: 97.289%\n",
      "Epoch 15, 100% \t Train loss: 0.033 took: 4.38s  Val. loss: 0.089  Val. score: 97.367%\n",
      "Training finished, took 110.549s\n",
      "\n",
      "Parameters configuration 76 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0023541243054821114\n",
      "h_sizes \t [784, 165, 43]\n",
      "penalty \t 0.00019911261419852956\n",
      "dropout \t 0.026522144615850257\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.3870 +/- 0.0214\n",
      "Time for evaluation: 334.6 s\n",
      "Estimated time to finish : 3.49 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.017 took: 13.15s  Val. loss: 0.373  Val. score: 90.378%\n",
      "Epoch 2, 100% \t Train loss: 0.303 took: 12.55s  Val. loss: 0.222  Val. score: 94.383%\n",
      "Epoch 3, 100% \t Train loss: 0.193 took: 14.22s  Val. loss: 0.175  Val. score: 95.522%\n",
      "Epoch 4, 100% \t Train loss: 0.140 took: 13.35s  Val. loss: 0.176  Val. score: 96.083%\n",
      "Epoch 5, 100% \t Train loss: 0.113 took: 13.39s  Val. loss: 0.156  Val. score: 96.378%\n",
      "Epoch 6, 100% \t Train loss: 0.090 took: 13.57s  Val. loss: 0.146  Val. score: 96.694%\n",
      "Epoch 7, 100% \t Train loss: 0.080 took: 14.18s  Val. loss: 0.139  Val. score: 96.822%\n",
      "Epoch 8, 100% \t Train loss: 0.066 took: 14.17s  Val. loss: 0.131  Val. score: 97.111%\n",
      "Epoch 9, 100% \t Train loss: 0.061 took: 13.46s  Val. loss: 0.154  Val. score: 96.789%\n",
      "Epoch 10, 100% \t Train loss: 0.048 took: 13.37s  Val. loss: 0.133  Val. score: 97.378%\n",
      "Epoch 11, 100% \t Train loss: 0.042 took: 13.35s  Val. loss: 0.135  Val. score: 97.356%\n",
      "Epoch 12, 100% \t Train loss: 0.039 took: 14.18s  Val. loss: 0.154  Val. score: 97.261%\n",
      "Epoch 13, 100% \t Train loss: 0.035 took: 14.27s  Val. loss: 0.146  Val. score: 97.406%\n",
      "Epoch 14, 100% \t Train loss: 0.030 took: 14.64s  Val. loss: 0.135  Val. score: 97.578%\n",
      "Epoch 15, 100% \t Train loss: 0.026 took: 14.36s  Val. loss: 0.135  Val. score: 97.589%\n",
      "Training finished, took 294.555s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.905 took: 13.31s  Val. loss: 0.306  Val. score: 92.139%\n",
      "Epoch 2, 100% \t Train loss: 0.278 took: 13.31s  Val. loss: 0.214  Val. score: 94.867%\n",
      "Epoch 3, 100% \t Train loss: 0.203 took: 14.33s  Val. loss: 0.186  Val. score: 95.528%\n",
      "Epoch 4, 100% \t Train loss: 0.158 took: 14.15s  Val. loss: 0.156  Val. score: 96.461%\n",
      "Epoch 5, 100% \t Train loss: 0.125 took: 15.17s  Val. loss: 0.145  Val. score: 96.544%\n",
      "Epoch 6, 100% \t Train loss: 0.106 took: 15.33s  Val. loss: 0.139  Val. score: 96.833%\n",
      "Epoch 7, 100% \t Train loss: 0.087 took: 15.35s  Val. loss: 0.138  Val. score: 96.906%\n",
      "Epoch 8, 100% \t Train loss: 0.079 took: 14.85s  Val. loss: 0.124  Val. score: 97.344%\n",
      "Epoch 9, 100% \t Train loss: 0.065 took: 15.30s  Val. loss: 0.148  Val. score: 97.200%\n",
      "Epoch 10, 100% \t Train loss: 0.060 took: 13.78s  Val. loss: 0.138  Val. score: 97.311%\n",
      "Epoch 11, 100% \t Train loss: 0.054 took: 15.27s  Val. loss: 0.138  Val. score: 97.383%\n",
      "Epoch 12, 100% \t Train loss: 0.044 took: 14.40s  Val. loss: 0.144  Val. score: 97.472%\n",
      "Epoch 13, 100% \t Train loss: 0.041 took: 13.79s  Val. loss: 0.134  Val. score: 97.644%\n",
      "Epoch 14, 100% \t Train loss: 0.037 took: 14.11s  Val. loss: 0.157  Val. score: 97.578%\n",
      "Epoch 15, 100% \t Train loss: 0.032 took: 13.78s  Val. loss: 0.141  Val. score: 97.667%\n",
      "Training finished, took 305.951s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.981 took: 11.86s  Val. loss: 0.317  Val. score: 91.950%\n",
      "Epoch 2, 100% \t Train loss: 0.299 took: 11.85s  Val. loss: 0.213  Val. score: 94.389%\n",
      "Epoch 3, 100% \t Train loss: 0.202 took: 13.63s  Val. loss: 0.182  Val. score: 95.400%\n",
      "Epoch 4, 100% \t Train loss: 0.148 took: 13.57s  Val. loss: 0.167  Val. score: 96.172%\n",
      "Epoch 5, 100% \t Train loss: 0.119 took: 14.64s  Val. loss: 0.162  Val. score: 96.239%\n",
      "Epoch 6, 100% \t Train loss: 0.097 took: 13.77s  Val. loss: 0.146  Val. score: 96.700%\n",
      "Epoch 7, 100% \t Train loss: 0.081 took: 14.78s  Val. loss: 0.143  Val. score: 96.817%\n",
      "Epoch 8, 100% \t Train loss: 0.067 took: 14.91s  Val. loss: 0.148  Val. score: 97.139%\n",
      "Epoch 9, 100% \t Train loss: 0.060 took: 14.28s  Val. loss: 0.145  Val. score: 97.094%\n",
      "Epoch 10, 100% \t Train loss: 0.050 took: 13.54s  Val. loss: 0.142  Val. score: 97.367%\n",
      "Epoch 11, 100% \t Train loss: 0.043 took: 13.59s  Val. loss: 0.150  Val. score: 97.222%\n",
      "Epoch 12, 100% \t Train loss: 0.040 took: 15.13s  Val. loss: 0.154  Val. score: 97.267%\n",
      "Epoch 13, 100% \t Train loss: 0.038 took: 14.19s  Val. loss: 0.161  Val. score: 97.150%\n",
      "Epoch 14, 100% \t Train loss: 0.030 took: 14.84s  Val. loss: 0.152  Val. score: 97.394%\n",
      "Epoch 15, 100% \t Train loss: 0.027 took: 13.95s  Val. loss: 0.165  Val. score: 97.144%\n",
      "Training finished, took 297.293s\n",
      "\n",
      "Parameters configuration 77 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00725300156526568\n",
      "h_sizes \t [784, 450, 250, 145, 88, 52, 32, 19]\n",
      "penalty \t 0.0010275147670114097\n",
      "dropout \t 0.06599719668695245\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4667 +/- 0.2300\n",
      "Time for evaluation: 899.0 s\n",
      "Estimated time to finish : 3.37 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.379 took: 4.54s  Val. loss: 0.190  Val. score: 94.433%\n",
      "Epoch 2, 100% \t Train loss: 0.179 took: 4.27s  Val. loss: 0.143  Val. score: 95.772%\n",
      "Epoch 3, 100% \t Train loss: 0.131 took: 4.45s  Val. loss: 0.108  Val. score: 96.817%\n",
      "Epoch 4, 100% \t Train loss: 0.103 took: 4.40s  Val. loss: 0.107  Val. score: 96.906%\n",
      "Epoch 5, 100% \t Train loss: 0.088 took: 4.82s  Val. loss: 0.103  Val. score: 96.928%\n",
      "Epoch 6, 100% \t Train loss: 0.070 took: 4.45s  Val. loss: 0.096  Val. score: 97.289%\n",
      "Epoch 7, 100% \t Train loss: 0.060 took: 4.69s  Val. loss: 0.092  Val. score: 97.411%\n",
      "Epoch 8, 100% \t Train loss: 0.054 took: 4.39s  Val. loss: 0.095  Val. score: 97.400%\n",
      "Epoch 9, 100% \t Train loss: 0.048 took: 4.64s  Val. loss: 0.096  Val. score: 97.444%\n",
      "Epoch 10, 100% \t Train loss: 0.046 took: 4.67s  Val. loss: 0.088  Val. score: 97.556%\n",
      "Epoch 11, 100% \t Train loss: 0.036 took: 4.54s  Val. loss: 0.092  Val. score: 97.694%\n",
      "Epoch 12, 100% \t Train loss: 0.032 took: 4.62s  Val. loss: 0.094  Val. score: 97.650%\n",
      "Epoch 13, 100% \t Train loss: 0.031 took: 4.80s  Val. loss: 0.091  Val. score: 97.806%\n",
      "Epoch 14, 100% \t Train loss: 0.027 took: 4.45s  Val. loss: 0.092  Val. score: 97.733%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 4.80s  Val. loss: 0.101  Val. score: 97.667%\n",
      "Training finished, took 116.704s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.410 took: 4.48s  Val. loss: 0.180  Val. score: 94.700%\n",
      "Epoch 2, 100% \t Train loss: 0.183 took: 4.51s  Val. loss: 0.138  Val. score: 95.878%\n",
      "Epoch 3, 100% \t Train loss: 0.136 took: 4.72s  Val. loss: 0.120  Val. score: 96.589%\n",
      "Epoch 4, 100% \t Train loss: 0.109 took: 4.88s  Val. loss: 0.103  Val. score: 96.900%\n",
      "Epoch 5, 100% \t Train loss: 0.089 took: 4.88s  Val. loss: 0.093  Val. score: 97.183%\n",
      "Epoch 6, 100% \t Train loss: 0.080 took: 4.87s  Val. loss: 0.100  Val. score: 97.028%\n",
      "Epoch 7, 100% \t Train loss: 0.067 took: 4.46s  Val. loss: 0.094  Val. score: 97.311%\n",
      "Epoch 8, 100% \t Train loss: 0.058 took: 4.55s  Val. loss: 0.092  Val. score: 97.417%\n",
      "Epoch 9, 100% \t Train loss: 0.053 took: 4.85s  Val. loss: 0.093  Val. score: 97.389%\n",
      "Epoch 10, 100% \t Train loss: 0.047 took: 4.76s  Val. loss: 0.088  Val. score: 97.656%\n",
      "Epoch 11, 100% \t Train loss: 0.043 took: 4.79s  Val. loss: 0.090  Val. score: 97.639%\n",
      "Epoch 12, 100% \t Train loss: 0.037 took: 4.81s  Val. loss: 0.099  Val. score: 97.567%\n",
      "Epoch 13, 100% \t Train loss: 0.035 took: 4.48s  Val. loss: 0.089  Val. score: 97.678%\n",
      "Epoch 14, 100% \t Train loss: 0.031 took: 4.49s  Val. loss: 0.098  Val. score: 97.522%\n",
      "Epoch 15, 100% \t Train loss: 0.029 took: 4.86s  Val. loss: 0.094  Val. score: 97.622%\n",
      "Training finished, took 118.124s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.393 took: 4.52s  Val. loss: 0.193  Val. score: 94.100%\n",
      "Epoch 2, 100% \t Train loss: 0.180 took: 4.31s  Val. loss: 0.141  Val. score: 95.733%\n",
      "Epoch 3, 100% \t Train loss: 0.132 took: 4.37s  Val. loss: 0.123  Val. score: 96.094%\n",
      "Epoch 4, 100% \t Train loss: 0.106 took: 4.55s  Val. loss: 0.106  Val. score: 96.678%\n",
      "Epoch 5, 100% \t Train loss: 0.087 took: 4.82s  Val. loss: 0.104  Val. score: 96.744%\n",
      "Epoch 6, 100% \t Train loss: 0.073 took: 4.84s  Val. loss: 0.095  Val. score: 97.100%\n",
      "Epoch 7, 100% \t Train loss: 0.060 took: 4.37s  Val. loss: 0.091  Val. score: 97.311%\n",
      "Epoch 8, 100% \t Train loss: 0.053 took: 4.67s  Val. loss: 0.092  Val. score: 97.256%\n",
      "Epoch 9, 100% \t Train loss: 0.047 took: 4.76s  Val. loss: 0.093  Val. score: 97.356%\n",
      "Epoch 10, 100% \t Train loss: 0.042 took: 4.38s  Val. loss: 0.092  Val. score: 97.489%\n",
      "Epoch 11, 100% \t Train loss: 0.037 took: 4.35s  Val. loss: 0.091  Val. score: 97.567%\n",
      "Epoch 12, 100% \t Train loss: 0.035 took: 4.72s  Val. loss: 0.099  Val. score: 97.406%\n",
      "Epoch 13, 100% \t Train loss: 0.030 took: 4.59s  Val. loss: 0.096  Val. score: 97.528%\n",
      "Epoch 14, 100% \t Train loss: 0.029 took: 4.77s  Val. loss: 0.096  Val. score: 97.706%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 4.78s  Val. loss: 0.090  Val. score: 97.711%\n",
      "Training finished, took 116.929s\n",
      "\n",
      "Parameters configuration 78 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.009388429321100844\n",
      "h_sizes \t [784, 176, 44]\n",
      "penalty \t 0.001882987655095027\n",
      "dropout \t 0.11315995195569131\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6667 +/- 0.0363\n",
      "Time for evaluation: 352.9 s\n",
      "Estimated time to finish : 3.21 h \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.375 took: 4.62s  Val. loss: 0.188  Val. score: 94.350%\n",
      "Epoch 2, 100% \t Train loss: 0.176 took: 4.59s  Val. loss: 0.141  Val. score: 95.506%\n",
      "Epoch 3, 100% \t Train loss: 0.127 took: 4.73s  Val. loss: 0.118  Val. score: 96.411%\n",
      "Epoch 4, 100% \t Train loss: 0.100 took: 4.86s  Val. loss: 0.113  Val. score: 96.661%\n",
      "Epoch 5, 100% \t Train loss: 0.081 took: 4.52s  Val. loss: 0.092  Val. score: 97.161%\n",
      "Epoch 6, 100% \t Train loss: 0.070 took: 4.46s  Val. loss: 0.096  Val. score: 97.078%\n",
      "Epoch 7, 100% \t Train loss: 0.058 took: 4.70s  Val. loss: 0.087  Val. score: 97.306%\n",
      "Epoch 8, 100% \t Train loss: 0.050 took: 4.46s  Val. loss: 0.093  Val. score: 97.228%\n",
      "Epoch 9, 100% \t Train loss: 0.043 took: 4.99s  Val. loss: 0.097  Val. score: 97.194%\n",
      "Epoch 10, 100% \t Train loss: 0.042 took: 4.91s  Val. loss: 0.091  Val. score: 97.489%\n",
      "Epoch 11, 100% \t Train loss: 0.032 took: 4.47s  Val. loss: 0.089  Val. score: 97.617%\n",
      "Epoch 12, 100% \t Train loss: 0.027 took: 5.01s  Val. loss: 0.088  Val. score: 97.594%\n",
      "Epoch 13, 100% \t Train loss: 0.027 took: 4.46s  Val. loss: 0.087  Val. score: 97.572%\n",
      "Epoch 14, 100% \t Train loss: 0.023 took: 4.46s  Val. loss: 0.092  Val. score: 97.628%\n",
      "Epoch 15, 100% \t Train loss: 0.021 took: 4.55s  Val. loss: 0.097  Val. score: 97.550%\n",
      "Training finished, took 118.816s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.395 took: 4.61s  Val. loss: 0.186  Val. score: 94.456%\n",
      "Epoch 2, 100% \t Train loss: 0.178 took: 4.54s  Val. loss: 0.145  Val. score: 95.617%\n",
      "Epoch 3, 100% \t Train loss: 0.129 took: 4.94s  Val. loss: 0.126  Val. score: 96.350%\n",
      "Epoch 4, 100% \t Train loss: 0.102 took: 4.89s  Val. loss: 0.103  Val. score: 96.911%\n",
      "Epoch 5, 100% \t Train loss: 0.084 took: 5.03s  Val. loss: 0.109  Val. score: 96.667%\n",
      "Epoch 6, 100% \t Train loss: 0.068 took: 5.06s  Val. loss: 0.096  Val. score: 97.189%\n",
      "Epoch 7, 100% \t Train loss: 0.059 took: 5.14s  Val. loss: 0.095  Val. score: 97.267%\n",
      "Epoch 8, 100% \t Train loss: 0.051 took: 4.54s  Val. loss: 0.101  Val. score: 97.106%\n",
      "Epoch 9, 100% \t Train loss: 0.046 took: 4.91s  Val. loss: 0.093  Val. score: 97.433%\n",
      "Epoch 10, 100% \t Train loss: 0.039 took: 4.53s  Val. loss: 0.097  Val. score: 97.439%\n",
      "Epoch 11, 100% \t Train loss: 0.035 took: 5.07s  Val. loss: 0.096  Val. score: 97.511%\n",
      "Epoch 12, 100% \t Train loss: 0.032 took: 5.03s  Val. loss: 0.097  Val. score: 97.567%\n",
      "Epoch 13, 100% \t Train loss: 0.029 took: 4.54s  Val. loss: 0.097  Val. score: 97.661%\n",
      "Epoch 14, 100% \t Train loss: 0.024 took: 4.93s  Val. loss: 0.096  Val. score: 97.644%\n",
      "Epoch 15, 100% \t Train loss: 0.022 took: 5.04s  Val. loss: 0.107  Val. score: 97.539%\n",
      "Training finished, took 121.628s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.363 took: 4.53s  Val. loss: 0.171  Val. score: 94.983%\n",
      "Epoch 2, 100% \t Train loss: 0.166 took: 4.64s  Val. loss: 0.140  Val. score: 95.639%\n",
      "Epoch 3, 100% \t Train loss: 0.121 took: 4.79s  Val. loss: 0.120  Val. score: 96.444%\n",
      "Epoch 4, 100% \t Train loss: 0.095 took: 5.00s  Val. loss: 0.105  Val. score: 96.872%\n",
      "Epoch 5, 100% \t Train loss: 0.079 took: 5.55s  Val. loss: 0.101  Val. score: 97.100%\n",
      "Epoch 6, 100% \t Train loss: 0.064 took: 5.50s  Val. loss: 0.092  Val. score: 97.439%\n",
      "Epoch 7, 100% \t Train loss: 0.053 took: 5.27s  Val. loss: 0.090  Val. score: 97.456%\n",
      "Epoch 8, 100% \t Train loss: 0.044 took: 5.98s  Val. loss: 0.095  Val. score: 97.467%\n",
      "Epoch 9, 100% \t Train loss: 0.040 took: 4.56s  Val. loss: 0.091  Val. score: 97.639%\n",
      "Epoch 10, 100% \t Train loss: 0.036 took: 4.48s  Val. loss: 0.090  Val. score: 97.672%\n",
      "Epoch 11, 100% \t Train loss: 0.032 took: 4.44s  Val. loss: 0.095  Val. score: 97.572%\n",
      "Epoch 12, 100% \t Train loss: 0.028 took: 5.01s  Val. loss: 0.095  Val. score: 97.639%\n",
      "Epoch 13, 100% \t Train loss: 0.023 took: 4.97s  Val. loss: 0.104  Val. score: 97.506%\n",
      "Epoch 14, 100% \t Train loss: 0.024 took: 4.79s  Val. loss: 0.098  Val. score: 97.833%\n",
      "Epoch 15, 100% \t Train loss: 0.019 took: 5.16s  Val. loss: 0.101  Val. score: 97.733%\n",
      "Training finished, took 126.640s\n",
      "\n",
      "Parameters configuration 79 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.009132725389088516\n",
      "h_sizes \t [784, 184, 47]\n",
      "penalty \t 0.0016600906122926984\n",
      "dropout \t 0.1028446558133636\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6074 +/- 0.0892\n",
      "Time for evaluation: 368.3 s\n",
      "Estimated time to finish : 3.06 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.491 took: 4.36s  Val. loss: 0.218  Val. score: 93.389%\n",
      "Epoch 2, 100% \t Train loss: 0.225 took: 4.19s  Val. loss: 0.164  Val. score: 95.094%\n",
      "Epoch 3, 100% \t Train loss: 0.168 took: 4.63s  Val. loss: 0.133  Val. score: 95.906%\n",
      "Epoch 4, 100% \t Train loss: 0.134 took: 4.68s  Val. loss: 0.121  Val. score: 96.367%\n",
      "Epoch 5, 100% \t Train loss: 0.113 took: 4.54s  Val. loss: 0.108  Val. score: 96.961%\n",
      "Epoch 6, 100% \t Train loss: 0.101 took: 4.87s  Val. loss: 0.098  Val. score: 97.028%\n",
      "Epoch 7, 100% \t Train loss: 0.088 took: 4.78s  Val. loss: 0.099  Val. score: 97.089%\n",
      "Epoch 8, 100% \t Train loss: 0.079 took: 5.55s  Val. loss: 0.094  Val. score: 97.339%\n",
      "Epoch 9, 100% \t Train loss: 0.071 took: 4.59s  Val. loss: 0.090  Val. score: 97.356%\n",
      "Epoch 10, 100% \t Train loss: 0.065 took: 4.64s  Val. loss: 0.086  Val. score: 97.583%\n",
      "Epoch 11, 100% \t Train loss: 0.059 took: 4.83s  Val. loss: 0.091  Val. score: 97.467%\n",
      "Epoch 12, 100% \t Train loss: 0.054 took: 4.80s  Val. loss: 0.092  Val. score: 97.556%\n",
      "Epoch 13, 100% \t Train loss: 0.053 took: 4.30s  Val. loss: 0.085  Val. score: 97.611%\n",
      "Epoch 14, 100% \t Train loss: 0.047 took: 4.74s  Val. loss: 0.088  Val. score: 97.600%\n",
      "Epoch 15, 100% \t Train loss: 0.043 took: 4.45s  Val. loss: 0.091  Val. score: 97.556%\n",
      "Training finished, took 119.930s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.468 took: 4.52s  Val. loss: 0.208  Val. score: 93.806%\n",
      "Epoch 2, 100% \t Train loss: 0.225 took: 4.31s  Val. loss: 0.148  Val. score: 95.467%\n",
      "Epoch 3, 100% \t Train loss: 0.171 took: 4.63s  Val. loss: 0.133  Val. score: 95.778%\n",
      "Epoch 4, 100% \t Train loss: 0.138 took: 4.64s  Val. loss: 0.115  Val. score: 96.367%\n",
      "Epoch 5, 100% \t Train loss: 0.115 took: 4.77s  Val. loss: 0.104  Val. score: 96.794%\n",
      "Epoch 6, 100% \t Train loss: 0.102 took: 4.80s  Val. loss: 0.098  Val. score: 97.022%\n",
      "Epoch 7, 100% \t Train loss: 0.089 took: 4.75s  Val. loss: 0.098  Val. score: 97.067%\n",
      "Epoch 8, 100% \t Train loss: 0.078 took: 4.36s  Val. loss: 0.092  Val. score: 97.167%\n",
      "Epoch 9, 100% \t Train loss: 0.069 took: 4.43s  Val. loss: 0.089  Val. score: 97.267%\n",
      "Epoch 10, 100% \t Train loss: 0.058 took: 4.39s  Val. loss: 0.094  Val. score: 97.339%\n",
      "Epoch 11, 100% \t Train loss: 0.055 took: 4.70s  Val. loss: 0.089  Val. score: 97.383%\n",
      "Epoch 12, 100% \t Train loss: 0.053 took: 4.70s  Val. loss: 0.089  Val. score: 97.444%\n",
      "Epoch 13, 100% \t Train loss: 0.046 took: 4.32s  Val. loss: 0.088  Val. score: 97.522%\n",
      "Epoch 14, 100% \t Train loss: 0.043 took: 4.79s  Val. loss: 0.089  Val. score: 97.528%\n",
      "Epoch 15, 100% \t Train loss: 0.042 took: 4.80s  Val. loss: 0.091  Val. score: 97.511%\n",
      "Training finished, took 117.448s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.462 took: 4.50s  Val. loss: 0.217  Val. score: 93.517%\n",
      "Epoch 2, 100% \t Train loss: 0.218 took: 4.53s  Val. loss: 0.156  Val. score: 95.294%\n",
      "Epoch 3, 100% \t Train loss: 0.162 took: 4.70s  Val. loss: 0.126  Val. score: 95.983%\n",
      "Epoch 4, 100% \t Train loss: 0.133 took: 4.79s  Val. loss: 0.114  Val. score: 96.511%\n",
      "Epoch 5, 100% \t Train loss: 0.112 took: 4.78s  Val. loss: 0.101  Val. score: 96.961%\n",
      "Epoch 6, 100% \t Train loss: 0.103 took: 4.83s  Val. loss: 0.097  Val. score: 97.083%\n",
      "Epoch 7, 100% \t Train loss: 0.085 took: 4.78s  Val. loss: 0.097  Val. score: 97.106%\n",
      "Epoch 8, 100% \t Train loss: 0.077 took: 4.60s  Val. loss: 0.094  Val. score: 97.178%\n",
      "Epoch 9, 100% \t Train loss: 0.070 took: 4.39s  Val. loss: 0.093  Val. score: 97.294%\n",
      "Epoch 10, 100% \t Train loss: 0.065 took: 4.69s  Val. loss: 0.088  Val. score: 97.328%\n",
      "Epoch 11, 100% \t Train loss: 0.059 took: 4.82s  Val. loss: 0.082  Val. score: 97.578%\n",
      "Epoch 12, 100% \t Train loss: 0.055 took: 4.73s  Val. loss: 0.085  Val. score: 97.533%\n",
      "Epoch 13, 100% \t Train loss: 0.047 took: 4.39s  Val. loss: 0.089  Val. score: 97.478%\n",
      "Epoch 14, 100% \t Train loss: 0.047 took: 4.75s  Val. loss: 0.084  Val. score: 97.678%\n",
      "Epoch 15, 100% \t Train loss: 0.044 took: 4.86s  Val. loss: 0.085  Val. score: 97.722%\n",
      "Training finished, took 118.397s\n",
      "\n",
      "Parameters configuration 80 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0063841359690157435\n",
      "h_sizes \t [784, 184, 35]\n",
      "penalty \t 0.004410530921923416\n",
      "dropout \t 0.17879078646643765\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5963 +/- 0.0909\n",
      "Time for evaluation: 356.9 s\n",
      "Estimated time to finish : 2.90 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.765 took: 7.64s  Val. loss: 0.256  Val. score: 93.394%\n",
      "Epoch 2, 100% \t Train loss: 0.343 took: 7.22s  Val. loss: 0.182  Val. score: 95.272%\n",
      "Epoch 3, 100% \t Train loss: 0.262 took: 8.16s  Val. loss: 0.161  Val. score: 95.911%\n",
      "Epoch 4, 100% \t Train loss: 0.221 took: 8.31s  Val. loss: 0.147  Val. score: 96.289%\n",
      "Epoch 5, 100% \t Train loss: 0.193 took: 8.41s  Val. loss: 0.151  Val. score: 96.433%\n",
      "Epoch 6, 100% \t Train loss: 0.162 took: 8.53s  Val. loss: 0.136  Val. score: 96.950%\n",
      "Epoch 7, 100% \t Train loss: 0.148 took: 8.24s  Val. loss: 0.140  Val. score: 97.089%\n",
      "Epoch 8, 100% \t Train loss: 0.142 took: 8.89s  Val. loss: 0.122  Val. score: 97.289%\n",
      "Epoch 9, 100% \t Train loss: 0.128 took: 7.85s  Val. loss: 0.137  Val. score: 97.172%\n",
      "Epoch 10, 100% \t Train loss: 0.121 took: 7.88s  Val. loss: 0.139  Val. score: 97.300%\n",
      "Epoch 11, 100% \t Train loss: 0.114 took: 8.36s  Val. loss: 0.134  Val. score: 97.306%\n",
      "Epoch 12, 100% \t Train loss: 0.103 took: 8.31s  Val. loss: 0.132  Val. score: 97.556%\n",
      "Epoch 13, 100% \t Train loss: 0.100 took: 7.98s  Val. loss: 0.144  Val. score: 97.389%\n",
      "Epoch 14, 100% \t Train loss: 0.095 took: 8.40s  Val. loss: 0.141  Val. score: 97.456%\n",
      "Epoch 15, 100% \t Train loss: 0.089 took: 7.87s  Val. loss: 0.140  Val. score: 97.594%\n",
      "Training finished, took 186.708s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.755 took: 7.44s  Val. loss: 0.240  Val. score: 93.411%\n",
      "Epoch 2, 100% \t Train loss: 0.335 took: 6.95s  Val. loss: 0.182  Val. score: 95.239%\n",
      "Epoch 3, 100% \t Train loss: 0.254 took: 8.11s  Val. loss: 0.150  Val. score: 95.828%\n",
      "Epoch 4, 100% \t Train loss: 0.218 took: 8.34s  Val. loss: 0.147  Val. score: 96.311%\n",
      "Epoch 5, 100% \t Train loss: 0.190 took: 7.83s  Val. loss: 0.134  Val. score: 96.672%\n",
      "Epoch 6, 100% \t Train loss: 0.170 took: 7.80s  Val. loss: 0.134  Val. score: 96.756%\n",
      "Epoch 7, 100% \t Train loss: 0.159 took: 8.33s  Val. loss: 0.138  Val. score: 96.822%\n",
      "Epoch 8, 100% \t Train loss: 0.138 took: 7.83s  Val. loss: 0.135  Val. score: 96.856%\n",
      "Epoch 9, 100% \t Train loss: 0.133 took: 7.83s  Val. loss: 0.124  Val. score: 97.072%\n",
      "Epoch 10, 100% \t Train loss: 0.122 took: 7.84s  Val. loss: 0.127  Val. score: 97.194%\n",
      "Epoch 11, 100% \t Train loss: 0.115 took: 7.83s  Val. loss: 0.119  Val. score: 97.333%\n",
      "Epoch 12, 100% \t Train loss: 0.106 took: 8.01s  Val. loss: 0.122  Val. score: 97.389%\n",
      "Epoch 13, 100% \t Train loss: 0.104 took: 8.64s  Val. loss: 0.125  Val. score: 97.489%\n",
      "Epoch 14, 100% \t Train loss: 0.099 took: 8.91s  Val. loss: 0.136  Val. score: 97.439%\n",
      "Epoch 15, 100% \t Train loss: 0.098 took: 8.36s  Val. loss: 0.136  Val. score: 97.467%\n",
      "Training finished, took 184.023s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.795 took: 7.60s  Val. loss: 0.245  Val. score: 93.528%\n",
      "Epoch 2, 100% \t Train loss: 0.359 took: 7.66s  Val. loss: 0.200  Val. score: 94.639%\n",
      "Epoch 3, 100% \t Train loss: 0.263 took: 7.78s  Val. loss: 0.154  Val. score: 95.967%\n",
      "Epoch 4, 100% \t Train loss: 0.220 took: 8.44s  Val. loss: 0.142  Val. score: 96.417%\n",
      "Epoch 5, 100% \t Train loss: 0.187 took: 7.90s  Val. loss: 0.138  Val. score: 96.711%\n",
      "Epoch 6, 100% \t Train loss: 0.166 took: 8.52s  Val. loss: 0.132  Val. score: 96.589%\n",
      "Epoch 7, 100% \t Train loss: 0.150 took: 8.53s  Val. loss: 0.118  Val. score: 97.089%\n",
      "Epoch 8, 100% \t Train loss: 0.136 took: 7.88s  Val. loss: 0.131  Val. score: 97.117%\n",
      "Epoch 9, 100% \t Train loss: 0.126 took: 8.40s  Val. loss: 0.131  Val. score: 97.172%\n",
      "Epoch 10, 100% \t Train loss: 0.118 took: 8.58s  Val. loss: 0.137  Val. score: 97.222%\n",
      "Epoch 11, 100% \t Train loss: 0.110 took: 8.27s  Val. loss: 0.130  Val. score: 97.317%\n",
      "Epoch 12, 100% \t Train loss: 0.104 took: 8.49s  Val. loss: 0.125  Val. score: 97.417%\n",
      "Epoch 13, 100% \t Train loss: 0.097 took: 8.29s  Val. loss: 0.144  Val. score: 97.317%\n",
      "Epoch 14, 100% \t Train loss: 0.093 took: 8.46s  Val. loss: 0.130  Val. score: 97.433%\n",
      "Epoch 15, 100% \t Train loss: 0.087 took: 8.37s  Val. loss: 0.135  Val. score: 97.433%\n",
      "Training finished, took 188.583s\n",
      "\n",
      "Parameters configuration 81 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.009752196267247772\n",
      "h_sizes \t [784, 324, 134, 50, 15]\n",
      "penalty \t 0.0003826375431677099\n",
      "dropout \t 0.24246159332502737\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4981 +/- 0.0694\n",
      "Time for evaluation: 560.5 s\n",
      "Estimated time to finish : 2.76 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.449 took: 7.69s  Val. loss: 0.197  Val. score: 94.439%\n",
      "Epoch 2, 100% \t Train loss: 0.196 took: 7.40s  Val. loss: 0.150  Val. score: 95.878%\n",
      "Epoch 3, 100% \t Train loss: 0.139 took: 8.35s  Val. loss: 0.141  Val. score: 96.372%\n",
      "Epoch 4, 100% \t Train loss: 0.114 took: 8.65s  Val. loss: 0.131  Val. score: 96.606%\n",
      "Epoch 5, 100% \t Train loss: 0.098 took: 8.69s  Val. loss: 0.114  Val. score: 97.067%\n",
      "Epoch 6, 100% \t Train loss: 0.081 took: 8.97s  Val. loss: 0.121  Val. score: 97.106%\n",
      "Epoch 7, 100% \t Train loss: 0.073 took: 9.38s  Val. loss: 0.122  Val. score: 97.178%\n",
      "Epoch 8, 100% \t Train loss: 0.063 took: 8.87s  Val. loss: 0.102  Val. score: 97.517%\n",
      "Epoch 9, 100% \t Train loss: 0.054 took: 9.14s  Val. loss: 0.106  Val. score: 97.428%\n",
      "Epoch 10, 100% \t Train loss: 0.049 took: 9.67s  Val. loss: 0.112  Val. score: 97.489%\n",
      "Epoch 11, 100% \t Train loss: 0.044 took: 9.58s  Val. loss: 0.108  Val. score: 97.767%\n",
      "Epoch 12, 100% \t Train loss: 0.040 took: 9.44s  Val. loss: 0.117  Val. score: 97.556%\n",
      "Epoch 13, 100% \t Train loss: 0.037 took: 11.80s  Val. loss: 0.113  Val. score: 97.656%\n",
      "Epoch 14, 100% \t Train loss: 0.033 took: 10.02s  Val. loss: 0.114  Val. score: 97.706%\n",
      "Epoch 15, 100% \t Train loss: 0.032 took: 9.36s  Val. loss: 0.121  Val. score: 97.700%\n",
      "Training finished, took 206.722s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.508 took: 7.89s  Val. loss: 0.203  Val. score: 94.217%\n",
      "Epoch 2, 100% \t Train loss: 0.207 took: 8.34s  Val. loss: 0.152  Val. score: 95.750%\n",
      "Epoch 3, 100% \t Train loss: 0.156 took: 9.63s  Val. loss: 0.128  Val. score: 96.450%\n",
      "Epoch 4, 100% \t Train loss: 0.123 took: 9.50s  Val. loss: 0.110  Val. score: 97.044%\n",
      "Epoch 5, 100% \t Train loss: 0.103 took: 9.78s  Val. loss: 0.120  Val. score: 97.061%\n",
      "Epoch 6, 100% \t Train loss: 0.089 took: 10.14s  Val. loss: 0.115  Val. score: 97.122%\n",
      "Epoch 7, 100% \t Train loss: 0.080 took: 9.52s  Val. loss: 0.097  Val. score: 97.450%\n",
      "Epoch 8, 100% \t Train loss: 0.065 took: 9.34s  Val. loss: 0.110  Val. score: 97.406%\n",
      "Epoch 9, 100% \t Train loss: 0.059 took: 9.21s  Val. loss: 0.104  Val. score: 97.633%\n",
      "Epoch 10, 100% \t Train loss: 0.053 took: 9.50s  Val. loss: 0.110  Val. score: 97.356%\n",
      "Epoch 11, 100% \t Train loss: 0.046 took: 10.87s  Val. loss: 0.109  Val. score: 97.561%\n",
      "Epoch 12, 100% \t Train loss: 0.043 took: 10.44s  Val. loss: 0.116  Val. score: 97.467%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, 100% \t Train loss: 0.042 took: 9.46s  Val. loss: 0.103  Val. score: 97.644%\n",
      "Epoch 14, 100% \t Train loss: 0.040 took: 10.58s  Val. loss: 0.111  Val. score: 97.689%\n",
      "Epoch 15, 100% \t Train loss: 0.033 took: 9.53s  Val. loss: 0.115  Val. score: 97.689%\n",
      "Training finished, took 219.472s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.463 took: 8.01s  Val. loss: 0.187  Val. score: 94.667%\n",
      "Epoch 2, 100% \t Train loss: 0.192 took: 8.25s  Val. loss: 0.140  Val. score: 96.039%\n",
      "Epoch 3, 100% \t Train loss: 0.143 took: 9.57s  Val. loss: 0.132  Val. score: 96.244%\n",
      "Epoch 4, 100% \t Train loss: 0.115 took: 10.17s  Val. loss: 0.124  Val. score: 96.600%\n",
      "Epoch 5, 100% \t Train loss: 0.099 took: 9.26s  Val. loss: 0.110  Val. score: 97.094%\n",
      "Epoch 6, 100% \t Train loss: 0.085 took: 9.49s  Val. loss: 0.113  Val. score: 97.100%\n",
      "Epoch 7, 100% \t Train loss: 0.069 took: 9.15s  Val. loss: 0.120  Val. score: 97.150%\n",
      "Epoch 8, 100% \t Train loss: 0.064 took: 10.36s  Val. loss: 0.114  Val. score: 97.156%\n",
      "Epoch 9, 100% \t Train loss: 0.051 took: 10.34s  Val. loss: 0.116  Val. score: 97.311%\n",
      "Epoch 10, 100% \t Train loss: 0.048 took: 9.81s  Val. loss: 0.117  Val. score: 97.372%\n",
      "Epoch 11, 100% \t Train loss: 0.045 took: 11.23s  Val. loss: 0.112  Val. score: 97.494%\n",
      "Epoch 12, 100% \t Train loss: 0.037 took: 11.39s  Val. loss: 0.113  Val. score: 97.483%\n",
      "Epoch 13, 100% \t Train loss: 0.039 took: 10.04s  Val. loss: 0.128  Val. score: 97.289%\n",
      "Epoch 14, 100% \t Train loss: 0.034 took: 10.53s  Val. loss: 0.134  Val. score: 97.467%\n",
      "Epoch 15, 100% \t Train loss: 0.032 took: 9.22s  Val. loss: 0.128  Val. score: 97.322%\n",
      "Training finished, took 224.121s\n",
      "\n",
      "Parameters configuration 82 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.013909282948619515\n",
      "h_sizes \t [784, 338, 153, 61, 30]\n",
      "penalty \t 0.0015819485864566184\n",
      "dropout \t 0.14965454364809813\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5704 +/- 0.1755\n",
      "Time for evaluation: 651.5 s\n",
      "Estimated time to finish : 2.62 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.371 took: 5.39s  Val. loss: 0.164  Val. score: 95.217%\n",
      "Epoch 2, 100% \t Train loss: 0.178 took: 4.53s  Val. loss: 0.131  Val. score: 96.006%\n",
      "Epoch 3, 100% \t Train loss: 0.140 took: 4.99s  Val. loss: 0.115  Val. score: 96.650%\n",
      "Epoch 4, 100% \t Train loss: 0.115 took: 5.00s  Val. loss: 0.111  Val. score: 96.811%\n",
      "Epoch 5, 100% \t Train loss: 0.101 took: 4.76s  Val. loss: 0.110  Val. score: 96.928%\n",
      "Epoch 6, 100% \t Train loss: 0.087 took: 4.50s  Val. loss: 0.110  Val. score: 96.956%\n",
      "Epoch 7, 100% \t Train loss: 0.083 took: 4.38s  Val. loss: 0.102  Val. score: 97.111%\n",
      "Epoch 8, 100% \t Train loss: 0.071 took: 4.57s  Val. loss: 0.100  Val. score: 97.356%\n",
      "Epoch 9, 100% \t Train loss: 0.066 took: 4.78s  Val. loss: 0.102  Val. score: 97.456%\n",
      "Epoch 10, 100% \t Train loss: 0.059 took: 4.45s  Val. loss: 0.104  Val. score: 97.400%\n",
      "Epoch 11, 100% \t Train loss: 0.057 took: 4.85s  Val. loss: 0.102  Val. score: 97.478%\n",
      "Epoch 12, 100% \t Train loss: 0.052 took: 4.96s  Val. loss: 0.100  Val. score: 97.528%\n",
      "Epoch 13, 100% \t Train loss: 0.048 took: 4.76s  Val. loss: 0.108  Val. score: 97.444%\n",
      "Epoch 14, 100% \t Train loss: 0.046 took: 4.83s  Val. loss: 0.107  Val. score: 97.478%\n",
      "Epoch 15, 100% \t Train loss: 0.044 took: 4.95s  Val. loss: 0.110  Val. score: 97.539%\n",
      "Training finished, took 122.374s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.365 took: 4.35s  Val. loss: 0.171  Val. score: 94.650%\n",
      "Epoch 2, 100% \t Train loss: 0.186 took: 4.59s  Val. loss: 0.130  Val. score: 96.167%\n",
      "Epoch 3, 100% \t Train loss: 0.148 took: 4.71s  Val. loss: 0.115  Val. score: 96.589%\n",
      "Epoch 4, 100% \t Train loss: 0.123 took: 4.80s  Val. loss: 0.104  Val. score: 96.983%\n",
      "Epoch 5, 100% \t Train loss: 0.106 took: 4.72s  Val. loss: 0.102  Val. score: 96.956%\n",
      "Epoch 6, 100% \t Train loss: 0.093 took: 5.07s  Val. loss: 0.090  Val. score: 97.244%\n",
      "Epoch 7, 100% \t Train loss: 0.081 took: 4.53s  Val. loss: 0.097  Val. score: 97.383%\n",
      "Epoch 8, 100% \t Train loss: 0.075 took: 4.72s  Val. loss: 0.091  Val. score: 97.539%\n",
      "Epoch 9, 100% \t Train loss: 0.067 took: 4.47s  Val. loss: 0.094  Val. score: 97.556%\n",
      "Epoch 10, 100% \t Train loss: 0.066 took: 4.71s  Val. loss: 0.103  Val. score: 97.211%\n",
      "Epoch 11, 100% \t Train loss: 0.059 took: 4.76s  Val. loss: 0.091  Val. score: 97.539%\n",
      "Epoch 12, 100% \t Train loss: 0.056 took: 4.80s  Val. loss: 0.093  Val. score: 97.667%\n",
      "Epoch 13, 100% \t Train loss: 0.054 took: 4.41s  Val. loss: 0.097  Val. score: 97.567%\n",
      "Epoch 14, 100% \t Train loss: 0.051 took: 4.84s  Val. loss: 0.098  Val. score: 97.544%\n",
      "Epoch 15, 100% \t Train loss: 0.047 took: 4.92s  Val. loss: 0.095  Val. score: 97.600%\n",
      "Training finished, took 120.171s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.383 took: 4.76s  Val. loss: 0.183  Val. score: 94.578%\n",
      "Epoch 2, 100% \t Train loss: 0.188 took: 4.37s  Val. loss: 0.138  Val. score: 95.861%\n",
      "Epoch 3, 100% \t Train loss: 0.146 took: 4.84s  Val. loss: 0.124  Val. score: 96.211%\n",
      "Epoch 4, 100% \t Train loss: 0.127 took: 4.79s  Val. loss: 0.112  Val. score: 96.644%\n",
      "Epoch 5, 100% \t Train loss: 0.106 took: 4.91s  Val. loss: 0.118  Val. score: 96.606%\n",
      "Epoch 6, 100% \t Train loss: 0.095 took: 4.51s  Val. loss: 0.099  Val. score: 96.994%\n",
      "Epoch 7, 100% \t Train loss: 0.087 took: 4.64s  Val. loss: 0.099  Val. score: 97.194%\n",
      "Epoch 8, 100% \t Train loss: 0.075 took: 4.83s  Val. loss: 0.100  Val. score: 97.183%\n",
      "Epoch 9, 100% \t Train loss: 0.071 took: 4.89s  Val. loss: 0.101  Val. score: 97.300%\n",
      "Epoch 10, 100% \t Train loss: 0.067 took: 5.09s  Val. loss: 0.104  Val. score: 97.300%\n",
      "Epoch 11, 100% \t Train loss: 0.062 took: 4.87s  Val. loss: 0.097  Val. score: 97.361%\n",
      "Epoch 12, 100% \t Train loss: 0.059 took: 5.03s  Val. loss: 0.103  Val. score: 97.294%\n",
      "Epoch 13, 100% \t Train loss: 0.056 took: 5.04s  Val. loss: 0.098  Val. score: 97.372%\n",
      "Epoch 14, 100% \t Train loss: 0.050 took: 4.91s  Val. loss: 0.102  Val. score: 97.378%\n",
      "Epoch 15, 100% \t Train loss: 0.044 took: 4.46s  Val. loss: 0.100  Val. score: 97.389%\n",
      "Training finished, took 123.048s\n",
      "\n",
      "Parameters configuration 83 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.016388848637946613\n",
      "h_sizes \t [784, 167, 47]\n",
      "penalty \t 0.00012218545700531748\n",
      "dropout \t 0.1911133678657312\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5093 +/- 0.0887\n",
      "Time for evaluation: 366.8 s\n",
      "Estimated time to finish : 2.46 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.520 took: 13.23s  Val. loss: 0.860  Val. score: 67.711%\n",
      "Epoch 2, 100% \t Train loss: 0.841 took: 13.37s  Val. loss: 0.591  Val. score: 85.533%\n",
      "Epoch 3, 100% \t Train loss: 0.639 took: 14.26s  Val. loss: 0.494  Val. score: 90.572%\n",
      "Epoch 4, 100% \t Train loss: 0.525 took: 15.44s  Val. loss: 0.393  Val. score: 92.200%\n",
      "Epoch 5, 100% \t Train loss: 0.431 took: 15.57s  Val. loss: 0.327  Val. score: 93.933%\n",
      "Epoch 6, 100% \t Train loss: 0.371 took: 14.87s  Val. loss: 0.286  Val. score: 94.106%\n",
      "Epoch 7, 100% \t Train loss: 0.314 took: 14.67s  Val. loss: 0.264  Val. score: 94.872%\n",
      "Epoch 8, 100% \t Train loss: 0.274 took: 15.52s  Val. loss: 0.256  Val. score: 94.889%\n",
      "Epoch 9, 100% \t Train loss: 0.263 took: 15.90s  Val. loss: 0.242  Val. score: 95.483%\n",
      "Epoch 10, 100% \t Train loss: 0.228 took: 17.31s  Val. loss: 0.233  Val. score: 95.467%\n",
      "Epoch 11, 100% \t Train loss: 0.208 took: 15.69s  Val. loss: 0.248  Val. score: 95.817%\n",
      "Epoch 12, 100% \t Train loss: 0.195 took: 15.31s  Val. loss: 0.263  Val. score: 95.828%\n",
      "Epoch 13, 100% \t Train loss: 0.176 took: 16.51s  Val. loss: 0.226  Val. score: 96.200%\n",
      "Epoch 14, 100% \t Train loss: 0.168 took: 16.85s  Val. loss: 0.231  Val. score: 96.467%\n",
      "Epoch 15, 100% \t Train loss: 0.157 took: 14.94s  Val. loss: 0.221  Val. score: 96.572%\n",
      "Training finished, took 326.475s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 100% \t Train loss: 1.502 took: 13.64s  Val. loss: 0.746  Val. score: 75.944%\n",
      "Epoch 2, 100% \t Train loss: 0.762 took: 13.95s  Val. loss: 0.437  Val. score: 84.861%\n",
      "Epoch 3, 100% \t Train loss: 0.542 took: 15.24s  Val. loss: 0.360  Val. score: 90.411%\n",
      "Epoch 4, 100% \t Train loss: 0.442 took: 15.38s  Val. loss: 0.293  Val. score: 93.483%\n",
      "Epoch 5, 100% \t Train loss: 0.374 took: 15.19s  Val. loss: 0.267  Val. score: 94.483%\n",
      "Epoch 6, 100% \t Train loss: 0.318 took: 15.75s  Val. loss: 0.246  Val. score: 95.067%\n",
      "Epoch 7, 100% \t Train loss: 0.283 took: 15.13s  Val. loss: 0.239  Val. score: 95.472%\n",
      "Epoch 8, 100% \t Train loss: 0.259 took: 16.35s  Val. loss: 0.216  Val. score: 95.644%\n",
      "Epoch 9, 100% \t Train loss: 0.233 took: 15.53s  Val. loss: 0.222  Val. score: 96.078%\n",
      "Epoch 10, 100% \t Train loss: 0.208 took: 15.37s  Val. loss: 0.213  Val. score: 96.406%\n",
      "Epoch 11, 100% \t Train loss: 0.203 took: 15.18s  Val. loss: 0.208  Val. score: 96.483%\n",
      "Epoch 12, 100% \t Train loss: 0.196 took: 16.22s  Val. loss: 0.204  Val. score: 96.517%\n",
      "Epoch 13, 100% \t Train loss: 0.184 took: 15.91s  Val. loss: 0.213  Val. score: 96.639%\n",
      "Epoch 14, 100% \t Train loss: 0.167 took: 16.20s  Val. loss: 0.214  Val. score: 96.756%\n",
      "Epoch 15, 100% \t Train loss: 0.151 took: 15.84s  Val. loss: 0.224  Val. score: 96.778%\n",
      "Training finished, took 328.169s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.430 took: 14.01s  Val. loss: 0.678  Val. score: 81.239%\n",
      "Epoch 2, 100% \t Train loss: 0.685 took: 13.67s  Val. loss: 0.404  Val. score: 85.961%\n",
      "Epoch 3, 100% \t Train loss: 0.493 took: 14.78s  Val. loss: 0.312  Val. score: 90.189%\n",
      "Epoch 4, 100% \t Train loss: 0.397 took: 15.53s  Val. loss: 0.255  Val. score: 94.450%\n",
      "Epoch 5, 100% \t Train loss: 0.329 took: 16.70s  Val. loss: 0.228  Val. score: 95.067%\n",
      "Epoch 6, 100% \t Train loss: 0.282 took: 14.93s  Val. loss: 0.204  Val. score: 95.828%\n",
      "Epoch 7, 100% \t Train loss: 0.245 took: 15.64s  Val. loss: 0.191  Val. score: 96.156%\n",
      "Epoch 8, 100% \t Train loss: 0.215 took: 14.46s  Val. loss: 0.188  Val. score: 96.444%\n",
      "Epoch 9, 100% \t Train loss: 0.197 took: 14.81s  Val. loss: 0.196  Val. score: 96.200%\n",
      "Epoch 10, 100% \t Train loss: 0.178 took: 16.23s  Val. loss: 0.194  Val. score: 96.611%\n",
      "Epoch 11, 100% \t Train loss: 0.162 took: 14.66s  Val. loss: 0.180  Val. score: 96.839%\n",
      "Epoch 12, 100% \t Train loss: 0.155 took: 15.03s  Val. loss: 0.180  Val. score: 96.744%\n",
      "Epoch 13, 100% \t Train loss: 0.144 took: 15.76s  Val. loss: 0.177  Val. score: 96.922%\n",
      "Epoch 14, 100% \t Train loss: 0.141 took: 16.08s  Val. loss: 0.176  Val. score: 97.100%\n",
      "Epoch 15, 100% \t Train loss: 0.130 took: 14.72s  Val. loss: 0.189  Val. score: 97.078%\n",
      "Training finished, took 326.326s\n",
      "\n",
      "Parameters configuration 84 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.004177507220179145\n",
      "h_sizes \t [784, 461, 273, 153, 83, 44, 26, 18]\n",
      "penalty \t 0.0001616368621925495\n",
      "dropout \t 0.23491944373257026\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 96.8093 +/- 0.2076\n",
      "Time for evaluation: 982.2 s\n",
      "Estimated time to finish : 2.34 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.549 took: 6.33s  Val. loss: 0.261  Val. score: 92.239%\n",
      "Epoch 2, 100% \t Train loss: 0.244 took: 7.28s  Val. loss: 0.164  Val. score: 95.056%\n",
      "Epoch 3, 100% \t Train loss: 0.171 took: 7.14s  Val. loss: 0.133  Val. score: 95.978%\n",
      "Epoch 4, 100% \t Train loss: 0.133 took: 7.03s  Val. loss: 0.124  Val. score: 96.194%\n",
      "Epoch 5, 100% \t Train loss: 0.108 took: 7.42s  Val. loss: 0.111  Val. score: 96.611%\n",
      "Epoch 6, 100% \t Train loss: 0.088 took: 6.71s  Val. loss: 0.098  Val. score: 97.000%\n",
      "Epoch 7, 100% \t Train loss: 0.072 took: 7.96s  Val. loss: 0.089  Val. score: 97.261%\n",
      "Epoch 8, 100% \t Train loss: 0.061 took: 6.54s  Val. loss: 0.091  Val. score: 97.328%\n",
      "Epoch 9, 100% \t Train loss: 0.050 took: 6.44s  Val. loss: 0.086  Val. score: 97.500%\n",
      "Epoch 10, 100% \t Train loss: 0.044 took: 7.02s  Val. loss: 0.087  Val. score: 97.433%\n",
      "Epoch 11, 100% \t Train loss: 0.039 took: 7.75s  Val. loss: 0.084  Val. score: 97.533%\n",
      "Epoch 12, 100% \t Train loss: 0.031 took: 7.70s  Val. loss: 0.085  Val. score: 97.589%\n",
      "Epoch 13, 100% \t Train loss: 0.028 took: 7.59s  Val. loss: 0.083  Val. score: 97.694%\n",
      "Epoch 14, 100% \t Train loss: 0.023 took: 7.16s  Val. loss: 0.084  Val. score: 97.711%\n",
      "Epoch 15, 100% \t Train loss: 0.020 took: 6.93s  Val. loss: 0.087  Val. score: 97.617%\n",
      "Training finished, took 170.838s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.532 took: 6.64s  Val. loss: 0.245  Val. score: 92.900%\n",
      "Epoch 2, 100% \t Train loss: 0.223 took: 6.59s  Val. loss: 0.169  Val. score: 94.917%\n",
      "Epoch 3, 100% \t Train loss: 0.159 took: 7.74s  Val. loss: 0.140  Val. score: 95.689%\n",
      "Epoch 4, 100% \t Train loss: 0.123 took: 7.39s  Val. loss: 0.121  Val. score: 96.328%\n",
      "Epoch 5, 100% \t Train loss: 0.097 took: 8.07s  Val. loss: 0.108  Val. score: 96.683%\n",
      "Epoch 6, 100% \t Train loss: 0.079 took: 6.93s  Val. loss: 0.113  Val. score: 96.639%\n",
      "Epoch 7, 100% \t Train loss: 0.066 took: 6.93s  Val. loss: 0.110  Val. score: 96.767%\n",
      "Epoch 8, 100% \t Train loss: 0.057 took: 7.06s  Val. loss: 0.096  Val. score: 97.172%\n",
      "Epoch 9, 100% \t Train loss: 0.050 took: 7.53s  Val. loss: 0.096  Val. score: 97.306%\n",
      "Epoch 10, 100% \t Train loss: 0.039 took: 7.05s  Val. loss: 0.102  Val. score: 97.211%\n",
      "Epoch 11, 100% \t Train loss: 0.034 took: 6.90s  Val. loss: 0.102  Val. score: 97.278%\n",
      "Epoch 12, 100% \t Train loss: 0.030 took: 7.14s  Val. loss: 0.099  Val. score: 97.356%\n",
      "Epoch 13, 100% \t Train loss: 0.025 took: 7.14s  Val. loss: 0.100  Val. score: 97.439%\n",
      "Epoch 14, 100% \t Train loss: 0.023 took: 7.15s  Val. loss: 0.099  Val. score: 97.506%\n",
      "Epoch 15, 100% \t Train loss: 0.020 took: 7.20s  Val. loss: 0.102  Val. score: 97.506%\n",
      "Training finished, took 172.911s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.527 took: 6.71s  Val. loss: 0.255  Val. score: 92.417%\n",
      "Epoch 2, 100% \t Train loss: 0.224 took: 6.35s  Val. loss: 0.169  Val. score: 95.000%\n",
      "Epoch 3, 100% \t Train loss: 0.158 took: 7.10s  Val. loss: 0.141  Val. score: 95.839%\n",
      "Epoch 4, 100% \t Train loss: 0.126 took: 6.61s  Val. loss: 0.120  Val. score: 96.467%\n",
      "Epoch 5, 100% \t Train loss: 0.100 took: 8.67s  Val. loss: 0.113  Val. score: 96.572%\n",
      "Epoch 6, 100% \t Train loss: 0.082 took: 6.98s  Val. loss: 0.113  Val. score: 96.661%\n",
      "Epoch 7, 100% \t Train loss: 0.068 took: 7.34s  Val. loss: 0.097  Val. score: 97.117%\n",
      "Epoch 8, 100% \t Train loss: 0.057 took: 7.41s  Val. loss: 0.097  Val. score: 97.172%\n",
      "Epoch 9, 100% \t Train loss: 0.047 took: 6.98s  Val. loss: 0.095  Val. score: 97.394%\n",
      "Epoch 10, 100% \t Train loss: 0.040 took: 6.53s  Val. loss: 0.091  Val. score: 97.489%\n",
      "Epoch 11, 100% \t Train loss: 0.033 took: 7.57s  Val. loss: 0.091  Val. score: 97.517%\n",
      "Epoch 12, 100% \t Train loss: 0.029 took: 7.38s  Val. loss: 0.090  Val. score: 97.583%\n",
      "Epoch 13, 100% \t Train loss: 0.025 took: 6.84s  Val. loss: 0.093  Val. score: 97.644%\n",
      "Epoch 14, 100% \t Train loss: 0.024 took: 8.61s  Val. loss: 0.094  Val. score: 97.728%\n",
      "Epoch 15, 100% \t Train loss: 0.018 took: 8.08s  Val. loss: 0.105  Val. score: 97.456%\n",
      "Training finished, took 175.259s\n",
      "\n",
      "Parameters configuration 85 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0031908952683813315\n",
      "h_sizes \t [784, 280, 93, 33]\n",
      "penalty \t 0.0012313622487824258\n",
      "dropout \t 0.07076706395508195\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5259 +/- 0.0673\n",
      "Time for evaluation: 520.3 s\n",
      "Estimated time to finish : 2.20 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.887 took: 16.97s  Val. loss: 0.386  Val. score: 87.828%\n",
      "Epoch 2, 100% \t Train loss: 0.270 took: 15.85s  Val. loss: 0.194  Val. score: 95.389%\n",
      "Epoch 3, 100% \t Train loss: 0.178 took: 15.50s  Val. loss: 0.158  Val. score: 96.261%\n",
      "Epoch 4, 100% \t Train loss: 0.137 took: 16.08s  Val. loss: 0.156  Val. score: 96.433%\n",
      "Epoch 5, 100% \t Train loss: 0.112 took: 16.24s  Val. loss: 0.152  Val. score: 96.539%\n",
      "Epoch 6, 100% \t Train loss: 0.093 took: 16.37s  Val. loss: 0.153  Val. score: 96.733%\n",
      "Epoch 7, 100% \t Train loss: 0.083 took: 16.42s  Val. loss: 0.152  Val. score: 96.844%\n",
      "Epoch 8, 100% \t Train loss: 0.068 took: 16.19s  Val. loss: 0.149  Val. score: 96.750%\n",
      "Epoch 9, 100% \t Train loss: 0.058 took: 16.35s  Val. loss: 0.136  Val. score: 97.261%\n",
      "Epoch 10, 100% \t Train loss: 0.049 took: 17.30s  Val. loss: 0.139  Val. score: 97.383%\n",
      "Epoch 11, 100% \t Train loss: 0.043 took: 16.50s  Val. loss: 0.156  Val. score: 97.489%\n",
      "Epoch 12, 100% \t Train loss: 0.043 took: 15.76s  Val. loss: 0.154  Val. score: 97.122%\n",
      "Epoch 13, 100% \t Train loss: 0.039 took: 17.78s  Val. loss: 0.146  Val. score: 97.389%\n",
      "Epoch 14, 100% \t Train loss: 0.033 took: 16.91s  Val. loss: 0.144  Val. score: 97.383%\n",
      "Epoch 15, 100% \t Train loss: 0.026 took: 18.76s  Val. loss: 0.163  Val. score: 97.478%\n",
      "Training finished, took 354.786s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.364 took: 16.21s  Val. loss: 0.867  Val. score: 68.328%\n",
      "Epoch 2, 100% \t Train loss: 0.572 took: 16.77s  Val. loss: 0.309  Val. score: 92.322%\n",
      "Epoch 3, 100% \t Train loss: 0.250 took: 16.98s  Val. loss: 0.206  Val. score: 95.272%\n",
      "Epoch 4, 100% \t Train loss: 0.174 took: 16.28s  Val. loss: 0.178  Val. score: 96.083%\n",
      "Epoch 5, 100% \t Train loss: 0.134 took: 18.10s  Val. loss: 0.152  Val. score: 96.478%\n",
      "Epoch 6, 100% \t Train loss: 0.115 took: 18.56s  Val. loss: 0.152  Val. score: 96.539%\n",
      "Epoch 7, 100% \t Train loss: 0.099 took: 16.23s  Val. loss: 0.158  Val. score: 96.956%\n",
      "Epoch 8, 100% \t Train loss: 0.078 took: 22.20s  Val. loss: 0.141  Val. score: 97.083%\n",
      "Epoch 9, 100% \t Train loss: 0.071 took: 18.92s  Val. loss: 0.147  Val. score: 97.128%\n",
      "Epoch 10, 100% \t Train loss: 0.061 took: 20.29s  Val. loss: 0.144  Val. score: 97.317%\n",
      "Epoch 11, 100% \t Train loss: 0.056 took: 18.39s  Val. loss: 0.134  Val. score: 97.417%\n",
      "Epoch 12, 100% \t Train loss: 0.044 took: 22.59s  Val. loss: 0.147  Val. score: 97.539%\n",
      "Epoch 13, 100% \t Train loss: 0.041 took: 27.79s  Val. loss: 0.152  Val. score: 97.400%\n",
      "Epoch 14, 100% \t Train loss: 0.040 took: 22.88s  Val. loss: 0.151  Val. score: 97.550%\n",
      "Epoch 15, 100% \t Train loss: 0.034 took: 20.44s  Val. loss: 0.142  Val. score: 97.444%\n",
      "Training finished, took 398.922s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.961 took: 16.29s  Val. loss: 0.374  Val. score: 91.772%\n",
      "Epoch 2, 100% \t Train loss: 0.321 took: 14.85s  Val. loss: 0.230  Val. score: 94.539%\n",
      "Epoch 3, 100% \t Train loss: 0.206 took: 16.29s  Val. loss: 0.190  Val. score: 95.556%\n",
      "Epoch 4, 100% \t Train loss: 0.158 took: 14.94s  Val. loss: 0.160  Val. score: 96.239%\n",
      "Epoch 5, 100% \t Train loss: 0.128 took: 15.15s  Val. loss: 0.160  Val. score: 96.439%\n",
      "Epoch 6, 100% \t Train loss: 0.109 took: 16.40s  Val. loss: 0.151  Val. score: 96.544%\n",
      "Epoch 7, 100% \t Train loss: 0.091 took: 16.33s  Val. loss: 0.153  Val. score: 96.694%\n",
      "Epoch 8, 100% \t Train loss: 0.076 took: 16.36s  Val. loss: 0.154  Val. score: 96.822%\n",
      "Epoch 9, 100% \t Train loss: 0.074 took: 16.96s  Val. loss: 0.148  Val. score: 97.178%\n",
      "Epoch 10, 100% \t Train loss: 0.065 took: 16.63s  Val. loss: 0.157  Val. score: 97.072%\n",
      "Epoch 11, 100% \t Train loss: 0.055 took: 15.31s  Val. loss: 0.165  Val. score: 97.244%\n",
      "Epoch 12, 100% \t Train loss: 0.052 took: 18.09s  Val. loss: 0.142  Val. score: 97.272%\n",
      "Epoch 13, 100% \t Train loss: 0.047 took: 19.35s  Val. loss: 0.131  Val. score: 97.306%\n",
      "Epoch 14, 100% \t Train loss: 0.040 took: 17.49s  Val. loss: 0.171  Val. score: 97.256%\n",
      "Epoch 15, 100% \t Train loss: 0.036 took: 18.52s  Val. loss: 0.143  Val. score: 97.383%\n",
      "Training finished, took 349.938s\n",
      "\n",
      "Parameters configuration 86 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008446811597212667\n",
      "h_sizes \t [784, 511, 321, 207, 120, 84, 54, 37, 18]\n",
      "penalty \t 0.005335661616788348\n",
      "dropout \t 0.06842791454409938\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.4352 +/- 0.0391\n",
      "Time for evaluation: 1104.9 s\n",
      "Estimated time to finish : 2.08 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.524 took: 4.50s  Val. loss: 0.254  Val. score: 92.506%\n",
      "Epoch 2, 100% \t Train loss: 0.251 took: 4.41s  Val. loss: 0.195  Val. score: 94.189%\n",
      "Epoch 3, 100% \t Train loss: 0.191 took: 4.50s  Val. loss: 0.156  Val. score: 95.133%\n",
      "Epoch 4, 100% \t Train loss: 0.154 took: 4.46s  Val. loss: 0.131  Val. score: 95.944%\n",
      "Epoch 5, 100% \t Train loss: 0.133 took: 4.11s  Val. loss: 0.115  Val. score: 96.472%\n",
      "Epoch 6, 100% \t Train loss: 0.113 took: 4.58s  Val. loss: 0.108  Val. score: 96.661%\n",
      "Epoch 7, 100% \t Train loss: 0.098 took: 4.55s  Val. loss: 0.098  Val. score: 97.017%\n",
      "Epoch 8, 100% \t Train loss: 0.086 took: 4.50s  Val. loss: 0.097  Val. score: 96.956%\n",
      "Epoch 9, 100% \t Train loss: 0.078 took: 4.43s  Val. loss: 0.090  Val. score: 97.261%\n",
      "Epoch 10, 100% \t Train loss: 0.071 took: 4.64s  Val. loss: 0.089  Val. score: 97.267%\n",
      "Epoch 11, 100% \t Train loss: 0.062 took: 4.60s  Val. loss: 0.086  Val. score: 97.367%\n",
      "Epoch 12, 100% \t Train loss: 0.058 took: 4.09s  Val. loss: 0.082  Val. score: 97.417%\n",
      "Epoch 13, 100% \t Train loss: 0.053 took: 4.36s  Val. loss: 0.082  Val. score: 97.467%\n",
      "Epoch 14, 100% \t Train loss: 0.045 took: 4.37s  Val. loss: 0.081  Val. score: 97.600%\n",
      "Epoch 15, 100% \t Train loss: 0.042 took: 4.10s  Val. loss: 0.082  Val. score: 97.556%\n",
      "Training finished, took 114.489s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.529 took: 4.62s  Val. loss: 0.260  Val. score: 92.400%\n",
      "Epoch 2, 100% \t Train loss: 0.260 took: 4.78s  Val. loss: 0.193  Val. score: 94.417%\n",
      "Epoch 3, 100% \t Train loss: 0.196 took: 4.59s  Val. loss: 0.162  Val. score: 95.350%\n",
      "Epoch 4, 100% \t Train loss: 0.157 took: 4.90s  Val. loss: 0.134  Val. score: 95.900%\n",
      "Epoch 5, 100% \t Train loss: 0.129 took: 4.63s  Val. loss: 0.122  Val. score: 96.389%\n",
      "Epoch 6, 100% \t Train loss: 0.111 took: 4.90s  Val. loss: 0.114  Val. score: 96.550%\n",
      "Epoch 7, 100% \t Train loss: 0.098 took: 4.67s  Val. loss: 0.104  Val. score: 96.850%\n",
      "Epoch 8, 100% \t Train loss: 0.088 took: 4.13s  Val. loss: 0.100  Val. score: 97.167%\n",
      "Epoch 9, 100% \t Train loss: 0.077 took: 4.85s  Val. loss: 0.095  Val. score: 97.167%\n",
      "Epoch 10, 100% \t Train loss: 0.068 took: 4.86s  Val. loss: 0.093  Val. score: 97.150%\n",
      "Epoch 11, 100% \t Train loss: 0.065 took: 4.51s  Val. loss: 0.093  Val. score: 97.206%\n",
      "Epoch 12, 100% \t Train loss: 0.056 took: 4.38s  Val. loss: 0.091  Val. score: 97.256%\n",
      "Epoch 13, 100% \t Train loss: 0.051 took: 4.57s  Val. loss: 0.091  Val. score: 97.350%\n",
      "Epoch 14, 100% \t Train loss: 0.048 took: 4.37s  Val. loss: 0.097  Val. score: 97.367%\n",
      "Epoch 15, 100% \t Train loss: 0.042 took: 4.14s  Val. loss: 0.093  Val. score: 97.389%\n",
      "Training finished, took 119.288s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.526 took: 4.82s  Val. loss: 0.258  Val. score: 92.650%\n",
      "Epoch 2, 100% \t Train loss: 0.254 took: 4.67s  Val. loss: 0.191  Val. score: 94.328%\n",
      "Epoch 3, 100% \t Train loss: 0.192 took: 4.56s  Val. loss: 0.156  Val. score: 95.267%\n",
      "Epoch 4, 100% \t Train loss: 0.153 took: 4.20s  Val. loss: 0.135  Val. score: 95.906%\n",
      "Epoch 5, 100% \t Train loss: 0.130 took: 4.33s  Val. loss: 0.124  Val. score: 96.283%\n",
      "Epoch 6, 100% \t Train loss: 0.111 took: 4.71s  Val. loss: 0.110  Val. score: 96.767%\n",
      "Epoch 7, 100% \t Train loss: 0.096 took: 4.85s  Val. loss: 0.106  Val. score: 96.872%\n",
      "Epoch 8, 100% \t Train loss: 0.084 took: 4.54s  Val. loss: 0.102  Val. score: 97.067%\n",
      "Epoch 9, 100% \t Train loss: 0.071 took: 4.67s  Val. loss: 0.101  Val. score: 97.089%\n",
      "Epoch 10, 100% \t Train loss: 0.066 took: 4.92s  Val. loss: 0.094  Val. score: 97.172%\n",
      "Epoch 11, 100% \t Train loss: 0.058 took: 4.74s  Val. loss: 0.089  Val. score: 97.472%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, 100% \t Train loss: 0.051 took: 4.34s  Val. loss: 0.089  Val. score: 97.456%\n",
      "Epoch 13, 100% \t Train loss: 0.049 took: 4.59s  Val. loss: 0.090  Val. score: 97.417%\n",
      "Epoch 14, 100% \t Train loss: 0.044 took: 4.78s  Val. loss: 0.088  Val. score: 97.511%\n",
      "Epoch 15, 100% \t Train loss: 0.038 took: 4.86s  Val. loss: 0.088  Val. score: 97.506%\n",
      "Training finished, took 121.855s\n",
      "\n",
      "Parameters configuration 87 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003432700635609312\n",
      "h_sizes \t [784, 179, 32]\n",
      "penalty \t 0.0009354459154807876\n",
      "dropout \t 0.1048926579957761\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.4833 +/- 0.0698\n",
      "Time for evaluation: 356.8 s\n",
      "Estimated time to finish : 1.92 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.430 took: 5.89s  Val. loss: 0.181  Val. score: 94.667%\n",
      "Epoch 2, 100% \t Train loss: 0.176 took: 6.39s  Val. loss: 0.141  Val. score: 95.911%\n",
      "Epoch 3, 100% \t Train loss: 0.132 took: 5.93s  Val. loss: 0.127  Val. score: 96.422%\n",
      "Epoch 4, 100% \t Train loss: 0.105 took: 5.95s  Val. loss: 0.124  Val. score: 96.539%\n",
      "Epoch 5, 100% \t Train loss: 0.088 took: 6.00s  Val. loss: 0.115  Val. score: 96.972%\n",
      "Epoch 6, 100% \t Train loss: 0.074 took: 6.33s  Val. loss: 0.109  Val. score: 97.244%\n",
      "Epoch 7, 100% \t Train loss: 0.066 took: 5.99s  Val. loss: 0.103  Val. score: 97.372%\n",
      "Epoch 8, 100% \t Train loss: 0.054 took: 6.36s  Val. loss: 0.117  Val. score: 97.356%\n",
      "Epoch 9, 100% \t Train loss: 0.052 took: 6.03s  Val. loss: 0.113  Val. score: 97.350%\n",
      "Epoch 10, 100% \t Train loss: 0.045 took: 6.38s  Val. loss: 0.112  Val. score: 97.589%\n",
      "Epoch 11, 100% \t Train loss: 0.041 took: 6.31s  Val. loss: 0.112  Val. score: 97.628%\n",
      "Epoch 12, 100% \t Train loss: 0.039 took: 6.15s  Val. loss: 0.115  Val. score: 97.544%\n",
      "Epoch 13, 100% \t Train loss: 0.034 took: 5.70s  Val. loss: 0.109  Val. score: 97.528%\n",
      "Epoch 14, 100% \t Train loss: 0.032 took: 6.50s  Val. loss: 0.117  Val. score: 97.372%\n",
      "Epoch 15, 100% \t Train loss: 0.031 took: 6.40s  Val. loss: 0.124  Val. score: 97.422%\n",
      "Training finished, took 151.436s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.383 took: 5.99s  Val. loss: 0.157  Val. score: 95.428%\n",
      "Epoch 2, 100% \t Train loss: 0.167 took: 5.98s  Val. loss: 0.139  Val. score: 95.944%\n",
      "Epoch 3, 100% \t Train loss: 0.129 took: 5.68s  Val. loss: 0.125  Val. score: 96.561%\n",
      "Epoch 4, 100% \t Train loss: 0.097 took: 6.43s  Val. loss: 0.131  Val. score: 96.383%\n",
      "Epoch 5, 100% \t Train loss: 0.082 took: 6.73s  Val. loss: 0.103  Val. score: 97.167%\n",
      "Epoch 6, 100% \t Train loss: 0.071 took: 6.77s  Val. loss: 0.107  Val. score: 97.239%\n",
      "Epoch 7, 100% \t Train loss: 0.060 took: 6.58s  Val. loss: 0.098  Val. score: 97.539%\n",
      "Epoch 8, 100% \t Train loss: 0.053 took: 6.50s  Val. loss: 0.101  Val. score: 97.533%\n",
      "Epoch 9, 100% \t Train loss: 0.046 took: 6.67s  Val. loss: 0.101  Val. score: 97.483%\n",
      "Epoch 10, 100% \t Train loss: 0.039 took: 6.53s  Val. loss: 0.111  Val. score: 97.522%\n",
      "Epoch 11, 100% \t Train loss: 0.036 took: 6.48s  Val. loss: 0.105  Val. score: 97.656%\n",
      "Epoch 12, 100% \t Train loss: 0.035 took: 6.34s  Val. loss: 0.111  Val. score: 97.550%\n",
      "Epoch 13, 100% \t Train loss: 0.032 took: 5.73s  Val. loss: 0.113  Val. score: 97.733%\n",
      "Epoch 14, 100% \t Train loss: 0.028 took: 5.64s  Val. loss: 0.102  Val. score: 97.894%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 6.31s  Val. loss: 0.117  Val. score: 97.733%\n",
      "Training finished, took 155.631s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.433 took: 7.81s  Val. loss: 0.171  Val. score: 94.983%\n",
      "Epoch 2, 100% \t Train loss: 0.178 took: 6.40s  Val. loss: 0.125  Val. score: 96.250%\n",
      "Epoch 3, 100% \t Train loss: 0.130 took: 6.33s  Val. loss: 0.126  Val. score: 96.217%\n",
      "Epoch 4, 100% \t Train loss: 0.101 took: 6.59s  Val. loss: 0.104  Val. score: 97.117%\n",
      "Epoch 5, 100% \t Train loss: 0.087 took: 6.62s  Val. loss: 0.097  Val. score: 97.356%\n",
      "Epoch 6, 100% \t Train loss: 0.074 took: 5.65s  Val. loss: 0.098  Val. score: 97.367%\n",
      "Epoch 7, 100% \t Train loss: 0.063 took: 6.03s  Val. loss: 0.095  Val. score: 97.522%\n",
      "Epoch 8, 100% \t Train loss: 0.054 took: 6.05s  Val. loss: 0.097  Val. score: 97.528%\n",
      "Epoch 9, 100% \t Train loss: 0.047 took: 6.22s  Val. loss: 0.102  Val. score: 97.489%\n",
      "Epoch 10, 100% \t Train loss: 0.042 took: 6.46s  Val. loss: 0.096  Val. score: 97.672%\n",
      "Epoch 11, 100% \t Train loss: 0.038 took: 6.60s  Val. loss: 0.103  Val. score: 97.594%\n",
      "Epoch 12, 100% \t Train loss: 0.035 took: 6.66s  Val. loss: 0.107  Val. score: 97.633%\n",
      "Epoch 13, 100% \t Train loss: 0.033 took: 5.89s  Val. loss: 0.117  Val. score: 97.394%\n",
      "Epoch 14, 100% \t Train loss: 0.029 took: 6.47s  Val. loss: 0.116  Val. score: 97.489%\n",
      "Epoch 15, 100% \t Train loss: 0.028 took: 5.87s  Val. loss: 0.108  Val. score: 97.672%\n",
      "Training finished, took 155.615s\n",
      "\n",
      "Parameters configuration 88 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.01572542247335979\n",
      "h_sizes \t [784, 265, 88, 29]\n",
      "penalty \t 0.00013644547818043702\n",
      "dropout \t 0.12356540501116278\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.6093 +/- 0.1346\n",
      "Time for evaluation: 463.9 s\n",
      "Estimated time to finish : 1.77 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.513 took: 8.23s  Val. loss: 0.202  Val. score: 94.217%\n",
      "Epoch 2, 100% \t Train loss: 0.208 took: 8.05s  Val. loss: 0.155  Val. score: 95.733%\n",
      "Epoch 3, 100% \t Train loss: 0.158 took: 8.75s  Val. loss: 0.134  Val. score: 96.328%\n",
      "Epoch 4, 100% \t Train loss: 0.124 took: 8.81s  Val. loss: 0.131  Val. score: 96.689%\n",
      "Epoch 5, 100% \t Train loss: 0.100 took: 8.29s  Val. loss: 0.126  Val. score: 96.750%\n",
      "Epoch 6, 100% \t Train loss: 0.080 took: 8.87s  Val. loss: 0.118  Val. score: 97.039%\n",
      "Epoch 7, 100% \t Train loss: 0.074 took: 8.38s  Val. loss: 0.103  Val. score: 97.356%\n",
      "Epoch 8, 100% \t Train loss: 0.065 took: 8.56s  Val. loss: 0.103  Val. score: 97.400%\n",
      "Epoch 9, 100% \t Train loss: 0.055 took: 8.99s  Val. loss: 0.112  Val. score: 97.450%\n",
      "Epoch 10, 100% \t Train loss: 0.048 took: 8.40s  Val. loss: 0.107  Val. score: 97.511%\n",
      "Epoch 11, 100% \t Train loss: 0.043 took: 8.08s  Val. loss: 0.113  Val. score: 97.511%\n",
      "Epoch 12, 100% \t Train loss: 0.040 took: 8.72s  Val. loss: 0.116  Val. score: 97.411%\n",
      "Epoch 13, 100% \t Train loss: 0.036 took: 8.95s  Val. loss: 0.122  Val. score: 97.600%\n",
      "Epoch 14, 100% \t Train loss: 0.035 took: 8.64s  Val. loss: 0.121  Val. score: 97.617%\n",
      "Epoch 15, 100% \t Train loss: 0.031 took: 8.57s  Val. loss: 0.120  Val. score: 97.500%\n",
      "Training finished, took 197.529s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.534 took: 7.13s  Val. loss: 0.194  Val. score: 94.528%\n",
      "Epoch 2, 100% \t Train loss: 0.202 took: 7.60s  Val. loss: 0.147  Val. score: 95.889%\n",
      "Epoch 3, 100% \t Train loss: 0.147 took: 7.57s  Val. loss: 0.129  Val. score: 96.606%\n",
      "Epoch 4, 100% \t Train loss: 0.118 took: 8.12s  Val. loss: 0.120  Val. score: 96.800%\n",
      "Epoch 5, 100% \t Train loss: 0.098 took: 8.62s  Val. loss: 0.114  Val. score: 97.083%\n",
      "Epoch 6, 100% \t Train loss: 0.083 took: 8.38s  Val. loss: 0.117  Val. score: 97.267%\n",
      "Epoch 7, 100% \t Train loss: 0.066 took: 8.79s  Val. loss: 0.109  Val. score: 97.472%\n",
      "Epoch 8, 100% \t Train loss: 0.059 took: 8.50s  Val. loss: 0.104  Val. score: 97.456%\n",
      "Epoch 9, 100% \t Train loss: 0.052 took: 8.13s  Val. loss: 0.112  Val. score: 97.333%\n",
      "Epoch 10, 100% \t Train loss: 0.046 took: 9.00s  Val. loss: 0.105  Val. score: 97.667%\n",
      "Epoch 11, 100% \t Train loss: 0.044 took: 8.27s  Val. loss: 0.110  Val. score: 97.572%\n",
      "Epoch 12, 100% \t Train loss: 0.037 took: 8.39s  Val. loss: 0.109  Val. score: 97.650%\n",
      "Epoch 13, 100% \t Train loss: 0.034 took: 8.76s  Val. loss: 0.109  Val. score: 97.739%\n",
      "Epoch 14, 100% \t Train loss: 0.033 took: 8.47s  Val. loss: 0.117  Val. score: 97.683%\n",
      "Epoch 15, 100% \t Train loss: 0.029 took: 8.77s  Val. loss: 0.120  Val. score: 97.600%\n",
      "Training finished, took 192.743s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.525 took: 8.01s  Val. loss: 0.217  Val. score: 93.972%\n",
      "Epoch 2, 100% \t Train loss: 0.201 took: 8.29s  Val. loss: 0.154  Val. score: 95.928%\n",
      "Epoch 3, 100% \t Train loss: 0.146 took: 7.58s  Val. loss: 0.133  Val. score: 96.483%\n",
      "Epoch 4, 100% \t Train loss: 0.116 took: 9.51s  Val. loss: 0.116  Val. score: 96.922%\n",
      "Epoch 5, 100% \t Train loss: 0.095 took: 8.84s  Val. loss: 0.122  Val. score: 96.811%\n",
      "Epoch 6, 100% \t Train loss: 0.082 took: 8.63s  Val. loss: 0.119  Val. score: 97.072%\n",
      "Epoch 7, 100% \t Train loss: 0.070 took: 8.91s  Val. loss: 0.114  Val. score: 97.289%\n",
      "Epoch 8, 100% \t Train loss: 0.059 took: 10.02s  Val. loss: 0.110  Val. score: 97.506%\n",
      "Epoch 9, 100% \t Train loss: 0.053 took: 8.57s  Val. loss: 0.115  Val. score: 97.617%\n",
      "Epoch 10, 100% \t Train loss: 0.047 took: 8.49s  Val. loss: 0.116  Val. score: 97.378%\n",
      "Epoch 11, 100% \t Train loss: 0.042 took: 9.15s  Val. loss: 0.120  Val. score: 97.244%\n",
      "Epoch 12, 100% \t Train loss: 0.036 took: 9.29s  Val. loss: 0.114  Val. score: 97.633%\n",
      "Epoch 13, 100% \t Train loss: 0.036 took: 9.45s  Val. loss: 0.120  Val. score: 97.667%\n",
      "Epoch 14, 100% \t Train loss: 0.034 took: 8.76s  Val. loss: 0.129  Val. score: 97.628%\n",
      "Epoch 15, 100% \t Train loss: 0.027 took: 8.14s  Val. loss: 0.132  Val. score: 97.644%\n",
      "Training finished, took 204.089s\n",
      "\n",
      "Parameters configuration 89 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.012112711037655618\n",
      "h_sizes \t [784, 316, 136, 57, 19]\n",
      "penalty \t 0.005332367583470696\n",
      "dropout \t 0.11952940241394577\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.5815 +/- 0.0604\n",
      "Time for evaluation: 595.6 s\n",
      "Estimated time to finish : 1.63 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.897 took: 13.11s  Val. loss: 0.321  Val. score: 91.022%\n",
      "Epoch 2, 100% \t Train loss: 0.314 took: 12.97s  Val. loss: 0.212  Val. score: 94.328%\n",
      "Epoch 3, 100% \t Train loss: 0.215 took: 14.75s  Val. loss: 0.186  Val. score: 94.967%\n",
      "Epoch 4, 100% \t Train loss: 0.166 took: 16.46s  Val. loss: 0.156  Val. score: 95.778%\n",
      "Epoch 5, 100% \t Train loss: 0.130 took: 16.31s  Val. loss: 0.146  Val. score: 96.356%\n",
      "Epoch 6, 100% \t Train loss: 0.111 took: 15.28s  Val. loss: 0.137  Val. score: 96.428%\n",
      "Epoch 7, 100% \t Train loss: 0.089 took: 15.35s  Val. loss: 0.135  Val. score: 96.817%\n",
      "Epoch 8, 100% \t Train loss: 0.077 took: 15.64s  Val. loss: 0.144  Val. score: 96.794%\n",
      "Epoch 9, 100% \t Train loss: 0.067 took: 13.63s  Val. loss: 0.136  Val. score: 96.872%\n",
      "Epoch 10, 100% \t Train loss: 0.058 took: 14.27s  Val. loss: 0.135  Val. score: 96.939%\n",
      "Epoch 11, 100% \t Train loss: 0.051 took: 15.21s  Val. loss: 0.139  Val. score: 97.011%\n",
      "Epoch 12, 100% \t Train loss: 0.045 took: 15.40s  Val. loss: 0.140  Val. score: 97.278%\n",
      "Epoch 13, 100% \t Train loss: 0.040 took: 14.51s  Val. loss: 0.134  Val. score: 97.272%\n",
      "Epoch 14, 100% \t Train loss: 0.034 took: 14.97s  Val. loss: 0.147  Val. score: 97.256%\n",
      "Epoch 15, 100% \t Train loss: 0.035 took: 15.50s  Val. loss: 0.137  Val. score: 97.294%\n",
      "Training finished, took 322.490s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.138 took: 13.96s  Val. loss: 0.412  Val. score: 87.256%\n",
      "Epoch 2, 100% \t Train loss: 0.385 took: 13.09s  Val. loss: 0.212  Val. score: 94.150%\n",
      "Epoch 3, 100% \t Train loss: 0.242 took: 14.37s  Val. loss: 0.182  Val. score: 95.211%\n",
      "Epoch 4, 100% \t Train loss: 0.180 took: 14.72s  Val. loss: 0.153  Val. score: 96.033%\n",
      "Epoch 5, 100% \t Train loss: 0.147 took: 13.70s  Val. loss: 0.128  Val. score: 96.644%\n",
      "Epoch 6, 100% \t Train loss: 0.118 took: 15.53s  Val. loss: 0.128  Val. score: 96.750%\n",
      "Epoch 7, 100% \t Train loss: 0.101 took: 14.35s  Val. loss: 0.124  Val. score: 96.817%\n",
      "Epoch 8, 100% \t Train loss: 0.086 took: 14.08s  Val. loss: 0.120  Val. score: 97.111%\n",
      "Epoch 9, 100% \t Train loss: 0.072 took: 14.89s  Val. loss: 0.121  Val. score: 97.189%\n",
      "Epoch 10, 100% \t Train loss: 0.062 took: 14.06s  Val. loss: 0.124  Val. score: 97.344%\n",
      "Epoch 11, 100% \t Train loss: 0.054 took: 15.03s  Val. loss: 0.125  Val. score: 97.328%\n",
      "Epoch 12, 100% \t Train loss: 0.047 took: 15.51s  Val. loss: 0.115  Val. score: 97.572%\n",
      "Epoch 13, 100% \t Train loss: 0.039 took: 14.56s  Val. loss: 0.128  Val. score: 97.428%\n",
      "Epoch 14, 100% \t Train loss: 0.038 took: 14.09s  Val. loss: 0.133  Val. score: 97.428%\n",
      "Epoch 15, 100% \t Train loss: 0.031 took: 14.34s  Val. loss: 0.144  Val. score: 97.378%\n",
      "Training finished, took 313.312s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 1.002 took: 14.14s  Val. loss: 0.408  Val. score: 88.744%\n",
      "Epoch 2, 100% \t Train loss: 0.358 took: 13.91s  Val. loss: 0.241  Val. score: 93.689%\n",
      "Epoch 3, 100% \t Train loss: 0.235 took: 14.23s  Val. loss: 0.202  Val. score: 94.894%\n",
      "Epoch 4, 100% \t Train loss: 0.182 took: 14.11s  Val. loss: 0.185  Val. score: 95.383%\n",
      "Epoch 5, 100% \t Train loss: 0.149 took: 15.44s  Val. loss: 0.161  Val. score: 96.033%\n",
      "Epoch 6, 100% \t Train loss: 0.120 took: 14.78s  Val. loss: 0.166  Val. score: 96.167%\n",
      "Epoch 7, 100% \t Train loss: 0.103 took: 15.43s  Val. loss: 0.167  Val. score: 96.178%\n",
      "Epoch 8, 100% \t Train loss: 0.088 took: 15.70s  Val. loss: 0.160  Val. score: 96.361%\n",
      "Epoch 9, 100% \t Train loss: 0.075 took: 14.21s  Val. loss: 0.152  Val. score: 96.589%\n",
      "Epoch 10, 100% \t Train loss: 0.063 took: 14.54s  Val. loss: 0.155  Val. score: 96.683%\n",
      "Epoch 11, 100% \t Train loss: 0.056 took: 14.89s  Val. loss: 0.156  Val. score: 96.733%\n",
      "Epoch 12, 100% \t Train loss: 0.050 took: 15.33s  Val. loss: 0.143  Val. score: 97.106%\n",
      "Epoch 13, 100% \t Train loss: 0.046 took: 15.79s  Val. loss: 0.151  Val. score: 97.050%\n",
      "Epoch 14, 100% \t Train loss: 0.038 took: 18.19s  Val. loss: 0.155  Val. score: 97.178%\n",
      "Epoch 15, 100% \t Train loss: 0.034 took: 15.16s  Val. loss: 0.164  Val. score: 97.200%\n",
      "Training finished, took 329.819s\n",
      "\n",
      "Parameters configuration 90 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0027246045795521023\n",
      "h_sizes \t [784, 458, 259, 157, 99, 65, 40, 23]\n",
      "penalty \t 0.0009123352338428327\n",
      "dropout \t 0.09505034202060961\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.2907 +/- 0.0726\n",
      "Time for evaluation: 966.8 s\n",
      "Estimated time to finish : 1.49 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.409 took: 4.48s  Val. loss: 0.180  Val. score: 94.456%\n",
      "Epoch 2, 100% \t Train loss: 0.189 took: 5.13s  Val. loss: 0.135  Val. score: 95.983%\n",
      "Epoch 3, 100% \t Train loss: 0.142 took: 5.23s  Val. loss: 0.113  Val. score: 96.611%\n",
      "Epoch 4, 100% \t Train loss: 0.118 took: 4.56s  Val. loss: 0.105  Val. score: 96.861%\n",
      "Epoch 5, 100% \t Train loss: 0.101 took: 4.76s  Val. loss: 0.104  Val. score: 96.928%\n",
      "Epoch 6, 100% \t Train loss: 0.088 took: 4.72s  Val. loss: 0.101  Val. score: 96.889%\n",
      "Epoch 7, 100% \t Train loss: 0.079 took: 4.84s  Val. loss: 0.098  Val. score: 97.217%\n",
      "Epoch 8, 100% \t Train loss: 0.070 took: 4.46s  Val. loss: 0.096  Val. score: 97.239%\n",
      "Epoch 9, 100% \t Train loss: 0.065 took: 5.03s  Val. loss: 0.097  Val. score: 97.250%\n",
      "Epoch 10, 100% \t Train loss: 0.059 took: 4.34s  Val. loss: 0.090  Val. score: 97.494%\n",
      "Epoch 11, 100% \t Train loss: 0.053 took: 4.97s  Val. loss: 0.093  Val. score: 97.428%\n",
      "Epoch 12, 100% \t Train loss: 0.050 took: 5.15s  Val. loss: 0.097  Val. score: 97.383%\n",
      "Epoch 13, 100% \t Train loss: 0.044 took: 4.66s  Val. loss: 0.092  Val. score: 97.567%\n",
      "Epoch 14, 100% \t Train loss: 0.039 took: 4.63s  Val. loss: 0.099  Val. score: 97.511%\n",
      "Epoch 15, 100% \t Train loss: 0.040 took: 5.20s  Val. loss: 0.094  Val. score: 97.650%\n",
      "Training finished, took 126.454s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 100% \t Train loss: 0.419 took: 5.19s  Val. loss: 0.196  Val. score: 94.072%\n",
      "Epoch 2, 100% \t Train loss: 0.202 took: 4.70s  Val. loss: 0.134  Val. score: 95.917%\n",
      "Epoch 3, 100% \t Train loss: 0.151 took: 5.22s  Val. loss: 0.121  Val. score: 96.311%\n",
      "Epoch 4, 100% \t Train loss: 0.118 took: 4.93s  Val. loss: 0.109  Val. score: 96.756%\n",
      "Epoch 5, 100% \t Train loss: 0.103 took: 5.01s  Val. loss: 0.102  Val. score: 96.911%\n",
      "Epoch 6, 100% \t Train loss: 0.086 took: 4.75s  Val. loss: 0.099  Val. score: 97.083%\n",
      "Epoch 7, 100% \t Train loss: 0.079 took: 4.69s  Val. loss: 0.093  Val. score: 97.217%\n",
      "Epoch 8, 100% \t Train loss: 0.067 took: 4.74s  Val. loss: 0.095  Val. score: 97.356%\n",
      "Epoch 9, 100% \t Train loss: 0.063 took: 4.42s  Val. loss: 0.094  Val. score: 97.383%\n",
      "Epoch 10, 100% \t Train loss: 0.056 took: 6.99s  Val. loss: 0.089  Val. score: 97.472%\n",
      "Epoch 11, 100% \t Train loss: 0.053 took: 5.18s  Val. loss: 0.104  Val. score: 97.189%\n",
      "Epoch 12, 100% \t Train loss: 0.049 took: 5.60s  Val. loss: 0.089  Val. score: 97.611%\n",
      "Epoch 13, 100% \t Train loss: 0.043 took: 4.68s  Val. loss: 0.086  Val. score: 97.606%\n",
      "Epoch 14, 100% \t Train loss: 0.042 took: 4.89s  Val. loss: 0.083  Val. score: 97.767%\n",
      "Epoch 15, 100% \t Train loss: 0.040 took: 5.05s  Val. loss: 0.089  Val. score: 97.767%\n",
      "Training finished, took 131.148s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.396 took: 4.69s  Val. loss: 0.192  Val. score: 94.444%\n",
      "Epoch 2, 100% \t Train loss: 0.193 took: 4.87s  Val. loss: 0.141  Val. score: 95.717%\n",
      "Epoch 3, 100% \t Train loss: 0.147 took: 4.51s  Val. loss: 0.132  Val. score: 96.178%\n",
      "Epoch 4, 100% \t Train loss: 0.117 took: 5.04s  Val. loss: 0.111  Val. score: 96.667%\n",
      "Epoch 5, 100% \t Train loss: 0.100 took: 4.92s  Val. loss: 0.099  Val. score: 97.039%\n",
      "Epoch 6, 100% \t Train loss: 0.087 took: 4.69s  Val. loss: 0.104  Val. score: 96.939%\n",
      "Epoch 7, 100% \t Train loss: 0.074 took: 5.46s  Val. loss: 0.097  Val. score: 97.194%\n",
      "Epoch 8, 100% \t Train loss: 0.066 took: 4.81s  Val. loss: 0.094  Val. score: 97.256%\n",
      "Epoch 9, 100% \t Train loss: 0.059 took: 5.48s  Val. loss: 0.090  Val. score: 97.361%\n",
      "Epoch 10, 100% \t Train loss: 0.053 took: 4.38s  Val. loss: 0.101  Val. score: 97.261%\n",
      "Epoch 11, 100% \t Train loss: 0.051 took: 5.77s  Val. loss: 0.093  Val. score: 97.428%\n",
      "Epoch 12, 100% \t Train loss: 0.045 took: 5.77s  Val. loss: 0.089  Val. score: 97.606%\n",
      "Epoch 13, 100% \t Train loss: 0.042 took: 4.82s  Val. loss: 0.095  Val. score: 97.550%\n",
      "Epoch 14, 100% \t Train loss: 0.040 took: 6.45s  Val. loss: 0.090  Val. score: 97.667%\n",
      "Epoch 15, 100% \t Train loss: 0.037 took: 5.09s  Val. loss: 0.091  Val. score: 97.700%\n",
      "Training finished, took 130.668s\n",
      "\n",
      "Parameters configuration 91 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00912423331356473\n",
      "h_sizes \t [784, 185, 52]\n",
      "penalty \t 0.005116964279816358\n",
      "dropout \t 0.2011255120090813\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.7056 +/- 0.0478\n",
      "Time for evaluation: 389.5 s\n",
      "Estimated time to finish : 1.34 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.379 took: 5.15s  Val. loss: 0.213  Val. score: 93.472%\n",
      "Epoch 2, 100% \t Train loss: 0.173 took: 4.62s  Val. loss: 0.144  Val. score: 95.656%\n",
      "Epoch 3, 100% \t Train loss: 0.125 took: 4.72s  Val. loss: 0.118  Val. score: 96.578%\n",
      "Epoch 4, 100% \t Train loss: 0.101 took: 4.92s  Val. loss: 0.117  Val. score: 96.561%\n",
      "Epoch 5, 100% \t Train loss: 0.080 took: 5.10s  Val. loss: 0.107  Val. score: 96.950%\n",
      "Epoch 6, 100% \t Train loss: 0.067 took: 5.00s  Val. loss: 0.099  Val. score: 97.144%\n",
      "Epoch 7, 100% \t Train loss: 0.055 took: 4.85s  Val. loss: 0.102  Val. score: 97.256%\n",
      "Epoch 8, 100% \t Train loss: 0.047 took: 4.64s  Val. loss: 0.097  Val. score: 97.328%\n",
      "Epoch 9, 100% \t Train loss: 0.041 took: 5.27s  Val. loss: 0.091  Val. score: 97.444%\n",
      "Epoch 10, 100% \t Train loss: 0.036 took: 4.77s  Val. loss: 0.100  Val. score: 97.589%\n",
      "Epoch 11, 100% \t Train loss: 0.030 took: 5.20s  Val. loss: 0.104  Val. score: 97.517%\n",
      "Epoch 12, 100% \t Train loss: 0.028 took: 4.90s  Val. loss: 0.106  Val. score: 97.400%\n",
      "Epoch 13, 100% \t Train loss: 0.025 took: 5.26s  Val. loss: 0.096  Val. score: 97.767%\n",
      "Epoch 14, 100% \t Train loss: 0.022 took: 5.49s  Val. loss: 0.111  Val. score: 97.561%\n",
      "Epoch 15, 100% \t Train loss: 0.022 took: 4.84s  Val. loss: 0.109  Val. score: 97.589%\n",
      "Training finished, took 128.429s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.378 took: 4.89s  Val. loss: 0.163  Val. score: 95.067%\n",
      "Epoch 2, 100% \t Train loss: 0.164 took: 4.42s  Val. loss: 0.121  Val. score: 96.367%\n",
      "Epoch 3, 100% \t Train loss: 0.120 took: 4.50s  Val. loss: 0.106  Val. score: 96.956%\n",
      "Epoch 4, 100% \t Train loss: 0.096 took: 4.90s  Val. loss: 0.104  Val. score: 96.967%\n",
      "Epoch 5, 100% \t Train loss: 0.075 took: 4.93s  Val. loss: 0.093  Val. score: 97.289%\n",
      "Epoch 6, 100% \t Train loss: 0.061 took: 4.79s  Val. loss: 0.088  Val. score: 97.500%\n",
      "Epoch 7, 100% \t Train loss: 0.055 took: 4.52s  Val. loss: 0.086  Val. score: 97.639%\n",
      "Epoch 8, 100% \t Train loss: 0.045 took: 4.53s  Val. loss: 0.091  Val. score: 97.411%\n",
      "Epoch 9, 100% \t Train loss: 0.040 took: 4.85s  Val. loss: 0.086  Val. score: 97.622%\n",
      "Epoch 10, 100% \t Train loss: 0.035 took: 4.88s  Val. loss: 0.092  Val. score: 97.544%\n",
      "Epoch 11, 100% \t Train loss: 0.030 took: 4.46s  Val. loss: 0.094  Val. score: 97.539%\n",
      "Epoch 12, 100% \t Train loss: 0.027 took: 4.42s  Val. loss: 0.088  Val. score: 97.672%\n",
      "Epoch 13, 100% \t Train loss: 0.023 took: 5.26s  Val. loss: 0.092  Val. score: 97.733%\n",
      "Epoch 14, 100% \t Train loss: 0.023 took: 4.89s  Val. loss: 0.095  Val. score: 97.828%\n",
      "Epoch 15, 100% \t Train loss: 0.021 took: 5.23s  Val. loss: 0.096  Val. score: 97.867%\n",
      "Training finished, took 126.612s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.377 took: 4.83s  Val. loss: 0.182  Val. score: 94.739%\n",
      "Epoch 2, 100% \t Train loss: 0.169 took: 4.74s  Val. loss: 0.138  Val. score: 95.817%\n",
      "Epoch 3, 100% \t Train loss: 0.119 took: 4.78s  Val. loss: 0.133  Val. score: 96.056%\n",
      "Epoch 4, 100% \t Train loss: 0.093 took: 5.11s  Val. loss: 0.100  Val. score: 97.028%\n",
      "Epoch 5, 100% \t Train loss: 0.074 took: 5.53s  Val. loss: 0.093  Val. score: 97.006%\n",
      "Epoch 6, 100% \t Train loss: 0.059 took: 5.21s  Val. loss: 0.094  Val. score: 97.256%\n",
      "Epoch 7, 100% \t Train loss: 0.053 took: 4.94s  Val. loss: 0.099  Val. score: 97.178%\n",
      "Epoch 8, 100% \t Train loss: 0.040 took: 4.66s  Val. loss: 0.093  Val. score: 97.389%\n",
      "Epoch 9, 100% \t Train loss: 0.036 took: 4.68s  Val. loss: 0.090  Val. score: 97.583%\n",
      "Epoch 10, 100% \t Train loss: 0.031 took: 4.43s  Val. loss: 0.097  Val. score: 97.356%\n",
      "Epoch 11, 100% \t Train loss: 0.026 took: 4.72s  Val. loss: 0.099  Val. score: 97.428%\n",
      "Epoch 12, 100% \t Train loss: 0.026 took: 4.66s  Val. loss: 0.101  Val. score: 97.422%\n",
      "Epoch 13, 100% \t Train loss: 0.024 took: 4.30s  Val. loss: 0.101  Val. score: 97.506%\n",
      "Epoch 14, 100% \t Train loss: 0.019 took: 4.67s  Val. loss: 0.100  Val. score: 97.528%\n",
      "Epoch 15, 100% \t Train loss: 0.019 took: 4.99s  Val. loss: 0.093  Val. score: 97.778%\n",
      "Training finished, took 123.179s\n",
      "\n",
      "Parameters configuration 92 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.010805060864098812\n",
      "h_sizes \t [784, 165, 37]\n",
      "penalty \t 0.008465757241652785\n",
      "dropout \t 0.063763057936604\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.7444 +/- 0.1158\n",
      "Time for evaluation: 379.4 s\n",
      "Estimated time to finish : 1.19 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.619 took: 7.68s  Val. loss: 0.276  Val. score: 91.894%\n",
      "Epoch 2, 100% \t Train loss: 0.280 took: 7.96s  Val. loss: 0.189  Val. score: 94.411%\n",
      "Epoch 3, 100% \t Train loss: 0.201 took: 8.55s  Val. loss: 0.149  Val. score: 95.506%\n",
      "Epoch 4, 100% \t Train loss: 0.160 took: 8.76s  Val. loss: 0.122  Val. score: 96.267%\n",
      "Epoch 5, 100% \t Train loss: 0.129 took: 7.09s  Val. loss: 0.110  Val. score: 96.739%\n",
      "Epoch 6, 100% \t Train loss: 0.105 took: 7.90s  Val. loss: 0.098  Val. score: 96.967%\n",
      "Epoch 7, 100% \t Train loss: 0.093 took: 8.81s  Val. loss: 0.095  Val. score: 97.256%\n",
      "Epoch 8, 100% \t Train loss: 0.077 took: 6.63s  Val. loss: 0.094  Val. score: 97.222%\n",
      "Epoch 9, 100% \t Train loss: 0.069 took: 7.00s  Val. loss: 0.088  Val. score: 97.494%\n",
      "Epoch 10, 100% \t Train loss: 0.059 took: 7.05s  Val. loss: 0.089  Val. score: 97.406%\n",
      "Epoch 11, 100% \t Train loss: 0.051 took: 6.97s  Val. loss: 0.090  Val. score: 97.483%\n",
      "Epoch 12, 100% \t Train loss: 0.045 took: 6.68s  Val. loss: 0.081  Val. score: 97.694%\n",
      "Epoch 13, 100% \t Train loss: 0.041 took: 6.89s  Val. loss: 0.083  Val. score: 97.811%\n",
      "Epoch 14, 100% \t Train loss: 0.037 took: 6.74s  Val. loss: 0.085  Val. score: 97.689%\n",
      "Epoch 15, 100% \t Train loss: 0.034 took: 7.08s  Val. loss: 0.081  Val. score: 97.817%\n",
      "Training finished, took 174.349s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.570 took: 6.06s  Val. loss: 0.254  Val. score: 92.578%\n",
      "Epoch 2, 100% \t Train loss: 0.235 took: 6.03s  Val. loss: 0.171  Val. score: 94.761%\n",
      "Epoch 3, 100% \t Train loss: 0.165 took: 6.17s  Val. loss: 0.140  Val. score: 95.611%\n",
      "Epoch 4, 100% \t Train loss: 0.128 took: 6.78s  Val. loss: 0.124  Val. score: 96.256%\n",
      "Epoch 5, 100% \t Train loss: 0.106 took: 6.56s  Val. loss: 0.115  Val. score: 96.578%\n",
      "Epoch 6, 100% \t Train loss: 0.090 took: 6.82s  Val. loss: 0.108  Val. score: 96.878%\n",
      "Epoch 7, 100% \t Train loss: 0.077 took: 6.33s  Val. loss: 0.103  Val. score: 97.089%\n",
      "Epoch 8, 100% \t Train loss: 0.064 took: 6.42s  Val. loss: 0.105  Val. score: 96.922%\n",
      "Epoch 9, 100% \t Train loss: 0.056 took: 7.01s  Val. loss: 0.102  Val. score: 97.228%\n",
      "Epoch 10, 100% \t Train loss: 0.051 took: 6.35s  Val. loss: 0.102  Val. score: 97.228%\n",
      "Epoch 11, 100% \t Train loss: 0.043 took: 6.42s  Val. loss: 0.106  Val. score: 97.211%\n",
      "Epoch 12, 100% \t Train loss: 0.036 took: 7.13s  Val. loss: 0.099  Val. score: 97.478%\n",
      "Epoch 13, 100% \t Train loss: 0.032 took: 7.13s  Val. loss: 0.107  Val. score: 97.372%\n",
      "Epoch 14, 100% \t Train loss: 0.028 took: 6.62s  Val. loss: 0.103  Val. score: 97.494%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 6.93s  Val. loss: 0.103  Val. score: 97.500%\n",
      "Training finished, took 157.886s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.568 took: 6.00s  Val. loss: 0.230  Val. score: 93.117%\n",
      "Epoch 2, 100% \t Train loss: 0.243 took: 6.01s  Val. loss: 0.161  Val. score: 95.267%\n",
      "Epoch 3, 100% \t Train loss: 0.175 took: 7.00s  Val. loss: 0.141  Val. score: 95.744%\n",
      "Epoch 4, 100% \t Train loss: 0.140 took: 6.89s  Val. loss: 0.115  Val. score: 96.567%\n",
      "Epoch 5, 100% \t Train loss: 0.113 took: 7.08s  Val. loss: 0.104  Val. score: 96.906%\n",
      "Epoch 6, 100% \t Train loss: 0.091 took: 6.61s  Val. loss: 0.096  Val. score: 97.128%\n",
      "Epoch 7, 100% \t Train loss: 0.077 took: 6.55s  Val. loss: 0.096  Val. score: 97.256%\n",
      "Epoch 8, 100% \t Train loss: 0.068 took: 6.65s  Val. loss: 0.092  Val. score: 97.356%\n",
      "Epoch 9, 100% \t Train loss: 0.057 took: 7.52s  Val. loss: 0.093  Val. score: 97.394%\n",
      "Epoch 10, 100% \t Train loss: 0.050 took: 9.52s  Val. loss: 0.091  Val. score: 97.483%\n",
      "Epoch 11, 100% \t Train loss: 0.044 took: 7.29s  Val. loss: 0.084  Val. score: 97.722%\n",
      "Epoch 12, 100% \t Train loss: 0.039 took: 9.50s  Val. loss: 0.089  Val. score: 97.622%\n",
      "Epoch 13, 100% \t Train loss: 0.034 took: 7.71s  Val. loss: 0.097  Val. score: 97.439%\n",
      "Epoch 14, 100% \t Train loss: 0.030 took: 8.68s  Val. loss: 0.091  Val. score: 97.633%\n",
      "Epoch 15, 100% \t Train loss: 0.027 took: 7.66s  Val. loss: 0.089  Val. score: 97.717%\n",
      "Training finished, took 177.749s\n",
      "\n",
      "Parameters configuration 93 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003233962781215107\n",
      "h_sizes \t [784, 287, 91, 35]\n",
      "penalty \t 0.003116382818302528\n",
      "dropout \t 0.13103538813961335\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6778 +/- 0.1322\n",
      "Time for evaluation: 511.2 s\n",
      "Estimated time to finish : 1.04 h \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.408 took: 4.55s  Val. loss: 0.186  Val. score: 94.311%\n",
      "Epoch 2, 100% \t Train loss: 0.196 took: 4.63s  Val. loss: 0.156  Val. score: 95.022%\n",
      "Epoch 3, 100% \t Train loss: 0.151 took: 4.98s  Val. loss: 0.126  Val. score: 96.200%\n",
      "Epoch 4, 100% \t Train loss: 0.121 took: 4.94s  Val. loss: 0.102  Val. score: 96.917%\n",
      "Epoch 5, 100% \t Train loss: 0.099 took: 4.53s  Val. loss: 0.102  Val. score: 96.922%\n",
      "Epoch 6, 100% \t Train loss: 0.088 took: 4.21s  Val. loss: 0.104  Val. score: 97.122%\n",
      "Epoch 7, 100% \t Train loss: 0.078 took: 4.04s  Val. loss: 0.089  Val. score: 97.333%\n",
      "Epoch 8, 100% \t Train loss: 0.067 took: 4.52s  Val. loss: 0.091  Val. score: 97.300%\n",
      "Epoch 9, 100% \t Train loss: 0.065 took: 4.51s  Val. loss: 0.093  Val. score: 97.400%\n",
      "Epoch 10, 100% \t Train loss: 0.056 took: 4.14s  Val. loss: 0.091  Val. score: 97.444%\n",
      "Epoch 11, 100% \t Train loss: 0.052 took: 4.54s  Val. loss: 0.097  Val. score: 97.383%\n",
      "Epoch 12, 100% \t Train loss: 0.046 took: 4.52s  Val. loss: 0.092  Val. score: 97.533%\n",
      "Epoch 13, 100% \t Train loss: 0.044 took: 4.49s  Val. loss: 0.094  Val. score: 97.533%\n",
      "Epoch 14, 100% \t Train loss: 0.043 took: 4.47s  Val. loss: 0.094  Val. score: 97.589%\n",
      "Epoch 15, 100% \t Train loss: 0.039 took: 4.46s  Val. loss: 0.103  Val. score: 97.411%\n",
      "Training finished, took 118.395s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.425 took: 4.72s  Val. loss: 0.176  Val. score: 94.750%\n",
      "Epoch 2, 100% \t Train loss: 0.197 took: 4.47s  Val. loss: 0.135  Val. score: 95.950%\n",
      "Epoch 3, 100% \t Train loss: 0.152 took: 4.65s  Val. loss: 0.110  Val. score: 96.739%\n",
      "Epoch 4, 100% \t Train loss: 0.119 took: 4.10s  Val. loss: 0.100  Val. score: 96.994%\n",
      "Epoch 5, 100% \t Train loss: 0.103 took: 4.19s  Val. loss: 0.101  Val. score: 97.067%\n",
      "Epoch 6, 100% \t Train loss: 0.088 took: 4.09s  Val. loss: 0.097  Val. score: 97.256%\n",
      "Epoch 7, 100% \t Train loss: 0.078 took: 4.35s  Val. loss: 0.091  Val. score: 97.478%\n",
      "Epoch 8, 100% \t Train loss: 0.071 took: 4.44s  Val. loss: 0.092  Val. score: 97.328%\n",
      "Epoch 9, 100% \t Train loss: 0.064 took: 4.39s  Val. loss: 0.091  Val. score: 97.567%\n",
      "Epoch 10, 100% \t Train loss: 0.059 took: 4.44s  Val. loss: 0.089  Val. score: 97.544%\n",
      "Epoch 11, 100% \t Train loss: 0.053 took: 4.44s  Val. loss: 0.089  Val. score: 97.639%\n",
      "Epoch 12, 100% \t Train loss: 0.049 took: 4.40s  Val. loss: 0.090  Val. score: 97.578%\n",
      "Epoch 13, 100% \t Train loss: 0.047 took: 4.19s  Val. loss: 0.090  Val. score: 97.661%\n",
      "Epoch 14, 100% \t Train loss: 0.042 took: 3.99s  Val. loss: 0.095  Val. score: 97.672%\n",
      "Epoch 15, 100% \t Train loss: 0.040 took: 4.00s  Val. loss: 0.094  Val. score: 97.706%\n",
      "Training finished, took 112.551s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.401 took: 4.33s  Val. loss: 0.205  Val. score: 93.989%\n",
      "Epoch 2, 100% \t Train loss: 0.188 took: 4.62s  Val. loss: 0.146  Val. score: 95.639%\n",
      "Epoch 3, 100% \t Train loss: 0.144 took: 4.53s  Val. loss: 0.132  Val. score: 96.139%\n",
      "Epoch 4, 100% \t Train loss: 0.119 took: 4.04s  Val. loss: 0.121  Val. score: 96.311%\n",
      "Epoch 5, 100% \t Train loss: 0.103 took: 4.94s  Val. loss: 0.105  Val. score: 96.811%\n",
      "Epoch 6, 100% \t Train loss: 0.087 took: 4.05s  Val. loss: 0.104  Val. score: 96.894%\n",
      "Epoch 7, 100% \t Train loss: 0.077 took: 4.82s  Val. loss: 0.097  Val. score: 97.228%\n",
      "Epoch 8, 100% \t Train loss: 0.068 took: 4.75s  Val. loss: 0.102  Val. score: 97.094%\n",
      "Epoch 9, 100% \t Train loss: 0.061 took: 4.54s  Val. loss: 0.097  Val. score: 97.272%\n",
      "Epoch 10, 100% \t Train loss: 0.055 took: 4.67s  Val. loss: 0.093  Val. score: 97.406%\n",
      "Epoch 11, 100% \t Train loss: 0.051 took: 4.68s  Val. loss: 0.096  Val. score: 97.322%\n",
      "Epoch 12, 100% \t Train loss: 0.047 took: 4.42s  Val. loss: 0.098  Val. score: 97.461%\n",
      "Epoch 13, 100% \t Train loss: 0.043 took: 4.39s  Val. loss: 0.099  Val. score: 97.400%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, 100% \t Train loss: 0.041 took: 4.50s  Val. loss: 0.100  Val. score: 97.450%\n",
      "Epoch 15, 100% \t Train loss: 0.037 took: 4.60s  Val. loss: 0.099  Val. score: 97.522%\n",
      "Training finished, took 120.510s\n",
      "\n",
      "Parameters configuration 94 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.008896490515412279\n",
      "h_sizes \t [784, 172, 47]\n",
      "penalty \t 0.004739055219698434\n",
      "dropout \t 0.18488255719514723\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.5463 +/- 0.1214\n",
      "Time for evaluation: 353.1 s\n",
      "Estimated time to finish : 53.13 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.949 took: 9.82s  Val. loss: 0.374  Val. score: 89.989%\n",
      "Epoch 2, 100% \t Train loss: 0.376 took: 10.50s  Val. loss: 0.228  Val. score: 93.806%\n",
      "Epoch 3, 100% \t Train loss: 0.260 took: 10.06s  Val. loss: 0.192  Val. score: 94.928%\n",
      "Epoch 4, 100% \t Train loss: 0.202 took: 11.01s  Val. loss: 0.168  Val. score: 95.739%\n",
      "Epoch 5, 100% \t Train loss: 0.171 took: 10.27s  Val. loss: 0.147  Val. score: 96.261%\n",
      "Epoch 6, 100% \t Train loss: 0.145 took: 11.76s  Val. loss: 0.138  Val. score: 96.600%\n",
      "Epoch 7, 100% \t Train loss: 0.124 took: 10.55s  Val. loss: 0.133  Val. score: 96.917%\n",
      "Epoch 8, 100% \t Train loss: 0.110 took: 11.35s  Val. loss: 0.134  Val. score: 96.806%\n",
      "Epoch 9, 100% \t Train loss: 0.096 took: 10.82s  Val. loss: 0.133  Val. score: 97.017%\n",
      "Epoch 10, 100% \t Train loss: 0.085 took: 11.05s  Val. loss: 0.140  Val. score: 96.972%\n",
      "Epoch 11, 100% \t Train loss: 0.082 took: 11.02s  Val. loss: 0.128  Val. score: 97.011%\n",
      "Epoch 12, 100% \t Train loss: 0.066 took: 9.68s  Val. loss: 0.131  Val. score: 97.317%\n",
      "Epoch 13, 100% \t Train loss: 0.061 took: 10.95s  Val. loss: 0.141  Val. score: 97.294%\n",
      "Epoch 14, 100% \t Train loss: 0.057 took: 10.15s  Val. loss: 0.136  Val. score: 97.350%\n",
      "Epoch 15, 100% \t Train loss: 0.050 took: 11.84s  Val. loss: 0.141  Val. score: 97.472%\n",
      "Training finished, took 242.717s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.915 took: 10.47s  Val. loss: 0.299  Val. score: 91.744%\n",
      "Epoch 2, 100% \t Train loss: 0.345 took: 10.85s  Val. loss: 0.217  Val. score: 94.100%\n",
      "Epoch 3, 100% \t Train loss: 0.251 took: 10.61s  Val. loss: 0.168  Val. score: 95.456%\n",
      "Epoch 4, 100% \t Train loss: 0.201 took: 10.35s  Val. loss: 0.151  Val. score: 95.967%\n",
      "Epoch 5, 100% \t Train loss: 0.168 took: 10.42s  Val. loss: 0.134  Val. score: 96.494%\n",
      "Epoch 6, 100% \t Train loss: 0.142 took: 10.79s  Val. loss: 0.146  Val. score: 96.367%\n",
      "Epoch 7, 100% \t Train loss: 0.127 took: 10.65s  Val. loss: 0.135  Val. score: 96.650%\n",
      "Epoch 8, 100% \t Train loss: 0.112 took: 12.04s  Val. loss: 0.125  Val. score: 96.906%\n",
      "Epoch 9, 100% \t Train loss: 0.098 took: 12.17s  Val. loss: 0.123  Val. score: 96.961%\n",
      "Epoch 10, 100% \t Train loss: 0.088 took: 11.24s  Val. loss: 0.121  Val. score: 97.194%\n",
      "Epoch 11, 100% \t Train loss: 0.077 took: 10.95s  Val. loss: 0.120  Val. score: 97.367%\n",
      "Epoch 12, 100% \t Train loss: 0.072 took: 9.88s  Val. loss: 0.124  Val. score: 97.250%\n",
      "Epoch 13, 100% \t Train loss: 0.068 took: 10.08s  Val. loss: 0.119  Val. score: 97.444%\n",
      "Epoch 14, 100% \t Train loss: 0.058 took: 10.58s  Val. loss: 0.131  Val. score: 97.500%\n",
      "Epoch 15, 100% \t Train loss: 0.055 took: 10.33s  Val. loss: 0.135  Val. score: 97.217%\n",
      "Training finished, took 243.141s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.861 took: 10.43s  Val. loss: 0.306  Val. score: 91.300%\n",
      "Epoch 2, 100% \t Train loss: 0.325 took: 9.73s  Val. loss: 0.195  Val. score: 94.622%\n",
      "Epoch 3, 100% \t Train loss: 0.232 took: 9.69s  Val. loss: 0.163  Val. score: 95.678%\n",
      "Epoch 4, 100% \t Train loss: 0.185 took: 9.73s  Val. loss: 0.142  Val. score: 96.489%\n",
      "Epoch 5, 100% \t Train loss: 0.156 took: 11.02s  Val. loss: 0.139  Val. score: 96.572%\n",
      "Epoch 6, 100% \t Train loss: 0.133 took: 10.65s  Val. loss: 0.125  Val. score: 97.072%\n",
      "Epoch 7, 100% \t Train loss: 0.115 took: 10.99s  Val. loss: 0.137  Val. score: 96.778%\n",
      "Epoch 8, 100% \t Train loss: 0.098 took: 10.83s  Val. loss: 0.133  Val. score: 97.139%\n",
      "Epoch 9, 100% \t Train loss: 0.090 took: 10.76s  Val. loss: 0.126  Val. score: 97.228%\n",
      "Epoch 10, 100% \t Train loss: 0.082 took: 11.26s  Val. loss: 0.124  Val. score: 97.350%\n",
      "Epoch 11, 100% \t Train loss: 0.071 took: 10.97s  Val. loss: 0.136  Val. score: 97.217%\n",
      "Epoch 12, 100% \t Train loss: 0.065 took: 11.15s  Val. loss: 0.128  Val. score: 97.411%\n",
      "Epoch 13, 100% \t Train loss: 0.063 took: 11.07s  Val. loss: 0.142  Val. score: 97.178%\n",
      "Epoch 14, 100% \t Train loss: 0.056 took: 10.03s  Val. loss: 0.128  Val. score: 97.506%\n",
      "Epoch 15, 100% \t Train loss: 0.055 took: 9.73s  Val. loss: 0.135  Val. score: 97.444%\n",
      "Training finished, took 237.734s\n",
      "\n",
      "Parameters configuration 95 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003458581583551235\n",
      "h_sizes \t [784, 383, 176, 78, 33, 20]\n",
      "penalty \t 0.0006185549730053594\n",
      "dropout \t 0.16622836400030946\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.3778 +/- 0.1145\n",
      "Time for evaluation: 724.8 s\n",
      "Estimated time to finish : 44.45 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.525 took: 7.97s  Val. loss: 0.220  Val. score: 93.461%\n",
      "Epoch 2, 100% \t Train loss: 0.185 took: 7.69s  Val. loss: 0.160  Val. score: 95.372%\n",
      "Epoch 3, 100% \t Train loss: 0.131 took: 7.71s  Val. loss: 0.131  Val. score: 96.222%\n",
      "Epoch 4, 100% \t Train loss: 0.101 took: 8.04s  Val. loss: 0.125  Val. score: 96.456%\n",
      "Epoch 5, 100% \t Train loss: 0.077 took: 7.98s  Val. loss: 0.111  Val. score: 96.928%\n",
      "Epoch 6, 100% \t Train loss: 0.062 took: 7.78s  Val. loss: 0.109  Val. score: 96.994%\n",
      "Epoch 7, 100% \t Train loss: 0.048 took: 7.23s  Val. loss: 0.125  Val. score: 96.728%\n",
      "Epoch 8, 100% \t Train loss: 0.042 took: 7.04s  Val. loss: 0.104  Val. score: 97.400%\n",
      "Epoch 9, 100% \t Train loss: 0.033 took: 7.79s  Val. loss: 0.114  Val. score: 97.111%\n",
      "Epoch 10, 100% \t Train loss: 0.030 took: 7.37s  Val. loss: 0.111  Val. score: 97.506%\n",
      "Epoch 11, 100% \t Train loss: 0.022 took: 7.51s  Val. loss: 0.121  Val. score: 97.339%\n",
      "Epoch 12, 100% \t Train loss: 0.021 took: 6.99s  Val. loss: 0.127  Val. score: 97.289%\n",
      "Epoch 13, 100% \t Train loss: 0.017 took: 7.26s  Val. loss: 0.131  Val. score: 97.344%\n",
      "Epoch 14, 100% \t Train loss: 0.016 took: 7.52s  Val. loss: 0.133  Val. score: 97.461%\n",
      "Epoch 15, 100% \t Train loss: 0.013 took: 7.44s  Val. loss: 0.137  Val. score: 97.406%\n",
      "Training finished, took 178.297s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.540 took: 7.07s  Val. loss: 0.207  Val. score: 94.128%\n",
      "Epoch 2, 100% \t Train loss: 0.197 took: 7.06s  Val. loss: 0.145  Val. score: 95.717%\n",
      "Epoch 3, 100% \t Train loss: 0.138 took: 7.93s  Val. loss: 0.127  Val. score: 96.333%\n",
      "Epoch 4, 100% \t Train loss: 0.107 took: 7.23s  Val. loss: 0.118  Val. score: 96.700%\n",
      "Epoch 5, 100% \t Train loss: 0.080 took: 7.89s  Val. loss: 0.106  Val. score: 97.061%\n",
      "Epoch 6, 100% \t Train loss: 0.064 took: 7.89s  Val. loss: 0.096  Val. score: 97.378%\n",
      "Epoch 7, 100% \t Train loss: 0.051 took: 7.83s  Val. loss: 0.096  Val. score: 97.522%\n",
      "Epoch 8, 100% \t Train loss: 0.039 took: 7.68s  Val. loss: 0.101  Val. score: 97.589%\n",
      "Epoch 9, 100% \t Train loss: 0.034 took: 7.14s  Val. loss: 0.103  Val. score: 97.522%\n",
      "Epoch 10, 100% \t Train loss: 0.027 took: 7.33s  Val. loss: 0.112  Val. score: 97.322%\n",
      "Epoch 11, 100% \t Train loss: 0.023 took: 7.08s  Val. loss: 0.113  Val. score: 97.478%\n",
      "Epoch 12, 100% \t Train loss: 0.020 took: 7.02s  Val. loss: 0.107  Val. score: 97.678%\n",
      "Epoch 13, 100% \t Train loss: 0.017 took: 7.00s  Val. loss: 0.112  Val. score: 97.683%\n",
      "Epoch 14, 100% \t Train loss: 0.015 took: 7.14s  Val. loss: 0.127  Val. score: 97.483%\n",
      "Epoch 15, 100% \t Train loss: 0.014 took: 6.98s  Val. loss: 0.130  Val. score: 97.489%\n",
      "Training finished, took 175.533s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 100% \t Train loss: 0.534 took: 7.07s  Val. loss: 0.219  Val. score: 93.706%\n",
      "Epoch 2, 100% \t Train loss: 0.200 took: 7.14s  Val. loss: 0.150  Val. score: 95.567%\n",
      "Epoch 3, 100% \t Train loss: 0.136 took: 7.55s  Val. loss: 0.130  Val. score: 96.206%\n",
      "Epoch 4, 100% \t Train loss: 0.103 took: 7.16s  Val. loss: 0.128  Val. score: 96.356%\n",
      "Epoch 5, 100% \t Train loss: 0.083 took: 7.21s  Val. loss: 0.104  Val. score: 96.833%\n",
      "Epoch 6, 100% \t Train loss: 0.066 took: 7.86s  Val. loss: 0.100  Val. score: 97.244%\n",
      "Epoch 7, 100% \t Train loss: 0.053 took: 7.69s  Val. loss: 0.104  Val. score: 97.256%\n",
      "Epoch 8, 100% \t Train loss: 0.044 took: 7.17s  Val. loss: 0.100  Val. score: 97.433%\n",
      "Epoch 9, 100% \t Train loss: 0.036 took: 7.47s  Val. loss: 0.117  Val. score: 97.028%\n",
      "Epoch 10, 100% \t Train loss: 0.031 took: 7.02s  Val. loss: 0.109  Val. score: 97.350%\n",
      "Epoch 11, 100% \t Train loss: 0.026 took: 7.02s  Val. loss: 0.103  Val. score: 97.522%\n",
      "Epoch 12, 100% \t Train loss: 0.020 took: 7.56s  Val. loss: 0.107  Val. score: 97.683%\n",
      "Epoch 13, 100% \t Train loss: 0.019 took: 7.81s  Val. loss: 0.106  Val. score: 97.867%\n",
      "Epoch 14, 100% \t Train loss: 0.015 took: 7.83s  Val. loss: 0.126  Val. score: 97.556%\n",
      "Epoch 15, 100% \t Train loss: 0.015 took: 7.32s  Val. loss: 0.118  Val. score: 97.728%\n",
      "Training finished, took 176.364s\n",
      "\n",
      "Parameters configuration 96 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.005705934084080705\n",
      "h_sizes \t [784, 324, 118, 55, 19]\n",
      "penalty \t 0.00017976461896136996\n",
      "dropout \t 0.047978918639824786\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.5407 +/- 0.1366\n",
      "Time for evaluation: 531.4 s\n",
      "Estimated time to finish : 35.56 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.473 took: 4.76s  Val. loss: 0.247  Val. score: 92.628%\n",
      "Epoch 2, 100% \t Train loss: 0.225 took: 4.81s  Val. loss: 0.184  Val. score: 94.561%\n",
      "Epoch 3, 100% \t Train loss: 0.170 took: 4.79s  Val. loss: 0.161  Val. score: 95.172%\n",
      "Epoch 4, 100% \t Train loss: 0.133 took: 4.91s  Val. loss: 0.139  Val. score: 95.772%\n",
      "Epoch 5, 100% \t Train loss: 0.109 took: 4.88s  Val. loss: 0.125  Val. score: 96.250%\n",
      "Epoch 6, 100% \t Train loss: 0.090 took: 4.65s  Val. loss: 0.108  Val. score: 96.683%\n",
      "Epoch 7, 100% \t Train loss: 0.078 took: 4.62s  Val. loss: 0.102  Val. score: 97.006%\n",
      "Epoch 8, 100% \t Train loss: 0.064 took: 4.97s  Val. loss: 0.101  Val. score: 97.083%\n",
      "Epoch 9, 100% \t Train loss: 0.055 took: 4.91s  Val. loss: 0.095  Val. score: 97.289%\n",
      "Epoch 10, 100% \t Train loss: 0.047 took: 5.01s  Val. loss: 0.100  Val. score: 97.056%\n",
      "Epoch 11, 100% \t Train loss: 0.042 took: 4.95s  Val. loss: 0.095  Val. score: 97.300%\n",
      "Epoch 12, 100% \t Train loss: 0.035 took: 5.05s  Val. loss: 0.096  Val. score: 97.328%\n",
      "Epoch 13, 100% \t Train loss: 0.031 took: 4.98s  Val. loss: 0.096  Val. score: 97.278%\n",
      "Epoch 14, 100% \t Train loss: 0.028 took: 4.54s  Val. loss: 0.089  Val. score: 97.528%\n",
      "Epoch 15, 100% \t Train loss: 0.024 took: 4.98s  Val. loss: 0.094  Val. score: 97.511%\n",
      "Training finished, took 123.318s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.476 took: 4.70s  Val. loss: 0.261  Val. score: 92.739%\n",
      "Epoch 2, 100% \t Train loss: 0.221 took: 4.77s  Val. loss: 0.191  Val. score: 94.594%\n",
      "Epoch 3, 100% \t Train loss: 0.163 took: 4.87s  Val. loss: 0.156  Val. score: 95.433%\n",
      "Epoch 4, 100% \t Train loss: 0.126 took: 4.93s  Val. loss: 0.130  Val. score: 96.189%\n",
      "Epoch 5, 100% \t Train loss: 0.104 took: 4.49s  Val. loss: 0.124  Val. score: 96.339%\n",
      "Epoch 6, 100% \t Train loss: 0.086 took: 5.00s  Val. loss: 0.107  Val. score: 96.822%\n",
      "Epoch 7, 100% \t Train loss: 0.073 took: 4.73s  Val. loss: 0.100  Val. score: 97.072%\n",
      "Epoch 8, 100% \t Train loss: 0.062 took: 5.68s  Val. loss: 0.098  Val. score: 97.122%\n",
      "Epoch 9, 100% \t Train loss: 0.054 took: 5.19s  Val. loss: 0.098  Val. score: 97.156%\n",
      "Epoch 10, 100% \t Train loss: 0.045 took: 5.15s  Val. loss: 0.095  Val. score: 97.217%\n",
      "Epoch 11, 100% \t Train loss: 0.037 took: 4.51s  Val. loss: 0.103  Val. score: 97.189%\n",
      "Epoch 12, 100% \t Train loss: 0.035 took: 4.82s  Val. loss: 0.090  Val. score: 97.383%\n",
      "Epoch 13, 100% \t Train loss: 0.027 took: 4.53s  Val. loss: 0.092  Val. score: 97.456%\n",
      "Epoch 14, 100% \t Train loss: 0.025 took: 4.73s  Val. loss: 0.091  Val. score: 97.356%\n",
      "Epoch 15, 100% \t Train loss: 0.023 took: 4.90s  Val. loss: 0.092  Val. score: 97.461%\n",
      "Training finished, took 124.645s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.481 took: 4.30s  Val. loss: 0.275  Val. score: 92.239%\n",
      "Epoch 2, 100% \t Train loss: 0.241 took: 4.32s  Val. loss: 0.201  Val. score: 94.011%\n",
      "Epoch 3, 100% \t Train loss: 0.179 took: 4.90s  Val. loss: 0.160  Val. score: 95.200%\n",
      "Epoch 4, 100% \t Train loss: 0.141 took: 4.86s  Val. loss: 0.138  Val. score: 95.894%\n",
      "Epoch 5, 100% \t Train loss: 0.114 took: 4.87s  Val. loss: 0.122  Val. score: 96.283%\n",
      "Epoch 6, 100% \t Train loss: 0.095 took: 4.83s  Val. loss: 0.111  Val. score: 96.578%\n",
      "Epoch 7, 100% \t Train loss: 0.079 took: 4.56s  Val. loss: 0.098  Val. score: 96.978%\n",
      "Epoch 8, 100% \t Train loss: 0.068 took: 4.93s  Val. loss: 0.106  Val. score: 96.733%\n",
      "Epoch 9, 100% \t Train loss: 0.057 took: 4.98s  Val. loss: 0.091  Val. score: 97.144%\n",
      "Epoch 10, 100% \t Train loss: 0.050 took: 4.60s  Val. loss: 0.094  Val. score: 97.167%\n",
      "Epoch 11, 100% \t Train loss: 0.042 took: 4.58s  Val. loss: 0.090  Val. score: 97.256%\n",
      "Epoch 12, 100% \t Train loss: 0.035 took: 4.84s  Val. loss: 0.089  Val. score: 97.411%\n",
      "Epoch 13, 100% \t Train loss: 0.031 took: 4.98s  Val. loss: 0.091  Val. score: 97.289%\n",
      "Epoch 14, 100% \t Train loss: 0.028 took: 4.94s  Val. loss: 0.087  Val. score: 97.450%\n",
      "Epoch 15, 100% \t Train loss: 0.025 took: 5.03s  Val. loss: 0.088  Val. score: 97.444%\n",
      "Training finished, took 120.710s\n",
      "\n",
      "Parameters configuration 97 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0029976321452246427\n",
      "h_sizes \t [784, 189, 46]\n",
      "penalty \t 0.00030929693247069704\n",
      "dropout \t 0.02922134765315329\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4722 +/- 0.0283\n",
      "Time for evaluation: 369.8 s\n",
      "Estimated time to finish : 26.58 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.463 took: 5.92s  Val. loss: 0.206  Val. score: 93.739%\n",
      "Epoch 2, 100% \t Train loss: 0.190 took: 5.83s  Val. loss: 0.158  Val. score: 95.244%\n",
      "Epoch 3, 100% \t Train loss: 0.131 took: 5.87s  Val. loss: 0.125  Val. score: 96.228%\n",
      "Epoch 4, 100% \t Train loss: 0.102 took: 6.00s  Val. loss: 0.121  Val. score: 96.450%\n",
      "Epoch 5, 100% \t Train loss: 0.081 took: 6.00s  Val. loss: 0.097  Val. score: 97.211%\n",
      "Epoch 6, 100% \t Train loss: 0.064 took: 5.98s  Val. loss: 0.093  Val. score: 97.356%\n",
      "Epoch 7, 100% \t Train loss: 0.050 took: 6.05s  Val. loss: 0.093  Val. score: 97.406%\n",
      "Epoch 8, 100% \t Train loss: 0.043 took: 5.96s  Val. loss: 0.092  Val. score: 97.472%\n",
      "Epoch 9, 100% \t Train loss: 0.034 took: 6.44s  Val. loss: 0.090  Val. score: 97.622%\n",
      "Epoch 10, 100% \t Train loss: 0.031 took: 6.33s  Val. loss: 0.094  Val. score: 97.494%\n",
      "Epoch 11, 100% \t Train loss: 0.024 took: 5.97s  Val. loss: 0.097  Val. score: 97.644%\n",
      "Epoch 12, 100% \t Train loss: 0.021 took: 6.64s  Val. loss: 0.097  Val. score: 97.694%\n",
      "Epoch 13, 100% \t Train loss: 0.016 took: 6.11s  Val. loss: 0.104  Val. score: 97.600%\n",
      "Epoch 14, 100% \t Train loss: 0.016 took: 6.29s  Val. loss: 0.098  Val. score: 97.772%\n",
      "Epoch 15, 100% \t Train loss: 0.014 took: 6.74s  Val. loss: 0.099  Val. score: 97.756%\n",
      "Training finished, took 149.291s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.516 took: 6.34s  Val. loss: 0.233  Val. score: 93.211%\n",
      "Epoch 2, 100% \t Train loss: 0.199 took: 5.91s  Val. loss: 0.160  Val. score: 95.061%\n",
      "Epoch 3, 100% \t Train loss: 0.142 took: 5.93s  Val. loss: 0.139  Val. score: 95.656%\n",
      "Epoch 4, 100% \t Train loss: 0.107 took: 6.58s  Val. loss: 0.146  Val. score: 95.683%\n",
      "Epoch 5, 100% \t Train loss: 0.085 took: 6.35s  Val. loss: 0.107  Val. score: 96.839%\n",
      "Epoch 6, 100% \t Train loss: 0.067 took: 6.76s  Val. loss: 0.105  Val. score: 97.083%\n",
      "Epoch 7, 100% \t Train loss: 0.056 took: 6.57s  Val. loss: 0.107  Val. score: 96.889%\n",
      "Epoch 8, 100% \t Train loss: 0.046 took: 6.14s  Val. loss: 0.099  Val. score: 97.200%\n",
      "Epoch 9, 100% \t Train loss: 0.037 took: 6.69s  Val. loss: 0.103  Val. score: 97.183%\n",
      "Epoch 10, 100% \t Train loss: 0.032 took: 6.07s  Val. loss: 0.114  Val. score: 97.111%\n",
      "Epoch 11, 100% \t Train loss: 0.026 took: 6.56s  Val. loss: 0.111  Val. score: 97.350%\n",
      "Epoch 12, 100% \t Train loss: 0.024 took: 6.72s  Val. loss: 0.108  Val. score: 97.489%\n",
      "Epoch 13, 100% \t Train loss: 0.018 took: 6.11s  Val. loss: 0.108  Val. score: 97.667%\n",
      "Epoch 14, 100% \t Train loss: 0.017 took: 6.36s  Val. loss: 0.107  Val. score: 97.600%\n",
      "Epoch 15, 100% \t Train loss: 0.015 took: 6.06s  Val. loss: 0.107  Val. score: 97.589%\n",
      "Training finished, took 152.280s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.504 took: 6.27s  Val. loss: 0.233  Val. score: 93.111%\n",
      "Epoch 2, 100% \t Train loss: 0.208 took: 6.38s  Val. loss: 0.159  Val. score: 95.111%\n",
      "Epoch 3, 100% \t Train loss: 0.146 took: 6.22s  Val. loss: 0.136  Val. score: 95.789%\n",
      "Epoch 4, 100% \t Train loss: 0.114 took: 6.16s  Val. loss: 0.113  Val. score: 96.578%\n",
      "Epoch 5, 100% \t Train loss: 0.089 took: 6.11s  Val. loss: 0.101  Val. score: 96.850%\n",
      "Epoch 6, 100% \t Train loss: 0.070 took: 6.47s  Val. loss: 0.108  Val. score: 96.861%\n",
      "Epoch 7, 100% \t Train loss: 0.059 took: 6.12s  Val. loss: 0.096  Val. score: 97.222%\n",
      "Epoch 8, 100% \t Train loss: 0.048 took: 6.11s  Val. loss: 0.097  Val. score: 97.244%\n",
      "Epoch 9, 100% \t Train loss: 0.041 took: 6.57s  Val. loss: 0.094  Val. score: 97.350%\n",
      "Epoch 10, 100% \t Train loss: 0.035 took: 6.72s  Val. loss: 0.093  Val. score: 97.439%\n",
      "Epoch 11, 100% \t Train loss: 0.029 took: 6.51s  Val. loss: 0.091  Val. score: 97.622%\n",
      "Epoch 12, 100% \t Train loss: 0.024 took: 6.53s  Val. loss: 0.092  Val. score: 97.528%\n",
      "Epoch 13, 100% \t Train loss: 0.021 took: 6.61s  Val. loss: 0.097  Val. score: 97.578%\n",
      "Epoch 14, 100% \t Train loss: 0.019 took: 6.85s  Val. loss: 0.094  Val. score: 97.689%\n",
      "Epoch 15, 100% \t Train loss: 0.015 took: 6.45s  Val. loss: 0.096  Val. score: 97.650%\n",
      "Training finished, took 153.313s\n",
      "\n",
      "Parameters configuration 98 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.00534631582989067\n",
      "h_sizes \t [784, 255, 69, 28]\n",
      "penalty \t 0.0004099755295656873\n",
      "dropout \t 0.04854067398332329\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.6648 +/- 0.0688\n",
      "Time for evaluation: 456.0 s\n",
      "Estimated time to finish : 17.70 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.532 took: 4.71s  Val. loss: 0.274  Val. score: 92.222%\n",
      "Epoch 2, 100% \t Train loss: 0.255 took: 4.71s  Val. loss: 0.203  Val. score: 93.911%\n",
      "Epoch 3, 100% \t Train loss: 0.196 took: 4.87s  Val. loss: 0.175  Val. score: 94.700%\n",
      "Epoch 4, 100% \t Train loss: 0.157 took: 4.78s  Val. loss: 0.139  Val. score: 95.822%\n",
      "Epoch 5, 100% \t Train loss: 0.134 took: 4.91s  Val. loss: 0.123  Val. score: 96.256%\n",
      "Epoch 6, 100% \t Train loss: 0.113 took: 4.87s  Val. loss: 0.116  Val. score: 96.489%\n",
      "Epoch 7, 100% \t Train loss: 0.096 took: 4.93s  Val. loss: 0.107  Val. score: 96.661%\n",
      "Epoch 8, 100% \t Train loss: 0.087 took: 4.55s  Val. loss: 0.099  Val. score: 96.928%\n",
      "Epoch 9, 100% \t Train loss: 0.075 took: 4.64s  Val. loss: 0.095  Val. score: 97.056%\n",
      "Epoch 10, 100% \t Train loss: 0.068 took: 4.60s  Val. loss: 0.098  Val. score: 96.983%\n",
      "Epoch 11, 100% \t Train loss: 0.061 took: 4.56s  Val. loss: 0.087  Val. score: 97.356%\n",
      "Epoch 12, 100% \t Train loss: 0.054 took: 4.97s  Val. loss: 0.088  Val. score: 97.422%\n",
      "Epoch 13, 100% \t Train loss: 0.049 took: 4.99s  Val. loss: 0.086  Val. score: 97.517%\n",
      "Epoch 14, 100% \t Train loss: 0.043 took: 4.56s  Val. loss: 0.082  Val. score: 97.561%\n",
      "Epoch 15, 100% \t Train loss: 0.040 took: 4.98s  Val. loss: 0.083  Val. score: 97.639%\n",
      "Training finished, took 120.973s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.553 took: 4.69s  Val. loss: 0.266  Val. score: 92.322%\n",
      "Epoch 2, 100% \t Train loss: 0.269 took: 4.25s  Val. loss: 0.196  Val. score: 94.206%\n",
      "Epoch 3, 100% \t Train loss: 0.198 took: 4.82s  Val. loss: 0.160  Val. score: 95.189%\n",
      "Epoch 4, 100% \t Train loss: 0.160 took: 4.85s  Val. loss: 0.138  Val. score: 95.778%\n",
      "Epoch 5, 100% \t Train loss: 0.132 took: 4.44s  Val. loss: 0.118  Val. score: 96.478%\n",
      "Epoch 6, 100% \t Train loss: 0.112 took: 4.44s  Val. loss: 0.109  Val. score: 96.650%\n",
      "Epoch 7, 100% \t Train loss: 0.097 took: 4.58s  Val. loss: 0.102  Val. score: 96.783%\n",
      "Epoch 8, 100% \t Train loss: 0.084 took: 4.89s  Val. loss: 0.095  Val. score: 97.000%\n",
      "Epoch 9, 100% \t Train loss: 0.073 took: 4.81s  Val. loss: 0.096  Val. score: 96.983%\n",
      "Epoch 10, 100% \t Train loss: 0.066 took: 4.94s  Val. loss: 0.087  Val. score: 97.306%\n",
      "Epoch 11, 100% \t Train loss: 0.060 took: 4.42s  Val. loss: 0.089  Val. score: 97.228%\n",
      "Epoch 12, 100% \t Train loss: 0.055 took: 4.56s  Val. loss: 0.084  Val. score: 97.417%\n",
      "Epoch 13, 100% \t Train loss: 0.047 took: 4.44s  Val. loss: 0.083  Val. score: 97.417%\n",
      "Epoch 14, 100% \t Train loss: 0.042 took: 4.94s  Val. loss: 0.088  Val. score: 97.456%\n",
      "Epoch 15, 100% \t Train loss: 0.040 took: 4.53s  Val. loss: 0.085  Val. score: 97.467%\n",
      "Training finished, took 118.765s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.521 took: 4.66s  Val. loss: 0.283  Val. score: 91.878%\n",
      "Epoch 2, 100% \t Train loss: 0.257 took: 4.69s  Val. loss: 0.214  Val. score: 93.778%\n",
      "Epoch 3, 100% \t Train loss: 0.192 took: 4.84s  Val. loss: 0.178  Val. score: 94.839%\n",
      "Epoch 4, 100% \t Train loss: 0.152 took: 5.35s  Val. loss: 0.152  Val. score: 95.428%\n",
      "Epoch 5, 100% \t Train loss: 0.126 took: 6.09s  Val. loss: 0.134  Val. score: 96.028%\n",
      "Epoch 6, 100% \t Train loss: 0.107 took: 4.64s  Val. loss: 0.122  Val. score: 96.356%\n",
      "Epoch 7, 100% \t Train loss: 0.091 took: 4.89s  Val. loss: 0.115  Val. score: 96.417%\n",
      "Epoch 8, 100% \t Train loss: 0.079 took: 4.84s  Val. loss: 0.113  Val. score: 96.556%\n",
      "Epoch 9, 100% \t Train loss: 0.071 took: 4.77s  Val. loss: 0.103  Val. score: 96.900%\n",
      "Epoch 10, 100% \t Train loss: 0.063 took: 4.48s  Val. loss: 0.106  Val. score: 96.872%\n",
      "Epoch 11, 100% \t Train loss: 0.056 took: 4.57s  Val. loss: 0.102  Val. score: 96.950%\n",
      "Epoch 12, 100% \t Train loss: 0.051 took: 4.63s  Val. loss: 0.102  Val. score: 96.967%\n",
      "Epoch 13, 100% \t Train loss: 0.045 took: 4.83s  Val. loss: 0.097  Val. score: 97.078%\n",
      "Epoch 14, 100% \t Train loss: 0.040 took: 4.60s  Val. loss: 0.096  Val. score: 97.183%\n",
      "Epoch 15, 100% \t Train loss: 0.037 took: 4.48s  Val. loss: 0.094  Val. score: 97.294%\n",
      "Training finished, took 122.201s\n",
      "\n",
      "Parameters configuration 99 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.0027067396193755375\n",
      "h_sizes \t [784, 185, 44]\n",
      "penalty \t 0.001314378774496794\n",
      "dropout \t 0.08440170890240617\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7ff4480948c0>\n",
      "===========================================================================\n",
      "Score: 97.4667 +/- 0.1406\n",
      "Time for evaluation: 363.1 s\n",
      "Estimated time to finish : 8.82 min \n",
      "\n",
      "Computing fold 1 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.544 took: 7.17s  Val. loss: 0.199  Val. score: 94.139%\n",
      "Epoch 2, 100% \t Train loss: 0.174 took: 7.22s  Val. loss: 0.144  Val. score: 95.861%\n",
      "Epoch 3, 100% \t Train loss: 0.126 took: 7.65s  Val. loss: 0.142  Val. score: 96.039%\n",
      "Epoch 4, 100% \t Train loss: 0.097 took: 7.12s  Val. loss: 0.121  Val. score: 96.556%\n",
      "Epoch 5, 100% \t Train loss: 0.078 took: 7.96s  Val. loss: 0.129  Val. score: 96.517%\n",
      "Epoch 6, 100% \t Train loss: 0.064 took: 7.58s  Val. loss: 0.117  Val. score: 97.106%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, 100% \t Train loss: 0.052 took: 7.08s  Val. loss: 0.121  Val. score: 96.939%\n",
      "Epoch 8, 100% \t Train loss: 0.047 took: 7.32s  Val. loss: 0.129  Val. score: 96.856%\n",
      "Epoch 9, 100% \t Train loss: 0.040 took: 7.62s  Val. loss: 0.116  Val. score: 97.222%\n",
      "Epoch 10, 100% \t Train loss: 0.033 took: 8.12s  Val. loss: 0.133  Val. score: 96.972%\n",
      "Epoch 11, 100% \t Train loss: 0.029 took: 7.88s  Val. loss: 0.144  Val. score: 96.844%\n",
      "Epoch 12, 100% \t Train loss: 0.024 took: 8.02s  Val. loss: 0.137  Val. score: 97.139%\n",
      "Epoch 13, 100% \t Train loss: 0.023 took: 7.76s  Val. loss: 0.128  Val. score: 97.311%\n",
      "Epoch 14, 100% \t Train loss: 0.022 took: 8.25s  Val. loss: 0.140  Val. score: 97.244%\n",
      "Epoch 15, 100% \t Train loss: 0.020 took: 7.09s  Val. loss: 0.141  Val. score: 97.300%\n",
      "Training finished, took 179.643s\n",
      "Computing fold 2 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.462 took: 8.06s  Val. loss: 0.200  Val. score: 94.306%\n",
      "Epoch 2, 100% \t Train loss: 0.165 took: 8.01s  Val. loss: 0.140  Val. score: 96.172%\n",
      "Epoch 3, 100% \t Train loss: 0.118 took: 7.73s  Val. loss: 0.119  Val. score: 96.800%\n",
      "Epoch 4, 100% \t Train loss: 0.087 took: 9.14s  Val. loss: 0.109  Val. score: 97.206%\n",
      "Epoch 5, 100% \t Train loss: 0.068 took: 8.66s  Val. loss: 0.100  Val. score: 97.350%\n",
      "Epoch 6, 100% \t Train loss: 0.055 took: 7.91s  Val. loss: 0.102  Val. score: 97.450%\n",
      "Epoch 7, 100% \t Train loss: 0.043 took: 7.60s  Val. loss: 0.112  Val. score: 97.339%\n",
      "Epoch 8, 100% \t Train loss: 0.036 took: 7.92s  Val. loss: 0.114  Val. score: 97.433%\n",
      "Epoch 9, 100% \t Train loss: 0.031 took: 7.94s  Val. loss: 0.123  Val. score: 97.500%\n",
      "Epoch 10, 100% \t Train loss: 0.026 took: 7.86s  Val. loss: 0.127  Val. score: 97.522%\n",
      "Epoch 11, 100% \t Train loss: 0.023 took: 7.77s  Val. loss: 0.119  Val. score: 97.461%\n",
      "Epoch 12, 100% \t Train loss: 0.017 took: 7.10s  Val. loss: 0.141  Val. score: 97.506%\n",
      "Epoch 13, 100% \t Train loss: 0.020 took: 7.10s  Val. loss: 0.133  Val. score: 97.622%\n",
      "Epoch 14, 100% \t Train loss: 0.018 took: 8.37s  Val. loss: 0.129  Val. score: 97.467%\n",
      "Epoch 15, 100% \t Train loss: 0.012 took: 7.20s  Val. loss: 0.131  Val. score: 97.811%\n",
      "Training finished, took 187.115s\n",
      "Computing fold 3 out of 3...\n",
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.418 took: 7.24s  Val. loss: 0.168  Val. score: 95.200%\n",
      "Epoch 2, 100% \t Train loss: 0.155 took: 7.15s  Val. loss: 0.163  Val. score: 94.956%\n",
      "Epoch 3, 100% \t Train loss: 0.105 took: 7.13s  Val. loss: 0.131  Val. score: 96.367%\n",
      "Epoch 4, 100% \t Train loss: 0.079 took: 7.14s  Val. loss: 0.118  Val. score: 96.628%\n",
      "Epoch 5, 100% \t Train loss: 0.058 took: 7.14s  Val. loss: 0.121  Val. score: 96.956%\n",
      "Epoch 6, 100% \t Train loss: 0.053 took: 7.46s  Val. loss: 0.105  Val. score: 97.256%\n",
      "Epoch 7, 100% \t Train loss: 0.040 took: 7.48s  Val. loss: 0.129  Val. score: 97.011%\n",
      "Epoch 8, 100% \t Train loss: 0.036 took: 8.17s  Val. loss: 0.103  Val. score: 97.550%\n",
      "Epoch 9, 100% \t Train loss: 0.029 took: 7.62s  Val. loss: 0.112  Val. score: 97.450%\n",
      "Epoch 10, 100% \t Train loss: 0.021 took: 8.30s  Val. loss: 0.129  Val. score: 97.228%\n",
      "Epoch 11, 100% \t Train loss: 0.023 took: 7.44s  Val. loss: 0.111  Val. score: 97.683%\n",
      "Epoch 12, 100% \t Train loss: 0.020 took: 7.58s  Val. loss: 0.107  Val. score: 97.683%\n",
      "Epoch 13, 100% \t Train loss: 0.017 took: 7.18s  Val. loss: 0.118  Val. score: 97.550%\n",
      "Epoch 14, 100% \t Train loss: 0.014 took: 7.89s  Val. loss: 0.120  Val. score: 97.767%\n",
      "Epoch 15, 100% \t Train loss: 0.014 took: 8.02s  Val. loss: 0.137  Val. score: 97.517%\n",
      "Training finished, took 177.888s\n",
      "\n",
      "Parameters configuration 100 out of 100\n",
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.013215368202102893\n",
      "h_sizes \t [784, 332, 135, 56, 21]\n",
      "penalty \t 0.0016787136089521613\n",
      "dropout \t 0.03994474565080411\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function leaky_relu at 0x7ff448094cb0>\n",
      "===========================================================================\n",
      "Score: 97.5426 +/- 0.2095\n",
      "Time for evaluation: 545.8 s\n",
      "Estimated time to finish : 0.00 s \n",
      "\n",
      "CPU times: user 23h 26min 33s, sys: 14h 6min 53s, total: 1d 13h 33min 27s\n",
      "Wall time: 14h 42min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scoring, deviations, _ = GridSearchCV(Net, x_training, y_training, list_of_dict, K_folds=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('HP_scoring2', scoring) # to make sure of not losing the results of the grid search\n",
    "np.save('HP_deviations2', deviations) \n",
    "np.save('dict_list2', list_of_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring2 = np.load('HP_scoring2.npy')\n",
    "deviations2 = np.load('HP_deviations2.npy')\n",
    "list_of_dict2 = np.load('dict_list2.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my metric to choose the best model\n",
    "composite_score = scoring2 - 2*deviations2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = list_of_dict2[np.argmax(composite_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003996024018867443\n",
      "h_sizes \t [784, 278, 94, 24]\n",
      "penalty \t 0.0014430192249231507\n",
      "dropout \t 0.08787206607182774\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f9e78b8c8c0>\n",
      "===========================================================================\n",
      "Score: 97.6926 +/- 0.0210\n"
     ]
    }
   ],
   "source": [
    "print_HP_score(score=scoring2[np.argmax(composite_score)], \n",
    "               dev = deviations2[np.argmax(composite_score)], \n",
    "               params=best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbose:  True\n",
      "Epoch 1, 100% \t Train loss: 0.462 took: 10.82s  Val. loss: 0.185  Val. score: 94.483%\n",
      "Epoch 2, 100% \t Train loss: 0.185 took: 11.45s  Val. loss: 0.124  Val. score: 96.400%\n",
      "Epoch 3, 100% \t Train loss: 0.133 took: 11.51s  Val. loss: 0.097  Val. score: 97.017%\n",
      "Epoch 4, 100% \t Train loss: 0.104 took: 10.90s  Val. loss: 0.081  Val. score: 97.467%\n",
      "Epoch 5, 100% \t Train loss: 0.080 took: 10.59s  Val. loss: 0.086  Val. score: 97.400%\n",
      "Epoch 6, 100% \t Train loss: 0.067 took: 10.71s  Val. loss: 0.076  Val. score: 97.700%\n",
      "Epoch 7, 100% \t Train loss: 0.057 took: 10.40s  Val. loss: 0.073  Val. score: 97.983%\n",
      "Epoch 8, 100% \t Train loss: 0.049 took: 10.68s  Val. loss: 0.069  Val. score: 97.983%\n",
      "Epoch 9, 100% \t Train loss: 0.040 took: 10.47s  Val. loss: 0.071  Val. score: 97.950%\n",
      "Epoch 10, 100% \t Train loss: 0.036 took: 11.11s  Val. loss: 0.068  Val. score: 98.167%\n",
      "Epoch 11, 100% \t Train loss: 0.032 took: 10.57s  Val. loss: 0.070  Val. score: 98.100%\n",
      "Epoch 12, 100% \t Train loss: 0.027 took: 11.26s  Val. loss: 0.080  Val. score: 98.133%\n",
      "Epoch 13, 100% \t Train loss: 0.024 took: 11.30s  Val. loss: 0.075  Val. score: 98.150%\n",
      "Epoch 14, 100% \t Train loss: 0.023 took: 11.39s  Val. loss: 0.080  Val. score: 98.050%\n",
      "Epoch 15, 100% \t Train loss: 0.019 took: 10.58s  Val. loss: 0.078  Val. score: 98.233%\n",
      "Training finished, took 185.508s\n",
      "CPU times: user 5min 8s, sys: 3min 26s, total: 8min 35s\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = train_torchNN(Net, x_training, y_training, x_test, y_test, train_log=True, verbose=True, debug=False, \n",
    "                           return_model=True, train_batch_size=128, val_batch_size=128, **best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net, train_loss_log, val_loss_log, val_acc_log = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained 98.23%\n"
     ]
    }
   ],
   "source": [
    "accuracy, predictions = eval_accuracy(best_net, x_test,y_test,return_predictions=True)\n",
    "print(\"Accuracy obtained {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAELCAYAAAAybErdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU1dnA8d+TzEy2mSwkhIEECLIEATfEpYq7WFxQX9RqFSvu7avVaqti64JLX7Uura3WWhegat2oCyp1qRYVNwgCsguyJoQtZN+X8/5xb5JhMgkDmWRmkuf7+cxn5i5z7pMQ5pmz3HPEGINSSinlKybcASillIo8mhyUUkq1oclBKaVUG5oclFJKtaHJQSmlVBuOcAcQChkZGSYnJyfcYSilVFRZtGjRLmNM30DHekRyyMnJIS8vL9xhKKVUVBGRTe0d02YlpZRSbWhyUEop1YYmB6WUUm1oclBKKdWGJgellFJt9IjRSkr1dE1NTezatYuSkhIaGxvDHY6KEvHx8WRnZ+N0Ovf5vZoclIoC+fn5iAg5OTk4nU5EJNwhqQhnjKGoqIj8/HyGDBmyz+/v1c1KeRt38+C/V6PTlqtIV1lZSVZWFi6XSxODCoqIkJ6eTk1NzX69v1cnh+UFpfzt0x/YUV4b7lCU2quYmF7931Xth858kejVf2253mQAVm8rD3MkSikVWXp1chjp9QCwZltZmCNRSqnI0quTQ1qSi0xPnNYclIpAn3/+OampqZ0u56KLLuK5555r9/iLL75ItE7cOW3aNO68884uKbtXJweAXK+HNZoclAqZE088kfvvv7/T5Rx33HGUlJR0qoyvv/6aBQsWMHXq1E7HE245OTm8+OKLe+y77bbbePLJJykoKAj59Xp9chjp9bB2RwUNjU3hDkWpXqO+vr5brvP4449z+eWXExsbu99ldFes+yMtLY3TTz+dp59+OuRl9/rkkOtNpq6hiY1FVeEORamod/311/P5559z33334Xa7yc3NBWDq1KlccsklTJ06lT59+nDDDTdQVVXF5MmT8Xq9JCcnM3bsWD766KOWsubNm4fD0Xor1tSpU7n00ku5+uqrSU1NJSsrq8MPxYaGBt577z0mTJiwx/4FCxYwbtw43G4348ePZ/369Xscz8nJ4d577+Wkk07C7Xbzr3/9C4CnnnqK3NxcUlJSOProo/n8889b3jN9+nROOeUUbrrpJtLT08nOzubBBx/co9xPP/2Uo446ipSUFEaOHLlH7P4/a3OZp556KgCTJk1i8+bNXHXVVbjdbk477bSW8yZMmMBbb73V7u9hf/X6m+BaO6XLGZbpDnM0SgXvnndWsHJr9wymGDUgmbsnjd7reU888QTLly/n1FNP5Y477tjj2Ouvv84LL7zAc889R21tLU1NTUyePJlZs2YRHx/Pn/70J8477zx++OEH+vYNuP4Ms2fP5tVXX+Xpp5/mrbfe4sILL2TixIkMHjy4zblr166lvLycUaNGtewrLS3l9NNP55ZbbuHmm29m6dKlTJo0ifj4+D3e+8wzzzBnzhwOPfRQampqePnll7nzzjt57733OPzww5k1axYTJ05k5cqVLdf+7LPPmDBhAoWFhSxbtozTTz+dQYMGcfHFF7NhwwYmTpzIU089xZQpU8jLy+OMM86gT58+XHDBBXv9vb7zzjvk5ORw//33M2XKlD2OHXTQQSxfvpy6ujpcLtdeywpWr685DMt0EyM6YkmprjZ+/HguvPBCYmNjSUxMxO12M2XKFDweD06nk1tuuQWXy8XChQvbLePkk0/m7LPPJiYmhsmTJ5OamsqSJUsCnltcXAyAx+Np2ffuu++SlJTEbbfdhsvl4ogjjuDKK69s896rr76aww47DBEhISGBGTNmcO2113LUUUfhcDi48sorOfjgg/nnP//Z8p7+/fu3lHv44YdzzTXXMHPmTABefvllxo4dy9SpU3E4HBx99NFce+21PPvss/vzq9xDcnIyxphO98/46/U1h3hnLDkZSTpiSUWdYL7JRxL/EUHV1dXccsstzJ07l127dhETE0N5eTk7d+5st4z+/fvvsZ2UlER5eeD/u2lpaQCUl5eTnGzd05Sfn8/gwYP3uDks0NQS/rFu2bKFn/zkJ3vsGzp0KFu2bGnZ9i83JyeHN954o+X9/tcZOnQob7/9dsDY90VZWRkiEpKRXb56fc0BrKalNds1OSgVCu3dye2//7HHHuOzzz7j448/prS0lJKSEtLS0kI2nc3w4cNxu92sXLmyZV9WVhabNm3a4xobN27ca6wDBw5sc9769esZOHBgy3agcrOzs4N6v8fjobGxkdra1tkatm7d2mFMzZYvX87o0aND2qQEmhwAyO2XzObdVVTVNYQ7FKWintfrZd26dXs9r6ysjLi4ONLT06mrq+Pee+8NadOIw+HgzDPP5D//+U/LvrPOOouKigoefvhh6uvr+fbbbzu8B6LZ1KlTefrpp1mwYAENDQ3MmDGDJUuWcPHFF7ecU1hY2FLu4sWLeeaZZ7jssssA+OlPf8qiRYv4xz/+QUNDAwsWLODpp59uadIaMWIEbrebZ599lqamJubPn8/s2bP3iMHr9bJ27do2sX300Uece+65+/U76ogmB6x7HYyB77dXhDsUpaLeTTfdRF5eHqmpqYwe3X7T180330xqaioDBgxg6NChJCYmhvxmtBtvvJGZM2e2THOemprKe++9x6uvvkpaWho33HADv/jFL/ZazsUXX8zdd9/NlClTSE9P56mnnmLu3Ll7dIQfd9xxFBYW4vV6Oeuss7jxxhtbkseQIUOYO3cuTzzxBOnp6Vx66aXcd999LU1VHo+HGTNm8Oijj5KSksLjjz/eklia3XHHHbz44ostw1cBSkpKmDt3Lj//+c9D8vvyJT1hRtJx48aZvLy8/X7/xl2VnPjIPB467yAuPGJQCCNTKjRWrVrFgQceGO4wotJFF13EhAkTAnY8h8r06dOZP3/+HrWU7nD77bcTGxvb4U2HHf3tiMgiY8y4QMd6fYc0wKA+iSQ4Y7VTWqke6JVXXgl3CF3mgQce6LKytVkJiIkRRvRz6zQaSill05qDLdfr4eNVO8IdhlIqCk2fPj3cIYSc1hxsI73JFFXWsVMX/lFKKU0OzXyn0VBKqd5Ok4Mt104Oq3UaDaWU0uTQLN0dR4Y7TmsOSimFJoc9jPR6dDirUkqhyWEPuV4P328vp7Ep+m8MVEqpztDk4CPX66G2oYlNRZXhDkWpqBWqZULBmtPoqquuCklZat9ocvChI5aUUsrS7clBRCaKyBoRWSci0zo47zwRMSIScN6PrjA804MI2u+g1H5qb5nQZ555hjFjxpCSksJhhx3Ghx9+2PKexYsXM378eFJSUujTpw/HHHMMxcXF/OEPf+Cll15i1qxZuN1u3G53ywR6qut16x3SIhILPAlMAPKBhSIyxxiz0u88D3Aj8E13xpfgiiUnPUlrDio6/HsabFvWPdfyHgSnP7jX0wItE/rMM8/w0EMP8a9//YuDDjqI999/n8mTJ7NkyRKGDRvGddddx8SJE/n0009pampi0aJFuFwubr31VlauXInD4QjJimlq33R3zeFIYJ0xZr0xpg54BTgnwHn3AQ8BNd0ZHEBuP134R6lQevzxx7nrrrs45JBDiImJ4YwzzuCkk05qmRDP5XKxefNmtmzZgtPp5OijjyYpKSnMUavunlspC9jis50PHOV7goiMBQYaY94TkVvaK0hErgGuARg0KHTTbOd6PXywchvVdY0kuGJDVq5SIRfEN/lIsGHDBq677jpuuOGGln0NDQ0tq6TNmDGD++67j/Hjx+N0OpkyZQp33303DodO/RZOEfXbF5EY4DFg6t7ONcb8Hfg7WOs5hCqGkfbCP2t3lHNwdmjXZFWqN/BfznLw4MHcc889XHDBBQHPHzJkCM8//zwAy5Yt47TTTmPIkCFcccUV7S6Nqbped//mC4CBPtvZ9r5mHmAMME9ENgJHA3O6s1O6dRoNbVpSan/4LxN60003MX36dJYsWYIxhurqaubPn8/q1asBmDVrVst6yampqTgcDmJjY1vKWr9+PU1NTd3/g/Ry3V1zWAgMF5EhWEnhIqBlEVZjTCmQ0bwtIvOA3xhj9n+Zt300OD2JeGeMdkortZ9uuukmLr/8clJTU8nKymLFihW4XC4uv/xyNmzYgNPpZOzYsTzyyCMAfPLJJ0ybNo2ysjLS0tK45JJLuPTSSwG46qqr+Pjjj0lPT8cYQ1FRUUviUF2rW5ODMaZBRK4HPgBigeeNMStE5F4gzxgzpzvjCSQ2Rhie6dHkoNR+OuKII1i+fPke+y677LI2ayI3mzVrVrtlHXDAAXzzTbcOWlS2bu9zMMbMBeb67burnXNP7I6Y/OV6PcxbszMcl1ZKqYigvT0BjPR62FVRS1GFLvyjlOqdNDkEkKvTaCilejlNDgHoiCWlVG+nySGAvu44+iS5tOagIooxOpW82jed+ZvR5BCAiJDbz8NqnUZDRQin00l1dXW4w1BRpr6+fr/vNNfk0I5cr4e128tp0oV/VATIzMykoKCAqqoqrUGooDQ1NbF9+3ZSUlL26/0RNX1GJBnp9VBV18iW4ioGp+skYCq8kpOTAdi6dSv19fVhjkZFi6SkJDIyMvZ+YgCaHNrh2ymtyUFFguTk5JYkoVRX02aldozop8NZlVK9lyaHdiTFORjUJ1GTg1KqV9Lk0IFcr4fV28rCHYZSSnU7TQ4dONDrYcOuSmrqdd1apVTvosmhA7neZJoMrNtREe5QlFKqW2ly6IBOo6GU6q00OXQgJz0RlyOGNdrvoJTqZTQ5dMARG8PwTLfWHJRSvY4mh73I9eqqcEqp3keTw16M9HrYUV5LcWVduENRSqluo8lhL3K91nQF2rSklOpNNDnsxciWVeG0U1op1XtoctiLTE8cqYlO1ujaDkqpXkSTw160LPyjzUpKqV5Ek0MQRno9fL9NF/5RSvUemhyCkOtNprKukYISXaZRKdU7aHIIgk6joZTqbTQ5BCFXRywppXoZTQ5BcMc5yE5L0JqDUqrX0OQQpJE6jYZSqhfR5BCkXK+H9bsqqW3QhX+UUj2fJocg5XqTaWwy/LCjMtyhKKVUl9PkEKSWaTS2a6e0UqrnCyo5iIh0dSCRbkhGEs5Y0U5ppVSvEGzNYZOI3CkiA7o0mgjmjI1haF+3dkorpXqFYJPDJ8A0YKOIvCEip3VhTBFLRywppXqLoJKDMWYqMAD4DTACeF9EfhCR20SkbxfGF1FyvckUltZQWlUf7lCUUqpLBd0hbYwpNcb82RgzBjgB+BKYDmwRkVdE5MSuCTFyjGyZRkM7pZVSPdv+jlb6AngTWAK4gEnAxyKyQEQO7OiNIjJRRNaIyDoRmRbg+M9FZJmILBGR+SIyaj9jDLmWaTR0bQelVA+3T8lBRAaKyL3AZuA1oAQ4B/AAE4EEYFYH748FngROB0YBPw3w4f9PY8xBxphDgT8Aj+1LjF2pf0o8nniHjlhSSvV4jmBOEpFJwLXAj4FSYAbwlDFmvc9pH4nIzcB7HRR1JLCu+X0i8gpWclnZfIIxxrfNJgmImEUUREQ7pZVSvUJQyQF4G1gIXAW8Yoypbee8H4CXOignC9jis50PHOV/kohcB9yM1WR1cqCCROQa4BqAQYMG7SX80BnpTeatxQUYY9DbP5RSPVWwzUrjjDFHGWNmdZAYMMasN8Zc3tmgjDFPGmOGArcBd7Rzzt+NMeOMMeP69u2+AVO5Xg/ltQ268I9SqkcLNjlsEZERgQ6IyAgRyQiynAJgoM92tr2vPa8A5wZZdrdomUZDm5aUUj1YsMnhr8Cv2zl2k308GAuB4SIyRERcwEXAHN8TRGS4z+aZwNogy+4WI3RVOKVULxBsn8N44Lp2jn0IPBFMIcaYBhG5HvgAiAWeN8assEdA5Rlj5gDXi8ipQD1QDFwWZIzdIjneSVZqgtYclFI9WrDJIQ1rlFIgZUB6sBc0xswF5vrtu8vn9Y3BlhUuuTpiSSnVwwXbrBRwVJHtKKAwNOFEh1yvhx92VlDX0BTuUJRSqksEmxxmA7eLyJm+O+3taVg3xPUaI70eGpoM63dVhDsUpZTqEsEmh3uBZcAcESmwp8kowOpMXgbc01UBRqJcHbGklOrhgp2VtQprsr2rgc+wps34FLgSOME+3msckOHGEaML/yileq5gO6QxxtQDz9uPXs3l0IV/lFI9m64hvZ90xJJSqicLOjmIyGki8qaIrBSR9X6PH7oyyEiU6/VQUFJNWY0u/KOU6nmCSg4icgbwbyARGAmsxpq2eyDQhNUP0as0T6PxvdYelFI9ULA1hzux1mE4w96+wxhzIjAa607nf4c+tMiWq9NoKKV6sGCTw0jgHaxagsHuyDbGfI+1VOidXRFcJMtKTcAT59B+B6VUjxRscmgCGowxBtgJ+C6gsBUYGurAIp2IMEI7pZVSPVSwyWENkGO/zgN+JSL9RaQv1mytG0MfWuTL9XpYva0MK2cqpVTPEWxyeAk40H59N1ZfQz6wDWultrvaeV+PNtLroaymgW1lNeEORSmlQiqom+CMMU/6vF4kIgcBE7FGL/3HGLOy3Tf3YLn9Wjul+6ckhDkapZQKnb3WHETEJSI3isiY5n3GmHxjzLPGmD/31sQA1nrSoHMsKaV6nr0mB2NMHfAg0Kfrw4kuKYlOvMnxrC4sC3coSikVUsH2OawCDujKQKKV1SmtNQelVM8SbHK4C7jT7mtQPkbaC//UN+rCP0qpniPYWVlvA9zAYhHZiLXym+/4TWOMOSHEsUWFXK+H+kbDhl2VjLA7qJVSKtoFmxwagV7b8dwR32k0NDkopXqKYIeyntjFcUStYZluYmOENdvK4JAB4Q5HKaVCQtdz6KQ4RyxDMpJ0OKtSqkcJquYgIsfv7RxjTK+btrvZSK+HJVtKwh2GUkqFTLB9DvPYswM6kNjOhRK9Rno9vPtdIRW1Dbjjgl55VSmlIlawn2QnBdiXDpwFnABcH7KIolCuz53Shw9OC3M0SinVecF2SH/azqE3ROSPwCR64YI/zZpXhdPkoJTqKULRIf0e8JMQlBO1slITSHLFWiOWlFKqBwhFcsjFWgyo14qJsRb+0Wk0lFI9RbCjlX4WYLcLGANcCbwRyqCi0Uivh38v34YxBhEJdzhKKdUpwXZIz2xnfy3wKnBjSKKJYrn9PLy8YAs7ymvplxwf7nCUUqpTgk0OQwLsqzHGbA9lMNGsecTS6m3lmhyUUlEv2NFKm7o6kGjXOmKpjBNG9A1zNEop1TlBdUiLyFkiEvBeBhG5TkTOCG1Y0SctyUWmJ047pZVSPUKwo5XuBJLaOZZgH+/1cr0enWNJKdUjBJscRgLftnNsCXBgaMKJbiO9HtbuqKBBF/5RSkW5YJNDDNZiP4F4AGewFxSRiSKyRkTWici0AMdvFpGVIvKdiHwsIoODLTvccr3J1DU0sbGoKtyhKKVUpwSbHJYCl7Rz7BLgu2AKEZFY4EngdGAU8FMRGeV32mJgnDHmYGA28IcgYww732k0lFIqmgWbHB4FJovI6yJymoiMEpEJIvI68D/Aw0GWcySwzhiz3hhTB7wCnON7gjHmv8aY5q/eXwPZQZYddsMy3cQIOo2GUirqBTuU9U0RuRH4PTDZ3i1ABXCDMSbYO6SzgC0+2/nAUR2cfyXtTOgnItcA1wAMGjQoyMt3rXhnLDkZSTpiSSkV9YJefMAY8xcRmQkcgzVd9y7gS2NMRVcEJiJTgHFYU4IHiufvwN8Bxo0bt7e1JrrNSK+H5QVac1BKRbd9WpnGGFMOfNCJ6xUAA322s+19exCRU4HfAScYY2o7cb1ul9svmbnLtlFZ20CSLvyjlIpSwd4Ed5uI/KWdY38WkVuCvN5CYLiIDBERF3ARMMevvMOAp4GzjTE7giw3YuTandLfb9emJaVU9Aq2Q/py2h+RtMQ+vlfGmAasVeM+AFYBrxljVojIvSJytn3aw1jDZl8XkSUiMqed4iKSjlhSSvUEwbZ7DALWtnNsPRD0vQjGmLnAXL99d/m8PjXYskLCGAjhFNuD+iSS4IzVTmmlVFQLtuZQhTXSKJBsrKm7o8/3H8KLk6G+JmRFNi/889UPRdTUN4asXKWU6k7BJofPgVtEJM53p739a/t49GmshR8+gbm/tmoQIXLNcQewZns5v3x5sU6loZSKSsEmh+nAcOB7Efm9iPyviPwe+N7ef1dHb45YB06C42+BxS9C3vMhK/bMg/tzz9mj+Wjldqa9sYympogZaauUUkEJ9ia4pSJyEvAIcBtWUmkC5gPnGWOWdl2IXezE26FwKfz7Nug3GgYdHZJiLzsmh5Kqev74n+9JSXByx5kH6vKhSqmoEWzNAWPMAmPM8VgT7WUDHmPMiUCSiITua3d3i4mFyc9A6kB49VIo2xqyom84ZRhTj8nhufkbePK/60JWrlJKdbWgk0MzY0w1kAjcLiIbgP8CPwl1YN0qIRUufAnqKuG1n0FDaPrXRYS7zhrF5MOyeOTD73nha11QTykVHYJODiKSIiLXiMgXwBqsO5iLgV8AA7oovu7TbxSc+1fIXwj/vjVkxcbECA+dfzCnHpjJXW8v5+0lbW4IV0qpiNNhchCRGBE5Q0ReBQqBv2Hd0/CkfcqvjDFPG2N6xmRCo8+F8TfDopmQNyNkxTpjY3ji4rEcmdOHX7+2lP+ujrobv5VSvUy7yUFEHsWa9+gd4CzgTWAi1g1xd2HNytrznHwHDD0F5t4CWxaErNh4ZyzPXjaOkf09/OKlRSzcuDtkZSulVKh1VHO4CcjEupt5kDHmEmPMh8aYJqDnjs2MiYXznoWULKuDunxbyIr2xDuZdfmRDEhN4IqZC1m5tWdUuJRSPU9HyeE5oBw4E1gjIk+IyJHdE1aYJfaxOqhry+C1y6ChLmRFp7vjeOHKo/DEOfjZ8wvYsKsyZGUrpVSotJscjDFXA16sZUDzgGuBr0RkFda9Dj239gDgHQPnPAFbvoYPbg9p0VmpCbxw1VE0GcOUZ79hW2nopu9QSqlQ6LBD2hhTY4x52RjT3NdwO9AITMPqc3hQRKaISHzXhxoGY86DY26Ahc/Cty+EtOihfd3MuvxISqvrufS5byiuDF3tRCmlOmtfboIrNMb8wRgzBmst6Cexps74B9ZIpp7plLvhgBPhvZshf1FIiz4oO4VnLxvHpt1VTJ25kIrahpCWr5RS+2ufb4IDMMbkGWN+iXV/w3nAvFAGFVFiHXD+DPB44dUpUBHaYahHH5DOkxePZXlBKde+kEdtg87kqpQKv/1KDs2MMfXGmDeNMf8TqoAiUnMHdXWx1UHdWB/S4ieM6sfD5x/MF+uKuPHlJTqTq1Iq7DqVHHqV/gfD2X+BzV/CB78LefGTx2Zz11mjeH/FNn775jJMCKcQV0qpfRXsSnAK4OALoHAJfPUEDDgUDr04pMVfMX4IJdX1/PnjtaQkOPntGTqTq1IqPDQ57KtT74Ft38E7v4LMA2HAYSEt/qZTh1NaVcczn28gNdHFdScNC2n5SikVDG1W2lfNHdTuTHhlClTuCmnxIsLdk0Zz7qEDePiDNbz0jc7kqpTqfpoc9kdSBlz4IlTtgtenhryDOiZGePiCQzh5ZCZ3vLWcd5aGbo0JpZQKhiaH/TXgUJj0OGz8HD4K/SqpztgY/nrJWI4Y3IebX1vCvDU6k6tSqvtocuiMQy6Co34OX/8Vlr4a8uLjnbE8O3UcwzM9/PzFRSzapDO5KqW6hyaHzjrtfhg8Ht65wVqLOsSS453848oj6Z+SwOUzFmqCUEp1C00OnRXrhAtmQmK63UFdFPJLZLjjeOHKI/HEOzn/b19x+xvfsVvnYlJKdSFNDqHg7gsXvgAV22H25dAY+jmSstMSef9Xx3HV+CG8lpfPyY/O45/fbKaxSW+WU0qFniaHUMk6HM76I2z4FD6e3iWX8MQ7+d2Zo5h7w3Hk9vPw2zeXMfmvX7B0S0mXXE8p1Xtpcgilwy6BI66GL/8C3/4DumgKjFyvh1euOZrHLzqUraU1nPvXL/jtm8t02m+lVMhocgi1H/+f1UE955cwaxIUfNsllxERzjk0i09+fQJXHDuEVxdu4eRH5/HKgs00aVOTUqqTNDmEmsMFl74Jpz8MO1bCMyfB7Ctg94YuuZwn3smdZ43ivRvGMzzTw7Q3lvE/T33JsvzSLrmeUqp3kJ4w++e4ceNMXl5euMNoq6YMvvwzfPWkdRf1EVfC8bdCUnqXXM4Yw1tLCvj9e6spqqzl4iMHccuPc0lNdHXJ9ZRS0U1EFhljxgU8psmhG5QVwrwHYPEL4HLDsTfC0f8LrsSuuVxNPX/86HtmfbmRlAQn004fyQWHDyQmRmd4VUq10uQQKXasho/vgTVzwdMfTvotHHoJxMR2yeVWFZZx19vLWbixmEMHpnL/uWMYk5XSJddSSkUfTQ6RZtOX8OGdUJAHfQ+EU6fDiB9DF6zdYIzhzcUF/N/cVRRV1jHlqMH85rRcUhKdIb+WUiq6aHKIRMbAqjnwn3tg9w8w+FiYcB9kH94llyuttpqa/vHVRlITXUw7fSTnj83WpialejFNDpGssR4WzYRPH4LKnTDqXDjlLkgf2iWXW7m1jDvfXs6iTcWMHZTKvedoU5NSvVVHyaHbh7KKyEQRWSMi60RkWoDjx4vItyLSICLnd3d83S7WCUdeDTcshhOmwdqP4MkjYe4tULEz5JcbNSCZ16/9EY9ccAibiqo4+4n53PX2cnZV1Ib8Wkqp6NWtNQcRiQW+ByYA+cBC4KfGmJU+5+QAycBvgDnGmNl7Kzeqaw7+yrfDpw/ColngTLRGNv3of8GVFPJLlVbX89iHa3jh6024HDFcfORgrjn+ALwp8SG/llIq8kRSzeFIYJ0xZr0xpg54BTjH9wRjzEZjzHdAUzfHFhk8/aw5mq77Bg44Af57P/x5rNX0FOIJ/VISnNxzzhj+c/MJnHXwAGZ9tZHj//Bf7nhrGfnFVSG9llIqunR3csgCtvhs59v79pmIXCMieSKSt3Nn6Jtfwi5jOFz0ElzxAZV2hiwAABhkSURBVKQNhnduhKeOgbwZIV+3+oC+bh654BDm/eZEzjs8m1cXbuHEh+dx6+ylbNxVGdJrKaWiQ3c3K50PTDTGXGVvXwocZYy5PsC5M4F3e12zUiDGwOr34JP7YOdqkBjIGQ+jzoGRk6zaRggVllbz9KfreXnBZuobmzj7kAFcf/IwhmV6QnodpVR4RcxoJRH5ETDdGPNje/t2AGPMAwHOnYkmhz0ZA9uXw8q3YcVbULQWEGsY7Khz4MBJkNw/ZJfbUV7Ds59v4IWvNlHT0MjpY7xcf9JwRg1IDtk1lFLhE0nJwYHVIX0KUIDVIX2xMWZFgHNnosmhfcZYtYgVb1nJYucqQGDgUVaiGHU2pGSH5FK7K+t4bv56Zn25iYraBk49sB+/PHkYhwxMDUn5SqnwiJjkYAdzBvAnIBZ43hjzexG5F8gzxswRkSOAN4E0oAbYZowZ3VGZvTI5+Nu5xkoSK9+2ahcA2UfYNYqzrX6LTiqtqmfmlxt5/osNlFbXc/yIvvzy5GEckdOn02UrpbpfRCWHrqDJwc+udbDKbnra9p21b8BYu0ZxDvQZ0qniK2obeOGrTTz7+XpKKqv58WD4+WFJHJRciZRvg/JC69FYDwMOg+xx0P8QcCaE4IdTSoWKJofebPd6WDnHqlFstRce8h4Mo8+17sZu705sY6C6GMq3QflWa2bZ5tfl26BsK6asECp3IOz5N2RiHIjba80VVWoPTotxQL8xVm0mexxkjbOu3QXzSSmlgqPJQVmKN1nzOa18G/IXWvv6jYHhp0FjnfVtv6ywNQE01LQtI6GPNaNscn/r2dOf+iQvn2938sLyWpaVJTFgQDbXnTKCCQf2I6ZqJ+TnWdcryLNWxqursMtKs9bezj7CShZZYyFRm6hUD9RQB6YJHHER9YVIk4Nqq2QLrHrHShRbvgZHvP2hPwA8Xr/XA6xk4PaCs/27p+samnhzcT5/nfcDm4qqOCAjiRNzMxk/PJ0jh6TjjnNAU6PVP9KcLPLzYMcqaK59pA+zk4WdNPqNtqYYUaquEravgMKl1mP3BkhMa/379Pg8kvtDXDcNvTYGqoqsWnJpfuBHxXbAWDVoVxK4PBDntl+7rVhd9nac2zre8tp+tLxOaj3fmdCpZKPJQXWsviak32gaGpt457utzF6Uz8KNxdQ1NOGIEQ4blMoxQzMYPzyDQwem4oy178GsKYOti1uTRf5CaxJCAEcCDDi0NVlkj4PkrIj69qW6QHUJbFvWmggKl1pDt409cUJiuvVForrEqvHWlrUtw+W2k4XX/qLTv02tF3c/a2nfjtRVQVlBgA99OxmUFbStZTvirdGCKdmQnA0pWRDrshJcXQXUVljPLa8roa7ceq6tgMYg5zqTGDjzURh3RXDn+79dk4MKl5r6RhZtKmb+ul18uW4X3xWUYgwkuWI56oB0jhmazvjhGeT28yDNH/jGQMlmu3axyHouXGo1fYE151R8CsSn2s8pkODzuqP9cckQo0unR5SKnXYCWGINoChcCsUbW48nZ1n9ZP0PaX0kD9jzC0Jthd0nVtj6KAvwuqm+7fWT+rbWkD1e64O9rKD1w7+qyO8NYp2Xkm3FlpINKQNbk0FKtpW8OvMFprHeL4lUQm25T3LxeT3i9P2e6l+Tg4oYJVV1fL2+yE4WRay3p+fIcMdx7LB0jh2awbHDM8hK9RvZ1FAL25ZbtYuSzVBTaj9KWl9X26/p6G9arAQRnwIJvokkyETjTAxvraWpEeqrrAQa54muGpQx1odtcwIoXAqF31l9XM3ShvgkgYPBewi4+4bu+lVFbROH/3ZDrc+HfrbPh7+9zzNg77WNKKHJQUWsgpJqvrBrFfPXFbVMHT4kI6klWfxoaDqpiUH+Z2xqsr5NBUoa7SUT3/3NneXtiXG0TRrtJpRUq524oRbqq60P9ZbnqgD7qq1HXWXra//jvs0NEmtdNyGt9RHvt+1/PCHNiq0z/ThNTVY8dZVQX2l/g/V7+O6vLbf6lQqXQvVuO/YYyMhtTQL9DwHvQVZsqttoclBRwRjD99srWpqgvl5fRGVdIyJwUFYKxw7L4NihGRw+OI0EV9esu01jg18S2ZckU9La9BUsR7zVqehMtJ99Xyf6vfZ5FrGuW11sXbe6eM9HTWnH13V5/JKH/SwxAT7oq1qbNuqqrA/+feFMgoxhrTUC7yHWQANX4r6Vo0JOk4OKSvWNTSzdUtLSBPXt5mIamgyxMcKwvm7GZKUwJiuZg7JSGDUgmUSXI9whW9/ufZNGXbnVqR7oA96ZADFdlOSaGu0YiluTSEviCJBMmh/GtI6gcSW2vnY2v/Z/+B4L8B5novbxRDBNDqpHqKxtYMGG3SzeXMyyglKWFZS1NEOJwNC+bg7KSrGSxoBkRmelWMNnlVIBdZQc9H+OihpJcQ5OGpnJSSMzW/ZtL6thWX4py7eWsryglC9/2MWbiwsAK2EMyUhizICUlqQxOiuZ5Hi9b0KpvdHkoKJav+R4+o2K59RRrWta7CivYUVBGcsKrISRt3E3c5a2jojJSU9kTFaKTy0jhZRETRhK+dLkoHqcTE88mSPj96hhFFXUsnxrGcsLSlmWX8qSLSW8+11hy/FBfRLJ9XoYnulmeD83wzM9HNA3KTL6MZQKA/3LV71CujuOE0b05YQRrWPmiyvrWLHVrmFsLWXt9nLmrdlBfWNrP1x2WoKdMDwMy3QzPNPNsEw3Hm2aUj2cJgfVa6UluRg/3JrOo1l9YxObiqpYt6OctdsrWLvDenzxQxF1DU0t5/VPiWeYnSiGZ3rs2oY7+PsxlIpwmhyU8uGMjWn50J84pnV/Y5Nhy+4q1u1oThjlrNtRwasLt1BV19hyXoY7jmGZSS0JY1imm9H9tU9DRR9NDkoFITZGyMlIIicjaY/O76Ymw9bSatbuqGDd9tak8dbiAsprG1rOy0pNYPSAZEYPSLGes5LxJse3zielVITR5KBUJ8TECNlpiWSnJXJSbmsHuDGGHeW1rNlWzoqtZazYWsrKrWV8tGo7zbcW9UlyMXpAMqN8ksaQ9CRiYjRhqPDT5KBUFxARa5htcjzH+3SCV9Y2sKqwrCVhrNhaxvPzN7R0gie5Yjmwf3JLLWPUgGRG9PPgcuhdxqp76R3SSoVZXUMTa3dYNYyVPrWMSrsvwxkrDM/02AnDuvN7eKablASnNkupTtE7pJWKYC5HjN2s1DojaVOTYWNRpV3DsBLGJ6t38Pqi/JZzHDFCaqKLPklO6znRRVqStZ2W6CIt0UWfJHtfoou0JCfuOIcmFBUUTQ5KRaCYGOGAvm4O6Otm0iEDAKsfY3tZLSu2lrJhVyXFVXXsrqynuLKO3VV1rN9Vwe5N9RRX1dHYFLhFwBkrPonESZ8k1x6JJcPtoq87jr6eODI98SQnaDLprTQ5KBUlRARvSjzelPbX8QYriZTVNFBcWUdxVd0eSaR1u47iynq+315BSVUdxVX1AROKKzaGvp44MjxxLUnDShytr5v3xzu7aIZZFRaaHJTqYUSElAQnKQlOckgK6j1NTYaymnqKKuvYUVbLzopadpa3PnaU15BfXMWSLcUUVdYRqKvSE+9oSRaZyfF7JJMMt4sMdxwZ7jj6JLm0gz0KaHJQShFj91+kJroY2tfd4bkNjU3srqxjh0/yaE4mO8pr2Fley7L8EnaW17Z0qvtLSXCS3pIwrOf0pDgyPC7Sk+Loaz9neOJIcsVq01YYaHJQSu0TR2wMmcnxZCZ33LwF1tDdneW1FFXWsrO8jqLKWnY1P1fUsquijtXbyimqKKK0uj5gGXGOmD2TSMtzHGmJTlITnaQkuEhNdJJq15gcsVoz6SxNDkqpLpMU5yApzkFOxt6bt+oarBqJlTSsxFFkvy6qqGNnRS2FpTUsKyilqLL9TncAT5yDFDtxpCa4rNcJgbbtpJJoJZU4h/abNNPkoJSKCC5HTFAd7tDaR1JSVU9JdT0lVXWUVtvbVfWUVNdR6nNsa2m1fayODnIKia5Y3HEOXI4Y6xEbQ5z9Os4R27Kv5bjfOb7HWs6397vjHC19QSkJTjzxjoi+G16Tg1Iq6vj2keyLpiZDRV2DlTjsJNKcYEqrrNflNQ3UNTZR19BEbUOT/bqRqroGSqqt/S2PxiZq65uotc/fFyKQHG8liuaaS7KdOFJ9kkhqYuv+FLu20x39MJoclFK9RkyMkBzvJDneycA+oS3bGEN9o2lJLK0JpJGa+iYqaxsora5v91FSVU9BcXXLdkMHVRxHjJBsJ5FfTRjB2fa9MKGkyUEppUJARHA5xBqmG9e5sowxVNY1WonCruGU+SWS5tdpXTQdvCYHpZSKMCKCO86BO85BVmpCWGLQ8V5KKaXa0OSglFKqDU0OSiml2uj25CAiE0VkjYisE5FpAY7Hicir9vFvRCSnu2NUSqnerluTg4jEAk8CpwOjgJ+KyCi/064Eio0xw4A/Ag91Z4xKKaW6v+ZwJLDOGLPeGFMHvAKc43fOOcAs+/Vs4BTRWbeUUqpbdXdyyAK2+Gzn2/sCnmOMaQBKgXT/gkTkGhHJE5G8nTt3dlG4SinVO0Vth7Qx5u/GmHHGmHF9+/bd+xuUUkoFrbtvgisABvpsZ9v7Ap2TLyIOIAUo6qjQRYsW7RKRTaEMNAQygF3hDmIfRFO8GmvXiaZ4oylWiMx4B7d3oLuTw0JguIgMwUoCFwEX+50zB7gM+Ao4H/jEmEDrTrUyxkRc1UFE8owx48IdR7CiKV6NtetEU7zRFCtEX7zdmhyMMQ0icj3wARALPG+MWSEi9wJ5xpg5wHPACyKyDtiNlUCUUkp1o26fW8kYMxeY67fvLp/XNcAF3R2XUkqpVlHbIR0F/h7uAPZRNMWrsXadaIo3mmKFKItX9tKcr5RSqhfSmoNSSqk2NDkopZRqQ5NDiInIQBH5r4isFJEVInJjuGPaGxGJFZHFIvJuuGPZGxFJFZHZIrJaRFaJyI/CHVN7ROQm+29guYi8LCLx4Y7Jl4g8LyI7RGS5z74+IvKRiKy1n9PCGWOzdmJ92P47+E5E3hSR1HDG6CtQvD7Hfi0iRkQywhFbsDQ5hF4D8GtjzCjgaOC6AJMLRpobgVXhDiJIjwPvG2NGAocQoXGLSBZwAzDOGDMGa+h2pA3LnglM9Ns3DfjYGDMc+NjejgQzaRvrR8AYY8zBwPfA7d0dVAdm0jZeRGQgcBqwubsD2leaHELMGFNojPnWfl2O9eHlP39UxBCRbOBM4Nlwx7I3IpICHI91LwzGmDpjTEl4o+qQA0iw7/RPBLaGOZ49GGM+w7qXyJfvxJezgHO7Nah2BIrVGPOhPf8awNdYMy5EhHZ+t2DNNH0rEPEjgTQ5dCF7LYrDgG/CG0mH/oT1x9oU7kCCMATYCcywm8GeFZGkcAcViDGmAHgE6xtiIVBqjPkwvFEFpZ8xptB+vQ3oF85g9sEVwL/DHURHROQcoMAYszTcsQRDk0MXERE38C/gV8aYsnDHE4iInAXsMMYsCncsQXIAY4GnjDGHAZVETrPHHuy2+nOwEtoAIElEpoQ3qn1jT1sT8d9wReR3WM25L4U7lvaISCLwW+CuvZ0bKTQ5dAERcWIlhpeMMW+EO54OHAucLSIbsdbWOFlEXgxvSB3KB/KNMc01sdlYySISnQpsMMbsNMbUA28Ax4Q5pmBsF5H+APbzjjDH0yERmQqcBVyytznYwmwo1heFpfb/t2zgWxHxhjWqDmhyCDF7YaLngFXGmMfCHU9HjDG3G2OyjTE5WJ2lnxhjIvbbrTFmG7BFRHLtXacAK8MYUkc2A0eLSKL9N3EKEdp57qd54kvs57fDGEuHRGQiVpPo2caYqnDH0xFjzDJjTKYxJsf+/5YPjLX/piOSJofQOxa4FOtb+BL7cUa4g+pBfgm8JCLfAYcC/xfmeAKyazezgW+BZVj/1yJq+gQReRlr9uNcEckXkSuBB4EJIrIWq/bzYDhjbNZOrE8AHuAj+//Z38IapI924o0qOn2GUkqpNrTmoJRSqg1NDkoppdrQ5KCUUqoNTQ5KKaXa0OSglFKqDU0OqlNEZKo9w2SJ/wyeIuKwj00PQ1zT7Wt3+1K4+0JEYkTkTyJSKCJNIvJWuGPaVz5/A8PCHYsKHU0OKlRSgNvCHUQUOh9rVtyHse6RuTW84Shl0eSgQuVD4JciEi0TtXWaiMSFoJgD7ec/GWO+MsZ8H4Iyleo0TQ4qVO63n+/o6KTm5p4A+2fac840b+fYTRU/F5EHRGSbiJSLyIv2lBTDROQDEakQkXUicpl/mbYD7cWXquymm3tFZI+/exHpKyJ/E5ECEam1F5C5xu+c5qaT40XkdREpYS+z7YrIRBH5SkSqRaRURN7ymfoD++edbm822uVP7aA8h4jcbsdXKyJbReRR8VlEyOf39r8i8pi94EyViLxrzxLsW55TRO4XkY0iUmc/32/PDeZ7XpKIPCgiP9jX3SYi/wrwRSBDRF4SkTI7tj/7xeYQkfvscmpEZJeIzBeR8R39HlV4RHR7rIoqhVjTGfxKRB4xxmwKUbm3A/Ow5vkZBfwBa3rxw4BnsKbF/gXWNN55xpgVfu9/C3geeAD4MXCn/f7pACKSDMwHEux9G+zznhKROGPMX/zKewl4Gas5qN3/P/a8P+8BnwAXAm7gXmC+iBxqT+n9P1gLAk0Fmle0+6GD38WLwCTgIeBLrFrHfUAOcJ7fubcDS4DLgUysaUY+FJHR9kSAYK3X8BP72HysiQF/BxwAXGz/HC6sRXUOwZpK42usJsQfA2nAdp9rvmD/bibbP890oBi42z5+G3CTfY0lQDIwDujTwc+swsUYow997PcD64PNAMOw/pOXAM/bxxz2sek+50/Hng3ar5yZwEaf7Rz7vZ/4nfeGvX+Kz740rCmb7/a/DjDN7/3PAOVAqr19J1ADDA9w3i7A4fdz/jHI30sesLb5/fa+IUA98JjPvvsD/T4ClHecff2f+e2/xN5/qN/vbSUQ43Pesfb+K+3tMf7/Nvb+O+z9B9vbV9jbZwfxN3CP3/53ge/9tt8I99+sPoJ7aLOSChljzG7gUeBnvs0nneS/gMtq+/kDn+sWY00tPTDA+1/z234F61v8GHt7Ilbz0Aa72cNhj3D6AEjHqq34enNvAYu1ANFY4FXTulIZxpgNwBfACXsrI4CJQB0w2y/O5gWEjvc7f7YxpmUBJ2PMF1gzgf7I73z/Kdqbt5tjPA3YZoyZE0SM7/ltLwMG+WwvBM4Qkd+LyHi7VqIilCYHFWp/xFoe8d4QlVfst13Xwf542treznbz0q2ZWB+U9X6P1+3j6X7vL2Tv0gBp59xt7F8zSibgwlrgyDfO5vUW/OP0/7mb9zX/3M0x+Me4ze94OlAQZIz+y2LWAr6d9v+H1cR0NvA5UCQiM0QkI8jyVTfSPgcVUsaYChF5AKsG8XCAU2rAass2xtT57Pf/cAuVfsB6v21o/cArwvqAvbGd96/x2w5mGuNi+7xAC7l4Cby28N4UYf3ujmvnuP/61IFGjfXDauvHJwYve/ZzeP2O76K1ltUpxurreAh4SKxFbs4CHsNaX/vCUFxDhY7WHFRX+CvWh+/9AY41d1S3fOCISCpdt0raT/y2LwIqsJo8AN4HRgKbjTF5AR7l+3pBY0wlsAi4QERim/eLyGCsn3Pefvwc72PVjFLaidM/OZzvOypLRI7FWn3sK3vXZ/bzRX7vu8R+bo7xQ8ArIpP2I+Z2GWO2GWOeBf5DiJKPCi2tOaiQM8bUisi9BF7c5t9AKfCMiNyN1exwK9YHdle42v6QXIg1wuYqrE7YUvv4H7G+tX4uIn/EqikkYSWM44wx5+znde/EaoN/V0T+itXPcQ/Wz/7ovhZmjJkn1gIys0XkMWAB1qirHOAM4Daz5z0SHuAtEXka6Is1Wmst8A+7vOV2edPtvosvsfoj7gReNsY0J88XgauBl+0a4Td22T/GujdjNUESkbeBpVgLIBVjjTibCDy9j78O1Q00OaiuMgO4BRjuu9MYUyIiZ2F9KL+G1Ul6L9aqYyd2QRznAH/B+tArxarN3OcTT6mIHIO18PttWG3yJVhJ4l/7e1FjzPsiciZWG/trWH0i84BbA3zLD9YUrJXwrsAaDloLbMTqPPfvY3gAawTZTKxk91/getM6jBWsUUbr7fLuwGqaeggriTX/HPUicpr9c1xjPxdhdazva/PYZ8AFwHVYTUmbsYYm/34fy1HdQFeCU6oHsW902wBcbTfbKLVftM9BKaVUG5oclFJKtaHNSkoppdrQmoNSSqk2NDkopZRqQ5ODUkqpNjQ5KKWUakOTg1JKqTb+HzJeOduzniFyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(len(train_loss_log))+1\n",
    "plt.plot(epochs, train_loss_log, label = 'train (dropout)')\n",
    "plt.plot(epochs, val_loss_log, label = 'test')\n",
    "plt.xlabel('Number of epochs', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.legend(fontsize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_architecture = {'out_size':10, 'n_epochs':best_params['n_epochs'],'h_sizes':best_params['h_sizes'], \n",
    "                      'dropout':best_params['dropout'], 'act':best_params['act']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model_architecture', model_architecture)\n",
    "torch.save(best_net.state_dict(), 'params.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model (just for check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architecture = np.load('model_architecture.npy', allow_pickle=True).item()\n",
    "best_net2 = Net(**architecture)\n",
    "best_net2.load_state_dict(torch.load('params.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy obtained 98.23%\n"
     ]
    }
   ],
   "source": [
    "accuracy, predictions = eval_accuracy(best_net2, x_test,y_test,return_predictions=True)\n",
    "print(\"Accuracy obtained {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and interpretation of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: \n",
      "===========================================================================\n",
      "out_size \t 10\n",
      "n_epochs \t 15\n",
      "loss \t \t CrossEntropyLoss()\n",
      "lr \t \t 0.003996024018867443\n",
      "h_sizes \t [784, 278, 94, 24]\n",
      "penalty \t 0.0014430192249231507\n",
      "dropout \t 0.08787206607182774\n",
      "optimizer \t <class 'torch.optim.adamax.Adamax'>\n",
      "act \t \t <function relu at 0x7f9e78b8c8c0>\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "# let's consider our best model for visualization pourposes\n",
    "print_parameters(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 3 hidden layers, hence 4 matrices of weights W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([278, 784])\n",
      "1 torch.Size([278])\n",
      "2 torch.Size([94, 278])\n",
      "3 torch.Size([94])\n",
      "4 torch.Size([24, 94])\n",
      "5 torch.Size([24])\n",
      "6 torch.Size([10, 24])\n",
      "7 torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for i,p in enumerate(list(best_net.parameters())):\n",
    "    print(i,p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that torch saves both the weigth matrices and the biases in model.parameters(). We now forget about biases for the sake of visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use deepcopy because I noticed that in the following process \n",
    "#I modified the network parameters even if I used detach\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_params = list(best_net.parameters())\n",
    "W01 = copy.deepcopy(net_params[0].detach().numpy())\n",
    "B1 = copy.deepcopy(net_params[1].detach().numpy())\n",
    "W12 = copy.deepcopy(net_params[2].detach().numpy())\n",
    "B2 = copy.deepcopy(net_params[3].detach().numpy())\n",
    "W23 = copy.deepcopy(net_params[4].detach().numpy())\n",
    "B3 = copy.deepcopy(net_params[5].detach().numpy())\n",
    "W34 = copy.deepcopy(net_params[6].detach().numpy())\n",
    "B4 = copy.deepcopy(net_params[7].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_weights(weight_mat, show=True, vrange=None):\n",
    "    if vrange == None:\n",
    "        plt.imshow(weight_mat.T, cmap='RdBu_r')\n",
    "    else:\n",
    "        plt.imshow(weight_mat.T, cmap='RdBu_r', vmin=-vrange, vmax=vrange)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if show:\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "W01_0 = W01[0].reshape(28,28)\n",
    "visualize_weights(W01_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "PF_12 = np.matmul(W12,W01) \n",
    "PF_23 = np.matmul(W23,PF_12) \n",
    "PF_34 = np.matmul(W34,PF_23) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1051.2x432 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "plt.figure(figsize=(14.6,6))\n",
    "#plt.suptitle(\"Perceptive field of the output layer\", size = 22)\n",
    "\n",
    "gs1 = gridspec.GridSpec(2,5)\n",
    "gs1.update(wspace=0, hspace=0)\n",
    "\n",
    "for i in range(10):\n",
    "        ax1 = plt.subplot(gs1[i])\n",
    "        visualize_weights(PF_34[i].reshape(28,28), show=False, vrange=5 )\n",
    "\n",
    "        plt.axis('on')\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to see if multipliying the perceptive field for the correspondent number gives us something meaningful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_digit(image):\n",
    "    \"\"\"\n",
    "    Shows with the correct orientation black digits on white background.\n",
    "    \"\"\"\n",
    "    reshaped_im = image.reshape(28,28)\n",
    "    flipped_im = reshaped_im[:,:].T\n",
    "    negative_im = np.ones((28,28))\n",
    "    negative_im = negative_im - flipped_im\n",
    "    plt.imshow(negative_im, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.argmax(np.tile(labels[100:],(1,10)) == np.tile(np.arange(10),(len(labels[100:]),1)), axis=0)\n",
    "first_digits = images[100:][indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I want to do is to take into account also the activation function of the neurons and their bias. In other words, I propagate the input and set to zero the weights instead of the output of the neurons, when the output should be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1_act.shape:  (278, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# activation of first neuron of the first hidden layer\n",
    "layer1_act = W01*first_digits[0]\n",
    "print(\"layer1_act.shape: \", layer1_act.shape) #278 neurons in the first layer\n",
    "visualize_weights(layer1_act[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W01.shape:  (278, 784)\n",
      "first_digits[0].shape:  (784,)\n",
      "B1.shape:  (278,)\n",
      "mask1.shape:  (278,)\n",
      "W12.shape:  (94, 278)\n"
     ]
    }
   ],
   "source": [
    "# we know that if the sum of all elements + the bias is smaller than 1 with relu we have no activation at all\n",
    "# thus I decided to mask that activation for the following layers\n",
    "print(\"W01.shape: \", W01.shape)\n",
    "print(\"first_digits[0].shape: \", first_digits[0].shape)\n",
    "print(\"B1.shape: \", B1.shape)\n",
    "mask1 = np.matmul(W01,first_digits[0]) + B1 < 0\n",
    "print(\"mask1.shape: \", mask1.shape)\n",
    "print(\"W12.shape: \", W12.shape)\n",
    "W12_biased = copy.deepcopy(W12)\n",
    "W12_biased[:,mask1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W12_biased.shape:  (94, 278)\n",
      "layer1_act.shape:  (278, 784)\n",
      "layer2_act.shape:  (94, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"W12_biased.shape: \", W12_biased.shape)\n",
    "print(\"layer1_act.shape: \", layer1_act.shape)\n",
    "layer2_act = np.matmul(W12_biased,layer1_act)\n",
    "print(\"layer2_act.shape: \", layer2_act.shape)\n",
    "visualize_weights(layer2_act[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask2.shape:  (94,)\n",
      "W23.shape:  (24, 94)\n"
     ]
    }
   ],
   "source": [
    "mask2 = layer2_act.sum(axis=1) + B2 < 0\n",
    "print(\"mask2.shape: \", mask2.shape)\n",
    "print(\"W23.shape: \", W23.shape)\n",
    "W23_biased = copy.deepcopy(W23)\n",
    "W23_biased[:,mask2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASYAAADrCAYAAADExTsEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAR0klEQVR4nO3df5BdZX3H8fdnb7IhGgOB1RgIAYS0JRYGOzFUR1EkaGgZ47QqP0YN/hjHmdJ26rRjbDq0w1/4Y7QzLVgzlJmoo6iZsaRjCg3BVnFA2SJoE4qJFCEhBDeA1RCS7O63f+xNu2zufe69uWf3PvfZz2vmTM653/PrTnY/e85znnOOIgIzs5wM9HoHzMymcjCZWXYcTGaWHQeTmWXHwWRm2XEwmVl25nQy82lDQ7Fs2bLp2hezWe+JJ57gwMiIulnHmZofLzLe1rwjHLkrItZ0s73p0FEwLVu2jHu+e+907YvZrPe2S97U9ToOM857taSteW+Jnw91vcFp0FEwmVn+BNTU5kFXpv2rHUxmBap1dTLYew4ms8J0dMSUKQeTWWEkGBxwMJlZRiaOmHq9F91xMJkVRz6VM7O8iP7vOe1gMiuQj5jMLCuS25jMLDPCV+XMLDPux2RmWfKpnJllZaKNqb+TycFkViAfMZlZVgaQG7/NLD8+YjKzrLiNycyy45t4zSxLPmIys6yUcMTU7zchm9kUEswdGGhraL0urZH0qKTdktY3qH9M0k8kPSTpXkkrqvgODiaz4gjV2huSa5FqwM3AFcAK4JoGwfPViLggIi4CPg18ropv4FM5s9IIBqo5l1sF7I6IxwAk3Q6sBXYemyEi/mfS/C+noveuOJjMCiNAtUpOhs4Anpw0vQe4+LjtSX8EfBwYBN5WxYZ9KmdWGtHJqdyQpOFJw0c73VxE3BwR5wKfAP6qiq/gIyaz0kidnMqNRMTKJrW9wJmTppfWP2vmduAL7W44xcFkVhgJanNrVazqAWC5pHOYCKSrgWtfui0tj4hd9cnfB3ZRAQeTWYFaXXFrR0SMSroeuAuoAbdFxA5JNwLDEbEFuF7SauAo8BywrusN42CyFlKNkCf9cHNy2W9ddVOy/gd33JisH7zw95J1a0KqqvGbiNgKbJ3y2Q2Txv+0kg1N4WAyK4yorLtAzziYzEojkJ/HZGZZkagNVtL43TMOJrPCSNU0fveSg8msQAMVNX73ioPJrDRqfYNu7hxMZoURMODGb+tn8wdO/GbwsV89l6xf+fmrTnjdAGPjzfet1ue/eNNKld3E2zMOJrPSSNQGHUxmlhH5iMnMcuSe32aWF/f8NrPcCLkfk5llxj2/zSw7EgNz+/tXu7/33rr27OF0P6ahR+5sWvvp1+5KLjt3fvrH69yzz0/Wj4w137f5fd6GMp0k35JiZtmp7kFxveJgMiuN+zGZWX6E2nj9d84cTGaFkcTA4Nxe70ZX+jtWzex4goGBgbaGlquS1kh6VNJuSesb1D8uaaekH0vaLumsKr6Cg8msQKoNtDUk1yHVgJuBK4AVwDWSVkyZ7UfAyoi4ENgMfLqK/fepXOE27/xFsv6hk/ck62PLVzWtzT/tG8lll/3hlcn66C9SL3WFuX3eSbBnqnt90ypgd0Q8NrFa3Q6sBXYemyEivjNp/vuB91WxYQeTWWEEVTV+nwE8OWl6D3BxYv4PA/9SxYYdTGal6eyIaUjS8KTpjRGxsfNN6n3ASuAtnS7biIPJrDSC2mDbv9ojEbGySW0vcOak6aX1z166uYlXhG8A3hIRhzvZ1WYcTGaFkSrrx/QAsFzSOUwE0tXAtVO29Trgi8CaiHimio2Cg8msSFU0fkfEqKTrgbuAGnBbROyQdCMwHBFbgM8AC4BvSgJ4IiLe2e22HUxmpanuqhwRsRXYOuWzGyaNr65kQ1M4mMwK5FtSrKdSjwYBeN/+f06vYCh19Re+//b3NK294fv3JJfVj/81Wd927aeS9Ys++HDT2sINtySXnc0kMVCr9Xo3uuJgMiuNYKD9q3JZ6u+9N7MG/HQBM8uM3ytnZvmp8KpcrziYzArkUzkzy4uE5gz2ei+64mAyK47AR0w2ncbG0/2Unn9xLFk//MbrkvU5LX5+z/9O875Kh8bTz0savHBNsv7dkY8n6wvvfKRp7aINyUVnN4Hcj8nM8iIYcDCZWU6Eg8nM8iJ3sDSz7Ejgq3JmlhsfMZlZXuTGbzPLjoPJptkjI4eS9dNfMS9ZX1xLL38g5ifr8+ac+LvdBp9/Mln/6N7mz1sCOGfOr5vWDp7QHs0S7sdkZvlxz28zy43vlTOzLPX5EVN/772ZHU9CA7W2htar0hpJj0raLWl9g/olkh6UNCrp3VV9BQeTWXHqV+XaGVJrkWrAzcAVwArgGkkrpsz2BHAd8NUqv4FP5cxKI6o6lVsF7I6IxwAk3Q6sBXYemyEiHq/XxqvY4DEOJrPCSEJz2278HpI0PGl6Y0RsrI+fAUzu87EHSL/vqyIOpgy8cLT5H5ttu0aSy56/eEF63a96RbK+dOH0nc1/7+CiZP3kk9LPknp6zsKmtfS3mu066mA5EhErp3NvToSDyaxAFd0rtxc4c9L00vpn087BZFaa6u6VewBYLukcJgLpauDaKlbciq/KmZVIA+0NCRExClwP3AU8AnwjInZIulHSOwEkvV7SHuA9wBcl7ahi933EZFYctQyddkXEVmDrlM9umDT+ABOneJVyMJmVRhAD/f2r3d97b2YNaKKdqY85mGbAoUR3AICH9zd/iMd3d+xPLjuvxfuXLljcuwvrr1qQ7kvzG3N+mazvOJToLjCvv29SnXZ9fq+cg8msMAFERW1MveJgMiuNqmv87hUHk1lxBG78NrPc+FTOzPLjYDKzrMjdBcwsRz5islYWP/1gsv6ORG31B85NLjtSOyVZnz+3dz+g57V4pEqMp/tYLerzd6P1ktuYzCwvEtT6+1e7v/fezBpwPyYzy5GDycxy4zYmM8uLb0kxsyy5H5OZ5UV+UJzBwr0/StYP7/xhsv78Iz9rWhv8k88ml50/0Lu/jKPjkZ6hxbOidCj9PKbTE79cBzk1ve3ZzqdyZpaTkIg+P5Xr71g1s+MFRJtDK5LWSHpU0m5J6xvU50n6er3+A0lnV/EVHExmxQnGo70hRVINuBm4AlgBXCNpxZTZPgw8FxHnAZ8HPlXFN3AwmRUmgLFob2hhFbA7Ih6LiCPA7cDaKfOsBTbVxzcDl0ndn0c6mMwKFBFtDS2cATw5aXpP/bOG89RfkPlL4LRu99+N32aFCaDVBdNJhiQNT5reGBEbK9+pDjmYzArUfi4xEhErm9T2AmdOml5a/6zRPHskzQFOBg60v/nGHExtGGzRV+je9/95sn7xjR9M1hf82eea1sbauXTSI78+kn5f3slHf5WsH12wOFk/nGgE6e+L4dMsOjpiSnkAWC7pHCYC6Grg2inzbAHWAfcB7wbuiTbOEVtxMJkVqIJsICJGJV0P3AXUgNsiYoekG4HhiNgC/CPwZUm7gWeZCK+uOZjMCnPsqlwl64rYCmyd8tkNk8ZfBN5Tzdb+n4PJrEAVncr1jIPJrDATvbr7O5kcTGYFSl+WyJ+DyaxAfX7A5GAyK81EB8v+TiYHUxvm3P/NZP1N37glWb/78OnJ+qqMf4hSu/ayFu+s++kLL0/Wd+55Nlm//NxFybo1V9VVuV5xMJkVKOO/dW1xMJkVJgjGO7kpJUMOJrPStPkQuJw5mMwK5A6WZpaViVtS+juZHExmBerzXHIwAdRaPQl0ztxkeezpx5P1N1zwW+nlM/4pWnDomaa18VekH1ty/54XkvVLzznlhPbJ0tyPyczyEzDW5/ekOJjMCuMjJjPLUGTdPNAOB5NZYSLgaJ/fk+JgMiuMT+XMLEs+lTOzrHT4XrksOZiA+Tu3Jet//JZPJusfevtrkvXzNr8jWe/+hcon7tDR9HXlrXub/4hcctZYctlLz073U+r3v+rZChibgWSSdCrwdeBs4HHgvRHxXIP57gR+F7g3Iq5sZ91+RbhZYYJgPNoburQe2B4Ry4Ht9elGPgO8v5MVO5jMChPA0fFoa+jSWmBTfXwT8K6G+xOxHUi//XQKn8qZlWaGTuWAxRGxrz7+NJC+R6kDDiazwnTYXWBI0vCk6Y0RsfHYhKS7gVc3WG7DS7YZEZIqS0MHk1mBOuhfORIRK5sVI2J1s5qk/ZKWRMQ+SUuA5nd8d8htTGaFOXbENAON31uAdfXxdcAd3a7wGAeTWWEigqNj7Q1dugm4XNIuYHV9GkkrJd16bCZJ3wO+CVwmaY+kdP8ZZtGpXOqPw9iKS5PL/s4pJyXr573r9cl6L/sptfrL818jh5L1/3jiuG4p/2ftb56WXPa5F9P9nBYM+u/idJmJW1Ii4gBwWYPPh4GPTJp+c6frnjXBZDZb+NG6ZpafgPE+vyfFwWRWmIkjpl7vRXccTGYF8mNPzCwrEcGRPn/ot4PJrDDBjN2SMm0cTGaFiZm7V27azJpgOjTa/NB2wdEDyWWv23V3sh5z5iXr6berdafVO/G+8/jzyfqp89PvzPv7v/l809qVKz6VXPZ1S16erNv0cTCZWVaCcDCZWV4i4EjiDKEfOJjMCuM2JjPLkoPJzLLiNiYzy04EjDqY+sOCuc0fsfGsXplc9pQffi1ZP/TGa09on9oxdyDdHWDe808m6w89lf4Bfc1pL0vW/+4fbmhac3eAfPmIycyyEoFvSTGzvLiNycyy4+4CZpYlB5OZZWXi6QL93cbkp8GblSYm2pjaGboh6VRJ2yTtqv+7qME8F0m6T9IOST+WdFU763YwmRVmPODw6HhbQ5fWA9sjYjmwvT491QvAByLitcAa4G8lndJqxbPmVG5Ooj/QI5emX9909tuWJ+tLF70qWT/61H8n6/MueGPT2o6//OvksqMvjibrn7ztS8n6wcGFybr1nxl8UNxa4K318U3AvwGfeMm+RPx00vhTkp4BXgkkn8cza4LJbNaYuatyiyNiX338aWBxamZJq4BB4GetVuxgMitMh/2YhiQNT5reGBEbj01Iuht4dYPlNrxkmxEhqelGJS0Bvgysi4iW55AOJrMCdRBMIxGxslkxIlY3q0naL2lJROyrB88zTeZbCHwb2BAR97ezU278NitMBIyOjrc1dGkLsK4+vg64Y+oMkgaBbwFfiojN7a7YwWRWmKi/ibedoUs3AZdL2gWsrk8jaaWkW+vzvBe4BLhO0kP14aJWK/apnFlxgpiBF15GxAHgsgafDwMfqY9/BfhKp+t2MJkVKHxLSn84kviPevMdtzatAdx31ceS9f0Pfy5ZP/jMwWT9rLfel6ynvHZTi2dF1eaf8LqtT9VP5frZrAkms9kigNYX5PPmYDIrTcCYHxRnZnkJtzGZWV4mTuUcTGaWk4DxGeguMJ0cTGYF8hGTmWXHwVSAX516brL+29u2zdCeHO+0FvUXZmQvrJ9EhK/KmVl+3I/JzLIS7vltZjlyG5OZ5SUcTGaWmcCN32aWGx8xmVmO3PhtZtmZiSdYTicHk1lhIvx0ATPLkE/lzCwvEYyPHun1XnTFr28yK0wQxPhYW0M3JJ0qaZukXfV/FzWY5yxJD9Zf27RDUvoB+nUOJrPSBMTYWFtDl9YD2yNiObC9Pj3VPuANEXERcDGwXtLprVbsYDIrzswcMQFrgU318U3Au47bk4gjEXG4PjmPNjPHbUxmpYnoJHSGJA1Pmt4YERvbXHZxROyrjz8NLG40k6QzgW8D5wF/ERFPtVqxg8msQB0E00hErGxWlHQ38OoGpQ0v2V5ESGp4KTAingQurJ/C/ZOkzRGxP7VTDiazwkSFV+UiYnWzmqT9kpZExD5JS4BnWqzrKUn/CbwZ2Jya121MZsUJxsfH2hq6tAVYVx9fB9wxdQZJSyXNr48vAt4EPNpqxQ4ms9LEjDV+3wRcLmkXsLo+jaSVkm6tz3M+8ANJDwP/Dnw2In7SasU+lTMrzMR75boOndbbiTgAXNbg82HgI/XxbcCFna7bwWRWmogq+ij1lIPJrDQF3JLiYDIrTkf9mLLkYDIrzEQbkx+ta2Y56aznd5YcTGYFcjCZWV4iqug82VMOJrPCRATjR31Vzsyy4jYmM8tQvweTOnnNi6RfAD+fvt0xm/XOiohXdrMCSXcCQ23OPhIRa7rZ3nToKJjMzGaCny5gZtlxMJlZdhxMZpYdB5OZZcfBZGbZcTCZWXYcTGaWHQeTmWXHwWRm2flfeOrOYiO4G70AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer3_act = np.matmul(W23_biased,layer2_act)\n",
    "visualize_weights(layer3_act[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask3.shape:  (24,)\n",
      "W34.shape:  (10, 24)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask3 = layer3_act.sum(axis=1) + B3 < 0\n",
    "print(\"mask3.shape: \", mask3.shape)\n",
    "print(\"W34.shape: \", W34.shape)\n",
    "W34_biased = copy.deepcopy(W34)\n",
    "W34_biased[:,mask3] = 0\n",
    "layer4_act = np.matmul(W34_biased,layer3_act)\n",
    "visualize_weights(layer4_act[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_layer_act(input_im, net_params):\n",
    "    W01 = copy.deepcopy(net_params[0].detach().numpy())\n",
    "    B1 = copy.deepcopy(net_params[1].detach().numpy())\n",
    "    W12 = copy.deepcopy(net_params[2].detach().numpy())\n",
    "    B2 = copy.deepcopy(net_params[3].detach().numpy())\n",
    "    W23 = copy.deepcopy(net_params[4].detach().numpy())\n",
    "    B3 = copy.deepcopy(net_params[5].detach().numpy())\n",
    "    W34 = copy.deepcopy(net_params[6].detach().numpy())\n",
    "    B4 = copy.deepcopy(net_params[7].detach().numpy())\n",
    "    \n",
    "    layer1_act = W01*input_im\n",
    "    mask1 = np.matmul(W01,input_im) + B1 < 0\n",
    "    W12_biased = copy.deepcopy(W12)\n",
    "    W12_biased[:,mask1] = 0\n",
    "    layer2_act = np.matmul(W12_biased,layer1_act)\n",
    "    mask2 = layer2_act.sum(axis=1) + B2 < 0\n",
    "    W23_biased = copy.deepcopy(W23)\n",
    "    W23_biased[:,mask2] = 0\n",
    "    layer3_act = np.matmul(W23_biased,layer2_act)\n",
    "    mask3 = layer3_act.sum(axis=1) + B3 < 0\n",
    "    W34_biased = copy.deepcopy(W34)\n",
    "    W34_biased[:,mask3] = 0\n",
    "    layer4_act = np.matmul(W34_biased,layer3_act)\n",
    "    return layer4_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_i  = out_layer_act(first_digits[0], net_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_weights(activation_i[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 928.8x928.8 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "plt.figure(figsize=(12.9,12.9))\n",
    "#plt.suptitle(\"Activation of the perceptive field\", size = 24, y=0.92)\n",
    "\n",
    "gs1 = gridspec.GridSpec(10,10)\n",
    "gs1.update(wspace=0, hspace=0)\n",
    "\n",
    "for i in range(10):\n",
    "    activation_i = out_layer_act(first_digits[i], net_params)\n",
    "    for j in range(10):\n",
    "        ax1 = plt.subplot(gs1[10*(i)+j])\n",
    "        activation_ij = activation_i[j]\n",
    "        visualize_weights(activation_ij.reshape(28,28), show=False, vrange=0.6)\n",
    "\n",
    "        plt.axis('on')\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dream_image(neuron, iterations=1000, lr=0.01):\n",
    "    input_image = np.random.rand(784).astype('float32')\n",
    "    input_im = torch.tensor(input_image, requires_grad=True).view(1,-1)\n",
    "\n",
    "\n",
    "    for i in range(iterations):\n",
    "        if i != 0:\n",
    "            input_im = updated_im.detach()\n",
    "        input_im = Variable(input_im, requires_grad=True)\n",
    "        out = best_net.forward(input_im)\n",
    "        objective = out[0,neuron]\n",
    "        objective.backward()\n",
    "        updated_im = input_im + lr*input_im.grad #gradient ascent\n",
    "        updated_im = F.softmax(updated_im) #keep it between 0 and 1\n",
    "    return updated_im.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAEhCAYAAACQmMFBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3de3hcd33n8c/Psi1fZFuSbfnu+CJfEhIb2wkNCTFumqaQQJsAy6WUPrTbhTQPLSzsbi9swW1ptw2lLN12d+lCEyiUtNuUcF0aAjWQUIc4jm+J47tlW/Jdki3LsmxLZ//4HTXj8Yy+37EndpTf+/U8ehLNfObcz+98dWbm65BlmQAAAFIx7GovAAAAwJVE8QMAAJJC8QMAAJJC8QMAAJJC8QMAAJJC8QMAAJJyRYufEMJ7QwhZwU9XCGFjCOEDIYThV3JZqi2EsCqEsDqEMKzo8Tn5ur73Ci/P4hDC90MIJ/P535MvX8W9DSpZhxDC3hDCQ5eyzGWm96shhB0hhLMhhM5qTfeVIoTwthDCIyGElhBCTwhhWwjhv4UQxl3tZRvqSoxXhT9VPxZLnWf5MvzqZUzznhDCh6uygFVytcbEcvJx8fYK8oxJL6EQwrR8DFsXQugMIRwNIXwvhLCymvO5WgXHv5N0QNL4/P//h6QmSR+7SstTDaskfVzSJyT1Fzx+UNJrJe26wsvz55LmSXq7pE5J2yStk/SdK7wclyyEMF3SX0v6sqRfkXTm6i7Ry9J/krRP0u8qnlPLJK2W9NMhhFuyLOsf5LXwGRivCp1/CeZTaqx4r+I4/TeXOM17JN2hOB68XFytMbGcj0v6I0nft4KMSVfECknvkPSgpLWSRkq6X9KaEMLPZ1n2zWrM5GoVPxuyLNuZ//9jIYRmSR/UZRY/IYQaSSHLspdiYLokWZb1Ku7AK+1aST/Msqyw2OnQxYP4y9kCSTWSvpBl2RNXe2G8Qgi1+X6/Et6cZdnRgt9/EEJol/QFxYLcHNBhKhyvXjJXcayoyOUe30NlPcuo6pgUQhgh6Xz2Mu82HEIIkkZkWXb2CszuCUkLC6/jIYR/lvScpP8iqSrFj7Isu2I/in/FZJKaix5/IH+8qeCx90naqFhZH5P0eUmNRa/LFCv235a0R1KfpGX5c5Ml/U9J+yX15v/9W0m1Ba9fKunrikVBj6QnJd1WNI+HFAuGWyQ9nS/PXkm/UZBZnS/LBT/5c3Py39+b//6fJZ2VNLHE9nle0tcKfh8j6U/zdTub//ejkoYNso1XDbIsqwf+vyA/XNLvSHoh305tkj4laVRB5oJ1KHj8g/m2OKN4V+m2/PeHHMfCIklfVbwr1aM4GL6haLsXr0fZ6Upao3jS3CFpvaTTkrZIurdE1rPf10haU+K1F6yfXjymV0r6v/n6bCh4/pd04XH8t5KmlZjmlyS9U9JWSd359nzdJZ5n1+bL9J4reX6/0n5UZrwqygzLj5W9kiYUPH5Dfmx9sij/H/Ljsyc//n4g6Zb8uQvOs3y6xefAmvy5yZI+K2l7fqzvl/R3kmYUzKvUObS34PlBz8E8szp/3fWS/lnSKUlfU7xbf1jxgliYHyepS9KfDLLNLljPgmUduHP5o3yddki6r8w+WSnp0Xx5jkv6K0mjC3Kr8tyqMq+fk/9+0VgpaXWZ5S61PR/KnxuheNd/r+JYvTf/fUSJ9b5f8ZrXpvguQUOZ+Q2sw89L+kvF8eOY4lhRX5T1jOOubZI/tjefz6/m0zynfCyVNE3SF/Nl6ZW0SdIvlZnmzYp3yU7my/QXhctU4fn495J2Ve38fjkMJooXjfOSxuS//0m+sT8l6U7F24utkp6SVFPwuix//EeS3irpDZKmSGpQPHGOS/qPkn5G0rskPSxpXP7a5YoXmSckvU3SXYoXxF5JK4oO+JOKg8sH8nk8pAsHqZmSPpc/dmu+w28uM6DNUCzS7i/aBivy3FsLDuYf5evwoXwdPqp4Ef3UINt4fD7/I5K+VbQsq3Vx8fNwvh0+plg4/IbiYPiIMVj9+/yxB/Nt8gHFweuEjOJH0nRJRyXtViwO3qz4dlyfpDfmmfn5sgwMFjdLmj/INNco3k5/Lp/mGyR9V/G4ai7Ieff7GlVW/OxXHNDuUH4BUSzgs3wb3yXp1/L9sl1SXdE0WxSL67dJepOkZ/P9UD/YtiyzLe7L53vjlTy/X2k/Bft2UX4+Fv4MK8jNzM/Th/PfR+fH4TpJIwtyf5ZP73P5MX+3pD+U9M5S55mk6xQLpY358X+zpOvy5xZJ+oziuLdSsXB+Oj+WRhWcQ9/Kj7mB1w/8cWieg3ludb5MuxTfWr1d8SJ6Xf7424u22fsVL+hzB9muF6xn/thDiuPs1nwaP6tYzGWSfrrEPtmXb887Jf1XxYKj8LxcJV/xc7NeHMcGttHMMstddkzKl/W8pD/Il2m14jXs70qsd6ti4fYmSb+ggqKtaH4D67BHsdi8M59/j+Kdp8KsZxx3bZP8sb35cm5RvHb+TL7+YxXHr6OK49sbFYubTNL7SkxzR75N7pD0e4rH1+9fwrk4Mt/n36za+X2VB5OG/EDvk/RowQHSJ+ljRa+9NX/tPQWPZYrV5Oii7B+o4C5QmWX5nuKJVjg41eSPPVp0UmbKB6iCx7+reMEKRYPEcMeJ/l1J/1qU+++KfwnW5r+/J3/dyqLcRxVP9KZy65bnDqioCFFR8aN4pyaT9MtFuXfnj7+61Doo/rW7X9J3il73Dhl3aPLcn+nioqRG8XNJ6wseu0MlTtYy01yjONgsKHisKT8OfvcS9vsaVVb8fLooV6P4l/G/FD3+ujz/m0XT7FDBX4CSbsxzv1jhOTZD8WL33Wqcsyn/FOzbUj/fLMremz/+K4qfCekqOhab82PxzweZ3wXnWcFx+IRjWWskzcpff2/B4w9JOlAi7z0HV+fT/GCJaayR9L2ix9YXjwvO9XxIFxc6tYpF5V+X2Cf/u2iaH82378L891XyX+gzSZ9wHhMXjUmKd8UyFd0xUizKMklLitZ7vfLrhjGvgXUoLnT+UvGP4IFrj3ccr2Sb7FW8+za1KPuBMtN4XHHcqSma5u8X5b4pafslnIt/rFhU31bpa8v9XK2vug/cRmtXfGvqy4q316RY8Q+T9OUQwvCBH8W7Pl2Kf+UU+k6WZT1Fj90p6eksy54tNfMQwmhJr1e849RfMI+guBOL59En6ZGixx6WNFvxYlOpL0q6Of+sk/J5v0vSP2Qvvpf+BsXi6sdF2+ExxVusN1/CfIu9QbGQ+scS85Au3g4DZuY//1D0+CPyfRB0paS1WcHnKLIs65P0FUmvDiGMr2AdCu3IsmxHwTSPKJ6Qs6VL2u+V+GrR74sUi68vFz6Yxc8JtOTLUehfsyzrKPh9c/7f2d4FCCHUKb4lcV7xIozquFfSTUU/HyoMZFn2VcW3of6X4ltbv1l4LCpeNIcpFkZVEUL49fzbsqcU9/m+/KlFjpdXeg4WH99SHLt/OoSwIF+emxTftvpsZWvyb05nWfYvBcvTq3iXodQ5UDz2PKy4fV9zifO+HAPjxpeKHh/4vfhcfzTLr+hO3yr6fbNiYTgl//1Sx3HL2izLDhU9tlJSa5Zla4oe/5LiW7HXOZbdPaZJUgjhFxU/2vKHWZb9qJLXDuZqFT8Dg8liSWOzLPvlLMva8+ea8v/uVCyQCn/GSZpYNK2DJaY/UYN/sLdR8a+c3ysxjw9Iaij6ynpHlmXniqZxOP/vpRQ//6R4i/I9+e93Kq73FwsyTZKuKbF8P8mfL94Ol6JJ8XZid9E8jhjzmJb/93Dhg1n8gNpxx3wbVXq/HVIsRBoc0yilvcRjvZJGFcy3kv1eieL1aSzzuBTXs7HosQuWvaAIHiWHvLD7huI3/H4uy7Kh9MH2l7stWZatK/op9QHoLyhelI4ovg1SaOBcqsp+CSH8hmLx8biktyhe9Af+IPIcM5Weg6WyX83z789/v0/xTvw3HPMvpaPEY4Xnb6HDZX6/lPH4cpU71w8VPa8yOUvxuFY8NlzqOG4ptZyDHTcDzxcqtey13gUIIbxZ8a7g57Ms+7j3dR5X69teW8oMHtKLF887VfpkKL64lqqgj2nwk6BT8RbaX+nCguPFiV74FeGGEMKIogJooOpuHWQ+JWVZ1h1C+KribcmPK77nvjvLsicLYscV3+t9e5nJ7K10viUcV7x9eluZ59vKPD5w8E8pfDD/a8NzorVLmlri8amK+7PUfq+GSvb7GcXPTxUrPrn/7aVFvw+c9OXW85lBl7QC+TdG/lHxrbKfzbJss/ESVFkIYYzi19G3KH4j6E8UP2844Fj+3xmKby1drncqvuX0kYJlmFvB6ys9By8aZ7MsOxdC+Jyk+0MID+TL9Knsynzbdori56oKf5deHI8HvoI+suh11fijsVjhuV749f2pRc8PqOSuj4d3HK90m5RaznaVvrNYbl0vWQjhZxTv0n9VLxbYVfNy7PD8XcUL1OwSf22ty7Jsj2Maj0l6TQhhaaknsyzrVvww8VLF97cvmk/RS2oUP1hY6J2Kt5kHTraBany0Y/mkePGdH0L4OcVeHMW3TL+j+B7+qTLb4VjxBC/BdxT/ephQZh7lip8Dip/5KS7M3ipfQf0Dxbf95gw8kLcpeIekZ7MsO1nherhUuN9bJC0MIfzbQJE32fI2D9ym+NfoOwsfDCHconhHb82lr8kF0xum+Nba7YqfhxuqXyEe6j6jWNj8guLXcT+Yn9sDHlcc195X4XR7VXpMGaP4132hUm91lnt9tc7Bz0qqV7xI1Ur6P87XXa7iseeditv3qfz3lvy/1xfl7i4xrbPyj9ul/LBgGQq9O//vmsuYtod3HK9km5TzA0kzQwi3Fj3+i4p3mp6vdOFLCSG8VvEt/O8pfpOs6v3KXnZdlbMs2xVC+FNJfxlCWKS4sc8oFgI/K+lzhe8Ll/FpxZ3xeAjhE4rvM05SHJjuy7KsS9KHFQ/afw4hfF7xbsYkxW8D1WRZ9tsF0+uS9EAIYZLip9ffpfge/nsL3rsd2OkfCSH8P0l9JYqoQt9TrMg/r3ji/W3R8wNNtL4XQviU4jc+Rip+4v7nFS90p43tMKgsy9aEEL6i+F7xnyu+pdav+MG8uyT9VpZl20u8rj+E8PuSPhdCeFDx/fZmxfdlPYPmpxU/EPfdEMLH89fcL2mhKjsRL4V3vz+seKH6mxA7Vs/NX3vCM5Msy/pCCB+T9NkQwpcUi9sZiq0ZdujSm9YV+yvFJnx/JKk7hFD4WbADvP1VFa/Oz/1i67IsOx9CeKviN/nek2XZbkl/EUK4U9IXQghLsiw7ko9rn5b04bz79tcVP0v4GkkvZFn292Xm/bzinZV3KN5V6MqybJviBe+3Qgi/q3je3q74TcFSr28MIfy64rfPzuR3BqtyDmZZ1hpC+LriRxm+kWXZfu9rL9NdIYRPKv9DV/EO+hcHPmeVZdnBEMIPJP1OCOGY4oX5lxTfFi72vKS7QwjfUbzj1TbIH34XybJsSz6Ors7vfv9YsYnj70n6ykt9J9Y7jle4Tcp5SLHFyT+FED6q+IfwuxWvze/PPzd2WUIIixU/K3RM0iclrYhthqKq/YF3KZ+SvtQfOfpmFGTfo9h3oluxl8NWxU+5zyzIlP2UvuL7oH+teHE7q3in4gu6sM/PtYoXuSOKfyEdUByU7irIPKSL+/y0qODbOnmuRvFCdETxwBuoi+ao6JsNBa/5ZP7cj8uswyjFb1sM9G5oz5dhtYq+VVbitea3vfLHhikezAO9aE7k//+A8r4l5dYhf12LXuzz8zpV1ufn0Xx+Z1S6x0il3/a66FsxpZbHs9/z3PsVC5UexQFtRfH0ZBzTerHPT6/i7emyfX5KvPaib5CUWb9y30ga9LX8mMfUewfZtpli0TwrPy+/VPTayYpjz7dV8M0exc/FbCo4n9dIem3+3EXnmeLbCd9W/AMs04t9fkYrfrj6aP7cNxUL9Av2u+JXk7+ieFHPdHGfH+scXK0S32Ityrwrz9zt3K6l1vMhlf5W2hoVfOuyYJ+sVLwzcCrfjhf0+cmzMxU/f9Sp+JmUP1YsUou/2XSr4tvQZ6zzRmXGJMU/TD+hOB6ey/9brs/Przm306o8f0eZ47JwHcxxvMJtslclxqT8uWmK45inz09xW5vVKroGVXreVev8HviqHMrI/+q/I8uymVd7WQDg5SaE8GXFAmJe9hL/cyoh/ntgDyq2EXjJu27jletl97YXAODlL3+L9dWKnxP68Etd+ADVRPEDALgU/6r4ttMXFL92DwwZvO0FAACS8nL8qjsAAMBLhuIHAAAkpaLP/IwdOzarr68fNON5G23YsOrUXP399ufrCvsDlFNTU1OVeUm+9R8xYoSZOX/ebpLqWe6+vstuuyBJGj7cPlQ82+jcueK+bBfzbMORI4ublF7Ms+6ejGc7S75jzcOz/p55VeNcbG9vV3d3d3VW7Cqrq6vLGhou9V9OqYxnjKvmsWfxjl8ennXzzM8zpniOYc+8PNvRc055xi/PdDzr7rkGVHO/epa7Wtfuao1xnkxLS8uxLMsmFz9eUfFTX1+v++67b9CMZ4eNGmX/0zOejdzd3W1mPIWGVdBJ0qlTp8yM5BvQpk4t1VX+Qu3tdpfwcePsZsOdnZ1mxmPy5IuOnYucOXPGzBw6VPzv5F3s7NmzZmb2bPvfxvOse1dXl5mpq6szM5LvWPPwrL+n+PNMZ8yYMYM+/5nPfMacxlDR0NCgj3zkI4NmPOOX58JVW2v/80WeMcVzjnt4zk3Jt/7WMeOdX2NjuX8p5kWe8dRzHZgwYYKZ8ZxTbW1270PPONDU1GRmjh49amZOn7b73HoLFs9ye47rahWRnoLVs8zve9/7Wko9ztteAAAgKRQ/AAAgKRQ/AAAgKRQ/AAAgKRQ/AAAgKRQ/AAAgKRV91b2mpsb8Wrjna4fV4vkaqOfrctX6SrTk+xqopzfDxIkTzYzna46er2l7vnbo+eq956vVnjYHnq+l7t+/38yMHj3azMyaNcvM7Nu3z8xI0vjx481MtXozeb5K7GnhYE3nlfTP3wwbNsw8Pz3nQm9vr5nx7GfPWFGtvjInT540M5JvbPK0vfB8BdkzpnjWzfP1a891qaenx8x41sszdm/dutXMeL56P23aNDOzfft2MyNJ06dPNzPV+mq9Z4zzjKfe63Ip3PkBAABJofgBAABJofgBAABJofgBAABJofgBAABJofgBAABJofgBAABJofgBAABJqajJYX9/v06dOjVoxtMAzNPEztOUytMwz9O4atKkSWbG07hKko4ePWpmPE3zZs+ebWY8zb08Tcs8Ddk8zcY827qjo8PMnD9/3sx41t3ToO+5554zM56mXZKv4dbUqVPNjGd/eJbJ0yAvJVmWuRpxWjyNQz3N4DzNAj3NCadMmWJmPA3zJF/jQc/Y3NjYaGaamprMjOcc9mwjz3Q8487YsWPNzPHjx81MQ0ODmfGs19q1a82MZ6yUpJaWFjMzc+ZMM+NpBOlpUOypJYYPr6iEuQB3fgAAQFIofgAAQFIofgAAQFIofgAAQFIofgAAQFIofgAAQFIofgAAQFIofgAAQFIq7hDkacBm8TRvmjFjhpmpr683M3v37jUznsaEVnPHAZ7t42k+52lM5Wk86Gla5lkeT+Muz7ymTZtmZjzb2tOQrK2tzcw8/fTTZmbx4sVmRpLmzZtnZjxNJz0NLg8cOGBmPI0Qrf3a19dnTmOoCCFcsfHLc/7Onz/fzDz77LNm5uDBg2bG01hVksaPH29mWltbzcysWbOqMq/Nmzebmc7OTjPj4dlGnsaUnnPGMx1PI8Q1a9aYGU8TTMk37niaZc6dO9fM7Nq1y8x4Ggt7j+tSuPMDAACSQvEDAACSQvEDAACSQvEDAACSQvEDAACSQvEDAACSQvEDAACSQvEDAACSUlGTwyzLdObMmUEzkyZNsmc63J6tp4Hhjh07zMzZs2fNjKdh3u7du82M5Gso5Vm3PXv2mBlP872mpiYz4+HZjp6mixs2bDAzvb29Zsaz7mPHjjUzb37zm82Mp2Gd5NvWnsZ2nmOtpaXFzKxatcrMWPvMc64OFf39/eru7h40U1dXZ07HM8aNGjXKzGzbts3MeM6Frq4uM+NpiilJEyZMMDOe88EzNnua2DU3N5sZz3jqaWTrGVOeeuopM3PixAkz4xmbOjo6zMztt99uZrxNID0NDBcuXGhmxowZY2Y858f06dPNzLFjx8xMOdz5AQAASaH4AQAASaH4AQAASaH4AQAASaH4AQAASaH4AQAASaH4AQAASaH4AQAASamog1kIQaNHjx4042k65GkqOGyYXZd5mm2dO3euKsszefJkMyNJc+fONTOehlueJnanT582M9ddd52ZmTp1qpnZuXOnmTl06JCZ8TT5a2xsNDP79+83M8uXLzczNTU1ZsZzLErSunXrzExfX5+ZWbFihWt+Fk+DvCzLqjKvoSCEYDZy8zSE8zSxmzVrlplpbW01M2984xvNTHt7u5lpa2szM5I0e/ZsM3PkyBEzs3nzZjPjaSroaRrracC6b98+M7N3714z42nM6GnO5xlPV65caWZOnTplZjzXJEn6yU9+YmY82/Hee+81M57t6DnPPA0Vy+HODwAASArFDwAASArFDwAASArFDwAASArFDwAASArFDwAASArFDwAASArFDwAASEpFTQ4luymap7HaiBEjzIyngeG2bdvMjKdxlafpoKeBnySzCaTkW/8ZM2aYme7ubjPjaUhWrYaKngZxniaYnkaInu3jaXA5fLh9CnR1dZkZyddwy9OQzdMA7cyZM2bG02zNOl9DCOY0hhJrfXp6esxpeMY4z7npOaeefPLJqkzHM1ZKvsagCxYsMDObNm0yM55t7TmnPI1KOzo6zIxnn3mmM2HCBDMzZ86cqszLcy3xampqMjOebeRphOjZ955GiJeDOz8AACApFD8AACApFD8AACApFD8AACApFD8AACApFD8AACApFD8AACApFD8AACApFTU5zLLMbNI2efJkczqnTp0yM56mgidPnjQz58+fNzOeZnh33XWXmZGkgwcPmpkTJ06YmalTp5qZRYsWmZnZs2ebGU/TtkcffbQq8/I0nTx+/LiZ8TRv9DTt8hxD3mZbnuNo/fr1ZmblypVmxtPYzdOg0GrI5pnPUJFlmTke1NfXm9PxNGjbv39/VTIjR440M57zd8WKFWZGkg4fPmxmnn76aTMzduxYM7Nq1Soz42ni55mXZxt5xgvPPvM0OdyxY0dVpuPZXzfddJOZkXzXZc8Y5xkzPGNqX1+fmWloaDAz5XDnBwAAJIXiBwAAJIXiBwAAJIXiBwAAJIXiBwAAJIXiBwAAJIXiBwAAJIXiBwAAJIXiBwAAJKWiDs9S7JI6GE/3U0/XTms+knTs2DEzM3r0aDPT3NxsZqzO1gOWL19uZo4ePWpmOjo6zIynC7anS6inW7JnG3k6V8+YMcPMrF271sx4ukl7jrM5c+aYGW8X0c7OTjMzd+5cMzN+/HgzM2yY/XeLZ3mszreeDulDRQhBw4cPPuR5xi/Peec59g4cOGBmPB3zly1bZmZaW1vNjOTrcuzpLO8Zv+rq6szMnj17zIynE7Bn3PF0lveM754O2B6efe/ppjxmzBjX/DzH7MyZM6syP8+8PN2rT58+bWbK4c4PAABICsUPAABICsUPAABICsUPAABICsUPAABICsUPAABICsUPAABICsUPAABISsVNDi2jRo0yM+3t7WbG07zIatDmzYwbN87MeJp2SVJtba2ZmThxopm5/fbbzcyWLVvMTH19vZnp7u42M42NjWbG09zq2WefNTOexowtLS1mxtN08cYbbzQz1113nZmRpGuuucbMeI7r6dOnmxlPMz5PEz2rQVwIwZzGUJFlmTkeeJqr7tq1y8x49k+1xi9Pcz5Ps1fJt789je6WLl1qZnbu3Glmzp07Z2Y8Y7OnuainoaenAaunMaNnXp519zR79TYCnDp1qpnxjKldXV1mxtNc1rPcnmavZV97ya8EAAAYgih+AABAUih+AABAUih+AABAUih+AABAUih+AABAUih+AABAUih+AABAUipucmg1AZs0aZI5jcOHD1c625I8TaDOnj1rZubNm2dmPM0CJV9jppEjR5oZTzMpT6Oo4cPtXbxs2TIzM3bsWDOzceNGM+NpBOhZ5k2bNpmZpqYmM+NpavfUU0+ZGUm6+eabzYynoeTevXvNjKcR5Pjx483MmTNnzMwrRZZlZnM5z3HuaTzoaRi3f/9+M9PZ2WlmqjWeSNILL7xgZjwNHD3j5YgRI8yMp3Hq5MmTzYynGV5NTY2ZWbJkiZnxnFOexpSejGe9Dh48aGYk6ZZbbnHlLJ4xznMOeY5rz7FYDnd+AABAUih+AABAUih+AABAUih+AABAUih+AABAUih+AABAUih+AABAUih+AABAUipucmg1VfI0XVqwYIGZ8TTbamhoMDOeRlqeRnfeZnAzZswwM54GaEePHjUzjY2NZsbTtO3IkSNmxrONPI3U2trazMzJkyfNzMKFC81Me3u7menr6zMznn0q+fbZoUOHzMy+ffvMzOtf/3oz49lGra2tgz7v2e9DRQjBbJzmabDpaXTnOYZvvPFGMzN37lwz4xmbPOeCJC1dutTMeBqVbt261cyMGjXKzKxYscLMVKspqGcs8GRqa2vNzHXXXWdmfvjDH5oZjxtuuMGV27Fjh5nx7LMnn3zSzHiuy559VldXZ2bK4c4PAABICsUPAABICsUPAABICsUPAABICsUPAABICsUPAABICsUPAABICsUPAABISkVNDkMIZnMiT5NDT1M9T1Muq0GbJM2fP9/MeJoF9vf3mxlJ6unpMTOeZoCzZs0yM7t37zYzx44dMzOexl2ebe1pSuVp2vbMM89UZV6eRoCe9fLsC8nXbM7T3Ot1r3udmfE0MPQ0uJw5c+agz1tNAYcSz/jV1NRkTsfTqNIzDnoyx48fNzP19fVmxnPeeZfp6aefNjPTpk0zM55j2NM41HOcd3R0mJmamhoz49nW58+fNzOHDx82M+9+97vNzBrTufkAABCsSURBVGOPPWZmvE1aPddBz7XbM78pU6aYme7ubjPjGU/L4c4PAABICsUPAABICsUPAABICsUPAABICsUPAABICsUPAABICsUPAABICsUPAABISsVNDocPH/wldXV15nSq1QDM0+jO06CutrbWzGzfvt3MSNINN9xgZjzN8E6ePGlmfuqnfsrMtLW1mZlHH33UzDQ3N5uZLVu2mJklS5aYmQULFpgZTyOxrq4uM7Ns2TIz09vba2YkadeuXWbG07jLOsck3/7wNLbbsGHDoM97m3sOBVmW6dy5c4NmPOvraazW2dlpZjwNFT1jnKeRq6cxo+QbdydOnGhmQghmxnOee5bn4YcfNjNZlpmZtWvXmhnPeOE5Nz3XyQMHDpiZu+66y8ycPXvWzEjSzp07zUxDQ4OZ8TTx9TTW9YxfmzdvNjPlcOcHAAAkheIHAAAkheIHAAAkheIHAAAkheIHAAAkheIHAAAkheIHAAAkheIHAAAkpaImh319fWbjOE9zvmuuucbMeBoueZr8jRs3zsx4GmB55iVJGzduNDOLFi0yM6dOnTIznoZ5nv3x9re/3cy0tLSYmenTp5sZTwMsz7p7Gs319PSYGY9rr73WlZszZ46Z8TQc6+joMDOeZnyexnZW0zJPw8Whoq+vz9y29fX15nQ8TQU9TQ49zQI9x9TYsWPNzMKFC82MJD311FNmxtN8bunSpWampqbGzHjG5rvvvtvMrFu3zszceuutZsbTyPX48eNm5vrrrzcznnU/ffq0mfE2afUcj54Gjq2trWbG0+jXw7M85XDnBwAAJIXiBwAAJIXiBwAAJIXiBwAAJIXiBwAAJIXiBwAAJIXiBwAAJIXiBwAAJKWiDmbDhg3T6NGjB5+goyna4cOHzYynAZanwdO5c+eqMq9JkyaZGUlavHixmTlw4ICZmTZtmpnxNAwcM2aMmfE01fM0i/Q08Dty5IiZ8TT3ampqqsryjB8/3sx4mklKvuZv+/btMzOeBo47duwwMyNHjjQz1v7wnD9DxbBhw1RXV3fZ0/Fsk8bGRjPjacLpOfbOnz9vZhYsWGBmJN8x7Bkv2tvbzYznHPaMX56Gn55mkZ7zbtOmTWbGukZK0rFjx8yM57pkNR2WfE0wJWn58uVmxtPA0NMU1jOdCRMmmJnLGZ+48wMAAJJC8QMAAJJC8QMAAJJC8QMAAJJC8QMAAJJC8QMAAJJC8QMAAJJC8QMAAJJSUZPDEILZxLCtrc2cTrUaD546dcrMeBpOeRouNTQ0mBnJ15zw6NGjZsbTTKuzs9PMeBqpzZs3z8y0tLSYmRBCVeblaaLmaVbnaZZ4/PhxM7Nnzx4zI/kayXnWzdNsrbm52cx4msi98MILZuaVoqamxjyPt23bZk7H0zzScy54plOtpnrz5883M5LvGN65c6eZWb9+vZmpra01M55Gtn19fWbGs189Y/zSpUvNjKeJrcehQ4fMzIwZM8yMp6GiJJ08edLMeBpqetbf0wjRM349++yzZqYc7vwAAICkUPwAAICkUPwAAICkUPwAAICkUPwAAICkUPwAAICkUPwAAICkUPwAAICkVNTksL+/X2fOnBk0c/3115vT8TRT8jSDGz9+vJk5e/asmfE0ivI0JpR8jRc9jaK+9a1vmZkPfehDZsbTnNDTBMuzHadMmWJmuru7zUx9fb2Z8TQk8zQ5nDlzppnxNKyTpFGjRpmZ7du3m5np06ebmeXLl5sZT4O4sWPHDvq8p9noUBFCMPelp/maZ/yymsFKvgabnqagjY2NZsbTEFWSDh48aGba29vNjKdB3z333GNm1q1bZ2Y8TXM9Y1N/f39V5jV37lwz4zk+PM0bPePyuHHjzIzkO649Y8qWLVvMjOc88zR7vRzc+QEAAEmh+AEAAEmh+AEAAEmh+AEAAEmh+AEAAEmh+AEAAEmh+AEAAEmh+AEAAEmpqMlhCMFsejZx4kRzOhMmTDAzU6dONTNPPvmkmTly5EhV5tXc3GxmJGnfvn1mxtMoytPob8+ePWbG06Cvt7fXzHga73kaBu7fv9/MzJkzx8x4mmAuWLDAzHi2oaf5mSTt3LnTzJw4ccLMeJp39vT0mBlPk8fDhw8P+rynqdtQ0d/fbx7rnmPY08TOc7488sgjZsYzVixevNjMeMZlyTfuPP7442bGc+x5mjwuWrTIzGzatMnMeM6XV73qVWbG01TQ04B19+7dZsbT4HL9+vVmxrMvJN/45Wmo2dXVVZXpWA2VpctrhMidHwAAkBSKHwAAkBSKHwAAkBSKHwAAkBSKHwAAkBSKHwAAkBSKHwAAkBSKHwAAkJSKmhxKdtM8TzMpT5OwjRs3mpm2tjYzM3r0aDPjaWK3du1aMyP5mmB5mkmdP3/ezDz22GNmxrON3vKWt5gZTyOx9vZ2M2M1yZR8+94znWHD7Nq+r6/PzHiaukm+xl2eZnN1dXVmZuTIkWbm4MGDZsZq+udt8DgU9Pf3mw3YPE0dPU1RPc1OPTzHsKdZoGdckqQXXnjBzHjOmcmTJ5uZ73//+2amtbXVzMyaNcvMeBrresblvXv3mhlPY1lPcz5Ps1dPE8yvf/3rZkbyNbv1NJ30jHGe69vmzZvNjOeaUw53fgAAQFIofgAAQFIofgAAQFIofgAAQFIofgAAQFIofgAAQFIofgAAQFIofgAAQFIqanLY399vNjH0NEU7ceKEmfE0Eps/f76Z8fA0yfI09pKkbdu2mZlDhw6ZmTvvvNPMfO1rXzMz06ZNMzOeRmLNzc1mZtKkSWbGs+/Hjx9vZqp1nO3Zs8fMeLah5GsS1tTUVJWM1axP8jUSGzVq1KDPe5rsDRUhBLPpqad5ZJZlZmbmzJlmxtPobv/+/WZm9uzZZsZzTEm+JrWe5b722mvNzDe+8Q0z4xkLzpw5Y2ZuuukmM+NpcDllyhQz42ly6JnX+vXrzYznWuLZF5L04x//2JWzzJs3z8x0d3ebmfr6ejPj2dblvHJGNgAAAAeKHwAAkBSKHwAAkBSKHwAAkBSKHwAAkBSKHwAAkBSKHwAAkBSKHwAAkJSKmhyGEMymZ0eOHDGn42kYOG7cODOzfPlyM7Nx40Yzs3v3bjPjbaY0Y8YMM3Pw4EEzc/ToUTOzbNkyM7Nu3Toz09bWZmaGD7cPFU+TP0/TvI6ODjPjWWZPk0NPg7TFixebGcnXuOz55583MxMnTqzKvDzb6OzZs4M+72no90py+PBhM+NpMOk5ZhYuXGhmPOfCsWPHqjIdSZo+fbqZ8YyX3/72t82Mp/GiZ7k95/Bjjz1mZjyNXLds2WJmPOOg5/z17FfPtWTy5MlmxsvTxNdzXWpsbDQzBw4cMDNjx441M+Vw5wcAACSF4gcAACSF4gcAACSF4gcAACSF4gcAACSF4gcAACSF4gcAACSF4gcAACSF4gcAACSl4g7Po0aNGjRTre7N+/fvNzOeDqGTJk0yM1u3bjUztbW1ZkaS+vv7zYyn++tzzz1nZo4fP25mGhoazIynE7Jn/T0dOW+88UYz4+myO3LkSDNjdS+WpFtuucXMeDqtVlNLS4uZue2228yMp1O01ZHd29l8KAghqKamZtCMZ/zyjDueLsie7rQTJkwwM9XqSi351t+z3LNnzzYznvPKM6ZY1yTJN154lsfTwd/Tnd+T2bVrl5lZsWKFmfFcSyTp/PnzZsZzPdm8ebOZedOb3mRmPP8awMmTJ81M2elf8isBAACGIIofAACQFIofAACQFIofAACQFIofAACQFIofAACQFIofAACQFIofAACQlIqaHHr09PSYGU8DME9Trte85jVm5uDBg2ZmypQpZsbTtEvyNdzq6OgwM729vWZm8uTJZqa7u9vMtLW1mZlFixaZGc8yjx492sx4Gq15GmDNmzfPzHiaYHZ2dpoZyddUsK6uzjUtyzPPPGNmhg+3T2/Ptn4lsY4bqwmiJO3Zs8fMePZzfX29mfE0e73mmmvMzKxZs8yMJD3xxBNmZvr06WbG0+hu/PjxZmbVqlVmZs2aNWbGs60947KnOWFjY2NV5uUZmzzXAE/zQklasmSJmfE08fU0Md63b5+Z8VxPPNe3crjzAwAAkkLxAwAAkkLxAwAAkkLxAwAAkkLxAwAAkkLxAwAAkkLxAwAAkkLxAwAAklJxk8MQwqDPnzp1ypzG8ePHzYyn2dj27dvNjKcBWHNzs5nZsGGDmZGk1772tWbmVa96lZm54YYbzMzJkyfNzAMPPGBmPA3ZTp8+bWY8jbumTp1qZjz73rPuniZqnmaJ119/vZmRfA23amtrzYynOaGn2djevXvNTJZlgz7vbZA2VFhNHT1jk2ebeMZBz/jlOYY9x9T69evNjOQ71j2NSj1NBT3n+f33329mrGuS5NsfnsZ7nvHd0xR13bp1ZsZzDfBs57e97W1mRpLOnDnjylk81wrPuOtpUOy5DpRdhkt+JQAAwBBE8QMAAJJC8QMAAJJC8QMAAJJC8QMAAJJC8QMAAJJC8QMAAJJC8QMAAJJSUZPDvr4+tbe3D5qZMGGCPVNHEzdPwzxPUyZPw6U5c+aYGU9jQsnXlMzTeNHTBGrr1q1mZvny5WbG0wxv27ZtZsbTtOz55583M729vWbG0yzx6NGjZsbTsK2hocHMSNLkyZPNTE9Pj5lpbW01MwcOHDAznnWzeI7DV5IxY8aYGU8TuxMnTpiZrq4uM7Nnzx4zM2/ePDPjZTW9lHzbaMWKFWZm06ZNZub1r3+9mTl06FBVMp4Glw8++KCZ8TTB9GznXbt2mRlPI0RPE1vJN855mio+99xzZqalpcXMnDt3zsx4aoly0hrZAABA8ih+AABAUih+AABAUih+AABAUih+AABAUih+AABAUih+AABAUih+AABAUirqEFRTU2M2MfQ0b/I0gWpubjYznmZbTU1NZsbT3MnTvFCSRo0aZWaeeeYZ17QsnuaEngZobW1tZqa2ttbMeJoKjhgxwsx4jo/+/n4z4+Fppuk5piVfk8NTp06ZGc+x71kmT9M2bwPHV4Isy9TX1zdoxnPseY7hxsZGM9Pd3W1mpk2bZmY856bnmPLasGGDmfEce54mtbNmzTIz69atMzOeZpGe/Tpu3Dgz4znHZ8yYYWY8+9XTvNHTEFaSFi9ebGY8TYOXLFliZjzjrmeMv5wmrNz5AQAASaH4AQAASaH4AQAASaH4AQAASaH4AQAASaH4AQAASaH4AQAASaH4AQAASamoyWF/f796enoGzXiaAY4cOdLMtLa2mpmTJ0+ameeff97MeBoleZsc9vb2mpnRo0e7pmXZtGmTmfE05fI001q4cKGZmTRpkpnxNACrlunTp5sZTxNM65gf0N7ebmY8jd08x6OnyaFnv547d+6y5zNUZFlmNjH0nOc1NTVmplrH+ZEjR8xMCMHM1NfXu+bnOT6tY0bybSNPgz7P8txwww1m5qabbjIznvP34MGDZqazs9PMeMYdz5jraWLr2ReSb/09x5qnWaSngaFn33vmVQ53fgAAQFIofgAAQFIofgAAQFIofgAAQFIofgAAQFIofgAAQFIofgAAQFIofgAAQFJCJU3MQghHJbW8dIsD4GXmmizLJl/thagGxi8gSSXHsIqKHwAAgKGOt70AAEBSKH4AAEBSKH4AAEBSKH4AAEBSKH4AAEBSKH4AAEBSKH4AAEBSKH4AAEBSKH4AAEBS/j990oRBWbYe9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for neuron in range(10):\n",
    "\n",
    "    opt_im = dream_image(neuron)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(opt_im.reshape(28,28), cmap='Greys')\n",
    "    plt.title(\"Perceptive field of neuron %d\"%neuron, fontsize=16)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(PF_34[neuron].reshape(28,28), cmap='Greys')\n",
    "    plt.title(\"Excitatory input for neuron %d\"%neuron, fontsize=16)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
